{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from os import path\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score\n",
    "import sklearn.preprocessing\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import src.lib.utility_classfier as uclf\n",
    "import src.lib.optimal_threhold_related as thres\n",
    "import src.lib.fairness_tests as fair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_path='/Users/lifuchen/Desktop/research/data.csv'\n",
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109490, 86)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df.Class.values\n",
    "X = df.drop(['GRID','Class', 'Race_B'], axis=1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def save_prediction(classifier, characteristic, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_white_scaled, y_val_white, X_test_white_scaled, y_test_white, X_val_black_scaled, y_val_black, X_test_black_scaled, y_test_black):\n",
    "    method_to_call = getattr(uclf, classifier)\n",
    "    y_val_score = method_to_call(X_train_scaled, y_train,X_val_scaled, y_val)\n",
    "    y_test_score = method_to_call(X_train_scaled, y_train,X_test_scaled, y_test)\n",
    "\n",
    "    y_val_score_white = method_to_call(X_train_scaled, y_train, X_val_white_scaled, y_val_white)\n",
    "    y_test_score_white = method_to_call(X_train_scaled, y_train,X_test_white_scaled, y_test_white)\n",
    "\n",
    "    y_val_score_black = method_to_call(X_train_scaled, y_train, X_val_black_scaled, y_val_black)\n",
    "    y_test_score_black = method_to_call(X_train_scaled, y_train,X_test_black_scaled, y_test_black)\n",
    "\n",
    "    my_dict = dict(val_score = y_val_score, test_score = y_test_score, val_1_score = y_val_score_white, test_1_score = y_test_score_white, val_2_score = y_val_score_black, test_2_score = y_test_score_black)\n",
    "    overall_prediction = pd.DataFrame.from_dict(my_dict, orient='index')\n",
    "    overall_prediction = overall_prediction.transpose()\n",
    "\n",
    "    result_path='/Users/lifuchen/Desktop/research/predictions/'\n",
    "    filename = str(classifier) + str(characteristic) + \"prediction.csv\"\n",
    "    overall_prediction.to_csv(path.join(result_path, filename), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_result (classifier, characteristic, records, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_white_scaled, y_val_white, X_test_white_scaled, y_test_white, X_val_black_scaled, y_val_black, X_test_black_scaled, y_test_black):\n",
    "    result_path='/Users/lifuchen/Desktop/research/predictions/'\n",
    "    filename = str(classifier) + characteristic + \"prediction.csv\"\n",
    "    prediction = pd.read_csv(path.join(result_path, filename))\n",
    "\n",
    "    y_val_score = prediction['val_score'][prediction['val_score'].notna()]\n",
    "    y_test_score = prediction['test_score'][prediction['test_score'].notna()]\n",
    "\n",
    "    y_val_score_white = prediction['val_1_score'][prediction['val_1_score'].notna()]\n",
    "    y_test_score_white = prediction['test_1_score'][prediction['test_1_score'].notna()]\n",
    "\n",
    "    y_val_score_black = prediction['val_2_score'][prediction['val_2_score'].notna()]\n",
    "    y_test_score_black = prediction['test_2_score'][prediction['test_2_score'].notna()]\n",
    "\n",
    "    threshold, ba_val, ba_test = balance_accuracy (y_val, y_val_score,y_test, y_test_score)\n",
    "    auroc = roc_auc_score(y_test, y_test_score)\n",
    "    precision, recall, tpr, tnr, pd_overall = thres.calculate_precision_metrics(y_test, y_test_score,threshold)\n",
    "\n",
    "    threshold_white, ba_val_white, ba_test_white = balance_accuracy (y_val_white, y_val_score_white,y_test_white, y_test_score_white)\n",
    "    precision_white, recall_white, tpr_white, tnr_white, pd_white = thres.calculate_precision_metrics(y_test_white, y_test_score_white,threshold_white)\n",
    "\n",
    "    threshold_black, ba_val_black, ba_test_black = balance_accuracy (y_val_black, y_val_score_black, y_test_black, y_test_score_black)\n",
    "    precision_black, recall_black, tpr_black, tnr_black, pd_black = thres.calculate_precision_metrics(y_test_black, y_test_score_black,threshold_black)\n",
    "\n",
    "    eod = fair.get_EOD(y_test_white, y_test_score_white,threshold_white, y_test_black, y_test_score_black, threshold_black)\n",
    "    sp = fair.get_SP(y_test_white, y_test_score_white,threshold_white, y_test_black, y_test_score_black, threshold_black)\n",
    "\n",
    "    records.append({\n",
    "        'auroc': auroc,\n",
    "        'overall threshold': threshold,\n",
    "        'white threshold': threshold_white,\n",
    "        'black threshold': threshold_black,\n",
    "        'overall ba validation': ba_val,\n",
    "        'overall ba test': ba_test,\n",
    "        'white ba validation': ba_val_white,\n",
    "        'white ba test': ba_test_white,\n",
    "        'black ba validation': ba_val_black,\n",
    "        'black ba test': ba_test_black,\n",
    "        'overall precision':precision,\n",
    "        'overall recall':recall,\n",
    "        'overall tpr':tpr,\n",
    "        'overall tnr':tnr,\n",
    "        'overall pd':pd_overall,\n",
    "        'white precision':precision_white,\n",
    "        'white recall':recall_white,\n",
    "        'white tpr':tpr_white,\n",
    "        'white tnr':tnr_white,\n",
    "        'white pd':pd_white,\n",
    "        'black precision':precision_black,\n",
    "        'black recall':recall_black,\n",
    "        'black tpr':tpr_black,\n",
    "        'black tnr':tnr_black,\n",
    "        'black pd':pd_black,\n",
    "        'eod': eod,\n",
    "        'di': sp,\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def balance_accuracy (y_val, y_val_score,y_test, y_test_score):\n",
    "    \n",
    "    threshold, _ = thres.get_optimal_threshold_Jvalue (y_val, y_val_score)\n",
    "    print (\"Optimal threshold by J value is \",threshold)\n",
    "\n",
    "    ba_val = thres.calculate_balanced_accuracy(y_val, y_val_score, threshold)\n",
    "    print (\"Balanced accuracy score of val is \", ba_val)\n",
    "\n",
    "    ba_test = thres.calculate_balanced_accuracy(y_test, y_test_score, threshold)\n",
    "    print (\"Balanced accuracy score of test is \",ba_test)\n",
    "\n",
    "    return threshold, ba_val, ba_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def fairness_metrics (X, y, attribute, random_state):\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, X_val_white, X_val_black, y_val_white, y_val_black, X_test_white, X_test_black, y_test_white, y_test_black \\\n",
    "        = fair.split_by_trait(X, y, attribute, random_state)\n",
    "    print(\"X train\", X_train.shape[0])\n",
    "    print(\"Y train\", y_train.shape[0])\n",
    "    print(X_val.shape[0], X_val_white.shape[0], X_val_black.shape[0])\n",
    "    print(y_val.shape[0], y_val_white.shape[0], y_val_black.shape[0])\n",
    "    print(X_test.shape[0], X_test_white.shape[0], X_test_black.shape[0])\n",
    "    print(y_test.shape[0], y_test_white.shape[0], y_test_black.shape[0])\n",
    "\n",
    "    max_abs_scaler = preprocessing.MaxAbsScaler()\n",
    "    X_train_scaled = max_abs_scaler.fit_transform(X_train)\n",
    "    X_test_scaled = max_abs_scaler.transform(X_test)\n",
    "    X_test_white_scaled = max_abs_scaler.transform(X_test_white)\n",
    "    X_test_black_scaled = max_abs_scaler.transform(X_test_black)\n",
    "    X_val_scaled = max_abs_scaler.transform(X_val)\n",
    "    X_val_white_scaled = max_abs_scaler.transform(X_val_white)\n",
    "    X_val_black_scaled = max_abs_scaler.transform(X_val_black)\n",
    "\n",
    "    characteristic = attribute + str(random_state)\n",
    "    save_prediction (\"logic_regression\", characteristic, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_white_scaled, y_val_white, X_test_white_scaled, y_test_white, X_val_black_scaled, y_val_black, X_test_black_scaled, y_test_black)\n",
    "    save_prediction (\"random_forest\", characteristic, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_white_scaled, y_val_white, X_test_white_scaled, y_test_white, X_val_black_scaled, y_val_black, X_test_black_scaled, y_test_black)\n",
    "    save_prediction (\"decision_tree\", characteristic, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_white_scaled, y_val_white, X_test_white_scaled, y_test_white, X_val_black_scaled, y_val_black, X_test_black_scaled, y_test_black)\n",
    "    save_prediction (\"gradiant_boosting\", characteristic, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_white_scaled, y_val_white, X_test_white_scaled, y_test_white, X_val_black_scaled, y_val_black, X_test_black_scaled, y_test_black)\n",
    "\n",
    "    get_result (\"logic_regression\", characteristic, records_lr, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_white_scaled, y_val_white, X_test_white_scaled, y_test_white, X_val_black_scaled, y_val_black, X_test_black_scaled, y_test_black)\n",
    "    get_result (\"random_forest\", characteristic, records_rf, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_white_scaled, y_val_white, X_test_white_scaled, y_test_white, X_val_black_scaled, y_val_black, X_test_black_scaled, y_test_black)\n",
    "    get_result (\"decision_tree\", characteristic, records_dt, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_white_scaled, y_val_white, X_test_white_scaled, y_test_white, X_val_black_scaled, y_val_black, X_test_black_scaled, y_test_black)\n",
    "    get_result (\"gradiant_boosting\", characteristic, records_gbt, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_white_scaled, y_val_white, X_test_white_scaled, y_test_white, X_val_black_scaled, y_val_black, X_test_black_scaled, y_test_black)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train 65694\n",
      "Y train 65694\n",
      "21898 18899 2999\n",
      "21898 18899 2999\n",
      "21898 18968 2930\n",
      "21898 18968 2930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25880760366778377\n",
      "0.2619702432901052\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19904\n",
      "           1       0.45      0.03      0.06      1994\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.51      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19821    83]\n",
      " [ 1926    68]]\n",
      "done in 0.554614s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25880760366778377\n",
      "0.26233596708062135\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19934\n",
      "           1       0.41      0.03      0.06      1964\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.66      0.51      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19841    93]\n",
      " [ 1900    64]]\n",
      "done in 0.514222s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25880760366778377\n",
      "0.26277255646844816\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17180\n",
      "           1       0.45      0.03      0.06      1719\n",
      "\n",
      "    accuracy                           0.91     18899\n",
      "   macro avg       0.68      0.51      0.51     18899\n",
      "weighted avg       0.87      0.91      0.87     18899\n",
      "\n",
      "Confusion_matrix\n",
      "[[17112    68]\n",
      " [ 1663    56]]\n",
      "done in 0.522433s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25880760366778377\n",
      "0.26277507724879745\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17260\n",
      "           1       0.40      0.03      0.06      1708\n",
      "\n",
      "    accuracy                           0.91     18968\n",
      "   macro avg       0.66      0.51      0.50     18968\n",
      "weighted avg       0.87      0.91      0.87     18968\n",
      "\n",
      "Confusion_matrix\n",
      "[[17181    79]\n",
      " [ 1655    53]]\n",
      "done in 0.531585s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25880760366778377\n",
      "0.25691425237396553\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95      2724\n",
      "           1       0.44      0.04      0.08       275\n",
      "\n",
      "    accuracy                           0.91      2999\n",
      "   macro avg       0.68      0.52      0.52      2999\n",
      "weighted avg       0.87      0.91      0.87      2999\n",
      "\n",
      "Confusion_matrix\n",
      "[[2709   15]\n",
      " [ 263   12]]\n",
      "done in 0.511643s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25880760366778377\n",
      "0.2594932907427493\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95      2674\n",
      "           1       0.44      0.04      0.08       256\n",
      "\n",
      "    accuracy                           0.91      2930\n",
      "   macro avg       0.68      0.52      0.52      2930\n",
      "weighted avg       0.87      0.91      0.88      2930\n",
      "\n",
      "Confusion_matrix\n",
      "[[2660   14]\n",
      " [ 245   11]]\n",
      "done in 0.510757s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19904\n",
      "           1       0.38      0.00      0.00      1994\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.65      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19896     8]\n",
      " [ 1989     5]]\n",
      "done in 17.584715s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19934\n",
      "           1       0.42      0.00      0.01      1964\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.66      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19927     7]\n",
      " [ 1959     5]]\n",
      "done in 17.109231s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17180\n",
      "           1       0.40      0.00      0.01      1719\n",
      "\n",
      "    accuracy                           0.91     18899\n",
      "   macro avg       0.65      0.50      0.48     18899\n",
      "weighted avg       0.86      0.91      0.87     18899\n",
      "\n",
      "Confusion_matrix\n",
      "[[17168    12]\n",
      " [ 1711     8]]\n",
      "done in 16.831591s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17260\n",
      "           1       0.54      0.00      0.01      1708\n",
      "\n",
      "    accuracy                           0.91     18968\n",
      "   macro avg       0.72      0.50      0.48     18968\n",
      "weighted avg       0.88      0.91      0.87     18968\n",
      "\n",
      "Confusion_matrix\n",
      "[[17254     6]\n",
      " [ 1701     7]]\n",
      "done in 17.506762s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2724\n",
      "           1       0.33      0.00      0.01       275\n",
      "\n",
      "    accuracy                           0.91      2999\n",
      "   macro avg       0.62      0.50      0.48      2999\n",
      "weighted avg       0.86      0.91      0.87      2999\n",
      "\n",
      "Confusion_matrix\n",
      "[[2722    2]\n",
      " [ 274    1]]\n",
      "done in 16.892070s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2674\n",
      "           1       0.00      0.00      0.00       256\n",
      "\n",
      "    accuracy                           0.91      2930\n",
      "   macro avg       0.46      0.50      0.48      2930\n",
      "weighted avg       0.83      0.91      0.87      2930\n",
      "\n",
      "Confusion_matrix\n",
      "[[2673    1]\n",
      " [ 256    0]]\n",
      "done in 16.907830s\n",
      "0.26448598669059525\n",
      "0.2722330649120758\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19904\n",
      "           1       0.00      0.00      0.00      1994\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.45      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19903     1]\n",
      " [ 1994     0]]\n",
      "done in 0.546402s\n",
      "0.26448598669059525\n",
      "0.2769244924266795\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19934\n",
      "           1       0.00      0.00      0.00      1964\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.46      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19931     3]\n",
      " [ 1964     0]]\n",
      "done in 0.543102s\n",
      "0.26448598669059525\n",
      "0.2712860393477675\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17180\n",
      "           1       0.00      0.00      0.00      1719\n",
      "\n",
      "    accuracy                           0.91     18899\n",
      "   macro avg       0.45      0.50      0.48     18899\n",
      "weighted avg       0.83      0.91      0.87     18899\n",
      "\n",
      "Confusion_matrix\n",
      "[[17180     0]\n",
      " [ 1719     0]]\n",
      "done in 0.546054s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26448598669059525\n",
      "0.2778694234760347\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17260\n",
      "           1       0.00      0.00      0.00      1708\n",
      "\n",
      "    accuracy                           0.91     18968\n",
      "   macro avg       0.45      0.50      0.48     18968\n",
      "weighted avg       0.83      0.91      0.87     18968\n",
      "\n",
      "Confusion_matrix\n",
      "[[17257     3]\n",
      " [ 1708     0]]\n",
      "done in 0.577810s\n",
      "0.26448598669059525\n",
      "0.27820099960359335\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2724\n",
      "           1       0.00      0.00      0.00       275\n",
      "\n",
      "    accuracy                           0.91      2999\n",
      "   macro avg       0.45      0.50      0.48      2999\n",
      "weighted avg       0.82      0.91      0.86      2999\n",
      "\n",
      "Confusion_matrix\n",
      "[[2723    1]\n",
      " [ 275    0]]\n",
      "done in 0.532821s\n",
      "0.26448598669059525\n",
      "0.270807273264847\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2674\n",
      "           1       0.00      0.00      0.00       256\n",
      "\n",
      "    accuracy                           0.91      2930\n",
      "   macro avg       0.46      0.50      0.48      2930\n",
      "weighted avg       0.83      0.91      0.87      2930\n",
      "\n",
      "Confusion_matrix\n",
      "[[2674    0]\n",
      " [ 256    0]]\n",
      "done in 0.537244s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19904\n",
      "           1       0.46      0.02      0.03      1994\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.51      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19864    40]\n",
      " [ 1960    34]]\n",
      "done in 30.482198s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19934\n",
      "           1       0.46      0.02      0.05      1964\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19878    56]\n",
      " [ 1917    47]]\n",
      "done in 30.226808s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17180\n",
      "           1       0.47      0.02      0.03      1719\n",
      "\n",
      "    accuracy                           0.91     18899\n",
      "   macro avg       0.69      0.51      0.49     18899\n",
      "weighted avg       0.87      0.91      0.87     18899\n",
      "\n",
      "Confusion_matrix\n",
      "[[17145    35]\n",
      " [ 1688    31]]\n",
      "done in 30.504662s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17260\n",
      "           1       0.44      0.02      0.04      1708\n",
      "\n",
      "    accuracy                           0.91     18968\n",
      "   macro avg       0.68      0.51      0.50     18968\n",
      "weighted avg       0.87      0.91      0.87     18968\n",
      "\n",
      "Confusion_matrix\n",
      "[[17210    50]\n",
      " [ 1668    40]]\n",
      "done in 30.558831s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2724\n",
      "           1       0.38      0.01      0.02       275\n",
      "\n",
      "    accuracy                           0.91      2999\n",
      "   macro avg       0.64      0.50      0.49      2999\n",
      "weighted avg       0.86      0.91      0.87      2999\n",
      "\n",
      "Confusion_matrix\n",
      "[[2719    5]\n",
      " [ 272    3]]\n",
      "done in 29.785765s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2674\n",
      "           1       0.54      0.03      0.05       256\n",
      "\n",
      "    accuracy                           0.91      2930\n",
      "   macro avg       0.73      0.51      0.50      2930\n",
      "weighted avg       0.88      0.91      0.88      2930\n",
      "\n",
      "Confusion_matrix\n",
      "[[2668    6]\n",
      " [ 249    7]]\n",
      "done in 29.960740s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41500000000000004\n",
      "threshold:0.2, J-value:0.26399999999999996\n",
      "threshold:0.30000000000000004, J-value:0.15\n",
      "threshold:0.4, J-value:0.07300000000000001\n",
      "threshold:0.5, J-value:0.030000000000000002\n",
      "threshold:0.6000000000000001, J-value:0.013000000000000001\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7073637260253429\n",
      "Balanced accuracy score of test is  0.700835312539527\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.40900000000000003\n",
      "threshold:0.2, J-value:0.257\n",
      "threshold:0.30000000000000004, J-value:0.15\n",
      "threshold:0.4, J-value:0.07\n",
      "threshold:0.5, J-value:0.029\n",
      "threshold:0.6000000000000001, J-value:0.012\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7044613682183851\n",
      "Balanced accuracy score of test is  0.7009158048417778\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.45199999999999996\n",
      "threshold:0.2, J-value:0.306\n",
      "threshold:0.30000000000000004, J-value:0.154\n",
      "threshold:0.4, J-value:0.085\n",
      "threshold:0.5, J-value:0.038\n",
      "threshold:0.6000000000000001, J-value:0.013\n",
      "threshold:0.7000000000000001, J-value:-0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7255766920304365\n",
      "Balanced accuracy score of test is  0.7001434531600599\n",
      "True positive rate of class 1 is  0.665\n",
      "True positive rate of class 2 is  0.652\n",
      "Positive prediction rate of class 1 is  0.299\n",
      "Positive prediction rate of class 2 is  0.287\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41000000000000003\n",
      "threshold:0.2, J-value:0.28200000000000003\n",
      "threshold:0.30000000000000004, J-value:0.11000000000000001\n",
      "threshold:0.4, J-value:0.029\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7049549472372101\n",
      "Balanced accuracy score of test is  0.6927976885841403\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.39299999999999996\n",
      "threshold:0.2, J-value:0.274\n",
      "threshold:0.30000000000000004, J-value:0.098\n",
      "threshold:0.4, J-value:0.022\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6961773197049208\n",
      "Balanced accuracy score of test is  0.6907924266148532\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.40900000000000003\n",
      "threshold:0.2, J-value:0.323\n",
      "threshold:0.30000000000000004, J-value:0.139\n",
      "threshold:0.4, J-value:0.032\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.704907221999733\n",
      "Balanced accuracy score of test is  0.6889900430067315\n",
      "True positive rate of class 1 is  0.734\n",
      "True positive rate of class 2 is  0.734\n",
      "Positive prediction rate of class 1 is  0.387\n",
      "Positive prediction rate of class 2 is  0.389\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.37899999999999995\n",
      "threshold:0.2, J-value:0.21299999999999997\n",
      "threshold:0.30000000000000004, J-value:0.08499999999999999\n",
      "threshold:0.4, J-value:0.028999999999999998\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.689387268517772\n",
      "Balanced accuracy score of test is  0.6746810298833401\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.374\n",
      "threshold:0.2, J-value:0.20599999999999996\n",
      "threshold:0.30000000000000004, J-value:0.088\n",
      "threshold:0.4, J-value:0.032\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6866057878087878\n",
      "Balanced accuracy score of test is  0.6737388093926475\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.4149999999999999\n",
      "threshold:0.2, J-value:0.263\n",
      "threshold:0.30000000000000004, J-value:0.063\n",
      "threshold:0.4, J-value:0.015\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7070377786677347\n",
      "Balanced accuracy score of test is  0.6798861724008975\n",
      "True positive rate of class 1 is  0.703\n",
      "True positive rate of class 2 is  0.641\n",
      "Positive prediction rate of class 1 is  0.386\n",
      "Positive prediction rate of class 2 is  0.312\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.42899999999999994\n",
      "threshold:0.2, J-value:0.27799999999999997\n",
      "threshold:0.30000000000000004, J-value:0.143\n",
      "threshold:0.4, J-value:0.060000000000000005\n",
      "threshold:0.5, J-value:0.015000000000000001\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7141743004334546\n",
      "Balanced accuracy score of test is  0.6986592670272183\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.42299999999999993\n",
      "threshold:0.2, J-value:0.26999999999999996\n",
      "threshold:0.30000000000000004, J-value:0.14\n",
      "threshold:0.4, J-value:0.056\n",
      "threshold:0.5, J-value:0.016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7110900495116892\n",
      "Balanced accuracy score of test is  0.6999248305974746\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.46699999999999997\n",
      "threshold:0.2, J-value:0.32699999999999996\n",
      "threshold:0.30000000000000004, J-value:0.164\n",
      "threshold:0.4, J-value:0.085\n",
      "threshold:0.5, J-value:0.009\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7335142170604725\n",
      "Balanced accuracy score of test is  0.6902536579094989\n",
      "True positive rate of class 1 is  0.674\n",
      "True positive rate of class 2 is  0.645\n",
      "Positive prediction rate of class 1 is  0.311\n",
      "Positive prediction rate of class 2 is  0.297\n",
      "X train 65694\n",
      "Y train 65694\n",
      "21898 18825 3073\n",
      "21898 18825 3073\n",
      "21898 18883 3015\n",
      "21898 18883 3015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2620886010458136\n",
      "0.25604140929807073\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.95     19980\n",
      "           1       0.49      0.04      0.07      1918\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.70      0.52      0.51     21898\n",
      "weighted avg       0.88      0.91      0.88     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19901    79]\n",
      " [ 1842    76]]\n",
      "done in 0.520531s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2620886010458136\n",
      "0.2579134535597028\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19972\n",
      "           1       0.44      0.03      0.06      1926\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.52      0.51     21898\n",
      "weighted avg       0.87      0.91      0.88     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19888    84]\n",
      " [ 1860    66]]\n",
      "done in 0.526739s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2620886010458136\n",
      "0.2555919075132823\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.95     17178\n",
      "           1       0.47      0.04      0.07      1647\n",
      "\n",
      "    accuracy                           0.91     18825\n",
      "   macro avg       0.69      0.52      0.51     18825\n",
      "weighted avg       0.88      0.91      0.88     18825\n",
      "\n",
      "Confusion_matrix\n",
      "[[17111    67]\n",
      " [ 1587    60]]\n",
      "done in 0.496659s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2620886010458136\n",
      "0.2606601132062545\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17196\n",
      "           1       0.45      0.04      0.07      1687\n",
      "\n",
      "    accuracy                           0.91     18883\n",
      "   macro avg       0.68      0.52      0.51     18883\n",
      "weighted avg       0.87      0.91      0.87     18883\n",
      "\n",
      "Confusion_matrix\n",
      "[[17124    72]\n",
      " [ 1627    60]]\n",
      "done in 0.525011s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2620886010458136\n",
      "0.25879502826931783\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.95      2802\n",
      "           1       0.57      0.06      0.11       271\n",
      "\n",
      "    accuracy                           0.91      3073\n",
      "   macro avg       0.74      0.53      0.53      3073\n",
      "weighted avg       0.89      0.91      0.88      3073\n",
      "\n",
      "Confusion_matrix\n",
      "[[2790   12]\n",
      " [ 255   16]]\n",
      "done in 0.487524s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2620886010458136\n",
      "0.24071107408844694\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2776\n",
      "           1       0.33      0.03      0.05       239\n",
      "\n",
      "    accuracy                           0.92      3015\n",
      "   macro avg       0.63      0.51      0.50      3015\n",
      "weighted avg       0.88      0.92      0.89      3015\n",
      "\n",
      "Confusion_matrix\n",
      "[[2764   12]\n",
      " [ 233    6]]\n",
      "done in 0.488679s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19980\n",
      "           1       0.83      0.00      0.01      1918\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.87      0.50      0.48     21898\n",
      "weighted avg       0.91      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19979     1]\n",
      " [ 1913     5]]\n",
      "done in 17.164409s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19972\n",
      "           1       0.45      0.00      0.01      1926\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19966     6]\n",
      " [ 1921     5]]\n",
      "done in 16.772022s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17178\n",
      "           1       0.67      0.00      0.00      1647\n",
      "\n",
      "    accuracy                           0.91     18825\n",
      "   macro avg       0.79      0.50      0.48     18825\n",
      "weighted avg       0.89      0.91      0.87     18825\n",
      "\n",
      "Confusion_matrix\n",
      "[[17176     2]\n",
      " [ 1643     4]]\n",
      "done in 16.641755s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17196\n",
      "           1       0.64      0.00      0.01      1687\n",
      "\n",
      "    accuracy                           0.91     18883\n",
      "   macro avg       0.77      0.50      0.48     18883\n",
      "weighted avg       0.89      0.91      0.87     18883\n",
      "\n",
      "Confusion_matrix\n",
      "[[17192     4]\n",
      " [ 1680     7]]\n",
      "done in 16.897504s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2802\n",
      "           1       0.25      0.00      0.01       271\n",
      "\n",
      "    accuracy                           0.91      3073\n",
      "   macro avg       0.58      0.50      0.48      3073\n",
      "weighted avg       0.85      0.91      0.87      3073\n",
      "\n",
      "Confusion_matrix\n",
      "[[2799    3]\n",
      " [ 270    1]]\n",
      "done in 16.930014s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2776\n",
      "           1       0.00      0.00      0.00       239\n",
      "\n",
      "    accuracy                           0.92      3015\n",
      "   macro avg       0.46      0.50      0.48      3015\n",
      "weighted avg       0.85      0.92      0.88      3015\n",
      "\n",
      "Confusion_matrix\n",
      "[[2774    2]\n",
      " [ 239    0]]\n",
      "done in 16.706320s\n",
      "0.26732574897465733\n",
      "0.2733186224889578\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19980\n",
      "           1       0.25      0.00      0.00      1918\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.58      0.50      0.48     21898\n",
      "weighted avg       0.85      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19974     6]\n",
      " [ 1916     2]]\n",
      "done in 0.548873s\n",
      "0.26732574897465733\n",
      "0.26671117932484617\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19972\n",
      "           1       0.20      0.00      0.00      1926\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.56      0.50      0.48     21898\n",
      "weighted avg       0.85      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19968     4]\n",
      " [ 1925     1]]\n",
      "done in 0.547091s\n",
      "0.26732574897465733\n",
      "0.2710635696483221\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17178\n",
      "           1       0.33      0.00      0.00      1647\n",
      "\n",
      "    accuracy                           0.91     18825\n",
      "   macro avg       0.62      0.50      0.48     18825\n",
      "weighted avg       0.86      0.91      0.87     18825\n",
      "\n",
      "Confusion_matrix\n",
      "[[17174     4]\n",
      " [ 1645     2]]\n",
      "done in 0.542657s\n",
      "0.26732574897465733\n",
      "0.2708907402588465\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17196\n",
      "           1       0.25      0.00      0.00      1687\n",
      "\n",
      "    accuracy                           0.91     18883\n",
      "   macro avg       0.58      0.50      0.48     18883\n",
      "weighted avg       0.85      0.91      0.87     18883\n",
      "\n",
      "Confusion_matrix\n",
      "[[17193     3]\n",
      " [ 1686     1]]\n",
      "done in 0.542471s\n",
      "0.26732574897465733\n",
      "0.28713293089278685\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2802\n",
      "           1       0.00      0.00      0.00       271\n",
      "\n",
      "    accuracy                           0.91      3073\n",
      "   macro avg       0.46      0.50      0.48      3073\n",
      "weighted avg       0.83      0.91      0.87      3073\n",
      "\n",
      "Confusion_matrix\n",
      "[[2800    2]\n",
      " [ 271    0]]\n",
      "done in 0.518902s\n",
      "0.26732574897465733\n",
      "0.24053451295113856\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2776\n",
      "           1       0.00      0.00      0.00       239\n",
      "\n",
      "    accuracy                           0.92      3015\n",
      "   macro avg       0.46      0.50      0.48      3015\n",
      "weighted avg       0.85      0.92      0.88      3015\n",
      "\n",
      "Confusion_matrix\n",
      "[[2775    1]\n",
      " [ 239    0]]\n",
      "done in 0.520998s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19980\n",
      "           1       0.46      0.02      0.04      1918\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.69      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19938    42]\n",
      " [ 1882    36]]\n",
      "done in 29.491685s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19972\n",
      "           1       0.44      0.02      0.04      1926\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19922    50]\n",
      " [ 1887    39]]\n",
      "done in 29.868090s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17178\n",
      "           1       0.47      0.02      0.04      1647\n",
      "\n",
      "    accuracy                           0.91     18825\n",
      "   macro avg       0.69      0.51      0.50     18825\n",
      "weighted avg       0.87      0.91      0.87     18825\n",
      "\n",
      "Confusion_matrix\n",
      "[[17143    35]\n",
      " [ 1616    31]]\n",
      "done in 29.630359s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17196\n",
      "           1       0.43      0.02      0.04      1687\n",
      "\n",
      "    accuracy                           0.91     18883\n",
      "   macro avg       0.67      0.51      0.49     18883\n",
      "weighted avg       0.87      0.91      0.87     18883\n",
      "\n",
      "Confusion_matrix\n",
      "[[17153    43]\n",
      " [ 1655    32]]\n",
      "done in 29.650699s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2802\n",
      "           1       0.38      0.02      0.04       271\n",
      "\n",
      "    accuracy                           0.91      3073\n",
      "   macro avg       0.65      0.51      0.49      3073\n",
      "weighted avg       0.87      0.91      0.87      3073\n",
      "\n",
      "Confusion_matrix\n",
      "[[2794    8]\n",
      " [ 266    5]]\n",
      "done in 30.001716s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2776\n",
      "           1       0.46      0.03      0.05       239\n",
      "\n",
      "    accuracy                           0.92      3015\n",
      "   macro avg       0.69      0.51      0.50      3015\n",
      "weighted avg       0.89      0.92      0.89      3015\n",
      "\n",
      "Confusion_matrix\n",
      "[[2769    7]\n",
      " [ 233    6]]\n",
      "done in 29.512711s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.406\n",
      "threshold:0.2, J-value:0.27499999999999997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.30000000000000004, J-value:0.155\n",
      "threshold:0.4, J-value:0.07200000000000001\n",
      "threshold:0.5, J-value:0.036000000000000004\n",
      "threshold:0.6000000000000001, J-value:0.013999999999999999\n",
      "threshold:0.7000000000000001, J-value:0.004\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7034173641837875\n",
      "Balanced accuracy score of test is  0.6987704125339338\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.406\n",
      "threshold:0.2, J-value:0.28099999999999997\n",
      "threshold:0.30000000000000004, J-value:0.155\n",
      "threshold:0.4, J-value:0.066\n",
      "threshold:0.5, J-value:0.032\n",
      "threshold:0.6000000000000001, J-value:0.012\n",
      "threshold:0.7000000000000001, J-value:0.003\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7025392647561872\n",
      "Balanced accuracy score of test is  0.7004324284896627\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41800000000000004\n",
      "threshold:0.2, J-value:0.243\n",
      "threshold:0.30000000000000004, J-value:0.151\n",
      "threshold:0.4, J-value:0.106\n",
      "threshold:0.5, J-value:0.05499999999999999\n",
      "threshold:0.6000000000000001, J-value:0.024999999999999998\n",
      "threshold:0.7000000000000001, J-value:0.006\n",
      "threshold:0.8, J-value:-0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7088558251749542\n",
      "Balanced accuracy score of test is  0.6851502116166062\n",
      "True positive rate of class 1 is  0.66\n",
      "True positive rate of class 2 is  0.598\n",
      "Positive prediction rate of class 1 is  0.295\n",
      "Positive prediction rate of class 2 is  0.257\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.399\n",
      "threshold:0.2, J-value:0.294\n",
      "threshold:0.30000000000000004, J-value:0.118\n",
      "threshold:0.4, J-value:0.023\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6993211146495818\n",
      "Balanced accuracy score of test is  0.695134793071671\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.386\n",
      "threshold:0.2, J-value:0.302\n",
      "threshold:0.30000000000000004, J-value:0.11500000000000002\n",
      "threshold:0.4, J-value:0.023\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6926343497348347\n",
      "Balanced accuracy score of test is  0.6907620436122432\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.40900000000000003\n",
      "threshold:0.2, J-value:0.301\n",
      "threshold:0.30000000000000004, J-value:0.121\n",
      "threshold:0.4, J-value:0.022\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7044849356416476\n",
      "Balanced accuracy score of test is  0.7062078726200668\n",
      "True positive rate of class 1 is  0.729\n",
      "True positive rate of class 2 is  0.741\n",
      "Positive prediction rate of class 1 is  0.382\n",
      "Positive prediction rate of class 2 is  0.361\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.35200000000000004\n",
      "threshold:0.2, J-value:0.21199999999999997\n",
      "threshold:0.30000000000000004, J-value:0.10800000000000001\n",
      "threshold:0.4, J-value:0.001\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.001\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6760591143802823\n",
      "Balanced accuracy score of test is  0.6841409489380668\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.3430000000000001\n",
      "threshold:0.2, J-value:0.21799999999999997\n",
      "threshold:0.30000000000000004, J-value:0.11499999999999999\n",
      "threshold:0.4, J-value:0.001\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.001\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6715745623717887\n",
      "Balanced accuracy score of test is  0.6788795673936385\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.40700000000000003\n",
      "threshold:0.2, J-value:0.174\n",
      "threshold:0.30000000000000004, J-value:0.06999999999999999\n",
      "threshold:0.4, J-value:-0.001\n",
      "threshold:0.5, J-value:-0.001\n",
      "threshold:0.6000000000000001, J-value:-0.001\n",
      "threshold:0.7000000000000001, J-value:-0.001\n",
      "threshold:0.8, J-value:-0.001\n",
      "threshold:0.9, J-value:-0.001\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7035696695296717\n",
      "Balanced accuracy score of test is  0.716918325636357\n",
      "True positive rate of class 1 is  0.699\n",
      "True positive rate of class 2 is  0.703\n",
      "Positive prediction rate of class 1 is  0.374\n",
      "Positive prediction rate of class 2 is  0.303\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41899999999999993\n",
      "threshold:0.2, J-value:0.27299999999999996\n",
      "threshold:0.30000000000000004, J-value:0.148\n",
      "threshold:0.4, J-value:0.059000000000000004\n",
      "threshold:0.5, J-value:0.017\n",
      "threshold:0.6000000000000001, J-value:0.006\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7093509567962122\n",
      "Balanced accuracy score of test is  0.7037857413670936\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.416\n",
      "threshold:0.2, J-value:0.276\n",
      "threshold:0.30000000000000004, J-value:0.149\n",
      "threshold:0.4, J-value:0.059000000000000004\n",
      "threshold:0.5, J-value:0.017\n",
      "threshold:0.6000000000000001, J-value:0.007\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7083581723647459\n",
      "Balanced accuracy score of test is  0.7027741491004442\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.42999999999999994\n",
      "threshold:0.2, J-value:0.248\n",
      "threshold:0.30000000000000004, J-value:0.134\n",
      "threshold:0.4, J-value:0.060000000000000005\n",
      "threshold:0.5, J-value:0.015\n",
      "threshold:0.6000000000000001, J-value:0.002\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7151112410481706\n",
      "Balanced accuracy score of test is  0.7092570207275752\n",
      "True positive rate of class 1 is  0.683\n",
      "True positive rate of class 2 is  0.665\n",
      "Positive prediction rate of class 1 is  0.314\n",
      "Positive prediction rate of class 2 is  0.28\n",
      "X train 65694\n",
      "Y train 65694\n",
      "21898 18936 2962\n",
      "21898 18936 2962\n",
      "21898 18829 3069\n",
      "21898 18829 3069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25945267743299616\n",
      "0.26016556622483566\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19950\n",
      "           1       0.46      0.03      0.06      1948\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.69      0.52      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19873    77]\n",
      " [ 1882    66]]\n",
      "done in 0.524424s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25945267743299616\n",
      "0.26243869330811537\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19883\n",
      "           1       0.50      0.03      0.05      2015\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.71      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19826    57]\n",
      " [ 1957    58]]\n",
      "done in 0.513772s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25945267743299616\n",
      "0.26292576969632264\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17239\n",
      "           1       0.44      0.03      0.06      1697\n",
      "\n",
      "    accuracy                           0.91     18936\n",
      "   macro avg       0.68      0.51      0.50     18936\n",
      "weighted avg       0.87      0.91      0.87     18936\n",
      "\n",
      "Confusion_matrix\n",
      "[[17175    64]\n",
      " [ 1647    50]]\n",
      "done in 0.512211s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25945267743299616\n",
      "0.263302347009054\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17079\n",
      "           1       0.53      0.03      0.05      1750\n",
      "\n",
      "    accuracy                           0.91     18829\n",
      "   macro avg       0.72      0.51      0.50     18829\n",
      "weighted avg       0.87      0.91      0.87     18829\n",
      "\n",
      "Confusion_matrix\n",
      "[[17037    42]\n",
      " [ 1703    47]]\n",
      "done in 0.510981s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25945267743299616\n",
      "0.24251964693514066\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2711\n",
      "           1       0.55      0.06      0.11       251\n",
      "\n",
      "    accuracy                           0.92      2962\n",
      "   macro avg       0.74      0.53      0.54      2962\n",
      "weighted avg       0.89      0.92      0.88      2962\n",
      "\n",
      "Confusion_matrix\n",
      "[[2698   13]\n",
      " [ 235   16]]\n",
      "done in 0.493766s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25945267743299616\n",
      "0.25713998508557556\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95      2804\n",
      "           1       0.42      0.04      0.08       265\n",
      "\n",
      "    accuracy                           0.91      3069\n",
      "   macro avg       0.67      0.52      0.51      3069\n",
      "weighted avg       0.87      0.91      0.88      3069\n",
      "\n",
      "Confusion_matrix\n",
      "[[2789   15]\n",
      " [ 254   11]]\n",
      "done in 0.493817s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19950\n",
      "           1       0.30      0.00      0.00      1948\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.61      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19943     7]\n",
      " [ 1945     3]]\n",
      "done in 16.744922s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19883\n",
      "           1       0.50      0.00      0.00      2015\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.70      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.86     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19878     5]\n",
      " [ 2010     5]]\n",
      "done in 16.687229s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17239\n",
      "           1       0.42      0.00      0.01      1697\n",
      "\n",
      "    accuracy                           0.91     18936\n",
      "   macro avg       0.66      0.50      0.48     18936\n",
      "weighted avg       0.87      0.91      0.87     18936\n",
      "\n",
      "Confusion_matrix\n",
      "[[17232     7]\n",
      " [ 1692     5]]\n",
      "done in 16.792244s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17079\n",
      "           1       0.50      0.00      0.00      1750\n",
      "\n",
      "    accuracy                           0.91     18829\n",
      "   macro avg       0.70      0.50      0.48     18829\n",
      "weighted avg       0.87      0.91      0.86     18829\n",
      "\n",
      "Confusion_matrix\n",
      "[[17076     3]\n",
      " [ 1747     3]]\n",
      "done in 16.731042s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2711\n",
      "           1       0.00      0.00      0.00       251\n",
      "\n",
      "    accuracy                           0.92      2962\n",
      "   macro avg       0.46      0.50      0.48      2962\n",
      "weighted avg       0.84      0.92      0.87      2962\n",
      "\n",
      "Confusion_matrix\n",
      "[[2711    0]\n",
      " [ 251    0]]\n",
      "done in 16.332964s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2804\n",
      "           1       0.50      0.00      0.01       265\n",
      "\n",
      "    accuracy                           0.91      3069\n",
      "   macro avg       0.71      0.50      0.48      3069\n",
      "weighted avg       0.88      0.91      0.87      3069\n",
      "\n",
      "Confusion_matrix\n",
      "[[2803    1]\n",
      " [ 264    1]]\n",
      "done in 16.453057s\n",
      "0.264372916262498\n",
      "0.27018076777808153\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19950\n",
      "           1       0.00      0.00      0.00      1948\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.46      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19949     1]\n",
      " [ 1948     0]]\n",
      "done in 0.546310s\n",
      "0.264372916262498\n",
      "0.2794088259193761\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19883\n",
      "           1       0.00      0.00      0.00      2015\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.45      0.50      0.48     21898\n",
      "weighted avg       0.82      0.91      0.86     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19879     4]\n",
      " [ 2015     0]]\n",
      "done in 0.538977s\n",
      "0.264372916262498\n",
      "0.2729337988270996\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17239\n",
      "           1       0.00      0.00      0.00      1697\n",
      "\n",
      "    accuracy                           0.91     18936\n",
      "   macro avg       0.46      0.50      0.48     18936\n",
      "weighted avg       0.83      0.91      0.87     18936\n",
      "\n",
      "Confusion_matrix\n",
      "[[17238     1]\n",
      " [ 1697     0]]\n",
      "done in 0.544735s\n",
      "0.264372916262498\n",
      "0.27474664355551137\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17079\n",
      "           1       0.00      0.00      0.00      1750\n",
      "\n",
      "    accuracy                           0.91     18829\n",
      "   macro avg       0.45      0.50      0.48     18829\n",
      "weighted avg       0.82      0.91      0.86     18829\n",
      "\n",
      "Confusion_matrix\n",
      "[[17079     0]\n",
      " [ 1750     0]]\n",
      "done in 0.540343s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.264372916262498\n",
      "0.2525807016254122\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2711\n",
      "           1       0.00      0.00      0.00       251\n",
      "\n",
      "    accuracy                           0.92      2962\n",
      "   macro avg       0.46      0.50      0.48      2962\n",
      "weighted avg       0.84      0.92      0.87      2962\n",
      "\n",
      "Confusion_matrix\n",
      "[[2711    0]\n",
      " [ 251    0]]\n",
      "done in 0.517319s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.264372916262498\n",
      "0.296758273731138\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2804\n",
      "           1       0.00      0.00      0.00       265\n",
      "\n",
      "    accuracy                           0.91      3069\n",
      "   macro avg       0.46      0.50      0.48      3069\n",
      "weighted avg       0.83      0.91      0.87      3069\n",
      "\n",
      "Confusion_matrix\n",
      "[[2801    3]\n",
      " [ 265    0]]\n",
      "done in 0.519005s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19950\n",
      "           1       0.44      0.02      0.03      1948\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19905    45]\n",
      " [ 1913    35]]\n",
      "done in 29.530747s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19883\n",
      "           1       0.43      0.02      0.03      2015\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19842    41]\n",
      " [ 1984    31]]\n",
      "done in 29.926323s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17239\n",
      "           1       0.41      0.02      0.03      1697\n",
      "\n",
      "    accuracy                           0.91     18936\n",
      "   macro avg       0.66      0.51      0.49     18936\n",
      "weighted avg       0.87      0.91      0.87     18936\n",
      "\n",
      "Confusion_matrix\n",
      "[[17201    38]\n",
      " [ 1671    26]]\n",
      "done in 29.619364s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17079\n",
      "           1       0.46      0.01      0.03      1750\n",
      "\n",
      "    accuracy                           0.91     18829\n",
      "   macro avg       0.68      0.51      0.49     18829\n",
      "weighted avg       0.87      0.91      0.87     18829\n",
      "\n",
      "Confusion_matrix\n",
      "[[17051    28]\n",
      " [ 1726    24]]\n",
      "done in 29.649841s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2711\n",
      "           1       0.56      0.04      0.07       251\n",
      "\n",
      "    accuracy                           0.92      2962\n",
      "   macro avg       0.74      0.52      0.51      2962\n",
      "weighted avg       0.89      0.92      0.88      2962\n",
      "\n",
      "Confusion_matrix\n",
      "[[2704    7]\n",
      " [ 242    9]]\n",
      "done in 29.591066s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95      2804\n",
      "           1       0.32      0.03      0.05       265\n",
      "\n",
      "    accuracy                           0.91      3069\n",
      "   macro avg       0.62      0.51      0.50      3069\n",
      "weighted avg       0.86      0.91      0.88      3069\n",
      "\n",
      "Confusion_matrix\n",
      "[[2789   15]\n",
      " [ 258    7]]\n",
      "done in 29.372350s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.396\n",
      "threshold:0.2, J-value:0.254\n",
      "threshold:0.30000000000000004, J-value:0.14\n",
      "threshold:0.4, J-value:0.067\n",
      "threshold:0.5, J-value:0.030000000000000002\n",
      "threshold:0.6000000000000001, J-value:0.011\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6982621080421794\n",
      "Balanced accuracy score of test is  0.708633358746683\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.387\n",
      "threshold:0.2, J-value:0.247\n",
      "threshold:0.30000000000000004, J-value:0.138\n",
      "threshold:0.4, J-value:0.064\n",
      "threshold:0.5, J-value:0.025\n",
      "threshold:0.6000000000000001, J-value:0.011\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6935497422745694\n",
      "Balanced accuracy score of test is  0.7124001237944677\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.4580000000000001\n",
      "threshold:0.2, J-value:0.299\n",
      "threshold:0.30000000000000004, J-value:0.152\n",
      "threshold:0.4, J-value:0.08800000000000001\n",
      "threshold:0.5, J-value:0.059000000000000004\n",
      "threshold:0.6000000000000001, J-value:0.014\n",
      "threshold:0.7000000000000001, J-value:0.004\n",
      "threshold:0.8, J-value:0.004\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7292027022856563\n",
      "Balanced accuracy score of test is  0.6836170699539741\n",
      "True positive rate of class 1 is  0.677\n",
      "True positive rate of class 2 is  0.615\n",
      "Positive prediction rate of class 1 is  0.291\n",
      "Positive prediction rate of class 2 is  0.28\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.387\n",
      "threshold:0.2, J-value:0.276\n",
      "threshold:0.30000000000000004, J-value:0.10200000000000001\n",
      "threshold:0.4, J-value:0.023\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6933087853102984\n",
      "Balanced accuracy score of test is  0.695963845069338\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.374\n",
      "threshold:0.2, J-value:0.279\n",
      "threshold:0.30000000000000004, J-value:0.10400000000000001\n",
      "threshold:0.4, J-value:0.024\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6871146650765796\n",
      "Balanced accuracy score of test is  0.7016364457604578\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.47600000000000003\n",
      "threshold:0.2, J-value:0.342\n",
      "threshold:0.30000000000000004, J-value:0.134\n",
      "threshold:0.4, J-value:0.026000000000000002\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7379122389086222\n",
      "Balanced accuracy score of test is  0.6873186552902861\n",
      "True positive rate of class 1 is  0.742\n",
      "True positive rate of class 2 is  0.743\n",
      "Positive prediction rate of class 1 is  0.376\n",
      "Positive prediction rate of class 2 is  0.401\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.35900000000000004\n",
      "threshold:0.2, J-value:0.226\n",
      "threshold:0.30000000000000004, J-value:0.10600000000000001\n",
      "threshold:0.4, J-value:0.003\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6796957743434562\n",
      "Balanced accuracy score of test is  0.6855804346244389\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.35200000000000004\n",
      "threshold:0.2, J-value:0.222\n",
      "threshold:0.30000000000000004, J-value:0.11100000000000002\n",
      "threshold:0.4, J-value:0.003\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6755665257645271\n",
      "Balanced accuracy score of test is  0.6859463334253427\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41000000000000003\n",
      "threshold:0.2, J-value:0.253\n",
      "threshold:0.30000000000000004, J-value:0.07600000000000001\n",
      "threshold:0.4, J-value:0.0\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7052248402186165\n",
      "Balanced accuracy score of test is  0.680913385190967\n",
      "True positive rate of class 1 is  0.685\n",
      "True positive rate of class 2 is  0.608\n",
      "Positive prediction rate of class 1 is  0.348\n",
      "Positive prediction rate of class 2 is  0.277\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.4149999999999999\n",
      "threshold:0.2, J-value:0.26\n",
      "threshold:0.30000000000000004, J-value:0.138\n",
      "threshold:0.4, J-value:0.053\n",
      "threshold:0.5, J-value:0.016\n",
      "threshold:0.6000000000000001, J-value:0.005\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy score of val is  0.7072499009330308\n",
      "Balanced accuracy score of test is  0.7106109200360571\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.401\n",
      "threshold:0.2, J-value:0.255\n",
      "threshold:0.30000000000000004, J-value:0.135\n",
      "threshold:0.4, J-value:0.05\n",
      "threshold:0.5, J-value:0.013\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7004537203623789\n",
      "Balanced accuracy score of test is  0.7135740466571312\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.504\n",
      "threshold:0.2, J-value:0.291\n",
      "threshold:0.30000000000000004, J-value:0.159\n",
      "threshold:0.4, J-value:0.07200000000000001\n",
      "threshold:0.5, J-value:0.032999999999999995\n",
      "threshold:0.6000000000000001, J-value:0.02\n",
      "threshold:0.7000000000000001, J-value:0.004\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7522223904088552\n",
      "Balanced accuracy score of test is  0.6913546685328238\n",
      "True positive rate of class 1 is  0.698\n",
      "True positive rate of class 2 is  0.657\n",
      "Positive prediction rate of class 1 is  0.31\n",
      "Positive prediction rate of class 2 is  0.307\n",
      "X train 65694\n",
      "Y train 65694\n",
      "21898 18932 2966\n",
      "21898 18932 2966\n",
      "21898 18882 3016\n",
      "21898 18882 3016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2588696445882092\n",
      "0.26295515784374507\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19908\n",
      "           1       0.46      0.04      0.07      1990\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.69      0.52      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19820    88]\n",
      " [ 1915    75]]\n",
      "done in 0.518459s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2588696445882092\n",
      "0.26084547415836146\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19918\n",
      "           1       0.43      0.03      0.06      1980\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19831    87]\n",
      " [ 1914    66]]\n",
      "done in 0.554159s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2588696445882092\n",
      "0.2631389701556421\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17204\n",
      "           1       0.48      0.04      0.07      1728\n",
      "\n",
      "    accuracy                           0.91     18932\n",
      "   macro avg       0.69      0.52      0.51     18932\n",
      "weighted avg       0.87      0.91      0.87     18932\n",
      "\n",
      "Confusion_matrix\n",
      "[[17136    68]\n",
      " [ 1666    62]]\n",
      "done in 0.515184s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2588696445882092\n",
      "0.26320409624024377\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17156\n",
      "           1       0.40      0.03      0.05      1726\n",
      "\n",
      "    accuracy                           0.91     18882\n",
      "   macro avg       0.66      0.51      0.50     18882\n",
      "weighted avg       0.86      0.91      0.87     18882\n",
      "\n",
      "Confusion_matrix\n",
      "[[17084    72]\n",
      " [ 1678    48]]\n",
      "done in 0.520531s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2588696445882092\n",
      "0.26178188249349765\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95      2704\n",
      "           1       0.39      0.05      0.09       262\n",
      "\n",
      "    accuracy                           0.91      2966\n",
      "   macro avg       0.65      0.52      0.52      2966\n",
      "weighted avg       0.87      0.91      0.88      2966\n",
      "\n",
      "Confusion_matrix\n",
      "[[2684   20]\n",
      " [ 249   13]]\n",
      "done in 0.491990s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2588696445882092\n",
      "0.24607906097861967\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96      2762\n",
      "           1       0.55      0.07      0.13       254\n",
      "\n",
      "    accuracy                           0.92      3016\n",
      "   macro avg       0.73      0.53      0.54      3016\n",
      "weighted avg       0.89      0.92      0.89      3016\n",
      "\n",
      "Confusion_matrix\n",
      "[[2747   15]\n",
      " [ 236   18]]\n",
      "done in 0.515493s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19908\n",
      "           1       0.38      0.00      0.01      1990\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.64      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19898    10]\n",
      " [ 1984     6]]\n",
      "done in 16.485183s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19918\n",
      "           1       0.18      0.00      0.00      1980\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.55      0.50      0.48     21898\n",
      "weighted avg       0.84      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19909     9]\n",
      " [ 1978     2]]\n",
      "done in 16.426363s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17204\n",
      "           1       0.69      0.01      0.01      1728\n",
      "\n",
      "    accuracy                           0.91     18932\n",
      "   macro avg       0.80      0.50      0.48     18932\n",
      "weighted avg       0.89      0.91      0.87     18932\n",
      "\n",
      "Confusion_matrix\n",
      "[[17200     4]\n",
      " [ 1719     9]]\n",
      "done in 16.506443s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17156\n",
      "           1       0.33      0.00      0.00      1726\n",
      "\n",
      "    accuracy                           0.91     18882\n",
      "   macro avg       0.62      0.50      0.48     18882\n",
      "weighted avg       0.86      0.91      0.87     18882\n",
      "\n",
      "Confusion_matrix\n",
      "[[17152     4]\n",
      " [ 1724     2]]\n",
      "done in 16.687687s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2704\n",
      "           1       0.50      0.01      0.02       262\n",
      "\n",
      "    accuracy                           0.91      2966\n",
      "   macro avg       0.71      0.50      0.48      2966\n",
      "weighted avg       0.88      0.91      0.87      2966\n",
      "\n",
      "Confusion_matrix\n",
      "[[2702    2]\n",
      " [ 260    2]]\n",
      "done in 16.384511s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2762\n",
      "           1       0.00      0.00      0.00       254\n",
      "\n",
      "    accuracy                           0.92      3016\n",
      "   macro avg       0.46      0.50      0.48      3016\n",
      "weighted avg       0.84      0.92      0.88      3016\n",
      "\n",
      "Confusion_matrix\n",
      "[[2762    0]\n",
      " [ 254    0]]\n",
      "done in 16.332824s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26428564201629917\n",
      "0.2712285449549372\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19908\n",
      "           1       0.00      0.00      0.00      1990\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.45      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19905     3]\n",
      " [ 1990     0]]\n",
      "done in 0.542418s\n",
      "0.26428564201629917\n",
      "0.27044922960654555\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19918\n",
      "           1       0.00      0.00      0.00      1980\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.45      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19915     3]\n",
      " [ 1980     0]]\n",
      "done in 0.542179s\n",
      "0.26428564201629917\n",
      "0.27193464291926434\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17204\n",
      "           1       0.00      0.00      0.00      1728\n",
      "\n",
      "    accuracy                           0.91     18932\n",
      "   macro avg       0.45      0.50      0.48     18932\n",
      "weighted avg       0.83      0.91      0.87     18932\n",
      "\n",
      "Confusion_matrix\n",
      "[[17201     3]\n",
      " [ 1728     0]]\n",
      "done in 0.539604s\n",
      "0.26428564201629917\n",
      "0.27233511337440713\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17156\n",
      "           1       0.00      0.00      0.00      1726\n",
      "\n",
      "    accuracy                           0.91     18882\n",
      "   macro avg       0.45      0.50      0.48     18882\n",
      "weighted avg       0.83      0.91      0.87     18882\n",
      "\n",
      "Confusion_matrix\n",
      "[[17155     1]\n",
      " [ 1726     0]]\n",
      "done in 0.539746s\n",
      "0.26428564201629917\n",
      "0.2667215164112277\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2704\n",
      "           1       0.00      0.00      0.00       262\n",
      "\n",
      "    accuracy                           0.91      2966\n",
      "   macro avg       0.46      0.50      0.48      2966\n",
      "weighted avg       0.83      0.91      0.87      2966\n",
      "\n",
      "Confusion_matrix\n",
      "[[2704    0]\n",
      " [ 262    0]]\n",
      "done in 0.514567s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26428564201629917\n",
      "0.2588664114511214\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2762\n",
      "           1       0.00      0.00      0.00       254\n",
      "\n",
      "    accuracy                           0.92      3016\n",
      "   macro avg       0.46      0.50      0.48      3016\n",
      "weighted avg       0.84      0.92      0.88      3016\n",
      "\n",
      "Confusion_matrix\n",
      "[[2760    2]\n",
      " [ 254    0]]\n",
      "done in 0.519698s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19908\n",
      "           1       0.44      0.02      0.04      1990\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.51      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19859    49]\n",
      " [ 1951    39]]\n",
      "done in 29.519114s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19918\n",
      "           1       0.36      0.02      0.03      1980\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.64      0.51      0.49     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19861    57]\n",
      " [ 1948    32]]\n",
      "done in 30.507973s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17204\n",
      "           1       0.44      0.02      0.03      1728\n",
      "\n",
      "    accuracy                           0.91     18932\n",
      "   macro avg       0.67      0.51      0.49     18932\n",
      "weighted avg       0.87      0.91      0.87     18932\n",
      "\n",
      "Confusion_matrix\n",
      "[[17167    37]\n",
      " [ 1699    29]]\n",
      "done in 30.037863s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17156\n",
      "           1       0.40      0.02      0.03      1726\n",
      "\n",
      "    accuracy                           0.91     18882\n",
      "   macro avg       0.65      0.51      0.49     18882\n",
      "weighted avg       0.86      0.91      0.87     18882\n",
      "\n",
      "Confusion_matrix\n",
      "[[17111    45]\n",
      " [ 1696    30]]\n",
      "done in 29.748306s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2704\n",
      "           1       0.48      0.04      0.07       262\n",
      "\n",
      "    accuracy                           0.91      2966\n",
      "   macro avg       0.70      0.52      0.51      2966\n",
      "weighted avg       0.88      0.91      0.88      2966\n",
      "\n",
      "Confusion_matrix\n",
      "[[2693   11]\n",
      " [ 252   10]]\n",
      "done in 29.588522s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.95      2762\n",
      "           1       0.27      0.02      0.03       254\n",
      "\n",
      "    accuracy                           0.91      3016\n",
      "   macro avg       0.59      0.51      0.49      3016\n",
      "weighted avg       0.86      0.91      0.88      3016\n",
      "\n",
      "Confusion_matrix\n",
      "[[2751   11]\n",
      " [ 250    4]]\n",
      "done in 29.762853s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.395\n",
      "threshold:0.2, J-value:0.262\n",
      "threshold:0.30000000000000004, J-value:0.156\n",
      "threshold:0.4, J-value:0.077\n",
      "threshold:0.5, J-value:0.034\n",
      "threshold:0.6000000000000001, J-value:0.015\n",
      "threshold:0.7000000000000001, J-value:0.005\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.697461968270123\n",
      "Balanced accuracy score of test is  0.7109123669671917\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.396\n",
      "threshold:0.2, J-value:0.26\n",
      "threshold:0.30000000000000004, J-value:0.157\n",
      "threshold:0.4, J-value:0.07300000000000001\n",
      "threshold:0.5, J-value:0.032\n",
      "threshold:0.6000000000000001, J-value:0.012\n",
      "threshold:0.7000000000000001, J-value:0.004\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6978623753519853\n",
      "Balanced accuracy score of test is  0.710599915113361\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.389\n",
      "threshold:0.2, J-value:0.269\n",
      "threshold:0.30000000000000004, J-value:0.155\n",
      "threshold:0.4, J-value:0.09999999999999999\n",
      "threshold:0.5, J-value:0.043000000000000003\n",
      "threshold:0.6000000000000001, J-value:0.03\n",
      "threshold:0.7000000000000001, J-value:0.011\n",
      "threshold:0.8, J-value:0.004\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6948117575319572\n",
      "Balanced accuracy score of test is  0.7118643343007178\n",
      "True positive rate of class 1 is  0.672\n",
      "True positive rate of class 2 is  0.646\n",
      "Positive prediction rate of class 1 is  0.289\n",
      "Positive prediction rate of class 2 is  0.258\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.37599999999999995\n",
      "threshold:0.2, J-value:0.279\n",
      "threshold:0.30000000000000004, J-value:0.11000000000000001\n",
      "threshold:0.4, J-value:0.027\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6880083560256577\n",
      "Balanced accuracy score of test is  0.6963343648352184\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.37599999999999995\n",
      "threshold:0.2, J-value:0.278\n",
      "threshold:0.30000000000000004, J-value:0.11000000000000001\n",
      "threshold:0.4, J-value:0.024\n",
      "threshold:0.5, J-value:0.005\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6883088531306243\n",
      "Balanced accuracy score of test is  0.6898729996458104\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.393\n",
      "threshold:0.2, J-value:0.269\n",
      "threshold:0.30000000000000004, J-value:0.131\n",
      "threshold:0.4, J-value:0.025\n",
      "threshold:0.5, J-value:0.007\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6966566353493835\n",
      "Balanced accuracy score of test is  0.7171768717179723\n",
      "True positive rate of class 1 is  0.722\n",
      "True positive rate of class 2 is  0.76\n",
      "Positive prediction rate of class 1 is  0.377\n",
      "Positive prediction rate of class 2 is  0.362\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.35500000000000004\n",
      "threshold:0.2, J-value:0.227\n",
      "threshold:0.30000000000000004, J-value:0.101\n",
      "threshold:0.4, J-value:0.003\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6776950353535812\n",
      "Balanced accuracy score of test is  0.6807762330605989\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.35300000000000004\n",
      "threshold:0.2, J-value:0.233\n",
      "threshold:0.30000000000000004, J-value:0.10800000000000001\n",
      "threshold:0.4, J-value:0.002\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6762535575275346\n",
      "Balanced accuracy score of test is  0.6804078151902776\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.374\n",
      "threshold:0.2, J-value:0.18799999999999997\n",
      "threshold:0.30000000000000004, J-value:0.06\n",
      "threshold:0.4, J-value:0.005\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6869198586205338\n",
      "Balanced accuracy score of test is  0.681453015331809\n",
      "True positive rate of class 1 is  0.652\n",
      "True positive rate of class 2 is  0.614\n",
      "Positive prediction rate of class 1 is  0.325\n",
      "Positive prediction rate of class 2 is  0.282\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.397\n",
      "threshold:0.2, J-value:0.27299999999999996\n",
      "threshold:0.30000000000000004, J-value:0.14400000000000002\n",
      "threshold:0.4, J-value:0.059000000000000004\n",
      "threshold:0.5, J-value:0.018000000000000002\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy score of val is  0.6984957437377767\n",
      "Balanced accuracy score of test is  0.7095634525798197\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.398\n",
      "threshold:0.2, J-value:0.27399999999999997\n",
      "threshold:0.30000000000000004, J-value:0.14600000000000002\n",
      "threshold:0.4, J-value:0.059000000000000004\n",
      "threshold:0.5, J-value:0.015000000000000001\n",
      "threshold:0.6000000000000001, J-value:0.002\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6989245879511224\n",
      "Balanced accuracy score of test is  0.7075214911518781\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.392\n",
      "threshold:0.2, J-value:0.263\n",
      "threshold:0.30000000000000004, J-value:0.132\n",
      "threshold:0.4, J-value:0.054000000000000006\n",
      "threshold:0.5, J-value:0.034\n",
      "threshold:0.6000000000000001, J-value:0.008\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6961513053886805\n",
      "Balanced accuracy score of test is  0.7224751549430688\n",
      "True positive rate of class 1 is  0.688\n",
      "True positive rate of class 2 is  0.689\n",
      "Positive prediction rate of class 1 is  0.311\n",
      "Positive prediction rate of class 2 is  0.281\n",
      "X train 65694\n",
      "Y train 65694\n",
      "21898 18875 3023\n",
      "21898 18875 3023\n",
      "21898 19009 2889\n",
      "21898 19009 2889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26307168792840674\n",
      "0.2547183682210981\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95     20006\n",
      "           1       0.38      0.03      0.06      1892\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.65      0.51      0.51     21898\n",
      "weighted avg       0.87      0.91      0.88     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19904   102]\n",
      " [ 1829    63]]\n",
      "done in 0.518024s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26307168792840674\n",
      "0.2562341245754884\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.95     19975\n",
      "           1       0.48      0.04      0.08      1923\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.70      0.52      0.52     21898\n",
      "weighted avg       0.88      0.91      0.88     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19886    89]\n",
      " [ 1841    82]]\n",
      "done in 0.521250s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26307168792840674\n",
      "0.2556868567406752\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.95     17241\n",
      "           1       0.38      0.03      0.06      1634\n",
      "\n",
      "    accuracy                           0.91     18875\n",
      "   macro avg       0.65      0.51      0.51     18875\n",
      "weighted avg       0.87      0.91      0.88     18875\n",
      "\n",
      "Confusion_matrix\n",
      "[[17160    81]\n",
      " [ 1584    50]]\n",
      "done in 0.503699s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26307168792840674\n",
      "0.2597512527864634\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17310\n",
      "           1       0.48      0.04      0.07      1699\n",
      "\n",
      "    accuracy                           0.91     19009\n",
      "   macro avg       0.70      0.52      0.51     19009\n",
      "weighted avg       0.87      0.91      0.87     19009\n",
      "\n",
      "Confusion_matrix\n",
      "[[17242    68]\n",
      " [ 1637    62]]\n",
      "done in 0.593209s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26307168792840674\n",
      "0.24867132197332495\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95      2765\n",
      "           1       0.38      0.05      0.09       258\n",
      "\n",
      "    accuracy                           0.91      3023\n",
      "   macro avg       0.65      0.52      0.52      3023\n",
      "weighted avg       0.87      0.91      0.88      3023\n",
      "\n",
      "Confusion_matrix\n",
      "[[2744   21]\n",
      " [ 245   13]]\n",
      "done in 0.562825s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26307168792840674\n",
      "0.23309217574806565\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      2665\n",
      "           1       0.49      0.09      0.15       224\n",
      "\n",
      "    accuracy                           0.92      2889\n",
      "   macro avg       0.71      0.54      0.56      2889\n",
      "weighted avg       0.89      0.92      0.90      2889\n",
      "\n",
      "Confusion_matrix\n",
      "[[2644   21]\n",
      " [ 204   20]]\n",
      "done in 0.502448s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     20006\n",
      "           1       0.43      0.00      0.01      1892\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19998     8]\n",
      " [ 1886     6]]\n",
      "done in 16.863882s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19975\n",
      "           1       0.53      0.00      0.01      1923\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.72      0.50      0.48     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19968     7]\n",
      " [ 1915     8]]\n",
      "done in 16.887379s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17241\n",
      "           1       0.73      0.00      0.01      1634\n",
      "\n",
      "    accuracy                           0.91     18875\n",
      "   macro avg       0.82      0.50      0.48     18875\n",
      "weighted avg       0.90      0.91      0.87     18875\n",
      "\n",
      "Confusion_matrix\n",
      "[[17238     3]\n",
      " [ 1626     8]]\n",
      "done in 16.822608s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17310\n",
      "           1       0.35      0.00      0.01      1699\n",
      "\n",
      "    accuracy                           0.91     19009\n",
      "   macro avg       0.63      0.50      0.48     19009\n",
      "weighted avg       0.86      0.91      0.87     19009\n",
      "\n",
      "Confusion_matrix\n",
      "[[17297    13]\n",
      " [ 1692     7]]\n",
      "done in 16.746621s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.96      2765\n",
      "           1       0.25      0.00      0.01       258\n",
      "\n",
      "    accuracy                           0.91      3023\n",
      "   macro avg       0.58      0.50      0.48      3023\n",
      "weighted avg       0.86      0.91      0.87      3023\n",
      "\n",
      "Confusion_matrix\n",
      "[[2762    3]\n",
      " [ 257    1]]\n",
      "done in 16.611125s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2665\n",
      "           1       0.00      0.00      0.00       224\n",
      "\n",
      "    accuracy                           0.92      2889\n",
      "   macro avg       0.46      0.50      0.48      2889\n",
      "weighted avg       0.85      0.92      0.89      2889\n",
      "\n",
      "Confusion_matrix\n",
      "[[2665    0]\n",
      " [ 224    0]]\n",
      "done in 16.683393s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2682128952371694\n",
      "0.2638709963739227\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     20006\n",
      "           1       0.56      0.00      0.01      1892\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.74      0.50      0.48     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19999     7]\n",
      " [ 1883     9]]\n",
      "done in 0.543181s\n",
      "0.2682128952371694\n",
      "0.26619820202997585\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19975\n",
      "           1       0.56      0.00      0.01      1923\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.74      0.50      0.48     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19968     7]\n",
      " [ 1914     9]]\n",
      "done in 0.545854s\n",
      "0.2682128952371694\n",
      "0.26452887711964745\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17241\n",
      "           1       0.50      0.00      0.01      1634\n",
      "\n",
      "    accuracy                           0.91     18875\n",
      "   macro avg       0.71      0.50      0.48     18875\n",
      "weighted avg       0.88      0.91      0.87     18875\n",
      "\n",
      "Confusion_matrix\n",
      "[[17234     7]\n",
      " [ 1627     7]]\n",
      "done in 0.541823s\n",
      "0.2682128952371694\n",
      "0.2686302724769611\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17310\n",
      "           1       0.55      0.00      0.01      1699\n",
      "\n",
      "    accuracy                           0.91     19009\n",
      "   macro avg       0.73      0.50      0.48     19009\n",
      "weighted avg       0.88      0.91      0.87     19009\n",
      "\n",
      "Confusion_matrix\n",
      "[[17305     5]\n",
      " [ 1693     6]]\n",
      "done in 0.543511s\n",
      "0.2682128952371694\n",
      "0.2597633221841926\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2765\n",
      "           1       1.00      0.01      0.02       258\n",
      "\n",
      "    accuracy                           0.92      3023\n",
      "   macro avg       0.96      0.50      0.49      3023\n",
      "weighted avg       0.92      0.92      0.88      3023\n",
      "\n",
      "Confusion_matrix\n",
      "[[2765    0]\n",
      " [ 256    2]]\n",
      "done in 0.516284s\n",
      "0.2682128952371694\n",
      "0.2501957004284727\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2665\n",
      "           1       0.60      0.01      0.03       224\n",
      "\n",
      "    accuracy                           0.92      2889\n",
      "   macro avg       0.76      0.51      0.49      2889\n",
      "weighted avg       0.90      0.92      0.89      2889\n",
      "\n",
      "Confusion_matrix\n",
      "[[2663    2]\n",
      " [ 221    3]]\n",
      "done in 0.515338s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     20006\n",
      "           1       0.36      0.02      0.04      1892\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.64      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19943    63]\n",
      " [ 1856    36]]\n",
      "done in 29.688744s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19975\n",
      "           1       0.47      0.02      0.05      1923\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.69      0.51      0.50     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19923    52]\n",
      " [ 1876    47]]\n",
      "done in 30.292547s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17241\n",
      "           1       0.37      0.02      0.03      1634\n",
      "\n",
      "    accuracy                           0.91     18875\n",
      "   macro avg       0.64      0.51      0.49     18875\n",
      "weighted avg       0.87      0.91      0.87     18875\n",
      "\n",
      "Confusion_matrix\n",
      "[[17191    50]\n",
      " [ 1605    29]]\n",
      "done in 30.006759s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17310\n",
      "           1       0.49      0.02      0.04      1699\n",
      "\n",
      "    accuracy                           0.91     19009\n",
      "   macro avg       0.70      0.51      0.50     19009\n",
      "weighted avg       0.87      0.91      0.87     19009\n",
      "\n",
      "Confusion_matrix\n",
      "[[17271    39]\n",
      " [ 1661    38]]\n",
      "done in 30.023381s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.95      2765\n",
      "           1       0.37      0.03      0.05       258\n",
      "\n",
      "    accuracy                           0.91      3023\n",
      "   macro avg       0.64      0.51      0.50      3023\n",
      "weighted avg       0.87      0.91      0.88      3023\n",
      "\n",
      "Confusion_matrix\n",
      "[[2753   12]\n",
      " [ 251    7]]\n",
      "done in 29.968863s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96      2665\n",
      "           1       0.39      0.04      0.07       224\n",
      "\n",
      "    accuracy                           0.92      2889\n",
      "   macro avg       0.66      0.52      0.52      2889\n",
      "weighted avg       0.88      0.92      0.89      2889\n",
      "\n",
      "Confusion_matrix\n",
      "[[2651   14]\n",
      " [ 215    9]]\n",
      "done in 30.271290s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.403\n",
      "threshold:0.2, J-value:0.266\n",
      "threshold:0.30000000000000004, J-value:0.151\n",
      "threshold:0.4, J-value:0.069\n",
      "threshold:0.5, J-value:0.028\n",
      "threshold:0.6000000000000001, J-value:0.01\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.701395448173159\n",
      "Balanced accuracy score of test is  0.7049753689772121\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.399\n",
      "threshold:0.2, J-value:0.262\n",
      "threshold:0.30000000000000004, J-value:0.148\n",
      "threshold:0.4, J-value:0.064\n",
      "threshold:0.5, J-value:0.026\n",
      "threshold:0.6000000000000001, J-value:0.009\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6995064105608609\n",
      "Balanced accuracy score of test is  0.7024306614588594\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.42700000000000005\n",
      "threshold:0.2, J-value:0.28800000000000003\n",
      "threshold:0.30000000000000004, J-value:0.16899999999999998\n",
      "threshold:0.4, J-value:0.104\n",
      "threshold:0.5, J-value:0.042\n",
      "threshold:0.6000000000000001, J-value:0.013000000000000001\n",
      "threshold:0.7000000000000001, J-value:-0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7132098350084808\n",
      "Balanced accuracy score of test is  0.7223808965424819\n",
      "True positive rate of class 1 is  0.669\n",
      "True positive rate of class 2 is  0.683\n",
      "Positive prediction rate of class 1 is  0.301\n",
      "Positive prediction rate of class 2 is  0.273\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.394\n",
      "threshold:0.2, J-value:0.28400000000000003\n",
      "threshold:0.30000000000000004, J-value:0.118\n",
      "threshold:0.4, J-value:0.027\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6967775682094526\n",
      "Balanced accuracy score of test is  0.6959603690780923\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.382\n",
      "threshold:0.2, J-value:0.275\n",
      "threshold:0.30000000000000004, J-value:0.125\n",
      "threshold:0.4, J-value:0.024\n",
      "threshold:0.5, J-value:0.005\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6907631441575925\n",
      "Balanced accuracy score of test is  0.69156718414917\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.425\n",
      "threshold:0.2, J-value:0.279\n",
      "threshold:0.30000000000000004, J-value:0.123\n",
      "threshold:0.4, J-value:0.028000000000000004\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7124731906303882\n",
      "Balanced accuracy score of test is  0.7256516349504154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positive rate of class 1 is  0.735\n",
      "True positive rate of class 2 is  0.795\n",
      "Positive prediction rate of class 1 is  0.386\n",
      "Positive prediction rate of class 2 is  0.378\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.35400000000000004\n",
      "threshold:0.2, J-value:0.215\n",
      "threshold:0.30000000000000004, J-value:0.053000000000000005\n",
      "threshold:0.4, J-value:0.049999999999999996\n",
      "threshold:0.5, J-value:0.005\n",
      "threshold:0.6000000000000001, J-value:0.005\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.001\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6772188480876455\n",
      "Balanced accuracy score of test is  0.6904182620371148\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.3549999999999999\n",
      "threshold:0.2, J-value:0.213\n",
      "threshold:0.30000000000000004, J-value:0.051000000000000004\n",
      "threshold:0.4, J-value:0.049999999999999996\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.004\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6775605238345843\n",
      "Balanced accuracy score of test is  0.6888223235267015\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.349\n",
      "threshold:0.2, J-value:0.222\n",
      "threshold:0.30000000000000004, J-value:0.064\n",
      "threshold:0.4, J-value:0.05\n",
      "threshold:0.5, J-value:0.007\n",
      "threshold:0.6000000000000001, J-value:0.008\n",
      "threshold:0.7000000000000001, J-value:0.004\n",
      "threshold:0.8, J-value:0.004\n",
      "threshold:0.9, J-value:0.004\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6745559807673438\n",
      "Balanced accuracy score of test is  0.697860828196194\n",
      "True positive rate of class 1 is  0.716\n",
      "True positive rate of class 2 is  0.67\n",
      "Positive prediction rate of class 1 is  0.372\n",
      "Positive prediction rate of class 2 is  0.305\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.4119999999999999\n",
      "threshold:0.2, J-value:0.265\n",
      "threshold:0.30000000000000004, J-value:0.15\n",
      "threshold:0.4, J-value:0.06199999999999999\n",
      "threshold:0.5, J-value:0.016\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7057861764092337\n",
      "Balanced accuracy score of test is  0.7053341768213908\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.407\n",
      "threshold:0.2, J-value:0.268\n",
      "threshold:0.30000000000000004, J-value:0.149\n",
      "threshold:0.4, J-value:0.061000000000000006\n",
      "threshold:0.5, J-value:0.015\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.703610142825835\n",
      "Balanced accuracy score of test is  0.7041050925732302\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.43800000000000006\n",
      "threshold:0.2, J-value:0.251\n",
      "threshold:0.30000000000000004, J-value:0.154\n",
      "threshold:0.4, J-value:0.075\n",
      "threshold:0.5, J-value:0.023\n",
      "threshold:0.6000000000000001, J-value:0.011\n",
      "threshold:0.7000000000000001, J-value:0.004\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7191534547289625\n",
      "Balanced accuracy score of test is  0.7124371817207182\n",
      "True positive rate of class 1 is  0.691\n",
      "True positive rate of class 2 is  0.683\n",
      "Positive prediction rate of class 1 is  0.319\n",
      "Positive prediction rate of class 2 is  0.291\n",
      "X train 65694\n",
      "Y train 65694\n",
      "21898 18970 2928\n",
      "21898 18970 2928\n",
      "21898 18892 3006\n",
      "21898 18892 3006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25860650985764894\n",
      "0.26393882410428504\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19911\n",
      "           1       0.44      0.03      0.06      1987\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.51      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19826    85]\n",
      " [ 1919    68]]\n",
      "done in 0.595026s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25860650985764894\n",
      "0.26085852705776025\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19927\n",
      "           1       0.45      0.03      0.06      1971\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19855    72]\n",
      " [ 1912    59]]\n",
      "done in 0.580908s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25860650985764894\n",
      "0.26590919284162867\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17229\n",
      "           1       0.43      0.03      0.06      1741\n",
      "\n",
      "    accuracy                           0.91     18970\n",
      "   macro avg       0.67      0.51      0.51     18970\n",
      "weighted avg       0.87      0.91      0.87     18970\n",
      "\n",
      "Confusion_matrix\n",
      "[[17155    74]\n",
      " [ 1685    56]]\n",
      "done in 0.528408s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25860650985764894\n",
      "0.2605670366255002\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17198\n",
      "           1       0.44      0.03      0.05      1694\n",
      "\n",
      "    accuracy                           0.91     18892\n",
      "   macro avg       0.68      0.51      0.50     18892\n",
      "weighted avg       0.87      0.91      0.87     18892\n",
      "\n",
      "Confusion_matrix\n",
      "[[17143    55]\n",
      " [ 1651    43]]\n",
      "done in 0.554948s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25860650985764894\n",
      "0.2511731496003881\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2682\n",
      "           1       0.52      0.05      0.09       246\n",
      "\n",
      "    accuracy                           0.92      2928\n",
      "   macro avg       0.72      0.52      0.52      2928\n",
      "weighted avg       0.89      0.92      0.88      2928\n",
      "\n",
      "Confusion_matrix\n",
      "[[2671   11]\n",
      " [ 234   12]]\n",
      "done in 0.535269s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25860650985764894\n",
      "0.2626904755761424\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95      2729\n",
      "           1       0.48      0.06      0.10       277\n",
      "\n",
      "    accuracy                           0.91      3006\n",
      "   macro avg       0.70      0.53      0.53      3006\n",
      "weighted avg       0.87      0.91      0.87      3006\n",
      "\n",
      "Confusion_matrix\n",
      "[[2712   17]\n",
      " [ 261   16]]\n",
      "done in 0.531376s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19911\n",
      "           1       0.50      0.00      0.00      1987\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.70      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19908     3]\n",
      " [ 1984     3]]\n",
      "done in 17.392160s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19927\n",
      "           1       0.73      0.00      0.01      1971\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.82      0.50      0.48     21898\n",
      "weighted avg       0.89      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19924     3]\n",
      " [ 1963     8]]\n",
      "done in 17.239525s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17229\n",
      "           1       0.57      0.00      0.00      1741\n",
      "\n",
      "    accuracy                           0.91     18970\n",
      "   macro avg       0.74      0.50      0.48     18970\n",
      "weighted avg       0.88      0.91      0.86     18970\n",
      "\n",
      "Confusion_matrix\n",
      "[[17226     3]\n",
      " [ 1737     4]]\n",
      "done in 17.234191s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17198\n",
      "           1       0.55      0.00      0.01      1694\n",
      "\n",
      "    accuracy                           0.91     18892\n",
      "   macro avg       0.73      0.50      0.48     18892\n",
      "weighted avg       0.88      0.91      0.87     18892\n",
      "\n",
      "Confusion_matrix\n",
      "[[17193     5]\n",
      " [ 1688     6]]\n",
      "done in 17.185079s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2682\n",
      "           1       0.00      0.00      0.00       246\n",
      "\n",
      "    accuracy                           0.92      2928\n",
      "   macro avg       0.46      0.50      0.48      2928\n",
      "weighted avg       0.84      0.92      0.88      2928\n",
      "\n",
      "Confusion_matrix\n",
      "[[2680    2]\n",
      " [ 246    0]]\n",
      "done in 17.360552s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2729\n",
      "           1       0.00      0.00      0.00       277\n",
      "\n",
      "    accuracy                           0.91      3006\n",
      "   macro avg       0.45      0.50      0.48      3006\n",
      "weighted avg       0.82      0.91      0.86      3006\n",
      "\n",
      "Confusion_matrix\n",
      "[[2729    0]\n",
      " [ 277    0]]\n",
      "done in 16.741886s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26445464621705217\n",
      "0.2702963274846509\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19911\n",
      "           1       0.32      0.00      0.01      1987\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.61      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19898    13]\n",
      " [ 1981     6]]\n",
      "done in 0.552648s\n",
      "0.26445464621705217\n",
      "0.26900537003743663\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19927\n",
      "           1       0.30      0.00      0.01      1971\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.61      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19913    14]\n",
      " [ 1965     6]]\n",
      "done in 0.552513s\n",
      "0.26445464621705217\n",
      "0.2725960626011161\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17229\n",
      "           1       0.31      0.00      0.00      1741\n",
      "\n",
      "    accuracy                           0.91     18970\n",
      "   macro avg       0.61      0.50      0.48     18970\n",
      "weighted avg       0.85      0.91      0.86     18970\n",
      "\n",
      "Confusion_matrix\n",
      "[[17220     9]\n",
      " [ 1737     4]]\n",
      "done in 0.548961s\n",
      "0.26445464621705217\n",
      "0.2687477613627732\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17198\n",
      "           1       0.25      0.00      0.00      1694\n",
      "\n",
      "    accuracy                           0.91     18892\n",
      "   macro avg       0.58      0.50      0.48     18892\n",
      "weighted avg       0.85      0.91      0.87     18892\n",
      "\n",
      "Confusion_matrix\n",
      "[[17189     9]\n",
      " [ 1691     3]]\n",
      "done in 0.545068s\n",
      "0.26445464621705217\n",
      "0.2553967458045464\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2682\n",
      "           1       0.33      0.01      0.02       246\n",
      "\n",
      "    accuracy                           0.92      2928\n",
      "   macro avg       0.62      0.50      0.49      2928\n",
      "weighted avg       0.87      0.92      0.88      2928\n",
      "\n",
      "Confusion_matrix\n",
      "[[2678    4]\n",
      " [ 244    2]]\n",
      "done in 0.520752s\n",
      "0.26445464621705217\n",
      "0.2706243797120013\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2729\n",
      "           1       0.38      0.01      0.02       277\n",
      "\n",
      "    accuracy                           0.91      3006\n",
      "   macro avg       0.64      0.50      0.49      3006\n",
      "weighted avg       0.86      0.91      0.87      3006\n",
      "\n",
      "Confusion_matrix\n",
      "[[2724    5]\n",
      " [ 274    3]]\n",
      "done in 0.521245s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19911\n",
      "           1       0.42      0.02      0.04      1987\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.66      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19855    56]\n",
      " [ 1947    40]]\n",
      "done in 29.799232s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19927\n",
      "           1       0.43      0.02      0.04      1971\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19879    48]\n",
      " [ 1935    36]]\n",
      "done in 30.066049s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17229\n",
      "           1       0.39      0.02      0.03      1741\n",
      "\n",
      "    accuracy                           0.91     18970\n",
      "   macro avg       0.65      0.51      0.49     18970\n",
      "weighted avg       0.86      0.91      0.87     18970\n",
      "\n",
      "Confusion_matrix\n",
      "[[17183    46]\n",
      " [ 1711    30]]\n",
      "done in 30.234664s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17198\n",
      "           1       0.41      0.02      0.03      1694\n",
      "\n",
      "    accuracy                           0.91     18892\n",
      "   macro avg       0.66      0.51      0.49     18892\n",
      "weighted avg       0.87      0.91      0.87     18892\n",
      "\n",
      "Confusion_matrix\n",
      "[[17161    37]\n",
      " [ 1668    26]]\n",
      "done in 30.231091s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2682\n",
      "           1       0.50      0.04      0.08       246\n",
      "\n",
      "    accuracy                           0.92      2928\n",
      "   macro avg       0.71      0.52      0.52      2928\n",
      "weighted avg       0.88      0.92      0.88      2928\n",
      "\n",
      "Confusion_matrix\n",
      "[[2672   10]\n",
      " [ 236   10]]\n",
      "done in 30.106200s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2729\n",
      "           1       0.48      0.04      0.07       277\n",
      "\n",
      "    accuracy                           0.91      3006\n",
      "   macro avg       0.69      0.52      0.51      3006\n",
      "weighted avg       0.87      0.91      0.87      3006\n",
      "\n",
      "Confusion_matrix\n",
      "[[2718   11]\n",
      " [ 267   10]]\n",
      "done in 29.868934s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.389\n",
      "threshold:0.2, J-value:0.251\n",
      "threshold:0.30000000000000004, J-value:0.145\n",
      "threshold:0.4, J-value:0.07\n",
      "threshold:0.5, J-value:0.030000000000000002\n",
      "threshold:0.6000000000000001, J-value:0.012\n",
      "threshold:0.7000000000000001, J-value:0.006\n",
      "threshold:0.8, J-value:0.002\n",
      "threshold:0.9, J-value:0.001\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6945505258844737\n",
      "Balanced accuracy score of test is  0.7042348279999268\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.388\n",
      "threshold:0.2, J-value:0.25\n",
      "threshold:0.30000000000000004, J-value:0.142\n",
      "threshold:0.4, J-value:0.067\n",
      "threshold:0.5, J-value:0.028\n",
      "threshold:0.6000000000000001, J-value:0.009999999999999998\n",
      "threshold:0.7000000000000001, J-value:0.005\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6940985919676658\n",
      "Balanced accuracy score of test is  0.7047947902566305\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.394\n",
      "threshold:0.2, J-value:0.258\n",
      "threshold:0.30000000000000004, J-value:0.167\n",
      "threshold:0.4, J-value:0.096\n",
      "threshold:0.5, J-value:0.045\n",
      "threshold:0.6000000000000001, J-value:0.023\n",
      "threshold:0.7000000000000001, J-value:0.015\n",
      "threshold:0.8, J-value:0.008\n",
      "threshold:0.9, J-value:0.004\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6970135137592987\n",
      "Balanced accuracy score of test is  0.7009258757059158\n",
      "True positive rate of class 1 is  0.659\n",
      "True positive rate of class 2 is  0.643\n",
      "Positive prediction rate of class 1 is  0.287\n",
      "Positive prediction rate of class 2 is  0.278\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.386\n",
      "threshold:0.2, J-value:0.28600000000000003\n",
      "threshold:0.30000000000000004, J-value:0.11000000000000001\n",
      "threshold:0.4, J-value:0.021\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6929827920456398\n",
      "Balanced accuracy score of test is  0.7015901037263943\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.389\n",
      "threshold:0.2, J-value:0.272\n",
      "threshold:0.30000000000000004, J-value:0.11699999999999999\n",
      "threshold:0.4, J-value:0.028\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6946195168245677\n",
      "Balanced accuracy score of test is  0.7017268351540835\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.40399999999999997\n",
      "threshold:0.2, J-value:0.312\n",
      "threshold:0.30000000000000004, J-value:0.10600000000000001\n",
      "threshold:0.4, J-value:0.027000000000000003\n",
      "threshold:0.5, J-value:-0.001\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.702115276186319\n",
      "Balanced accuracy score of test is  0.6950635836773894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positive rate of class 1 is  0.743\n",
      "True positive rate of class 2 is  0.74\n",
      "Positive prediction rate of class 1 is  0.375\n",
      "Positive prediction rate of class 2 is  0.386\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.348\n",
      "threshold:0.2, J-value:0.21099999999999997\n",
      "threshold:0.30000000000000004, J-value:0.11000000000000001\n",
      "threshold:0.4, J-value:0.007\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.002\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6740769195946623\n",
      "Balanced accuracy score of test is  0.6700628399696437\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.347\n",
      "threshold:0.2, J-value:0.21699999999999997\n",
      "threshold:0.30000000000000004, J-value:0.11100000000000002\n",
      "threshold:0.4, J-value:0.007\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6735025656520175\n",
      "Balanced accuracy score of test is  0.6690458364437368\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.353\n",
      "threshold:0.2, J-value:0.169\n",
      "threshold:0.30000000000000004, J-value:0.096\n",
      "threshold:0.4, J-value:0.005\n",
      "threshold:0.5, J-value:0.007\n",
      "threshold:0.6000000000000001, J-value:0.007\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6765382586711772\n",
      "Balanced accuracy score of test is  0.6765169664507305\n",
      "True positive rate of class 1 is  0.603\n",
      "True positive rate of class 2 is  0.599\n",
      "Positive prediction rate of class 1 is  0.295\n",
      "Positive prediction rate of class 2 is  0.279\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.405\n",
      "threshold:0.2, J-value:0.26399999999999996\n",
      "threshold:0.30000000000000004, J-value:0.138\n",
      "threshold:0.4, J-value:0.052\n",
      "threshold:0.5, J-value:0.017\n",
      "threshold:0.6000000000000001, J-value:0.008\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7025953717495295\n",
      "Balanced accuracy score of test is  0.7129174454796536\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.40700000000000003\n",
      "threshold:0.2, J-value:0.26399999999999996\n",
      "threshold:0.30000000000000004, J-value:0.138\n",
      "threshold:0.4, J-value:0.049999999999999996\n",
      "threshold:0.5, J-value:0.014000000000000002\n",
      "threshold:0.6000000000000001, J-value:0.007\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7034533529134803\n",
      "Balanced accuracy score of test is  0.7109446020260174\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.391\n",
      "threshold:0.2, J-value:0.268\n",
      "threshold:0.30000000000000004, J-value:0.135\n",
      "threshold:0.4, J-value:0.065\n",
      "threshold:0.5, J-value:0.037000000000000005\n",
      "threshold:0.6000000000000001, J-value:0.019\n",
      "threshold:0.7000000000000001, J-value:0.008\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6958585693239483\n",
      "Balanced accuracy score of test is  0.725199190933588\n",
      "True positive rate of class 1 is  0.692\n",
      "True positive rate of class 2 is  0.704\n",
      "Positive prediction rate of class 1 is  0.308\n",
      "Positive prediction rate of class 2 is  0.295\n",
      "X train 65694\n",
      "Y train 65694\n",
      "21898 18842 3056\n",
      "21898 18842 3056\n",
      "21898 18914 2984\n",
      "21898 18914 2984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2614767344183246\n",
      "0.2574320888106272\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19944\n",
      "           1       0.43      0.03      0.06      1954\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19864    80]\n",
      " [ 1893    61]]\n",
      "done in 0.579522s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2614767344183246\n",
      "0.25827171441251523\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19955\n",
      "           1       0.47      0.04      0.07      1943\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.69      0.52      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19873    82]\n",
      " [ 1871    72]]\n",
      "done in 0.565664s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2614767344183246\n",
      "0.25815018639306336\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17147\n",
      "           1       0.45      0.03      0.06      1695\n",
      "\n",
      "    accuracy                           0.91     18842\n",
      "   macro avg       0.68      0.51      0.51     18842\n",
      "weighted avg       0.87      0.91      0.87     18842\n",
      "\n",
      "Confusion_matrix\n",
      "[[17081    66]\n",
      " [ 1642    53]]\n",
      "done in 0.601031s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2614767344183246\n",
      "0.2597863125598751\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17231\n",
      "           1       0.43      0.03      0.06      1683\n",
      "\n",
      "    accuracy                           0.91     18914\n",
      "   macro avg       0.67      0.51      0.51     18914\n",
      "weighted avg       0.87      0.91      0.87     18914\n",
      "\n",
      "Confusion_matrix\n",
      "[[17160    71]\n",
      " [ 1629    54]]\n",
      "done in 0.676650s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2614767344183246\n",
      "0.2530046036508553\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95      2797\n",
      "           1       0.36      0.03      0.06       259\n",
      "\n",
      "    accuracy                           0.91      3056\n",
      "   macro avg       0.64      0.51      0.51      3056\n",
      "weighted avg       0.87      0.91      0.88      3056\n",
      "\n",
      "Confusion_matrix\n",
      "[[2783   14]\n",
      " [ 251    8]]\n",
      "done in 0.627656s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2614767344183246\n",
      "0.24867147669161593\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2724\n",
      "           1       0.62      0.07      0.12       260\n",
      "\n",
      "    accuracy                           0.92      2984\n",
      "   macro avg       0.77      0.53      0.54      2984\n",
      "weighted avg       0.89      0.92      0.88      2984\n",
      "\n",
      "Confusion_matrix\n",
      "[[2713   11]\n",
      " [ 242   18]]\n",
      "done in 0.609670s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19944\n",
      "           1       0.58      0.00      0.01      1954\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.75      0.50      0.48     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19939     5]\n",
      " [ 1947     7]]\n",
      "done in 17.046681s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19955\n",
      "           1       0.64      0.00      0.01      1943\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.77      0.50      0.48     21898\n",
      "weighted avg       0.89      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19951     4]\n",
      " [ 1936     7]]\n",
      "done in 17.296649s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17147\n",
      "           1       0.50      0.00      0.01      1695\n",
      "\n",
      "    accuracy                           0.91     18842\n",
      "   macro avg       0.71      0.50      0.48     18842\n",
      "weighted avg       0.87      0.91      0.87     18842\n",
      "\n",
      "Confusion_matrix\n",
      "[[17141     6]\n",
      " [ 1689     6]]\n",
      "done in 17.071765s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17231\n",
      "           1       0.44      0.00      0.01      1683\n",
      "\n",
      "    accuracy                           0.91     18914\n",
      "   macro avg       0.67      0.50      0.48     18914\n",
      "weighted avg       0.87      0.91      0.87     18914\n",
      "\n",
      "Confusion_matrix\n",
      "[[17222     9]\n",
      " [ 1676     7]]\n",
      "done in 16.858607s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2797\n",
      "           1       0.00      0.00      0.00       259\n",
      "\n",
      "    accuracy                           0.91      3056\n",
      "   macro avg       0.46      0.50      0.48      3056\n",
      "weighted avg       0.84      0.91      0.87      3056\n",
      "\n",
      "Confusion_matrix\n",
      "[[2796    1]\n",
      " [ 259    0]]\n",
      "done in 17.128496s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2724\n",
      "           1       0.67      0.01      0.02       260\n",
      "\n",
      "    accuracy                           0.91      2984\n",
      "   macro avg       0.79      0.50      0.48      2984\n",
      "weighted avg       0.89      0.91      0.87      2984\n",
      "\n",
      "Confusion_matrix\n",
      "[[2723    1]\n",
      " [ 258    2]]\n",
      "done in 17.664855s\n",
      "0.26691180010608717\n",
      "0.26804236350549815\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19944\n",
      "           1       0.34      0.01      0.03      1954\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.63      0.51      0.49     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19890    54]\n",
      " [ 1926    28]]\n",
      "done in 0.553631s\n",
      "0.26691180010608717\n",
      "0.2720697371491411\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19955\n",
      "           1       0.38      0.01      0.03      1943\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.65      0.51      0.49     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19909    46]\n",
      " [ 1915    28]]\n",
      "done in 0.558759s\n",
      "0.26691180010608717\n",
      "0.26965226840168327\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17147\n",
      "           1       0.35      0.01      0.03      1695\n",
      "\n",
      "    accuracy                           0.91     18842\n",
      "   macro avg       0.63      0.51      0.49     18842\n",
      "weighted avg       0.86      0.91      0.87     18842\n",
      "\n",
      "Confusion_matrix\n",
      "[[17102    45]\n",
      " [ 1671    24]]\n",
      "done in 0.553475s\n",
      "0.26691180010608717\n",
      "0.2733018765049085\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17231\n",
      "           1       0.39      0.01      0.03      1683\n",
      "\n",
      "    accuracy                           0.91     18914\n",
      "   macro avg       0.65      0.51      0.49     18914\n",
      "weighted avg       0.87      0.91      0.87     18914\n",
      "\n",
      "Confusion_matrix\n",
      "[[17193    38]\n",
      " [ 1659    24]]\n",
      "done in 0.545713s\n",
      "0.26691180010608717\n",
      "0.25811637265015813\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.95      2797\n",
      "           1       0.31      0.02      0.03       259\n",
      "\n",
      "    accuracy                           0.91      3056\n",
      "   macro avg       0.61      0.51      0.49      3056\n",
      "weighted avg       0.86      0.91      0.88      3056\n",
      "\n",
      "Confusion_matrix\n",
      "[[2788    9]\n",
      " [ 255    4]]\n",
      "done in 0.527023s\n",
      "0.26691180010608717\n",
      "0.264259856527497\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2724\n",
      "           1       0.33      0.02      0.03       260\n",
      "\n",
      "    accuracy                           0.91      2984\n",
      "   macro avg       0.62      0.51      0.49      2984\n",
      "weighted avg       0.86      0.91      0.87      2984\n",
      "\n",
      "Confusion_matrix\n",
      "[[2716    8]\n",
      " [ 256    4]]\n",
      "done in 0.532123s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19944\n",
      "           1       0.44      0.01      0.03      1954\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.51      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19910    34]\n",
      " [ 1927    27]]\n",
      "done in 29.703552s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19955\n",
      "           1       0.55      0.02      0.03      1943\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.73      0.51      0.49     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19926    29]\n",
      " [ 1908    35]]\n",
      "done in 30.424210s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17147\n",
      "           1       0.45      0.01      0.03      1695\n",
      "\n",
      "    accuracy                           0.91     18842\n",
      "   macro avg       0.68      0.51      0.49     18842\n",
      "weighted avg       0.87      0.91      0.87     18842\n",
      "\n",
      "Confusion_matrix\n",
      "[[17118    29]\n",
      " [ 1671    24]]\n",
      "done in 30.157869s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17231\n",
      "           1       0.50      0.01      0.03      1683\n",
      "\n",
      "    accuracy                           0.91     18914\n",
      "   macro avg       0.71      0.51      0.49     18914\n",
      "weighted avg       0.88      0.91      0.87     18914\n",
      "\n",
      "Confusion_matrix\n",
      "[[17207    24]\n",
      " [ 1659    24]]\n",
      "done in 29.993303s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2797\n",
      "           1       0.38      0.01      0.02       259\n",
      "\n",
      "    accuracy                           0.91      3056\n",
      "   macro avg       0.65      0.50      0.49      3056\n",
      "weighted avg       0.87      0.91      0.88      3056\n",
      "\n",
      "Confusion_matrix\n",
      "[[2792    5]\n",
      " [ 256    3]]\n",
      "done in 30.382307s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2724\n",
      "           1       0.69      0.04      0.08       260\n",
      "\n",
      "    accuracy                           0.91      2984\n",
      "   macro avg       0.80      0.52      0.52      2984\n",
      "weighted avg       0.90      0.91      0.88      2984\n",
      "\n",
      "Confusion_matrix\n",
      "[[2719    5]\n",
      " [ 249   11]]\n",
      "done in 30.311818s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41500000000000004\n",
      "threshold:0.2, J-value:0.26599999999999996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.30000000000000004, J-value:0.146\n",
      "threshold:0.4, J-value:0.07\n",
      "threshold:0.5, J-value:0.027\n",
      "threshold:0.6000000000000001, J-value:0.012\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7074866945769547\n",
      "Balanced accuracy score of test is  0.7028318348296019\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41800000000000004\n",
      "threshold:0.2, J-value:0.26599999999999996\n",
      "threshold:0.30000000000000004, J-value:0.149\n",
      "threshold:0.4, J-value:0.07200000000000001\n",
      "threshold:0.5, J-value:0.027\n",
      "threshold:0.6000000000000001, J-value:0.013000000000000001\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7091967376320634\n",
      "Balanced accuracy score of test is  0.6991537313067934\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.391\n",
      "threshold:0.2, J-value:0.26\n",
      "threshold:0.30000000000000004, J-value:0.13\n",
      "threshold:0.4, J-value:0.05600000000000001\n",
      "threshold:0.5, J-value:0.026\n",
      "threshold:0.6000000000000001, J-value:0.006\n",
      "threshold:0.7000000000000001, J-value:-0.001\n",
      "threshold:0.8, J-value:-0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6955087014078791\n",
      "Balanced accuracy score of test is  0.7263893595391393\n",
      "True positive rate of class 1 is  0.659\n",
      "True positive rate of class 2 is  0.688\n",
      "Positive prediction rate of class 1 is  0.296\n",
      "Positive prediction rate of class 2 is  0.275\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.394\n",
      "threshold:0.2, J-value:0.29000000000000004\n",
      "threshold:0.30000000000000004, J-value:0.11300000000000002\n",
      "threshold:0.4, J-value:0.018000000000000002\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6967967576358123\n",
      "Balanced accuracy score of test is  0.6978128349259327\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.399\n",
      "threshold:0.2, J-value:0.277\n",
      "threshold:0.30000000000000004, J-value:0.10900000000000001\n",
      "threshold:0.4, J-value:0.02\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6996633827257724\n",
      "Balanced accuracy score of test is  0.697949549467163\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.38699999999999996\n",
      "threshold:0.2, J-value:0.335\n",
      "threshold:0.30000000000000004, J-value:0.092\n",
      "threshold:0.4, J-value:0.008\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6933242042287449\n",
      "Balanced accuracy score of test is  0.7227917090251892\n",
      "True positive rate of class 1 is  0.747\n",
      "True positive rate of class 2 is  0.788\n",
      "Positive prediction rate of class 1 is  0.387\n",
      "Positive prediction rate of class 2 is  0.382\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.364\n",
      "threshold:0.2, J-value:0.23500000000000001\n",
      "threshold:0.30000000000000004, J-value:0.143\n",
      "threshold:0.4, J-value:0.011\n",
      "threshold:0.5, J-value:0.011\n",
      "threshold:0.6000000000000001, J-value:0.002\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6823207591286309\n",
      "Balanced accuracy score of test is  0.6769141788788026\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.366\n",
      "threshold:0.2, J-value:0.24000000000000002\n",
      "threshold:0.30000000000000004, J-value:0.149\n",
      "threshold:0.4, J-value:0.011\n",
      "threshold:0.5, J-value:0.011\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6831660913017801\n",
      "Balanced accuracy score of test is  0.675193371341217\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.35\n",
      "threshold:0.2, J-value:0.20399999999999996\n",
      "threshold:0.30000000000000004, J-value:0.10500000000000001\n",
      "threshold:0.4, J-value:0.012\n",
      "threshold:0.5, J-value:0.012\n",
      "threshold:0.6000000000000001, J-value:0.011\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6750600132795341\n",
      "Balanced accuracy score of test is  0.687481644640235\n",
      "True positive rate of class 1 is  0.632\n",
      "True positive rate of class 2 is  0.6\n",
      "Positive prediction rate of class 1 is  0.313\n",
      "Positive prediction rate of class 2 is  0.258\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.42799999999999994\n",
      "threshold:0.2, J-value:0.27299999999999996\n",
      "threshold:0.30000000000000004, J-value:0.138\n",
      "threshold:0.4, J-value:0.044\n",
      "threshold:0.5, J-value:0.012\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7139303766000277\n",
      "Balanced accuracy score of test is  0.708775509177688\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.42599999999999993\n",
      "threshold:0.2, J-value:0.27399999999999997\n",
      "threshold:0.30000000000000004, J-value:0.14100000000000001\n",
      "threshold:0.4, J-value:0.047\n",
      "threshold:0.5, J-value:0.012\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7131793223717248\n",
      "Balanced accuracy score of test is  0.7075193485135212\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.43600000000000005\n",
      "threshold:0.2, J-value:0.263\n",
      "threshold:0.30000000000000004, J-value:0.119\n",
      "threshold:0.4, J-value:0.024000000000000004\n",
      "threshold:0.5, J-value:0.01\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.717852000833767\n",
      "Balanced accuracy score of test is  0.7168445724613126\n",
      "True positive rate of class 1 is  0.695\n",
      "True positive rate of class 2 is  0.688\n",
      "Positive prediction rate of class 1 is  0.316\n",
      "Positive prediction rate of class 2 is  0.293\n",
      "X train 65694\n",
      "Y train 65694\n",
      "21898 18920 2978\n",
      "21898 18920 2978\n",
      "21898 18865 3033\n",
      "21898 18865 3033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2582371104483379\n",
      "0.2633338805897585\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19893\n",
      "           1       0.42      0.03      0.06      2005\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.66      0.51      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19799    94]\n",
      " [ 1938    67]]\n",
      "done in 0.552769s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2582371104483379\n",
      "0.26231292886047025\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19907\n",
      "           1       0.49      0.03      0.06      1991\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.70      0.52      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19837    70]\n",
      " [ 1924    67]]\n",
      "done in 0.553341s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2582371104483379\n",
      "0.2618893976431273\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17191\n",
      "           1       0.42      0.03      0.06      1729\n",
      "\n",
      "    accuracy                           0.91     18920\n",
      "   macro avg       0.66      0.51      0.51     18920\n",
      "weighted avg       0.87      0.91      0.87     18920\n",
      "\n",
      "Confusion_matrix\n",
      "[[17113    78]\n",
      " [ 1673    56]]\n",
      "done in 0.541776s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2582371104483379\n",
      "0.2644301021709705\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17135\n",
      "           1       0.47      0.03      0.05      1730\n",
      "\n",
      "    accuracy                           0.91     18865\n",
      "   macro avg       0.69      0.51      0.50     18865\n",
      "weighted avg       0.87      0.91      0.87     18865\n",
      "\n",
      "Confusion_matrix\n",
      "[[17081    54]\n",
      " [ 1683    47]]\n",
      "done in 0.552509s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2582371104483379\n",
      "0.2725110522990473\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95      2702\n",
      "           1       0.41      0.04      0.07       276\n",
      "\n",
      "    accuracy                           0.91      2978\n",
      "   macro avg       0.66      0.52      0.51      2978\n",
      "weighted avg       0.86      0.91      0.87      2978\n",
      "\n",
      "Confusion_matrix\n",
      "[[2686   16]\n",
      " [ 265   11]]\n",
      "done in 0.529106s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2582371104483379\n",
      "0.24914429236110083\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96      2772\n",
      "           1       0.56      0.08      0.13       261\n",
      "\n",
      "    accuracy                           0.92      3033\n",
      "   macro avg       0.74      0.54      0.55      3033\n",
      "weighted avg       0.89      0.92      0.88      3033\n",
      "\n",
      "Confusion_matrix\n",
      "[[2756   16]\n",
      " [ 241   20]]\n",
      "done in 0.532639s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19893\n",
      "           1       0.55      0.01      0.01      2005\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.73      0.50      0.48     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19884     9]\n",
      " [ 1994    11]]\n",
      "done in 17.709035s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19907\n",
      "           1       0.33      0.00      0.00      1991\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.62      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19903     4]\n",
      " [ 1989     2]]\n",
      "done in 17.495222s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17191\n",
      "           1       0.54      0.00      0.01      1729\n",
      "\n",
      "    accuracy                           0.91     18920\n",
      "   macro avg       0.72      0.50      0.48     18920\n",
      "weighted avg       0.88      0.91      0.87     18920\n",
      "\n",
      "Confusion_matrix\n",
      "[[17185     6]\n",
      " [ 1722     7]]\n",
      "done in 17.651040s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17135\n",
      "           1       0.60      0.00      0.00      1730\n",
      "\n",
      "    accuracy                           0.91     18865\n",
      "   macro avg       0.75      0.50      0.48     18865\n",
      "weighted avg       0.88      0.91      0.86     18865\n",
      "\n",
      "Confusion_matrix\n",
      "[[17133     2]\n",
      " [ 1727     3]]\n",
      "done in 17.326374s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2702\n",
      "           1       0.67      0.01      0.01       276\n",
      "\n",
      "    accuracy                           0.91      2978\n",
      "   macro avg       0.79      0.50      0.48      2978\n",
      "weighted avg       0.89      0.91      0.86      2978\n",
      "\n",
      "Confusion_matrix\n",
      "[[2701    1]\n",
      " [ 274    2]]\n",
      "done in 17.250474s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.96      2772\n",
      "           1       0.00      0.00      0.00       261\n",
      "\n",
      "    accuracy                           0.91      3033\n",
      "   macro avg       0.46      0.50      0.48      3033\n",
      "weighted avg       0.84      0.91      0.87      3033\n",
      "\n",
      "Confusion_matrix\n",
      "[[2772    0]\n",
      " [ 261    0]]\n",
      "done in 16.711571s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2638844630577774\n",
      "0.27072063991639456\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19893\n",
      "           1       0.08      0.00      0.00      2005\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.50      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.86     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19882    11]\n",
      " [ 2004     1]]\n",
      "done in 0.548336s\n",
      "0.2638844630577774\n",
      "0.27224900833516935\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19907\n",
      "           1       0.33      0.00      0.00      1991\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.62      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19903     4]\n",
      " [ 1989     2]]\n",
      "done in 0.544960s\n",
      "0.2638844630577774\n",
      "0.26930585598613827\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17191\n",
      "           1       0.10      0.00      0.00      1729\n",
      "\n",
      "    accuracy                           0.91     18920\n",
      "   macro avg       0.50      0.50      0.48     18920\n",
      "weighted avg       0.83      0.91      0.87     18920\n",
      "\n",
      "Confusion_matrix\n",
      "[[17182     9]\n",
      " [ 1728     1]]\n",
      "done in 0.540855s\n",
      "0.2638844630577774\n",
      "0.27463462524827614\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17135\n",
      "           1       0.25      0.00      0.00      1730\n",
      "\n",
      "    accuracy                           0.91     18865\n",
      "   macro avg       0.58      0.50      0.48     18865\n",
      "weighted avg       0.85      0.91      0.86     18865\n",
      "\n",
      "Confusion_matrix\n",
      "[[17132     3]\n",
      " [ 1729     1]]\n",
      "done in 0.539064s\n",
      "0.2638844630577774\n",
      "0.2797091261354845\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2702\n",
      "           1       0.00      0.00      0.00       276\n",
      "\n",
      "    accuracy                           0.91      2978\n",
      "   macro avg       0.45      0.50      0.48      2978\n",
      "weighted avg       0.82      0.91      0.86      2978\n",
      "\n",
      "Confusion_matrix\n",
      "[[2700    2]\n",
      " [ 276    0]]\n",
      "done in 0.525025s\n",
      "0.2638844630577774\n",
      "0.26873190687609205\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2772\n",
      "           1       0.33      0.00      0.01       261\n",
      "\n",
      "    accuracy                           0.91      3033\n",
      "   macro avg       0.62      0.50      0.48      3033\n",
      "weighted avg       0.86      0.91      0.87      3033\n",
      "\n",
      "Confusion_matrix\n",
      "[[2770    2]\n",
      " [ 260    1]]\n",
      "done in 0.519472s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19893\n",
      "           1       0.46      0.02      0.04      2005\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.51      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19846    47]\n",
      " [ 1965    40]]\n",
      "done in 29.988108s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19907\n",
      "           1       0.51      0.02      0.03      1991\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.71      0.51      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19874    33]\n",
      " [ 1957    34]]\n",
      "done in 30.038308s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17191\n",
      "           1       0.46      0.02      0.04      1729\n",
      "\n",
      "    accuracy                           0.91     18920\n",
      "   macro avg       0.68      0.51      0.49     18920\n",
      "weighted avg       0.87      0.91      0.87     18920\n",
      "\n",
      "Confusion_matrix\n",
      "[[17151    40]\n",
      " [ 1695    34]]\n",
      "done in 29.684837s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17135\n",
      "           1       0.44      0.01      0.03      1730\n",
      "\n",
      "    accuracy                           0.91     18865\n",
      "   macro avg       0.67      0.51      0.49     18865\n",
      "weighted avg       0.87      0.91      0.87     18865\n",
      "\n",
      "Confusion_matrix\n",
      "[[17104    31]\n",
      " [ 1706    24]]\n",
      "done in 29.665578s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2702\n",
      "           1       0.46      0.02      0.04       276\n",
      "\n",
      "    accuracy                           0.91      2978\n",
      "   macro avg       0.69      0.51      0.50      2978\n",
      "weighted avg       0.87      0.91      0.87      2978\n",
      "\n",
      "Confusion_matrix\n",
      "[[2695    7]\n",
      " [ 270    6]]\n",
      "done in 29.631129s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2772\n",
      "           1       0.83      0.04      0.07       261\n",
      "\n",
      "    accuracy                           0.92      3033\n",
      "   macro avg       0.88      0.52      0.51      3033\n",
      "weighted avg       0.91      0.92      0.88      3033\n",
      "\n",
      "Confusion_matrix\n",
      "[[2770    2]\n",
      " [ 251   10]]\n",
      "done in 29.509725s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.40800000000000003\n",
      "threshold:0.2, J-value:0.26599999999999996\n",
      "threshold:0.30000000000000004, J-value:0.145\n",
      "threshold:0.4, J-value:0.07\n",
      "threshold:0.5, J-value:0.028\n",
      "threshold:0.6000000000000001, J-value:0.008\n",
      "threshold:0.7000000000000001, J-value:0.005\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.703788610713201\n",
      "Balanced accuracy score of test is  0.6974195957964959\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41100000000000003\n",
      "threshold:0.2, J-value:0.27099999999999996\n",
      "threshold:0.30000000000000004, J-value:0.148\n",
      "threshold:0.4, J-value:0.07\n",
      "threshold:0.5, J-value:0.027\n",
      "threshold:0.6000000000000001, J-value:0.009\n",
      "threshold:0.7000000000000001, J-value:0.006\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7055928864280235\n",
      "Balanced accuracy score of test is  0.6968357366104937\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.386\n",
      "threshold:0.2, J-value:0.23399999999999999\n",
      "threshold:0.30000000000000004, J-value:0.129\n",
      "threshold:0.4, J-value:0.077\n",
      "threshold:0.5, J-value:0.034\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:-0.001\n",
      "threshold:0.8, J-value:-0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6926471534772953\n",
      "Balanced accuracy score of test is  0.701099666616908\n",
      "True positive rate of class 1 is  0.645\n",
      "True positive rate of class 2 is  0.648\n",
      "Positive prediction rate of class 1 is  0.288\n",
      "Positive prediction rate of class 2 is  0.28\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.404\n",
      "threshold:0.2, J-value:0.28500000000000003\n",
      "threshold:0.30000000000000004, J-value:0.11300000000000002\n",
      "threshold:0.4, J-value:0.026\n",
      "threshold:0.5, J-value:0.005\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7019962284506398\n",
      "Balanced accuracy score of test is  0.7005271524139232\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41100000000000003\n",
      "threshold:0.2, J-value:0.29100000000000004\n",
      "threshold:0.30000000000000004, J-value:0.11000000000000001\n",
      "threshold:0.4, J-value:0.024\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7053480779803305\n",
      "Balanced accuracy score of test is  0.6993695930480661\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.37999999999999995\n",
      "threshold:0.2, J-value:0.304\n",
      "threshold:0.30000000000000004, J-value:0.082\n",
      "threshold:0.4, J-value:0.018\n",
      "threshold:0.5, J-value:0.007\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.690116821677984\n",
      "Balanced accuracy score of test is  0.7099131711200677\n",
      "True positive rate of class 1 is  0.737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positive rate of class 2 is  0.77\n",
      "Positive prediction rate of class 1 is  0.375\n",
      "Positive prediction rate of class 2 is  0.386\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.37400000000000005\n",
      "threshold:0.2, J-value:0.21000000000000002\n",
      "threshold:0.30000000000000004, J-value:0.093\n",
      "threshold:0.4, J-value:0.008\n",
      "threshold:0.5, J-value:-0.001\n",
      "threshold:0.6000000000000001, J-value:-0.001\n",
      "threshold:0.7000000000000001, J-value:-0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.687285719246347\n",
      "Balanced accuracy score of test is  0.6872702163503284\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.38099999999999995\n",
      "threshold:0.2, J-value:0.21500000000000002\n",
      "threshold:0.30000000000000004, J-value:0.10099999999999999\n",
      "threshold:0.4, J-value:0.008\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6902225729840546\n",
      "Balanced accuracy score of test is  0.6843686906595194\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.33799999999999997\n",
      "threshold:0.2, J-value:0.182\n",
      "threshold:0.30000000000000004, J-value:0.043\n",
      "threshold:0.4, J-value:0.005\n",
      "threshold:0.5, J-value:-0.001\n",
      "threshold:0.6000000000000001, J-value:-0.001\n",
      "threshold:0.7000000000000001, J-value:-0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6693498642980509\n",
      "Balanced accuracy score of test is  0.7046822908891874\n",
      "True positive rate of class 1 is  0.677\n",
      "True positive rate of class 2 is  0.659\n",
      "Positive prediction rate of class 1 is  0.342\n",
      "Positive prediction rate of class 2 is  0.285\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.42399999999999993\n",
      "threshold:0.2, J-value:0.285\n",
      "threshold:0.30000000000000004, J-value:0.14100000000000001\n",
      "threshold:0.4, J-value:0.060000000000000005\n",
      "threshold:0.5, J-value:0.018000000000000002\n",
      "threshold:0.6000000000000001, J-value:0.006\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7122527341727118\n",
      "Balanced accuracy score of test is  0.7062079755746189\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.42999999999999994\n",
      "threshold:0.2, J-value:0.289\n",
      "threshold:0.30000000000000004, J-value:0.14300000000000002\n",
      "threshold:0.4, J-value:0.060000000000000005\n",
      "threshold:0.5, J-value:0.018000000000000002\n",
      "threshold:0.6000000000000001, J-value:0.008\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7147984948746668\n",
      "Balanced accuracy score of test is  0.7041347105862827\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.393\n",
      "threshold:0.2, J-value:0.26199999999999996\n",
      "threshold:0.30000000000000004, J-value:0.127\n",
      "threshold:0.4, J-value:0.05800000000000001\n",
      "threshold:0.5, J-value:0.019\n",
      "threshold:0.6000000000000001, J-value:-0.001\n",
      "threshold:0.7000000000000001, J-value:-0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.696484890419335\n",
      "Balanced accuracy score of test is  0.7199146638801811\n",
      "True positive rate of class 1 is  0.675\n",
      "True positive rate of class 2 is  0.705\n",
      "Positive prediction rate of class 1 is  0.304\n",
      "Positive prediction rate of class 2 is  0.303\n",
      "X train 65694\n",
      "Y train 65694\n",
      "21898 18905 2993\n",
      "21898 18905 2993\n",
      "21898 18918 2980\n",
      "21898 18918 2980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25971781934116017\n",
      "0.262211723749739\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19931\n",
      "           1       0.50      0.04      0.08      1967\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.71      0.52      0.52     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19849    82]\n",
      " [ 1884    83]]\n",
      "done in 0.527450s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25971781934116017\n",
      "0.2591531352572\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19956\n",
      "           1       0.46      0.03      0.06      1942\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.52      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19876    80]\n",
      " [ 1875    67]]\n",
      "done in 0.533969s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25971781934116017\n",
      "0.26055698870415095\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17217\n",
      "           1       0.52      0.04      0.08      1688\n",
      "\n",
      "    accuracy                           0.91     18905\n",
      "   macro avg       0.72      0.52      0.51     18905\n",
      "weighted avg       0.88      0.91      0.87     18905\n",
      "\n",
      "Confusion_matrix\n",
      "[[17153    64]\n",
      " [ 1619    69]]\n",
      "done in 0.526311s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25971781934116017\n",
      "0.26027395563350075\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17231\n",
      "           1       0.45      0.03      0.05      1687\n",
      "\n",
      "    accuracy                           0.91     18918\n",
      "   macro avg       0.68      0.51      0.50     18918\n",
      "weighted avg       0.87      0.91      0.87     18918\n",
      "\n",
      "Confusion_matrix\n",
      "[[17170    61]\n",
      " [ 1638    49]]\n",
      "done in 0.541580s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25971781934116017\n",
      "0.272663700374143\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95      2714\n",
      "           1       0.44      0.05      0.09       279\n",
      "\n",
      "    accuracy                           0.91      2993\n",
      "   macro avg       0.67      0.52      0.52      2993\n",
      "weighted avg       0.87      0.91      0.87      2993\n",
      "\n",
      "Confusion_matrix\n",
      "[[2696   18]\n",
      " [ 265   14]]\n",
      "done in 0.509136s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25971781934116017\n",
      "0.2520378064387914\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95      2725\n",
      "           1       0.49      0.07      0.12       255\n",
      "\n",
      "    accuracy                           0.91      2980\n",
      "   macro avg       0.70      0.53      0.54      2980\n",
      "weighted avg       0.88      0.91      0.88      2980\n",
      "\n",
      "Confusion_matrix\n",
      "[[2706   19]\n",
      " [ 237   18]]\n",
      "done in 0.493963s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19931\n",
      "           1       0.60      0.00      0.01      1967\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.76      0.50      0.48     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19927     4]\n",
      " [ 1961     6]]\n",
      "done in 17.001315s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19956\n",
      "           1       0.43      0.00      0.00      1942\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19952     4]\n",
      " [ 1939     3]]\n",
      "done in 16.935104s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17217\n",
      "           1       0.45      0.00      0.01      1688\n",
      "\n",
      "    accuracy                           0.91     18905\n",
      "   macro avg       0.68      0.50      0.48     18905\n",
      "weighted avg       0.87      0.91      0.87     18905\n",
      "\n",
      "Confusion_matrix\n",
      "[[17211     6]\n",
      " [ 1683     5]]\n",
      "done in 16.870413s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17231\n",
      "           1       0.57      0.00      0.00      1687\n",
      "\n",
      "    accuracy                           0.91     18918\n",
      "   macro avg       0.74      0.50      0.48     18918\n",
      "weighted avg       0.88      0.91      0.87     18918\n",
      "\n",
      "Confusion_matrix\n",
      "[[17228     3]\n",
      " [ 1683     4]]\n",
      "done in 16.813406s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2714\n",
      "           1       0.33      0.01      0.01       279\n",
      "\n",
      "    accuracy                           0.91      2993\n",
      "   macro avg       0.62      0.50      0.48      2993\n",
      "weighted avg       0.85      0.91      0.86      2993\n",
      "\n",
      "Confusion_matrix\n",
      "[[2710    4]\n",
      " [ 277    2]]\n",
      "done in 16.584462s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2725\n",
      "           1       0.00      0.00      0.00       255\n",
      "\n",
      "    accuracy                           0.91      2980\n",
      "   macro avg       0.46      0.50      0.48      2980\n",
      "weighted avg       0.84      0.91      0.87      2980\n",
      "\n",
      "Confusion_matrix\n",
      "[[2723    2]\n",
      " [ 255    0]]\n",
      "done in 16.661364s\n",
      "0.2649943867570085\n",
      "0.2698423370473158\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19931\n",
      "           1       0.33      0.00      0.01      1967\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.62      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19921    10]\n",
      " [ 1962     5]]\n",
      "done in 0.543857s\n",
      "0.2649943867570085\n",
      "0.2675627714271921\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19956\n",
      "           1       0.35      0.00      0.01      1942\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.63      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19943    13]\n",
      " [ 1935     7]]\n",
      "done in 0.544076s\n",
      "0.2649943867570085\n",
      "0.26939186254002206\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17217\n",
      "           1       0.29      0.00      0.00      1688\n",
      "\n",
      "    accuracy                           0.91     18905\n",
      "   macro avg       0.60      0.50      0.48     18905\n",
      "weighted avg       0.85      0.91      0.87     18905\n",
      "\n",
      "Confusion_matrix\n",
      "[[17212     5]\n",
      " [ 1686     2]]\n",
      "done in 0.540122s\n",
      "0.2649943867570085\n",
      "0.26901786238039543\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17231\n",
      "           1       0.44      0.00      0.00      1687\n",
      "\n",
      "    accuracy                           0.91     18918\n",
      "   macro avg       0.68      0.50      0.48     18918\n",
      "weighted avg       0.87      0.91      0.87     18918\n",
      "\n",
      "Confusion_matrix\n",
      "[[17226     5]\n",
      " [ 1683     4]]\n",
      "done in 0.544989s\n",
      "0.2649943867570085\n",
      "0.2726877164527246\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2714\n",
      "           1       0.38      0.01      0.02       279\n",
      "\n",
      "    accuracy                           0.91      2993\n",
      "   macro avg       0.64      0.50      0.49      2993\n",
      "weighted avg       0.86      0.91      0.86      2993\n",
      "\n",
      "Confusion_matrix\n",
      "[[2709    5]\n",
      " [ 276    3]]\n",
      "done in 0.519960s\n",
      "0.2649943867570085\n",
      "0.2583253853021249\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.95      2725\n",
      "           1       0.27      0.01      0.02       255\n",
      "\n",
      "    accuracy                           0.91      2980\n",
      "   macro avg       0.59      0.50      0.49      2980\n",
      "weighted avg       0.86      0.91      0.87      2980\n",
      "\n",
      "Confusion_matrix\n",
      "[[2717    8]\n",
      " [ 252    3]]\n",
      "done in 0.520879s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19931\n",
      "           1       0.46      0.02      0.04      1967\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19881    50]\n",
      " [ 1925    42]]\n",
      "done in 29.550102s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19956\n",
      "           1       0.43      0.02      0.04      1942\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19900    56]\n",
      " [ 1900    42]]\n",
      "done in 29.864018s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17217\n",
      "           1       0.44      0.02      0.04      1688\n",
      "\n",
      "    accuracy                           0.91     18905\n",
      "   macro avg       0.68      0.51      0.49     18905\n",
      "weighted avg       0.87      0.91      0.87     18905\n",
      "\n",
      "Confusion_matrix\n",
      "[[17176    41]\n",
      " [ 1656    32]]\n",
      "done in 29.551542s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17231\n",
      "           1       0.41      0.02      0.04      1687\n",
      "\n",
      "    accuracy                           0.91     18918\n",
      "   macro avg       0.66      0.51      0.49     18918\n",
      "weighted avg       0.87      0.91      0.87     18918\n",
      "\n",
      "Confusion_matrix\n",
      "[[17184    47]\n",
      " [ 1655    32]]\n",
      "done in 29.529104s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2714\n",
      "           1       0.53      0.04      0.07       279\n",
      "\n",
      "    accuracy                           0.91      2993\n",
      "   macro avg       0.72      0.52      0.51      2993\n",
      "weighted avg       0.87      0.91      0.87      2993\n",
      "\n",
      "Confusion_matrix\n",
      "[[2705    9]\n",
      " [ 269   10]]\n",
      "done in 29.525250s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2725\n",
      "           1       0.50      0.04      0.07       255\n",
      "\n",
      "    accuracy                           0.91      2980\n",
      "   macro avg       0.71      0.52      0.51      2980\n",
      "weighted avg       0.88      0.91      0.88      2980\n",
      "\n",
      "Confusion_matrix\n",
      "[[2716    9]\n",
      " [ 246    9]]\n",
      "done in 29.400131s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.395\n",
      "threshold:0.2, J-value:0.254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.30000000000000004, J-value:0.149\n",
      "threshold:0.4, J-value:0.07200000000000001\n",
      "threshold:0.5, J-value:0.038000000000000006\n",
      "threshold:0.6000000000000001, J-value:0.009999999999999998\n",
      "threshold:0.7000000000000001, J-value:0.003\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6973386092542913\n",
      "Balanced accuracy score of test is  0.6995201750751756\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.392\n",
      "threshold:0.2, J-value:0.247\n",
      "threshold:0.30000000000000004, J-value:0.15\n",
      "threshold:0.4, J-value:0.07200000000000001\n",
      "threshold:0.5, J-value:0.037000000000000005\n",
      "threshold:0.6000000000000001, J-value:0.009999999999999998\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6959635948928468\n",
      "Balanced accuracy score of test is  0.6987705365672221\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41200000000000003\n",
      "threshold:0.2, J-value:0.29700000000000004\n",
      "threshold:0.30000000000000004, J-value:0.142\n",
      "threshold:0.4, J-value:0.074\n",
      "threshold:0.5, J-value:0.043000000000000003\n",
      "threshold:0.6000000000000001, J-value:0.012\n",
      "threshold:0.7000000000000001, J-value:0.006\n",
      "threshold:0.8, J-value:0.003\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7061473363919462\n",
      "Balanced accuracy score of test is  0.7042057924087066\n",
      "True positive rate of class 1 is  0.654\n",
      "True positive rate of class 2 is  0.651\n",
      "Positive prediction rate of class 1 is  0.292\n",
      "Positive prediction rate of class 2 is  0.278\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.368\n",
      "threshold:0.2, J-value:0.275\n",
      "threshold:0.30000000000000004, J-value:0.119\n",
      "threshold:0.4, J-value:0.028\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6838165641978298\n",
      "Balanced accuracy score of test is  0.7032964024458339\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.376\n",
      "threshold:0.2, J-value:0.28400000000000003\n",
      "threshold:0.30000000000000004, J-value:0.11299999999999999\n",
      "threshold:0.4, J-value:0.026\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6877204402570258\n",
      "Balanced accuracy score of test is  0.6979484838966122\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.42\n",
      "threshold:0.2, J-value:0.34700000000000003\n",
      "threshold:0.30000000000000004, J-value:0.11199999999999999\n",
      "threshold:0.4, J-value:0.026000000000000002\n",
      "threshold:0.5, J-value:0.006\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7098504237948458\n",
      "Balanced accuracy score of test is  0.7084079870480302\n",
      "True positive rate of class 1 is  0.742\n",
      "True positive rate of class 2 is  0.765\n",
      "Positive prediction rate of class 1 is  0.381\n",
      "Positive prediction rate of class 2 is  0.384\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.36099999999999993\n",
      "threshold:0.2, J-value:0.20099999999999996\n",
      "threshold:0.30000000000000004, J-value:0.093\n",
      "threshold:0.4, J-value:0.012\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6805777976724325\n",
      "Balanced accuracy score of test is  0.683010862827159\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.3559999999999999\n",
      "threshold:0.2, J-value:0.20299999999999996\n",
      "threshold:0.30000000000000004, J-value:0.095\n",
      "threshold:0.4, J-value:0.012\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6780735252300782\n",
      "Balanced accuracy score of test is  0.68148376241288\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.394\n",
      "threshold:0.2, J-value:0.184\n",
      "threshold:0.30000000000000004, J-value:0.07899999999999999\n",
      "threshold:0.4, J-value:0.018000000000000002\n",
      "threshold:0.5, J-value:0.012\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.696953008824547\n",
      "Balanced accuracy score of test is  0.6920489296636085\n",
      "True positive rate of class 1 is  0.699\n",
      "True positive rate of class 2 is  0.667\n",
      "Positive prediction rate of class 1 is  0.368\n",
      "Positive prediction rate of class 2 is  0.315\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.4\n",
      "threshold:0.2, J-value:0.266\n",
      "threshold:0.30000000000000004, J-value:0.14\n",
      "threshold:0.4, J-value:0.060000000000000005\n",
      "threshold:0.5, J-value:0.018000000000000002\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7001391327788037\n",
      "Balanced accuracy score of test is  0.705527598409601\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.395\n",
      "threshold:0.2, J-value:0.266\n",
      "threshold:0.30000000000000004, J-value:0.14200000000000002\n",
      "threshold:0.4, J-value:0.059000000000000004\n",
      "threshold:0.5, J-value:0.017\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6974152351899519\n",
      "Balanced accuracy score of test is  0.7052201720634399\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.43400000000000005\n",
      "threshold:0.2, J-value:0.266\n",
      "threshold:0.30000000000000004, J-value:0.127\n",
      "threshold:0.4, J-value:0.068\n",
      "threshold:0.5, J-value:0.032999999999999995\n",
      "threshold:0.6000000000000001, J-value:0.009999999999999998\n",
      "threshold:0.7000000000000001, J-value:-0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7170677464256754\n",
      "Balanced accuracy score of test is  0.7071631588415183\n",
      "True positive rate of class 1 is  0.691\n",
      "True positive rate of class 2 is  0.675\n",
      "Positive prediction rate of class 1 is  0.317\n",
      "Positive prediction rate of class 2 is  0.296\n",
      "X train 65694\n",
      "Y train 65694\n",
      "21898 18847 3051\n",
      "21898 18847 3051\n",
      "21898 18817 3081\n",
      "21898 18817 3081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2599660464048286\n",
      "0.2551448535640254\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19973\n",
      "           1       0.50      0.04      0.07      1925\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.71      0.52      0.51     21898\n",
      "weighted avg       0.88      0.91      0.88     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19902    71]\n",
      " [ 1853    72]]\n",
      "done in 0.526724s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2599660464048286\n",
      "0.2649737104347409\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19866\n",
      "           1       0.44      0.03      0.06      2032\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19780    86]\n",
      " [ 1965    67]]\n",
      "done in 0.524349s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2599660464048286\n",
      "0.25506420355805376\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17189\n",
      "           1       0.49      0.03      0.07      1658\n",
      "\n",
      "    accuracy                           0.91     18847\n",
      "   macro avg       0.70      0.52      0.51     18847\n",
      "weighted avg       0.88      0.91      0.88     18847\n",
      "\n",
      "Confusion_matrix\n",
      "[[17129    60]\n",
      " [ 1600    58]]\n",
      "done in 0.528842s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2599660464048286\n",
      "0.26584342030026387\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17067\n",
      "           1       0.43      0.03      0.05      1750\n",
      "\n",
      "    accuracy                           0.91     18817\n",
      "   macro avg       0.67      0.51      0.50     18817\n",
      "weighted avg       0.86      0.91      0.87     18817\n",
      "\n",
      "Confusion_matrix\n",
      "[[17001    66]\n",
      " [ 1701    49]]\n",
      "done in 0.526616s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2599660464048286\n",
      "0.25564305437115337\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.95      2784\n",
      "           1       0.56      0.05      0.10       267\n",
      "\n",
      "    accuracy                           0.91      3051\n",
      "   macro avg       0.74      0.52      0.53      3051\n",
      "weighted avg       0.89      0.91      0.88      3051\n",
      "\n",
      "Confusion_matrix\n",
      "[[2773   11]\n",
      " [ 253   14]]\n",
      "done in 0.512819s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2599660464048286\n",
      "0.2596620160045082\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95      2799\n",
      "           1       0.47      0.06      0.11       282\n",
      "\n",
      "    accuracy                           0.91      3081\n",
      "   macro avg       0.69      0.53      0.53      3081\n",
      "weighted avg       0.87      0.91      0.87      3081\n",
      "\n",
      "Confusion_matrix\n",
      "[[2779   20]\n",
      " [ 264   18]]\n",
      "done in 0.512091s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19973\n",
      "           1       0.50      0.00      0.01      1925\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.71      0.50      0.48     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19968     5]\n",
      " [ 1920     5]]\n",
      "done in 16.822888s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19866\n",
      "           1       0.64      0.00      0.01      2032\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.78      0.50      0.48     21898\n",
      "weighted avg       0.88      0.91      0.86     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19861     5]\n",
      " [ 2023     9]]\n",
      "done in 16.645669s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17189\n",
      "           1       0.29      0.00      0.00      1658\n",
      "\n",
      "    accuracy                           0.91     18847\n",
      "   macro avg       0.60      0.50      0.48     18847\n",
      "weighted avg       0.86      0.91      0.87     18847\n",
      "\n",
      "Confusion_matrix\n",
      "[[17184     5]\n",
      " [ 1656     2]]\n",
      "done in 16.627262s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17067\n",
      "           1       0.70      0.00      0.01      1750\n",
      "\n",
      "    accuracy                           0.91     18817\n",
      "   macro avg       0.80      0.50      0.48     18817\n",
      "weighted avg       0.89      0.91      0.86     18817\n",
      "\n",
      "Confusion_matrix\n",
      "[[17064     3]\n",
      " [ 1743     7]]\n",
      "done in 16.690262s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2784\n",
      "           1       0.00      0.00      0.00       267\n",
      "\n",
      "    accuracy                           0.91      3051\n",
      "   macro avg       0.46      0.50      0.48      3051\n",
      "weighted avg       0.83      0.91      0.87      3051\n",
      "\n",
      "Confusion_matrix\n",
      "[[2784    0]\n",
      " [ 267    0]]\n",
      "done in 16.496783s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2799\n",
      "           1       1.00      0.00      0.01       282\n",
      "\n",
      "    accuracy                           0.91      3081\n",
      "   macro avg       0.95      0.50      0.48      3081\n",
      "weighted avg       0.92      0.91      0.87      3081\n",
      "\n",
      "Confusion_matrix\n",
      "[[2799    0]\n",
      " [ 281    1]]\n",
      "done in 16.503383s\n",
      "0.26553645312445306\n",
      "0.2694114094281803\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19973\n",
      "           1       0.12      0.00      0.00      1925\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.51      0.50      0.48     21898\n",
      "weighted avg       0.84      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19958    15]\n",
      " [ 1923     2]]\n",
      "done in 0.544256s\n",
      "0.26553645312445306\n",
      "0.279841317193865\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19866\n",
      "           1       0.06      0.00      0.00      2032\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.48      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.86     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19849    17]\n",
      " [ 2031     1]]\n",
      "done in 0.539418s\n",
      "0.26553645312445306\n",
      "0.26935524529999305\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17189\n",
      "           1       0.13      0.00      0.00      1658\n",
      "\n",
      "    accuracy                           0.91     18847\n",
      "   macro avg       0.52      0.50      0.48     18847\n",
      "weighted avg       0.84      0.91      0.87     18847\n",
      "\n",
      "Confusion_matrix\n",
      "[[17176    13]\n",
      " [ 1656     2]]\n",
      "done in 0.537713s\n",
      "0.26553645312445306\n",
      "0.28017006368715347\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17067\n",
      "           1       0.07      0.00      0.00      1750\n",
      "\n",
      "    accuracy                           0.91     18817\n",
      "   macro avg       0.49      0.50      0.48     18817\n",
      "weighted avg       0.83      0.91      0.86     18817\n",
      "\n",
      "Confusion_matrix\n",
      "[[17054    13]\n",
      " [ 1749     1]]\n",
      "done in 0.540797s\n",
      "0.26553645312445306\n",
      "0.2697583531593985\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2784\n",
      "           1       0.00      0.00      0.00       267\n",
      "\n",
      "    accuracy                           0.91      3051\n",
      "   macro avg       0.46      0.50      0.48      3051\n",
      "weighted avg       0.83      0.91      0.87      3051\n",
      "\n",
      "Confusion_matrix\n",
      "[[2782    2]\n",
      " [ 267    0]]\n",
      "done in 0.519562s\n",
      "0.26553645312445306\n",
      "0.265852219697231\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2799\n",
      "           1       0.25      0.00      0.01       282\n",
      "\n",
      "    accuracy                           0.91      3081\n",
      "   macro avg       0.58      0.50      0.48      3081\n",
      "weighted avg       0.85      0.91      0.87      3081\n",
      "\n",
      "Confusion_matrix\n",
      "[[2796    3]\n",
      " [ 281    1]]\n",
      "done in 0.520329s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19973\n",
      "           1       0.50      0.02      0.04      1925\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.71      0.51      0.49     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19938    35]\n",
      " [ 1890    35]]\n",
      "done in 30.135925s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19866\n",
      "           1       0.49      0.02      0.04      2032\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.70      0.51      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19825    41]\n",
      " [ 1992    40]]\n",
      "done in 30.584295s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17189\n",
      "           1       0.46      0.02      0.03      1658\n",
      "\n",
      "    accuracy                           0.91     18847\n",
      "   macro avg       0.69      0.51      0.49     18847\n",
      "weighted avg       0.87      0.91      0.87     18847\n",
      "\n",
      "Confusion_matrix\n",
      "[[17159    30]\n",
      " [ 1632    26]]\n",
      "done in 30.814995s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17067\n",
      "           1       0.50      0.02      0.04      1750\n",
      "\n",
      "    accuracy                           0.91     18817\n",
      "   macro avg       0.70      0.51      0.49     18817\n",
      "weighted avg       0.87      0.91      0.87     18817\n",
      "\n",
      "Confusion_matrix\n",
      "[[17032    35]\n",
      " [ 1715    35]]\n",
      "done in 29.773531s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.95      2784\n",
      "           1       0.64      0.03      0.06       267\n",
      "\n",
      "    accuracy                           0.91      3051\n",
      "   macro avg       0.78      0.52      0.51      3051\n",
      "weighted avg       0.89      0.91      0.88      3051\n",
      "\n",
      "Confusion_matrix\n",
      "[[2779    5]\n",
      " [ 258    9]]\n",
      "done in 29.589830s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2799\n",
      "           1       0.45      0.02      0.03       282\n",
      "\n",
      "    accuracy                           0.91      3081\n",
      "   macro avg       0.68      0.51      0.49      3081\n",
      "weighted avg       0.87      0.91      0.87      3081\n",
      "\n",
      "Confusion_matrix\n",
      "[[2793    6]\n",
      " [ 277    5]]\n",
      "done in 30.116621s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.40800000000000003\n",
      "threshold:0.2, J-value:0.261\n",
      "threshold:0.30000000000000004, J-value:0.156\n",
      "threshold:0.4, J-value:0.079\n",
      "threshold:0.5, J-value:0.033\n",
      "threshold:0.6000000000000001, J-value:0.012\n",
      "threshold:0.7000000000000001, J-value:0.003\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7040847091625643\n",
      "Balanced accuracy score of test is  0.7067499391592964\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.406\n",
      "threshold:0.2, J-value:0.26\n",
      "threshold:0.30000000000000004, J-value:0.153\n",
      "threshold:0.4, J-value:0.076\n",
      "threshold:0.5, J-value:0.032\n",
      "threshold:0.6000000000000001, J-value:0.013000000000000001\n",
      "threshold:0.7000000000000001, J-value:0.004\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7032736908285877\n",
      "Balanced accuracy score of test is  0.7066565217755234\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41800000000000004\n",
      "threshold:0.2, J-value:0.26299999999999996\n",
      "threshold:0.30000000000000004, J-value:0.183\n",
      "threshold:0.4, J-value:0.097\n",
      "threshold:0.5, J-value:0.048\n",
      "threshold:0.6000000000000001, J-value:0.006\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7090032932971717\n",
      "Balanced accuracy score of test is  0.7072434684119708\n",
      "True positive rate of class 1 is  0.67\n",
      "True positive rate of class 2 is  0.66\n",
      "Positive prediction rate of class 1 is  0.295\n",
      "Positive prediction rate of class 2 is  0.283\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.40800000000000003\n",
      "threshold:0.2, J-value:0.281\n",
      "threshold:0.30000000000000004, J-value:0.11499999999999999\n",
      "threshold:0.4, J-value:0.027\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7038495215293894\n",
      "Balanced accuracy score of test is  0.705961586329193\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.4\n",
      "threshold:0.2, J-value:0.273\n",
      "threshold:0.30000000000000004, J-value:0.10400000000000001\n",
      "threshold:0.4, J-value:0.022000000000000002\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7003053436775182\n",
      "Balanced accuracy score of test is  0.7025362897488051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.40199999999999997\n",
      "threshold:0.2, J-value:0.263\n",
      "threshold:0.30000000000000004, J-value:0.127\n",
      "threshold:0.4, J-value:0.018\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7008104094020406\n",
      "Balanced accuracy score of test is  0.7137845583148996\n",
      "True positive rate of class 1 is  0.75\n",
      "True positive rate of class 2 is  0.773\n",
      "Positive prediction rate of class 1 is  0.382\n",
      "Positive prediction rate of class 2 is  0.385\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.33799999999999997\n",
      "threshold:0.2, J-value:0.193\n",
      "threshold:0.30000000000000004, J-value:0.067\n",
      "threshold:0.4, J-value:0.054\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.669213113027262\n",
      "Balanced accuracy score of test is  0.6745815814381553\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.33599999999999997\n",
      "threshold:0.2, J-value:0.195\n",
      "threshold:0.30000000000000004, J-value:0.07\n",
      "threshold:0.4, J-value:0.059000000000000004\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.668126202263756\n",
      "Balanced accuracy score of test is  0.6728513338188149\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.35200000000000004\n",
      "threshold:0.2, J-value:0.181\n",
      "threshold:0.30000000000000004, J-value:0.05199999999999999\n",
      "threshold:0.4, J-value:0.025\n",
      "threshold:0.5, J-value:-0.001\n",
      "threshold:0.6000000000000001, J-value:-0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6758362391837789\n",
      "Balanced accuracy score of test is  0.6870196802809514\n",
      "True positive rate of class 1 is  0.579\n",
      "True positive rate of class 2 is  0.574\n",
      "Positive prediction rate of class 1 is  0.266\n",
      "Positive prediction rate of class 2 is  0.235\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41899999999999993\n",
      "threshold:0.2, J-value:0.26299999999999996\n",
      "threshold:0.30000000000000004, J-value:0.14300000000000002\n",
      "threshold:0.4, J-value:0.053\n",
      "threshold:0.5, J-value:0.016\n",
      "threshold:0.6000000000000001, J-value:0.005\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7095491250850987\n",
      "Balanced accuracy score of test is  0.7089998313503624\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.4169999999999999\n",
      "threshold:0.2, J-value:0.26499999999999996\n",
      "threshold:0.30000000000000004, J-value:0.14400000000000002\n",
      "threshold:0.4, J-value:0.049\n",
      "threshold:0.5, J-value:0.014\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7086122489338533\n",
      "Balanced accuracy score of test is  0.7089225991679851\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.43100000000000005\n",
      "threshold:0.2, J-value:0.256\n",
      "threshold:0.30000000000000004, J-value:0.137\n",
      "threshold:0.4, J-value:0.07100000000000001\n",
      "threshold:0.5, J-value:0.032\n",
      "threshold:0.6000000000000001, J-value:0.011\n",
      "threshold:0.7000000000000001, J-value:0.004\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7154405592147746\n",
      "Balanced accuracy score of test is  0.708976610187529\n",
      "True positive rate of class 1 is  0.692\n",
      "True positive rate of class 2 is  0.674\n",
      "Positive prediction rate of class 1 is  0.313\n",
      "Positive prediction rate of class 2 is  0.294\n"
     ]
    }
   ],
   "source": [
    "records_lr = []\n",
    "records_rf = []\n",
    "records_dt = []\n",
    "records_gbt = []\n",
    "for random_state in range(10):\n",
    "    fairness_metrics (X, y, \"Race_W\", random_state)\n",
    "\n",
    "result_lr = pd.DataFrame(records_lr)\n",
    "result_rf = pd.DataFrame(records_rf)\n",
    "result_dt = pd.DataFrame(records_dt)\n",
    "result_gbt = pd.DataFrame(records_gbt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def add_mean_sd(records, result_table, overall_records, type):\n",
    "    records.append({\n",
    "        'auroc': result_table[\"auroc\"].mean(),\n",
    "        'overall threshold': result_table[\"overall threshold\"].mean(),\n",
    "        'white threshold': result_table[\"white threshold\"].mean(),\n",
    "        'black threshold': result_table[\"black threshold\"].mean(),\n",
    "        'overall ba validation': result_table[\"overall ba validation\"].mean(),\n",
    "        'overall ba test': result_table[\"overall ba test\"].mean(),\n",
    "        'white ba validation': result_table[\"white ba validation\"].mean(),\n",
    "        'white ba test': result_table[\"white ba test\"].mean(),\n",
    "        'black ba validation': result_table[\"black ba validation\"].mean(),\n",
    "        'black ba test': result_table[\"black ba test\"].mean(),\n",
    "        'overall precision':result_table[\"overall precision\"].mean(),\n",
    "        'overall recall':result_table[\"overall recall\"].mean(),\n",
    "        'overall tpr':result_table[\"overall tpr\"].mean(),\n",
    "        'overall tnr':result_table[\"overall tnr\"].mean(),\n",
    "        'overall pd':result_table[\"overall pd\"].mean(),\n",
    "        'white precision':result_table[\"white precision\"].mean(),\n",
    "        'white recall':result_table[\"white recall\"].mean(),\n",
    "        'white tpr':result_table[\"white tpr\"].mean(),\n",
    "        'white tnr':result_table[\"white tnr\"].mean(),\n",
    "        'white pd':result_table[\"white pd\"].mean(),\n",
    "        'black precision':result_table[\"black precision\"].mean(),\n",
    "        'black recall':result_table[\"black recall\"].mean(),\n",
    "        'black tpr':result_table[\"black tpr\"].mean(),\n",
    "        'black tnr':result_table[\"black tnr\"].mean(),\n",
    "        'black pd':result_table[\"black pd\"].mean(),\n",
    "        'eod': result_table[\"eod\"].mean(),\n",
    "        'di': result_table[\"di\"].mean(),\n",
    "        })\n",
    "    records.append({\n",
    "        'auroc': result_table[\"auroc\"].std(),\n",
    "        'overall threshold': result_table[\"overall threshold\"].std(),\n",
    "        'white threshold': result_table[\"white threshold\"].std(),\n",
    "        'black threshold': result_table[\"black threshold\"].std(),\n",
    "        'overall ba validation': result_table[\"overall ba validation\"].std(),\n",
    "        'overall ba test': result_table[\"overall ba test\"].std(),\n",
    "        'white ba validation': result_table[\"white ba validation\"].std(),\n",
    "        'white ba test': result_table[\"white ba test\"].std(),\n",
    "        'black ba validation': result_table[\"black ba validation\"].std(),\n",
    "        'black ba test': result_table[\"black ba test\"].std(),\n",
    "        'overall precision':result_table[\"overall precision\"].std(),\n",
    "        'overall recall':result_table[\"overall recall\"].std(),\n",
    "        'overall tpr':result_table[\"overall tpr\"].std(),\n",
    "        'overall tnr':result_table[\"overall tnr\"].std(),\n",
    "        'overall pd':result_table[\"overall pd\"].std(),\n",
    "        'white precision':result_table[\"white precision\"].std(),\n",
    "        'white recall':result_table[\"white recall\"].std(),\n",
    "        'white tpr':result_table[\"white tpr\"].std(),\n",
    "        'white tnr':result_table[\"white tnr\"].std(),\n",
    "        'white pd':result_table[\"white pd\"].std(),\n",
    "        'black precision':result_table[\"black precision\"].std(),\n",
    "        'black recall':result_table[\"black recall\"].std(),\n",
    "        'black tpr':result_table[\"black tpr\"].std(),\n",
    "        'black tnr':result_table[\"black tnr\"].std(),\n",
    "        'black pd':result_table[\"black pd\"].std(),\n",
    "        'eod': result_table[\"eod\"].std(),\n",
    "        'di': result_table[\"di\"].std(),\n",
    "        })\n",
    "    overall_records.append({\n",
    "        'type': type,\n",
    "        'auroc': result_table[\"auroc\"].mean(),\n",
    "        'overall threshold': result_table[\"overall threshold\"].mean(),\n",
    "        'white threshold': result_table[\"white threshold\"].mean(),\n",
    "        'black threshold': result_table[\"black threshold\"].mean(),\n",
    "        'overall ba test': result_table[\"overall ba test\"].mean(),\n",
    "        'white ba test': result_table[\"white ba test\"].mean(),\n",
    "        'black ba test': result_table[\"black ba test\"].mean(),\n",
    "        'overall tpr':result_table[\"overall tpr\"].mean(),\n",
    "        'overall pd':result_table[\"overall pd\"].mean(),\n",
    "        'white tpr':result_table[\"white tpr\"].mean(),\n",
    "        'white pd':result_table[\"white pd\"].mean(),\n",
    "        'black tpr':result_table[\"black tpr\"].mean(),\n",
    "        'black pd':result_table[\"black pd\"].mean(),\n",
    "        'eod': result_table[\"eod\"].mean(),\n",
    "        'di': result_table[\"di\"].mean(),\n",
    "        })\n",
    "    pd_result = pd.DataFrame(records)\n",
    "    return pd_result, overall_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "overall_table = []\n",
    "result_lr, overall_records = add_mean_sd (records_lr, result_lr, overall_table, 'lr')\n",
    "result_rf, overall_records = add_mean_sd (records_rf, result_rf, overall_records, 'rf')\n",
    "result_dt, overall_records = add_mean_sd (records_dt, result_dt, overall_records, 'dt')\n",
    "result_gbt, overall_records = add_mean_sd (records_gbt, result_gbt, overall_records, 'gbt')\n",
    "\n",
    "result_path='/Users/lifuchen/Desktop/research/resample_data/'\n",
    "result_lr.to_csv(path.join(result_path,'race-lr-result.csv'), index=False)\n",
    "result_rf.to_csv(path.join(result_path,'race-rf-result.csv'), index=False)\n",
    "result_dt.to_csv(path.join(result_path,'race-dt-result.csv'), index=False)\n",
    "result_gbt.to_csv(path.join(result_path,'race-gbt-result.csv'), index=False)\n",
    "\n",
    "overall_result = pd.DataFrame(overall_table)\n",
    "result_path='/Users/lifuchen/Desktop/research/resample_result/'\n",
    "overall_result.to_csv(path.join(result_path,'race.csv'), index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
