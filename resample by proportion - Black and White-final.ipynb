{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from os import path\n",
    "import imblearn\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score\n",
    "import sklearn.preprocessing\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import src.lib.utility_classfier as uclf\n",
    "import src.lib.optimal_threhold_related as thres\n",
    "import src.lib.fairness_tests as fair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_path='/Users/lifuchen/Desktop/research/data.csv'\n",
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109490, 87)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df.Class.values\n",
    "X = df.drop(['GRID','Class', 'Race_B'], axis=1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def save_prediction(classifier, characteristic, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_white_scaled, y_val_white, X_test_white_scaled, y_test_white, X_val_black_scaled, y_val_black, X_test_black_scaled, y_test_black):\n",
    "    method_to_call = getattr(uclf, classifier)\n",
    "    y_val_score = method_to_call(X_train_scaled, y_train,X_val_scaled, y_val)\n",
    "    y_test_score = method_to_call(X_train_scaled, y_train,X_test_scaled, y_test)\n",
    "\n",
    "    y_val_score_white = method_to_call(X_train_scaled, y_train, X_val_white_scaled, y_val_white)\n",
    "    y_test_score_white = method_to_call(X_train_scaled, y_train,X_test_white_scaled, y_test_white)\n",
    "\n",
    "    y_val_score_black = method_to_call(X_train_scaled, y_train, X_val_black_scaled, y_val_black)\n",
    "    y_test_score_black = method_to_call(X_train_scaled, y_train,X_test_black_scaled, y_test_black)\n",
    "\n",
    "    my_dict = dict(val_score = y_val_score, test_score = y_test_score, val_1_score = y_val_score_white, test_1_score = y_test_score_white, val_2_score = y_val_score_black, test_2_score = y_test_score_black)\n",
    "    overall_prediction = pd.DataFrame.from_dict(my_dict, orient='index')\n",
    "    overall_prediction = overall_prediction.transpose()\n",
    "\n",
    "    result_path='/Users/lifuchen/Desktop/research/predictions/'\n",
    "    filename = str(classifier) + str(characteristic) + \"prediction.csv\"\n",
    "    overall_prediction.to_csv(path.join(result_path, filename), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_result (classifier, characteristic, records, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_white_scaled, y_val_white, X_test_white_scaled, y_test_white, X_val_black_scaled, y_val_black, X_test_black_scaled, y_test_black):\n",
    "    result_path='/Users/lifuchen/Desktop/research/predictions/'\n",
    "    filename = str(classifier) + characteristic + \"prediction.csv\"\n",
    "    prediction = pd.read_csv(path.join(result_path, filename))\n",
    "    \n",
    "    y_val_score = prediction['val_score'][prediction['val_score'].notna()]\n",
    "    y_test_score = prediction['test_score'][prediction['test_score'].notna()]\n",
    "    \n",
    "    y_val_score_white = prediction['val_1_score'][prediction['val_1_score'].notna()]\n",
    "    y_test_score_white = prediction['test_1_score'][prediction['test_1_score'].notna()]\n",
    "    \n",
    "    y_val_score_black = prediction['val_2_score'][prediction['val_2_score'].notna()]\n",
    "    y_test_score_black = prediction['test_2_score'][prediction['test_2_score'].notna()]\n",
    "    \n",
    "    threshold, ba_val, ba_test = balance_accuracy (y_val, y_val_score,y_test, y_test_score)\n",
    "    auroc = roc_auc_score(y_test, y_test_score)\n",
    "    precision, recall, tpr, tnr, pd_overall = thres.calculate_precision_metrics(y_test, y_test_score,threshold)\n",
    "    \n",
    "    threshold_white, ba_val_white, ba_test_white = balance_accuracy (y_val_white, y_val_score_white,y_test_white, y_test_score_white)\n",
    "    precision_white, recall_white, tpr_white, tnr_white, pd_white = thres.calculate_precision_metrics(y_test_white, y_test_score_white,threshold_white)\n",
    "    \n",
    "    threshold_black, ba_val_black, ba_test_black = balance_accuracy (y_val_black, y_val_score_black, y_test_black, y_test_score_black)\n",
    "    precision_black, recall_black, tpr_black, tnr_black, pd_black = thres.calculate_precision_metrics(y_test_black, y_test_score_black,threshold_black)\n",
    "\n",
    "    eod = fair.get_EOD(y_test_white, y_test_score_white,threshold_white, y_test_black, y_test_score_black, threshold_black)\n",
    "    sp = fair.get_SP(y_test_white, y_test_score_white,threshold_white, y_test_black, y_test_score_black, threshold_black)\n",
    "\n",
    "    records.append({\n",
    "        'auroc': auroc,\n",
    "        'overall threshold': threshold,\n",
    "        'white threshold': threshold_white,\n",
    "        'black threshold': threshold_black,\n",
    "        'overall ba validation': ba_val,\n",
    "        'overall ba test': ba_test,\n",
    "        'white ba validation': ba_val_white,\n",
    "        'white ba test': ba_test_white,\n",
    "        'black ba validation': ba_val_black,\n",
    "        'black ba test': ba_test_black,\n",
    "        'overall precision':precision,\n",
    "        'overall recall':recall,\n",
    "        'overall tpr':tpr,\n",
    "        'overall tnr':tnr,\n",
    "        'overall pd':pd_overall,\n",
    "        'white precision':precision_white,\n",
    "        'white recall':recall_white,\n",
    "        'white tpr':tpr_white,\n",
    "        'white tnr':tnr_white,\n",
    "        'white pd':pd_white,\n",
    "        'black precision':precision_black,\n",
    "        'black recall':recall_black,\n",
    "        'black tpr':tpr_black,\n",
    "        'black tnr':tnr_black,\n",
    "        'black pd':pd_black,\n",
    "        'eod': eod,\n",
    "        'di': sp,\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def balance_accuracy (y_val, y_val_score,y_test, y_test_score):\n",
    "    \n",
    "    threshold, _ = thres.get_optimal_threshold_Jvalue (y_val, y_val_score)\n",
    "    print (\"Optimal threshold by J value is \",threshold)\n",
    "\n",
    "    ba_val = thres.calculate_balanced_accuracy(y_val, y_val_score, threshold)\n",
    "    print (\"Balanced accuracy score of val is \", ba_val)\n",
    "\n",
    "    ba_test = thres.calculate_balanced_accuracy(y_test, y_test_score, threshold)\n",
    "    print (\"Balanced accuracy score of test is \",ba_test)\n",
    "\n",
    "    return threshold, ba_val, ba_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def fairness_metrics (X, y, attribute, random_state):\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, X_val_white, X_val_black, y_val_white, y_val_black, X_test_white, X_test_black, y_test_white, y_test_black \\\n",
    "        = fair.split_by_trait_balance_proportion(X, y, attribute, random_state)\n",
    "    \n",
    "    print(\"X train\", X_train.shape[0])\n",
    "    print(\"Y train\", y_train.shape[0])\n",
    "    print(X_val.shape[0], X_val_white.shape[0], X_val_black.shape[0])\n",
    "    print(y_val.shape[0], y_val_white.shape[0], y_val_black.shape[0])\n",
    "    print(X_test.shape[0], X_test_white.shape[0], X_test_black.shape[0])\n",
    "    print(y_test.shape[0], y_test_white.shape[0], y_test_black.shape[0])\n",
    "\n",
    "    max_abs_scaler = preprocessing.MaxAbsScaler()\n",
    "    X_train_scaled = max_abs_scaler.fit_transform(X_train)\n",
    "    X_test_scaled = max_abs_scaler.transform(X_test)\n",
    "    X_test_white_scaled = max_abs_scaler.transform(X_test_white)\n",
    "    X_test_black_scaled = max_abs_scaler.transform(X_test_black)\n",
    "    X_val_scaled = max_abs_scaler.transform(X_val)\n",
    "    X_val_white_scaled = max_abs_scaler.transform(X_val_white)\n",
    "    X_val_black_scaled = max_abs_scaler.transform(X_val_black)\n",
    "\n",
    "    characteristic = attribute + \"resample-by-proportion\" + str(random_state)\n",
    "    save_prediction (\"logic_regression\", characteristic, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_white_scaled, y_val_white, X_test_white_scaled, y_test_white, X_val_black_scaled, y_val_black, X_test_black_scaled, y_test_black)\n",
    "    save_prediction (\"random_forest\", characteristic, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_white_scaled, y_val_white, X_test_white_scaled, y_test_white, X_val_black_scaled, y_val_black, X_test_black_scaled, y_test_black)\n",
    "    save_prediction (\"decision_tree\", characteristic, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_white_scaled, y_val_white, X_test_white_scaled, y_test_white, X_val_black_scaled, y_val_black, X_test_black_scaled, y_test_black)\n",
    "    save_prediction (\"gradiant_boosting\", characteristic, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_white_scaled, y_val_white, X_test_white_scaled, y_test_white, X_val_black_scaled, y_val_black, X_test_black_scaled, y_test_black)\n",
    "\n",
    "    get_result (\"logic_regression\", characteristic, records_lr, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_white_scaled, y_val_white, X_test_white_scaled, y_test_white, X_val_black_scaled, y_val_black, X_test_black_scaled, y_test_black)\n",
    "    get_result (\"random_forest\", characteristic, records_rf, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_white_scaled, y_val_white, X_test_white_scaled, y_test_white, X_val_black_scaled, y_val_black, X_test_black_scaled, y_test_black)\n",
    "    get_result (\"decision_tree\", characteristic, records_dt, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_white_scaled, y_val_white, X_test_white_scaled, y_test_white, X_val_black_scaled, y_val_black, X_test_black_scaled, y_test_black)\n",
    "    get_result (\"gradiant_boosting\", characteristic, records_gbt, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_white_scaled, y_val_white, X_test_white_scaled, y_test_white, X_val_black_scaled, y_val_black, X_test_black_scaled, y_test_black)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lifuchen/Desktop/research/CVDPrediction-master/src/lib/fairness_tests.py:125: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train ['Class'] = y_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9055, 88)\n",
      "(56639, 88)\n",
      "0.09307098020280058 0.0988475865280149\n",
      "0.0987445678416224\n",
      "(65741, 87)\n",
      "X train 65741\n",
      "Y train 65741\n",
      "21898 18899 2999\n",
      "21898 18899 2999\n",
      "21898 18968 2930\n",
      "21898 18968 2930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2604923064941778\n",
      "0.26193884229301617\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19904\n",
      "           1       0.44      0.03      0.06      1994\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.51      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19825    79]\n",
      " [ 1931    63]]\n",
      "done in 1.231599s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2604923064941778\n",
      "0.2624918992182111\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19934\n",
      "           1       0.42      0.03      0.06      1964\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19845    89]\n",
      " [ 1899    65]]\n",
      "done in 1.164268s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2604923064941778\n",
      "0.2627803492598507\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17180\n",
      "           1       0.45      0.03      0.06      1719\n",
      "\n",
      "    accuracy                           0.91     18899\n",
      "   macro avg       0.68      0.51      0.50     18899\n",
      "weighted avg       0.87      0.91      0.87     18899\n",
      "\n",
      "Confusion_matrix\n",
      "[[17118    62]\n",
      " [ 1668    51]]\n",
      "done in 1.814597s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2604923064941778\n",
      "0.26294153278235627\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17260\n",
      "           1       0.42      0.03      0.06      1708\n",
      "\n",
      "    accuracy                           0.91     18968\n",
      "   macro avg       0.67      0.51      0.50     18968\n",
      "weighted avg       0.87      0.91      0.87     18968\n",
      "\n",
      "Confusion_matrix\n",
      "[[17188    72]\n",
      " [ 1656    52]]\n",
      "done in 1.525741s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2604923064941778\n",
      "0.256635861243931\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95      2724\n",
      "           1       0.41      0.04      0.08       275\n",
      "\n",
      "    accuracy                           0.91      2999\n",
      "   macro avg       0.66      0.52      0.51      2999\n",
      "weighted avg       0.87      0.91      0.87      2999\n",
      "\n",
      "Confusion_matrix\n",
      "[[2707   17]\n",
      " [ 263   12]]\n",
      "done in 1.552738s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2604923064941778\n",
      "0.2595810973599497\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95      2674\n",
      "           1       0.43      0.05      0.09       256\n",
      "\n",
      "    accuracy                           0.91      2930\n",
      "   macro avg       0.67      0.52      0.52      2930\n",
      "weighted avg       0.87      0.91      0.88      2930\n",
      "\n",
      "Confusion_matrix\n",
      "[[2657   17]\n",
      " [ 243   13]]\n",
      "done in 1.582875s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19904\n",
      "           1       0.60      0.00      0.01      1994\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.75      0.50      0.48     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19898     6]\n",
      " [ 1985     9]]\n",
      "done in 22.704571s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19934\n",
      "           1       0.58      0.00      0.01      1964\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.75      0.50      0.48     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19929     5]\n",
      " [ 1957     7]]\n",
      "done in 22.575452s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17180\n",
      "           1       0.31      0.00      0.00      1719\n",
      "\n",
      "    accuracy                           0.91     18899\n",
      "   macro avg       0.61      0.50      0.48     18899\n",
      "weighted avg       0.85      0.91      0.87     18899\n",
      "\n",
      "Confusion_matrix\n",
      "[[17171     9]\n",
      " [ 1715     4]]\n",
      "done in 22.119261s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17260\n",
      "           1       0.38      0.00      0.01      1708\n",
      "\n",
      "    accuracy                           0.91     18968\n",
      "   macro avg       0.64      0.50      0.48     18968\n",
      "weighted avg       0.86      0.91      0.87     18968\n",
      "\n",
      "Confusion_matrix\n",
      "[[17250    10]\n",
      " [ 1702     6]]\n",
      "done in 23.326212s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2724\n",
      "           1       0.50      0.00      0.01       275\n",
      "\n",
      "    accuracy                           0.91      2999\n",
      "   macro avg       0.70      0.50      0.48      2999\n",
      "weighted avg       0.87      0.91      0.87      2999\n",
      "\n",
      "Confusion_matrix\n",
      "[[2723    1]\n",
      " [ 274    1]]\n",
      "done in 23.656160s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2674\n",
      "           1       0.50      0.00      0.01       256\n",
      "\n",
      "    accuracy                           0.91      2930\n",
      "   macro avg       0.71      0.50      0.48      2930\n",
      "weighted avg       0.88      0.91      0.87      2930\n",
      "\n",
      "Confusion_matrix\n",
      "[[2673    1]\n",
      " [ 255    1]]\n",
      "done in 23.300357s\n",
      "0.2660099341853185\n",
      "0.2718957622583863\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19904\n",
      "           1       0.00      0.00      0.00      1994\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.45      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19903     1]\n",
      " [ 1994     0]]\n",
      "done in 0.727504s\n",
      "0.2660099341853185\n",
      "0.27681880821858246\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19934\n",
      "           1       0.00      0.00      0.00      1964\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.46      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19931     3]\n",
      " [ 1964     0]]\n",
      "done in 0.719220s\n",
      "0.2660099341853185\n",
      "0.27082135384554357\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17180\n",
      "           1       0.00      0.00      0.00      1719\n",
      "\n",
      "    accuracy                           0.91     18899\n",
      "   macro avg       0.45      0.50      0.48     18899\n",
      "weighted avg       0.83      0.91      0.87     18899\n",
      "\n",
      "Confusion_matrix\n",
      "[[17180     0]\n",
      " [ 1719     0]]\n",
      "done in 0.770680s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2660099341853185\n",
      "0.277763224668282\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17260\n",
      "           1       0.00      0.00      0.00      1708\n",
      "\n",
      "    accuracy                           0.91     18968\n",
      "   macro avg       0.45      0.50      0.48     18968\n",
      "weighted avg       0.83      0.91      0.87     18968\n",
      "\n",
      "Confusion_matrix\n",
      "[[17257     3]\n",
      " [ 1708     0]]\n",
      "done in 0.696257s\n",
      "0.2660099341853185\n",
      "0.2786664340137434\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2724\n",
      "           1       0.00      0.00      0.00       275\n",
      "\n",
      "    accuracy                           0.91      2999\n",
      "   macro avg       0.45      0.50      0.48      2999\n",
      "weighted avg       0.82      0.91      0.86      2999\n",
      "\n",
      "Confusion_matrix\n",
      "[[2723    1]\n",
      " [ 275    0]]\n",
      "done in 0.709711s\n",
      "0.2660099341853185\n",
      "0.270704920430903\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2674\n",
      "           1       0.00      0.00      0.00       256\n",
      "\n",
      "    accuracy                           0.91      2930\n",
      "   macro avg       0.46      0.50      0.48      2930\n",
      "weighted avg       0.83      0.91      0.87      2930\n",
      "\n",
      "Confusion_matrix\n",
      "[[2674    0]\n",
      " [ 256    0]]\n",
      "done in 0.716707s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19904\n",
      "           1       0.41      0.02      0.03      1994\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.66      0.51      0.49     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19855    49]\n",
      " [ 1960    34]]\n",
      "done in 37.624756s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19934\n",
      "           1       0.45      0.02      0.04      1964\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19882    52]\n",
      " [ 1922    42]]\n",
      "done in 39.034406s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17180\n",
      "           1       0.43      0.02      0.03      1719\n",
      "\n",
      "    accuracy                           0.91     18899\n",
      "   macro avg       0.67      0.51      0.49     18899\n",
      "weighted avg       0.87      0.91      0.87     18899\n",
      "\n",
      "Confusion_matrix\n",
      "[[17141    39]\n",
      " [ 1690    29]]\n",
      "done in 37.314183s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17260\n",
      "           1       0.45      0.02      0.04      1708\n",
      "\n",
      "    accuracy                           0.91     18968\n",
      "   macro avg       0.68      0.51      0.50     18968\n",
      "weighted avg       0.87      0.91      0.87     18968\n",
      "\n",
      "Confusion_matrix\n",
      "[[17214    46]\n",
      " [ 1671    37]]\n",
      "done in 37.225135s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2724\n",
      "           1       0.33      0.02      0.03       275\n",
      "\n",
      "    accuracy                           0.91      2999\n",
      "   macro avg       0.62      0.51      0.49      2999\n",
      "weighted avg       0.86      0.91      0.87      2999\n",
      "\n",
      "Confusion_matrix\n",
      "[[2714   10]\n",
      " [ 270    5]]\n",
      "done in 36.337740s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2674\n",
      "           1       0.45      0.02      0.04       256\n",
      "\n",
      "    accuracy                           0.91      2930\n",
      "   macro avg       0.68      0.51      0.50      2930\n",
      "weighted avg       0.87      0.91      0.87      2930\n",
      "\n",
      "Confusion_matrix\n",
      "[[2668    6]\n",
      " [ 251    5]]\n",
      "done in 37.211745s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41500000000000004\n",
      "threshold:0.2, J-value:0.267\n",
      "threshold:0.30000000000000004, J-value:0.154\n",
      "threshold:0.4, J-value:0.07200000000000001\n",
      "threshold:0.5, J-value:0.028\n",
      "threshold:0.6000000000000001, J-value:0.011\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7073861254180549\n",
      "Balanced accuracy score of test is  0.6993090181305028\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.40800000000000003\n",
      "threshold:0.2, J-value:0.26099999999999995\n",
      "threshold:0.30000000000000004, J-value:0.153\n",
      "threshold:0.4, J-value:0.069\n",
      "threshold:0.5, J-value:0.026\n",
      "threshold:0.6000000000000001, J-value:0.011\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7043735494754578\n",
      "Balanced accuracy score of test is  0.6996991188626354\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.45199999999999996\n",
      "threshold:0.2, J-value:0.31300000000000006\n",
      "threshold:0.30000000000000004, J-value:0.162\n",
      "threshold:0.4, J-value:0.09\n",
      "threshold:0.5, J-value:0.038\n",
      "threshold:0.6000000000000001, J-value:0.009\n",
      "threshold:0.7000000000000001, J-value:-0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7262588439460687\n",
      "Balanced accuracy score of test is  0.6966739902767389\n",
      "True positive rate of class 1 is  0.665\n",
      "True positive rate of class 2 is  0.656\n",
      "Positive prediction rate of class 1 is  0.301\n",
      "Positive prediction rate of class 2 is  0.297\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.40900000000000003\n",
      "threshold:0.2, J-value:0.28500000000000003\n",
      "threshold:0.30000000000000004, J-value:0.10200000000000001\n",
      "threshold:0.4, J-value:0.021\n",
      "threshold:0.5, J-value:0.005\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7045023232881926\n",
      "Balanced accuracy score of test is  0.6888760659667739\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.403\n",
      "threshold:0.2, J-value:0.28\n",
      "threshold:0.30000000000000004, J-value:0.101\n",
      "threshold:0.4, J-value:0.023\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7012657107003084\n",
      "Balanced accuracy score of test is  0.6972235489184562\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.43700000000000006\n",
      "threshold:0.2, J-value:0.339\n",
      "threshold:0.30000000000000004, J-value:0.124\n",
      "threshold:0.4, J-value:0.030000000000000002\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7181330930449873\n",
      "Balanced accuracy score of test is  0.6880346624906507\n",
      "True positive rate of class 1 is  0.745\n",
      "True positive rate of class 2 is  0.742\n",
      "Positive prediction rate of class 1 is  0.386\n",
      "Positive prediction rate of class 2 is  0.399\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.383\n",
      "threshold:0.2, J-value:0.21299999999999997\n",
      "threshold:0.30000000000000004, J-value:0.08499999999999999\n",
      "threshold:0.4, J-value:0.028999999999999998\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6915851805819389\n",
      "Balanced accuracy score of test is  0.6748602107933779\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.379\n",
      "threshold:0.2, J-value:0.20599999999999996\n",
      "threshold:0.30000000000000004, J-value:0.088\n",
      "threshold:0.4, J-value:0.032\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6894823045317655\n",
      "Balanced accuracy score of test is  0.6737388772350685\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41\n",
      "threshold:0.2, J-value:0.263\n",
      "threshold:0.30000000000000004, J-value:0.063\n",
      "threshold:0.4, J-value:0.015\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.705018689093579\n",
      "Balanced accuracy score of test is  0.681174621353777\n",
      "True positive rate of class 1 is  0.714\n",
      "True positive rate of class 2 is  0.648\n",
      "Positive prediction rate of class 1 is  0.398\n",
      "Positive prediction rate of class 2 is  0.318\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.43299999999999994\n",
      "threshold:0.2, J-value:0.27399999999999997\n",
      "threshold:0.30000000000000004, J-value:0.136\n",
      "threshold:0.4, J-value:0.054\n",
      "threshold:0.5, J-value:0.015000000000000001\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7162529590378854\n",
      "Balanced accuracy score of test is  0.6973411443098273\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.42899999999999994\n",
      "threshold:0.2, J-value:0.26399999999999996\n",
      "threshold:0.30000000000000004, J-value:0.132\n",
      "threshold:0.4, J-value:0.052\n",
      "threshold:0.5, J-value:0.015000000000000001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7146670845125459\n",
      "Balanced accuracy score of test is  0.6984215103893884\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.45199999999999996\n",
      "threshold:0.2, J-value:0.33799999999999997\n",
      "threshold:0.30000000000000004, J-value:0.163\n",
      "threshold:0.4, J-value:0.07200000000000001\n",
      "threshold:0.5, J-value:0.013999999999999999\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7263903350687491\n",
      "Balanced accuracy score of test is  0.6898592347606582\n",
      "True positive rate of class 1 is  0.675\n",
      "True positive rate of class 2 is  0.652\n",
      "Positive prediction rate of class 1 is  0.314\n",
      "Positive prediction rate of class 2 is  0.306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lifuchen/Desktop/research/CVDPrediction-master/src/lib/fairness_tests.py:125: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train ['Class'] = y_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8896, 88)\n",
      "(56798, 88)\n",
      "0.09772951628825272 0.10052315442743655\n",
      "0.10044422507403751\n",
      "(65716, 87)\n",
      "X train 65716\n",
      "Y train 65716\n",
      "21898 18825 3073\n",
      "21898 18825 3073\n",
      "21898 18883 3015\n",
      "21898 18883 3015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26278023499042535\n",
      "0.2560416876620835\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.95     19980\n",
      "           1       0.47      0.04      0.07      1918\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.69      0.52      0.51     21898\n",
      "weighted avg       0.88      0.91      0.88     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19900    80]\n",
      " [ 1846    72]]\n",
      "done in 1.289603s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26278023499042535\n",
      "0.25784192743203266\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19972\n",
      "           1       0.44      0.03      0.06      1926\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.52      0.51     21898\n",
      "weighted avg       0.87      0.91      0.88     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19888    84]\n",
      " [ 1860    66]]\n",
      "done in 1.442554s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26278023499042535\n",
      "0.2555892412007264\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17178\n",
      "           1       0.45      0.03      0.06      1647\n",
      "\n",
      "    accuracy                           0.91     18825\n",
      "   macro avg       0.68      0.52      0.51     18825\n",
      "weighted avg       0.87      0.91      0.88     18825\n",
      "\n",
      "Confusion_matrix\n",
      "[[17110    68]\n",
      " [ 1591    56]]\n",
      "done in 1.432050s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26278023499042535\n",
      "0.26065060756239294\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17196\n",
      "           1       0.45      0.03      0.06      1687\n",
      "\n",
      "    accuracy                           0.91     18883\n",
      "   macro avg       0.68      0.52      0.51     18883\n",
      "weighted avg       0.87      0.91      0.87     18883\n",
      "\n",
      "Confusion_matrix\n",
      "[[17125    71]\n",
      " [ 1629    58]]\n",
      "done in 1.196534s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26278023499042535\n",
      "0.2588133455322581\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.95      2802\n",
      "           1       0.57      0.06      0.11       271\n",
      "\n",
      "    accuracy                           0.91      3073\n",
      "   macro avg       0.74      0.53      0.53      3073\n",
      "weighted avg       0.89      0.91      0.88      3073\n",
      "\n",
      "Confusion_matrix\n",
      "[[2790   12]\n",
      " [ 255   16]]\n",
      "done in 1.112309s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26278023499042535\n",
      "0.24025111253929854\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2776\n",
      "           1       0.38      0.03      0.06       239\n",
      "\n",
      "    accuracy                           0.92      3015\n",
      "   macro avg       0.65      0.51      0.51      3015\n",
      "weighted avg       0.88      0.92      0.89      3015\n",
      "\n",
      "Confusion_matrix\n",
      "[[2763   13]\n",
      " [ 231    8]]\n",
      "done in 1.560827s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19980\n",
      "           1       0.78      0.00      0.01      1918\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.85      0.50      0.48     21898\n",
      "weighted avg       0.90      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19978     2]\n",
      " [ 1911     7]]\n",
      "done in 21.937592s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19972\n",
      "           1       0.86      0.00      0.01      1926\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.88      0.50      0.48     21898\n",
      "weighted avg       0.91      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19971     1]\n",
      " [ 1920     6]]\n",
      "done in 22.114864s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17178\n",
      "           1       0.50      0.00      0.00      1647\n",
      "\n",
      "    accuracy                           0.91     18825\n",
      "   macro avg       0.71      0.50      0.48     18825\n",
      "weighted avg       0.88      0.91      0.87     18825\n",
      "\n",
      "Confusion_matrix\n",
      "[[17175     3]\n",
      " [ 1644     3]]\n",
      "done in 22.135015s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17196\n",
      "           1       0.88      0.00      0.01      1687\n",
      "\n",
      "    accuracy                           0.91     18883\n",
      "   macro avg       0.89      0.50      0.48     18883\n",
      "weighted avg       0.91      0.91      0.87     18883\n",
      "\n",
      "Confusion_matrix\n",
      "[[17195     1]\n",
      " [ 1680     7]]\n",
      "done in 21.808341s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2802\n",
      "           1       0.00      0.00      0.00       271\n",
      "\n",
      "    accuracy                           0.91      3073\n",
      "   macro avg       0.46      0.50      0.48      3073\n",
      "weighted avg       0.83      0.91      0.87      3073\n",
      "\n",
      "Confusion_matrix\n",
      "[[2802    0]\n",
      " [ 271    0]]\n",
      "done in 21.697824s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2776\n",
      "           1       0.00      0.00      0.00       239\n",
      "\n",
      "    accuracy                           0.92      3015\n",
      "   macro avg       0.46      0.50      0.48      3015\n",
      "weighted avg       0.85      0.92      0.88      3015\n",
      "\n",
      "Confusion_matrix\n",
      "[[2776    0]\n",
      " [ 239    0]]\n",
      "done in 21.785367s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.267873312153786\n",
      "0.26841213982862927\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19980\n",
      "           1       0.40      0.00      0.00      1918\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.66      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19977     3]\n",
      " [ 1916     2]]\n",
      "done in 0.683696s\n",
      "0.267873312153786\n",
      "0.2693590617881709\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19972\n",
      "           1       0.14      0.00      0.00      1926\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.53      0.50      0.48     21898\n",
      "weighted avg       0.84      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19966     6]\n",
      " [ 1925     1]]\n",
      "done in 0.679691s\n",
      "0.267873312153786\n",
      "0.2653321701780912\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17178\n",
      "           1       0.67      0.00      0.00      1647\n",
      "\n",
      "    accuracy                           0.91     18825\n",
      "   macro avg       0.79      0.50      0.48     18825\n",
      "weighted avg       0.89      0.91      0.87     18825\n",
      "\n",
      "Confusion_matrix\n",
      "[[17177     1]\n",
      " [ 1645     2]]\n",
      "done in 0.687460s\n",
      "0.267873312153786\n",
      "0.27029520704815996\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17196\n",
      "           1       0.25      0.00      0.00      1687\n",
      "\n",
      "    accuracy                           0.91     18883\n",
      "   macro avg       0.58      0.50      0.48     18883\n",
      "weighted avg       0.85      0.91      0.87     18883\n",
      "\n",
      "Confusion_matrix\n",
      "[[17193     3]\n",
      " [ 1686     1]]\n",
      "done in 0.698056s\n",
      "0.267873312153786\n",
      "0.28727983545875585\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2802\n",
      "           1       0.00      0.00      0.00       271\n",
      "\n",
      "    accuracy                           0.91      3073\n",
      "   macro avg       0.46      0.50      0.48      3073\n",
      "weighted avg       0.83      0.91      0.87      3073\n",
      "\n",
      "Confusion_matrix\n",
      "[[2800    2]\n",
      " [ 271    0]]\n",
      "done in 0.602761s\n",
      "0.267873312153786\n",
      "0.24064137702781946\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2776\n",
      "           1       0.00      0.00      0.00       239\n",
      "\n",
      "    accuracy                           0.92      3015\n",
      "   macro avg       0.46      0.50      0.48      3015\n",
      "weighted avg       0.85      0.92      0.88      3015\n",
      "\n",
      "Confusion_matrix\n",
      "[[2775    1]\n",
      " [ 239    0]]\n",
      "done in 0.656115s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19980\n",
      "           1       0.48      0.02      0.03      1918\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.70      0.51      0.49     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19946    34]\n",
      " [ 1886    32]]\n",
      "done in 36.029977s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19972\n",
      "           1       0.43      0.02      0.04      1926\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19921    51]\n",
      " [ 1888    38]]\n",
      "done in 36.211335s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17178\n",
      "           1       0.53      0.02      0.03      1647\n",
      "\n",
      "    accuracy                           0.91     18825\n",
      "   macro avg       0.72      0.51      0.49     18825\n",
      "weighted avg       0.88      0.91      0.87     18825\n",
      "\n",
      "Confusion_matrix\n",
      "[[17152    26]\n",
      " [ 1618    29]]\n",
      "done in 36.128435s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17196\n",
      "           1       0.45      0.02      0.04      1687\n",
      "\n",
      "    accuracy                           0.91     18883\n",
      "   macro avg       0.68      0.51      0.50     18883\n",
      "weighted avg       0.87      0.91      0.87     18883\n",
      "\n",
      "Confusion_matrix\n",
      "[[17153    43]\n",
      " [ 1652    35]]\n",
      "done in 36.500863s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2802\n",
      "           1       0.27      0.01      0.02       271\n",
      "\n",
      "    accuracy                           0.91      3073\n",
      "   macro avg       0.59      0.50      0.49      3073\n",
      "weighted avg       0.86      0.91      0.87      3073\n",
      "\n",
      "Confusion_matrix\n",
      "[[2794    8]\n",
      " [ 268    3]]\n",
      "done in 36.311015s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2776\n",
      "           1       0.38      0.02      0.04       239\n",
      "\n",
      "    accuracy                           0.92      3015\n",
      "   macro avg       0.65      0.51      0.50      3015\n",
      "weighted avg       0.88      0.92      0.89      3015\n",
      "\n",
      "Confusion_matrix\n",
      "[[2768    8]\n",
      " [ 234    5]]\n",
      "done in 35.776475s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41000000000000003\n",
      "threshold:0.2, J-value:0.27699999999999997\n",
      "threshold:0.30000000000000004, J-value:0.154\n",
      "threshold:0.4, J-value:0.07100000000000001\n",
      "threshold:0.5, J-value:0.034\n",
      "threshold:0.6000000000000001, J-value:0.013000000000000001\n",
      "threshold:0.7000000000000001, J-value:0.003\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7050587083433799\n",
      "Balanced accuracy score of test is  0.6990169674720101\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.40800000000000003\n",
      "threshold:0.2, J-value:0.282\n",
      "threshold:0.30000000000000004, J-value:0.154\n",
      "threshold:0.4, J-value:0.066\n",
      "threshold:0.5, J-value:0.030000000000000002\n",
      "threshold:0.6000000000000001, J-value:0.011\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.703978285013597\n",
      "Balanced accuracy score of test is  0.7014256668780445\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.42400000000000004\n",
      "threshold:0.2, J-value:0.241\n",
      "threshold:0.30000000000000004, J-value:0.156\n",
      "threshold:0.4, J-value:0.10200000000000001\n",
      "threshold:0.5, J-value:0.05499999999999999\n",
      "threshold:0.6000000000000001, J-value:0.024\n",
      "threshold:0.7000000000000001, J-value:0.006\n",
      "threshold:0.8, J-value:-0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7117142209965996\n",
      "Balanced accuracy score of test is  0.6803564323007729\n",
      "True positive rate of class 1 is  0.664\n",
      "True positive rate of class 2 is  0.594\n",
      "Positive prediction rate of class 1 is  0.297\n",
      "Positive prediction rate of class 2 is  0.262\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.401\n",
      "threshold:0.2, J-value:0.29200000000000004\n",
      "threshold:0.30000000000000004, J-value:0.11400000000000002\n",
      "threshold:0.4, J-value:0.025\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7005348936005871\n",
      "Balanced accuracy score of test is  0.6955065232550909\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.393\n",
      "threshold:0.2, J-value:0.29100000000000004\n",
      "threshold:0.30000000000000004, J-value:0.122\n",
      "threshold:0.4, J-value:0.023\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6964228719709902\n",
      "Balanced accuracy score of test is  0.6982823337556756\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.40700000000000003\n",
      "threshold:0.2, J-value:0.355\n",
      "threshold:0.30000000000000004, J-value:0.11500000000000002\n",
      "threshold:0.4, J-value:0.024\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy score of val is  0.7035927157986783\n",
      "Balanced accuracy score of test is  0.7088817177721776\n",
      "True positive rate of class 1 is  0.743\n",
      "True positive rate of class 2 is  0.753\n",
      "Positive prediction rate of class 1 is  0.382\n",
      "Positive prediction rate of class 2 is  0.368\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.35800000000000004\n",
      "threshold:0.2, J-value:0.21799999999999997\n",
      "threshold:0.30000000000000004, J-value:0.10700000000000001\n",
      "threshold:0.4, J-value:0.001\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.001\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6794684152348386\n",
      "Balanced accuracy score of test is  0.6874879244233724\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.35100000000000003\n",
      "threshold:0.2, J-value:0.22399999999999998\n",
      "threshold:0.30000000000000004, J-value:0.11500000000000002\n",
      "threshold:0.4, J-value:0.001\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.001\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.675344899361894\n",
      "Balanced accuracy score of test is  0.6839213203936401\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41000000000000003\n",
      "threshold:0.2, J-value:0.182\n",
      "threshold:0.30000000000000004, J-value:0.064\n",
      "threshold:0.4, J-value:-0.001\n",
      "threshold:0.5, J-value:-0.001\n",
      "threshold:0.6000000000000001, J-value:-0.001\n",
      "threshold:0.7000000000000001, J-value:-0.001\n",
      "threshold:0.8, J-value:-0.001\n",
      "threshold:0.9, J-value:-0.001\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7047549062214391\n",
      "Balanced accuracy score of test is  0.7094785851229306\n",
      "True positive rate of class 1 is  0.682\n",
      "True positive rate of class 2 is  0.674\n",
      "Positive prediction rate of class 1 is  0.347\n",
      "Positive prediction rate of class 2 is  0.288\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.4169999999999999\n",
      "threshold:0.2, J-value:0.276\n",
      "threshold:0.30000000000000004, J-value:0.14500000000000002\n",
      "threshold:0.4, J-value:0.053\n",
      "threshold:0.5, J-value:0.015000000000000001\n",
      "threshold:0.6000000000000001, J-value:0.004\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.708470931828596\n",
      "Balanced accuracy score of test is  0.7042260514668615\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.417\n",
      "threshold:0.2, J-value:0.279\n",
      "threshold:0.30000000000000004, J-value:0.149\n",
      "threshold:0.4, J-value:0.05\n",
      "threshold:0.5, J-value:0.016\n",
      "threshold:0.6000000000000001, J-value:0.005\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7080880445844974\n",
      "Balanced accuracy score of test is  0.7035113175435541\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41800000000000004\n",
      "threshold:0.2, J-value:0.255\n",
      "threshold:0.30000000000000004, J-value:0.128\n",
      "threshold:0.4, J-value:0.067\n",
      "threshold:0.5, J-value:0.008\n",
      "threshold:0.6000000000000001, J-value:-0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7090408537918356\n",
      "Balanced accuracy score of test is  0.7072757527160479\n",
      "True positive rate of class 1 is  0.688\n",
      "True positive rate of class 2 is  0.665\n",
      "Positive prediction rate of class 1 is  0.317\n",
      "Positive prediction rate of class 2 is  0.284\n",
      "(8953, 88)\n",
      "(56741, 88)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lifuchen/Desktop/research/CVDPrediction-master/src/lib/fairness_tests.py:125: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train ['Class'] = y_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09624096975633648 0.09822707389772771\n",
      "0.09820007346638912\n",
      "(65710, 87)\n",
      "X train 65710\n",
      "Y train 65710\n",
      "21898 18936 2962\n",
      "21898 18936 2962\n",
      "21898 18829 3069\n",
      "21898 18829 3069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26003082919346904\n",
      "0.2600490790326492\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19950\n",
      "           1       0.47      0.03      0.06      1948\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.69      0.52      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19872    78]\n",
      " [ 1880    68]]\n",
      "done in 1.181340s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26003082919346904\n",
      "0.26235407891595325\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19883\n",
      "           1       0.52      0.03      0.06      2015\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.72      0.51      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19823    60]\n",
      " [ 1950    65]]\n",
      "done in 1.146051s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26003082919346904\n",
      "0.262752981090605\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17239\n",
      "           1       0.44      0.03      0.06      1697\n",
      "\n",
      "    accuracy                           0.91     18936\n",
      "   macro avg       0.68      0.51      0.50     18936\n",
      "weighted avg       0.87      0.91      0.87     18936\n",
      "\n",
      "Confusion_matrix\n",
      "[[17174    65]\n",
      " [ 1645    52]]\n",
      "done in 1.113778s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26003082919346904\n",
      "0.2631951918283704\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17079\n",
      "           1       0.54      0.03      0.06      1750\n",
      "\n",
      "    accuracy                           0.91     18829\n",
      "   macro avg       0.72      0.51      0.50     18829\n",
      "weighted avg       0.87      0.91      0.87     18829\n",
      "\n",
      "Confusion_matrix\n",
      "[[17034    45]\n",
      " [ 1698    52]]\n",
      "done in 1.140813s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26003082919346904\n",
      "0.24276309342513688\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2711\n",
      "           1       0.55      0.06      0.11       251\n",
      "\n",
      "    accuracy                           0.92      2962\n",
      "   macro avg       0.74      0.53      0.54      2962\n",
      "weighted avg       0.89      0.92      0.88      2962\n",
      "\n",
      "Confusion_matrix\n",
      "[[2698   13]\n",
      " [ 235   16]]\n",
      "done in 1.607748s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26003082919346904\n",
      "0.2571936634620913\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95      2804\n",
      "           1       0.46      0.05      0.09       265\n",
      "\n",
      "    accuracy                           0.91      3069\n",
      "   macro avg       0.69      0.52      0.52      3069\n",
      "weighted avg       0.88      0.91      0.88      3069\n",
      "\n",
      "Confusion_matrix\n",
      "[[2789   15]\n",
      " [ 252   13]]\n",
      "done in 1.108017s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19950\n",
      "           1       0.33      0.00      0.00      1948\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.62      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19942     8]\n",
      " [ 1944     4]]\n",
      "done in 21.812113s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19883\n",
      "           1       0.67      0.00      0.01      2015\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.79      0.50      0.48     21898\n",
      "weighted avg       0.89      0.91      0.86     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19879     4]\n",
      " [ 2007     8]]\n",
      "done in 22.702526s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17239\n",
      "           1       0.24      0.00      0.00      1697\n",
      "\n",
      "    accuracy                           0.91     18936\n",
      "   macro avg       0.57      0.50      0.48     18936\n",
      "weighted avg       0.85      0.91      0.87     18936\n",
      "\n",
      "Confusion_matrix\n",
      "[[17226    13]\n",
      " [ 1693     4]]\n",
      "done in 22.336135s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17079\n",
      "           1       0.54      0.00      0.01      1750\n",
      "\n",
      "    accuracy                           0.91     18829\n",
      "   macro avg       0.72      0.50      0.48     18829\n",
      "weighted avg       0.87      0.91      0.86     18829\n",
      "\n",
      "Confusion_matrix\n",
      "[[17073     6]\n",
      " [ 1743     7]]\n",
      "done in 22.317641s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2711\n",
      "           1       1.00      0.01      0.02       251\n",
      "\n",
      "    accuracy                           0.92      2962\n",
      "   macro avg       0.96      0.51      0.49      2962\n",
      "weighted avg       0.92      0.92      0.88      2962\n",
      "\n",
      "Confusion_matrix\n",
      "[[2711    0]\n",
      " [ 248    3]]\n",
      "done in 21.924224s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2804\n",
      "           1       0.00      0.00      0.00       265\n",
      "\n",
      "    accuracy                           0.91      3069\n",
      "   macro avg       0.46      0.50      0.48      3069\n",
      "weighted avg       0.83      0.91      0.87      3069\n",
      "\n",
      "Confusion_matrix\n",
      "[[2803    1]\n",
      " [ 265    0]]\n",
      "done in 21.697332s\n",
      "0.26492006915398814\n",
      "0.27016856556856156\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19950\n",
      "           1       0.00      0.00      0.00      1948\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.46      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19949     1]\n",
      " [ 1948     0]]\n",
      "done in 0.706660s\n",
      "0.26492006915398814\n",
      "0.27964218489224385\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19883\n",
      "           1       0.00      0.00      0.00      2015\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.45      0.50      0.48     21898\n",
      "weighted avg       0.82      0.91      0.86     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19879     4]\n",
      " [ 2015     0]]\n",
      "done in 0.691020s\n",
      "0.26492006915398814\n",
      "0.2730914504879504\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17239\n",
      "           1       0.00      0.00      0.00      1697\n",
      "\n",
      "    accuracy                           0.91     18936\n",
      "   macro avg       0.46      0.50      0.48     18936\n",
      "weighted avg       0.83      0.91      0.87     18936\n",
      "\n",
      "Confusion_matrix\n",
      "[[17238     1]\n",
      " [ 1697     0]]\n",
      "done in 0.663432s\n",
      "0.26492006915398814\n",
      "0.274905779489177\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17079\n",
      "           1       0.00      0.00      0.00      1750\n",
      "\n",
      "    accuracy                           0.91     18829\n",
      "   macro avg       0.45      0.50      0.48     18829\n",
      "weighted avg       0.82      0.91      0.86     18829\n",
      "\n",
      "Confusion_matrix\n",
      "[[17079     0]\n",
      " [ 1750     0]]\n",
      "done in 0.704296s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26492006915398814\n",
      "0.25148262740733723\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2711\n",
      "           1       0.00      0.00      0.00       251\n",
      "\n",
      "    accuracy                           0.92      2962\n",
      "   macro avg       0.46      0.50      0.48      2962\n",
      "weighted avg       0.84      0.92      0.87      2962\n",
      "\n",
      "Confusion_matrix\n",
      "[[2711    0]\n",
      " [ 251    0]]\n",
      "done in 0.598833s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26492006915398814\n",
      "0.29744700761607434\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2804\n",
      "           1       0.00      0.00      0.00       265\n",
      "\n",
      "    accuracy                           0.91      3069\n",
      "   macro avg       0.46      0.50      0.48      3069\n",
      "weighted avg       0.83      0.91      0.87      3069\n",
      "\n",
      "Confusion_matrix\n",
      "[[2801    3]\n",
      " [ 265    0]]\n",
      "done in 0.644059s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19950\n",
      "           1       0.41      0.02      0.03      1948\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.66      0.51      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19901    49]\n",
      " [ 1914    34]]\n",
      "done in 35.975742s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19883\n",
      "           1       0.42      0.01      0.03      2015\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.49     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19845    38]\n",
      " [ 1987    28]]\n",
      "done in 35.937779s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17239\n",
      "           1       0.36      0.01      0.03      1697\n",
      "\n",
      "    accuracy                           0.91     18936\n",
      "   macro avg       0.63      0.51      0.49     18936\n",
      "weighted avg       0.86      0.91      0.87     18936\n",
      "\n",
      "Confusion_matrix\n",
      "[[17196    43]\n",
      " [ 1673    24]]\n",
      "done in 36.458717s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17079\n",
      "           1       0.46      0.01      0.03      1750\n",
      "\n",
      "    accuracy                           0.91     18829\n",
      "   macro avg       0.68      0.51      0.49     18829\n",
      "weighted avg       0.87      0.91      0.87     18829\n",
      "\n",
      "Confusion_matrix\n",
      "[[17052    27]\n",
      " [ 1727    23]]\n",
      "done in 36.445951s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2711\n",
      "           1       0.62      0.04      0.07       251\n",
      "\n",
      "    accuracy                           0.92      2962\n",
      "   macro avg       0.77      0.52      0.52      2962\n",
      "weighted avg       0.89      0.92      0.88      2962\n",
      "\n",
      "Confusion_matrix\n",
      "[[2705    6]\n",
      " [ 241   10]]\n",
      "done in 36.027198s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2804\n",
      "           1       0.31      0.02      0.04       265\n",
      "\n",
      "    accuracy                           0.91      3069\n",
      "   macro avg       0.61      0.51      0.49      3069\n",
      "weighted avg       0.86      0.91      0.87      3069\n",
      "\n",
      "Confusion_matrix\n",
      "[[2793   11]\n",
      " [ 260    5]]\n",
      "done in 35.773188s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.395\n",
      "threshold:0.2, J-value:0.259\n",
      "threshold:0.30000000000000004, J-value:0.14200000000000002\n",
      "threshold:0.4, J-value:0.069\n",
      "threshold:0.5, J-value:0.031000000000000003\n",
      "threshold:0.6000000000000001, J-value:0.012\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6975352909995729\n",
      "Balanced accuracy score of test is  0.7060665313922676\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.386\n",
      "threshold:0.2, J-value:0.251\n",
      "threshold:0.30000000000000004, J-value:0.14\n",
      "threshold:0.4, J-value:0.066\n",
      "threshold:0.5, J-value:0.027\n",
      "threshold:0.6000000000000001, J-value:0.011\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6928490486430793\n",
      "Balanced accuracy score of test is  0.7098146094200899\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.45699999999999996\n",
      "threshold:0.2, J-value:0.316\n",
      "threshold:0.30000000000000004, J-value:0.153\n",
      "threshold:0.4, J-value:0.094\n",
      "threshold:0.5, J-value:0.059000000000000004\n",
      "threshold:0.6000000000000001, J-value:0.018000000000000002\n",
      "threshold:0.7000000000000001, J-value:0.003\n",
      "threshold:0.8, J-value:0.004\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7284282273341162\n",
      "Balanced accuracy score of test is  0.6812989529782252\n",
      "True positive rate of class 1 is  0.673\n",
      "True positive rate of class 2 is  0.615\n",
      "Positive prediction rate of class 1 is  0.292\n",
      "Positive prediction rate of class 2 is  0.284\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.38999999999999996\n",
      "threshold:0.2, J-value:0.28200000000000003\n",
      "threshold:0.30000000000000004, J-value:0.10500000000000001\n",
      "threshold:0.4, J-value:0.024\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6948756387889642\n",
      "Balanced accuracy score of test is  0.6909256245812194\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.376\n",
      "threshold:0.2, J-value:0.28\n",
      "threshold:0.30000000000000004, J-value:0.096\n",
      "threshold:0.4, J-value:0.024\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6878825618536419\n",
      "Balanced accuracy score of test is  0.6986128997181167\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.4749999999999999\n",
      "threshold:0.2, J-value:0.329\n",
      "threshold:0.30000000000000004, J-value:0.14\n",
      "threshold:0.4, J-value:0.035\n",
      "threshold:0.5, J-value:0.012\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7372487181484317\n",
      "Balanced accuracy score of test is  0.6945091917207225\n",
      "True positive rate of class 1 is  0.741\n",
      "True positive rate of class 2 is  0.758\n",
      "Positive prediction rate of class 1 is  0.38\n",
      "Positive prediction rate of class 2 is  0.403\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.35700000000000004\n",
      "threshold:0.2, J-value:0.21299999999999997\n",
      "threshold:0.30000000000000004, J-value:0.071\n",
      "threshold:0.4, J-value:0.003\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6785273759347032\n",
      "Balanced accuracy score of test is  0.684627864571016\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.34800000000000003\n",
      "threshold:0.2, J-value:0.20499999999999996\n",
      "threshold:0.30000000000000004, J-value:0.075\n",
      "threshold:0.4, J-value:0.003\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6740183580808519\n",
      "Balanced accuracy score of test is  0.6848223967612691\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41300000000000003\n",
      "threshold:0.2, J-value:0.26\n",
      "threshold:0.30000000000000004, J-value:0.047\n",
      "threshold:0.4, J-value:0.0\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7067003105247766\n",
      "Balanced accuracy score of test is  0.6811663930234435\n",
      "True positive rate of class 1 is  0.677\n",
      "True positive rate of class 2 is  0.604\n",
      "Positive prediction rate of class 1 is  0.341\n",
      "Positive prediction rate of class 2 is  0.273\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41000000000000003\n",
      "threshold:0.2, J-value:0.26699999999999996\n",
      "threshold:0.30000000000000004, J-value:0.135\n",
      "threshold:0.4, J-value:0.048\n",
      "threshold:0.5, J-value:0.015000000000000001\n",
      "threshold:0.6000000000000001, J-value:0.004\n",
      "threshold:0.7000000000000001, J-value:0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7053028104141257\n",
      "Balanced accuracy score of test is  0.7155300692674977\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.3950000000000001\n",
      "threshold:0.2, J-value:0.263\n",
      "threshold:0.30000000000000004, J-value:0.13\n",
      "threshold:0.4, J-value:0.046\n",
      "threshold:0.5, J-value:0.012\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6977241651333741\n",
      "Balanced accuracy score of test is  0.7176981924334814\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.511\n",
      "threshold:0.2, J-value:0.3\n",
      "threshold:0.30000000000000004, J-value:0.167\n",
      "threshold:0.4, J-value:0.066\n",
      "threshold:0.5, J-value:0.038\n",
      "threshold:0.6000000000000001, J-value:0.011\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7553577648094454\n",
      "Balanced accuracy score of test is  0.7015018975587435\n",
      "True positive rate of class 1 is  0.705\n",
      "True positive rate of class 2 is  0.675\n",
      "Positive prediction rate of class 1 is  0.31\n",
      "Positive prediction rate of class 2 is  0.307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lifuchen/Desktop/research/CVDPrediction-master/src/lib/fairness_tests.py:125: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train ['Class'] = y_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9002, 88)\n",
      "(56692, 88)\n",
      "0.09566699123661149 0.09817139315047264\n",
      "0.0981012658227848\n",
      "(65714, 87)\n",
      "X train 65714\n",
      "Y train 65714\n",
      "21898 18932 2966\n",
      "21898 18932 2966\n",
      "21898 18882 3016\n",
      "21898 18882 3016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2594885582453179\n",
      "0.26296014904277215\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19908\n",
      "           1       0.46      0.04      0.07      1990\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.52      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19820    88]\n",
      " [ 1916    74]]\n",
      "done in 1.177897s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2594885582453179\n",
      "0.2608636681910417\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19918\n",
      "           1       0.44      0.03      0.06      1980\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.52      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19833    85]\n",
      " [ 1912    68]]\n",
      "done in 1.106302s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2594885582453179\n",
      "0.2631469728160943\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17204\n",
      "           1       0.47      0.04      0.07      1728\n",
      "\n",
      "    accuracy                           0.91     18932\n",
      "   macro avg       0.69      0.52      0.51     18932\n",
      "weighted avg       0.87      0.91      0.87     18932\n",
      "\n",
      "Confusion_matrix\n",
      "[[17136    68]\n",
      " [ 1667    61]]\n",
      "done in 1.188234s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2594885582453179\n",
      "0.2632120757564372\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17156\n",
      "           1       0.42      0.03      0.05      1726\n",
      "\n",
      "    accuracy                           0.91     18882\n",
      "   macro avg       0.66      0.51      0.50     18882\n",
      "weighted avg       0.87      0.91      0.87     18882\n",
      "\n",
      "Confusion_matrix\n",
      "[[17086    70]\n",
      " [ 1676    50]]\n",
      "done in 1.564604s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2594885582453179\n",
      "0.26176765151191084\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95      2704\n",
      "           1       0.39      0.05      0.09       262\n",
      "\n",
      "    accuracy                           0.91      2966\n",
      "   macro avg       0.65      0.52      0.52      2966\n",
      "weighted avg       0.87      0.91      0.88      2966\n",
      "\n",
      "Confusion_matrix\n",
      "[[2684   20]\n",
      " [ 249   13]]\n",
      "done in 1.089544s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2594885582453179\n",
      "0.24616120411617515\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96      2762\n",
      "           1       0.55      0.07      0.13       254\n",
      "\n",
      "    accuracy                           0.92      3016\n",
      "   macro avg       0.73      0.53      0.54      3016\n",
      "weighted avg       0.89      0.92      0.89      3016\n",
      "\n",
      "Confusion_matrix\n",
      "[[2747   15]\n",
      " [ 236   18]]\n",
      "done in 1.144924s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19908\n",
      "           1       0.53      0.00      0.01      1990\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.72      0.50      0.48     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19901     7]\n",
      " [ 1982     8]]\n",
      "done in 21.620444s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19918\n",
      "           1       0.43      0.00      0.00      1980\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19914     4]\n",
      " [ 1977     3]]\n",
      "done in 21.971920s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17204\n",
      "           1       0.54      0.00      0.01      1728\n",
      "\n",
      "    accuracy                           0.91     18932\n",
      "   macro avg       0.72      0.50      0.48     18932\n",
      "weighted avg       0.88      0.91      0.87     18932\n",
      "\n",
      "Confusion_matrix\n",
      "[[17198     6]\n",
      " [ 1721     7]]\n",
      "done in 22.104046s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17156\n",
      "           1       0.33      0.00      0.00      1726\n",
      "\n",
      "    accuracy                           0.91     18882\n",
      "   macro avg       0.62      0.50      0.48     18882\n",
      "weighted avg       0.86      0.91      0.87     18882\n",
      "\n",
      "Confusion_matrix\n",
      "[[17152     4]\n",
      " [ 1724     2]]\n",
      "done in 22.849932s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2704\n",
      "           1       0.00      0.00      0.00       262\n",
      "\n",
      "    accuracy                           0.91      2966\n",
      "   macro avg       0.46      0.50      0.48      2966\n",
      "weighted avg       0.83      0.91      0.87      2966\n",
      "\n",
      "Confusion_matrix\n",
      "[[2704    0]\n",
      " [ 262    0]]\n",
      "done in 22.788066s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2762\n",
      "           1       0.00      0.00      0.00       254\n",
      "\n",
      "    accuracy                           0.92      3016\n",
      "   macro avg       0.46      0.50      0.48      3016\n",
      "weighted avg       0.84      0.92      0.88      3016\n",
      "\n",
      "Confusion_matrix\n",
      "[[2760    2]\n",
      " [ 254    0]]\n",
      "done in 22.550440s\n",
      "0.2649198813059806\n",
      "0.2711701793277212\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19908\n",
      "           1       0.00      0.00      0.00      1990\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.45      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19905     3]\n",
      " [ 1990     0]]\n",
      "done in 0.701912s\n",
      "0.2649198813059806\n",
      "0.27020473121508737\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19918\n",
      "           1       0.00      0.00      0.00      1980\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.45      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19915     3]\n",
      " [ 1980     0]]\n",
      "done in 0.735120s\n",
      "0.2649198813059806\n",
      "0.2717805222742531\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17204\n",
      "           1       0.00      0.00      0.00      1728\n",
      "\n",
      "    accuracy                           0.91     18932\n",
      "   macro avg       0.45      0.50      0.48     18932\n",
      "weighted avg       0.83      0.91      0.87     18932\n",
      "\n",
      "Confusion_matrix\n",
      "[[17201     3]\n",
      " [ 1728     0]]\n",
      "done in 0.666763s\n",
      "0.2649198813059806\n",
      "0.27206075434079136\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17156\n",
      "           1       0.00      0.00      0.00      1726\n",
      "\n",
      "    accuracy                           0.91     18882\n",
      "   macro avg       0.45      0.50      0.48     18882\n",
      "weighted avg       0.83      0.91      0.87     18882\n",
      "\n",
      "Confusion_matrix\n",
      "[[17155     1]\n",
      " [ 1726     0]]\n",
      "done in 0.732588s\n",
      "0.2649198813059806\n",
      "0.2672743557728522\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2704\n",
      "           1       0.00      0.00      0.00       262\n",
      "\n",
      "    accuracy                           0.91      2966\n",
      "   macro avg       0.46      0.50      0.48      2966\n",
      "weighted avg       0.83      0.91      0.87      2966\n",
      "\n",
      "Confusion_matrix\n",
      "[[2704    0]\n",
      " [ 262    0]]\n",
      "done in 0.704307s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2649198813059806\n",
      "0.25836094684665445\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2762\n",
      "           1       0.00      0.00      0.00       254\n",
      "\n",
      "    accuracy                           0.92      3016\n",
      "   macro avg       0.46      0.50      0.48      3016\n",
      "weighted avg       0.84      0.92      0.88      3016\n",
      "\n",
      "Confusion_matrix\n",
      "[[2760    2]\n",
      " [ 254    0]]\n",
      "done in 0.750100s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19908\n",
      "           1       0.45      0.02      0.03      1990\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.51      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19865    43]\n",
      " [ 1955    35]]\n",
      "done in 37.408461s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19918\n",
      "           1       0.33      0.01      0.03      1980\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.62      0.51      0.49     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19864    54]\n",
      " [ 1954    26]]\n",
      "done in 56.688656s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17204\n",
      "           1       0.44      0.02      0.03      1728\n",
      "\n",
      "    accuracy                           0.91     18932\n",
      "   macro avg       0.67      0.51      0.49     18932\n",
      "weighted avg       0.87      0.91      0.87     18932\n",
      "\n",
      "Confusion_matrix\n",
      "[[17167    37]\n",
      " [ 1699    29]]\n",
      "done in 80.664848s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17156\n",
      "           1       0.38      0.01      0.03      1726\n",
      "\n",
      "    accuracy                           0.91     18882\n",
      "   macro avg       0.64      0.51      0.49     18882\n",
      "weighted avg       0.86      0.91      0.87     18882\n",
      "\n",
      "Confusion_matrix\n",
      "[[17116    40]\n",
      " [ 1702    24]]\n",
      "done in 39.723705s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2704\n",
      "           1       0.54      0.03      0.05       262\n",
      "\n",
      "    accuracy                           0.91      2966\n",
      "   macro avg       0.73      0.51      0.50      2966\n",
      "weighted avg       0.88      0.91      0.87      2966\n",
      "\n",
      "Confusion_matrix\n",
      "[[2698    6]\n",
      " [ 255    7]]\n",
      "done in 38.170875s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95      2762\n",
      "           1       0.18      0.01      0.02       254\n",
      "\n",
      "    accuracy                           0.91      3016\n",
      "   macro avg       0.55      0.50      0.49      3016\n",
      "weighted avg       0.85      0.91      0.88      3016\n",
      "\n",
      "Confusion_matrix\n",
      "[[2748   14]\n",
      " [ 251    3]]\n",
      "done in 38.448243s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.396\n",
      "threshold:0.2, J-value:0.261\n",
      "threshold:0.30000000000000004, J-value:0.156\n",
      "threshold:0.4, J-value:0.078\n",
      "threshold:0.5, J-value:0.033\n",
      "threshold:0.6000000000000001, J-value:0.015\n",
      "threshold:0.7000000000000001, J-value:0.003\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.697663397356483\n",
      "Balanced accuracy score of test is  0.7098329413220467\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.397\n",
      "threshold:0.2, J-value:0.259\n",
      "threshold:0.30000000000000004, J-value:0.157\n",
      "threshold:0.4, J-value:0.075\n",
      "threshold:0.5, J-value:0.031000000000000003\n",
      "threshold:0.6000000000000001, J-value:0.012\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6983209923187544\n",
      "Balanced accuracy score of test is  0.7096964411100968\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.386\n",
      "threshold:0.2, J-value:0.272\n",
      "threshold:0.30000000000000004, J-value:0.155\n",
      "threshold:0.4, J-value:0.103\n",
      "threshold:0.5, J-value:0.043000000000000003\n",
      "threshold:0.6000000000000001, J-value:0.03\n",
      "threshold:0.7000000000000001, J-value:0.011\n",
      "threshold:0.8, J-value:0.004\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6933324675911288\n",
      "Balanced accuracy score of test is  0.7096919954158518\n",
      "True positive rate of class 1 is  0.672\n",
      "True positive rate of class 2 is  0.646\n",
      "Positive prediction rate of class 1 is  0.291\n",
      "Positive prediction rate of class 2 is  0.262\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.38999999999999996\n",
      "threshold:0.2, J-value:0.279\n",
      "threshold:0.30000000000000004, J-value:0.10900000000000001\n",
      "threshold:0.4, J-value:0.028\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6948676222179816\n",
      "Balanced accuracy score of test is  0.6920946334516974\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.39199999999999996\n",
      "threshold:0.2, J-value:0.269\n",
      "threshold:0.30000000000000004, J-value:0.11300000000000002\n",
      "threshold:0.4, J-value:0.031000000000000003\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6959281379438029\n",
      "Balanced accuracy score of test is  0.6992356892932876\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.385\n",
      "threshold:0.2, J-value:0.311\n",
      "threshold:0.30000000000000004, J-value:0.126\n",
      "threshold:0.4, J-value:0.020999999999999998\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6927734992547089\n",
      "Balanced accuracy score of test is  0.7187148990518111\n",
      "True positive rate of class 1 is  0.739\n",
      "True positive rate of class 2 is  0.776\n",
      "Positive prediction rate of class 1 is  0.377\n",
      "Positive prediction rate of class 2 is  0.375\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.355\n",
      "threshold:0.2, J-value:0.231\n",
      "threshold:0.30000000000000004, J-value:0.101\n",
      "threshold:0.4, J-value:0.003\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6775411112221748\n",
      "Balanced accuracy score of test is  0.6795586652751027\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.355\n",
      "threshold:0.2, J-value:0.23700000000000002\n",
      "threshold:0.30000000000000004, J-value:0.10800000000000001\n",
      "threshold:0.4, J-value:0.002\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6774467554918322\n",
      "Balanced accuracy score of test is  0.6783248910481878\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.356\n",
      "threshold:0.2, J-value:0.189\n",
      "threshold:0.30000000000000004, J-value:0.06\n",
      "threshold:0.4, J-value:0.005\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6779396652965355\n",
      "Balanced accuracy score of test is  0.6868838625439742\n",
      "True positive rate of class 1 is  0.628\n",
      "True positive rate of class 2 is  0.614\n",
      "Positive prediction rate of class 1 is  0.304\n",
      "Positive prediction rate of class 2 is  0.272\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.402\n",
      "threshold:0.2, J-value:0.27699999999999997\n",
      "threshold:0.30000000000000004, J-value:0.14\n",
      "threshold:0.4, J-value:0.056\n",
      "threshold:0.5, J-value:0.016\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7014107608567248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy score of test is  0.7110860842585915\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.404\n",
      "threshold:0.2, J-value:0.27799999999999997\n",
      "threshold:0.30000000000000004, J-value:0.14200000000000002\n",
      "threshold:0.4, J-value:0.056\n",
      "threshold:0.5, J-value:0.015000000000000001\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7019873715845583\n",
      "Balanced accuracy score of test is  0.7088171808720305\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.397\n",
      "threshold:0.2, J-value:0.27\n",
      "threshold:0.30000000000000004, J-value:0.134\n",
      "threshold:0.4, J-value:0.05800000000000001\n",
      "threshold:0.5, J-value:0.025\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6983038980983785\n",
      "Balanced accuracy score of test is  0.725869078095868\n",
      "True positive rate of class 1 is  0.693\n",
      "True positive rate of class 2 is  0.697\n",
      "Positive prediction rate of class 1 is  0.313\n",
      "Positive prediction rate of class 2 is  0.283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lifuchen/Desktop/research/CVDPrediction-master/src/lib/fairness_tests.py:125: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train ['Class'] = y_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9072, 88)\n",
      "(56622, 88)\n",
      "0.09936984973339796 0.10088853459840959\n",
      "0.10082404265632573\n",
      "(65706, 87)\n",
      "X train 65706\n",
      "Y train 65706\n",
      "21898 18875 3023\n",
      "21898 18875 3023\n",
      "21898 19009 2889\n",
      "21898 19009 2889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26344522424062633\n",
      "0.25475182747424246\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95     20006\n",
      "           1       0.38      0.03      0.06      1892\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.65      0.51      0.51     21898\n",
      "weighted avg       0.87      0.91      0.88     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19905   101]\n",
      " [ 1829    63]]\n",
      "done in 1.353804s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26344522424062633\n",
      "0.25633865636730396\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.95     19975\n",
      "           1       0.47      0.04      0.08      1923\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.69      0.52      0.52     21898\n",
      "weighted avg       0.88      0.91      0.88     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19886    89]\n",
      " [ 1843    80]]\n",
      "done in 1.336801s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26344522424062633\n",
      "0.2557042936416006\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.95     17241\n",
      "           1       0.38      0.03      0.06      1634\n",
      "\n",
      "    accuracy                           0.91     18875\n",
      "   macro avg       0.65      0.51      0.50     18875\n",
      "weighted avg       0.87      0.91      0.88     18875\n",
      "\n",
      "Confusion_matrix\n",
      "[[17162    79]\n",
      " [ 1585    49]]\n",
      "done in 1.374882s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26344522424062633\n",
      "0.2597323527117874\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17310\n",
      "           1       0.48      0.04      0.07      1699\n",
      "\n",
      "    accuracy                           0.91     19009\n",
      "   macro avg       0.70      0.52      0.51     19009\n",
      "weighted avg       0.87      0.91      0.87     19009\n",
      "\n",
      "Confusion_matrix\n",
      "[[17245    65]\n",
      " [ 1638    61]]\n",
      "done in 1.322292s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26344522424062633\n",
      "0.24880482155003328\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95      2765\n",
      "           1       0.39      0.05      0.10       258\n",
      "\n",
      "    accuracy                           0.91      3023\n",
      "   macro avg       0.65      0.52      0.52      3023\n",
      "weighted avg       0.87      0.91      0.88      3023\n",
      "\n",
      "Confusion_matrix\n",
      "[[2743   22]\n",
      " [ 244   14]]\n",
      "done in 1.264627s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26344522424062633\n",
      "0.23400886273203747\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      2665\n",
      "           1       0.44      0.08      0.14       224\n",
      "\n",
      "    accuracy                           0.92      2889\n",
      "   macro avg       0.68      0.54      0.55      2889\n",
      "weighted avg       0.89      0.92      0.90      2889\n",
      "\n",
      "Confusion_matrix\n",
      "[[2641   24]\n",
      " [ 205   19]]\n",
      "done in 1.414232s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     20006\n",
      "           1       0.50      0.00      0.00      1892\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.71      0.50      0.48     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[20003     3]\n",
      " [ 1889     3]]\n",
      "done in 24.664388s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19975\n",
      "           1       0.27      0.00      0.00      1923\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.59      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19967     8]\n",
      " [ 1920     3]]\n",
      "done in 23.865872s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17241\n",
      "           1       0.55      0.00      0.01      1634\n",
      "\n",
      "    accuracy                           0.91     18875\n",
      "   macro avg       0.73      0.50      0.48     18875\n",
      "weighted avg       0.88      0.91      0.87     18875\n",
      "\n",
      "Confusion_matrix\n",
      "[[17236     5]\n",
      " [ 1628     6]]\n",
      "done in 23.682524s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17310\n",
      "           1       0.33      0.00      0.00      1699\n",
      "\n",
      "    accuracy                           0.91     19009\n",
      "   macro avg       0.62      0.50      0.48     19009\n",
      "weighted avg       0.86      0.91      0.87     19009\n",
      "\n",
      "Confusion_matrix\n",
      "[[17304     6]\n",
      " [ 1696     3]]\n",
      "done in 23.520196s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.96      2765\n",
      "           1       0.00      0.00      0.00       258\n",
      "\n",
      "    accuracy                           0.91      3023\n",
      "   macro avg       0.46      0.50      0.48      3023\n",
      "weighted avg       0.84      0.91      0.87      3023\n",
      "\n",
      "Confusion_matrix\n",
      "[[2765    0]\n",
      " [ 258    0]]\n",
      "done in 32.654053s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2665\n",
      "           1       1.00      0.01      0.02       224\n",
      "\n",
      "    accuracy                           0.92      2889\n",
      "   macro avg       0.96      0.50      0.49      2889\n",
      "weighted avg       0.93      0.92      0.89      2889\n",
      "\n",
      "Confusion_matrix\n",
      "[[2665    0]\n",
      " [ 222    2]]\n",
      "done in 32.961406s\n",
      "0.26876779382967964\n",
      "0.26675807524478196\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     20006\n",
      "           1       0.50      0.00      0.01      1892\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.71      0.50      0.48     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19997     9]\n",
      " [ 1883     9]]\n",
      "done in 1.037151s\n",
      "0.26876779382967964\n",
      "0.2668530991218994\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19975\n",
      "           1       0.56      0.00      0.01      1923\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.74      0.50      0.48     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19968     7]\n",
      " [ 1914     9]]\n",
      "done in 1.049867s\n",
      "0.26876779382967964\n",
      "0.2679965967162509\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17241\n",
      "           1       0.44      0.00      0.01      1634\n",
      "\n",
      "    accuracy                           0.91     18875\n",
      "   macro avg       0.68      0.50      0.48     18875\n",
      "weighted avg       0.87      0.91      0.87     18875\n",
      "\n",
      "Confusion_matrix\n",
      "[[17232     9]\n",
      " [ 1627     7]]\n",
      "done in 103.190053s\n",
      "0.26876779382967964\n",
      "0.26920472091374603\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17310\n",
      "           1       0.55      0.00      0.01      1699\n",
      "\n",
      "    accuracy                           0.91     19009\n",
      "   macro avg       0.73      0.50      0.48     19009\n",
      "weighted avg       0.88      0.91      0.87     19009\n",
      "\n",
      "Confusion_matrix\n",
      "[[17305     5]\n",
      " [ 1693     6]]\n",
      "done in 1.581066s\n",
      "0.26876779382967964\n",
      "0.25902499791299954\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2765\n",
      "           1       1.00      0.01      0.02       258\n",
      "\n",
      "    accuracy                           0.92      3023\n",
      "   macro avg       0.96      0.50      0.49      3023\n",
      "weighted avg       0.92      0.92      0.88      3023\n",
      "\n",
      "Confusion_matrix\n",
      "[[2765    0]\n",
      " [ 256    2]]\n",
      "done in 1.164196s\n",
      "0.26876779382967964\n",
      "0.25137993240635326\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2665\n",
      "           1       0.60      0.01      0.03       224\n",
      "\n",
      "    accuracy                           0.92      2889\n",
      "   macro avg       0.76      0.51      0.49      2889\n",
      "weighted avg       0.90      0.92      0.89      2889\n",
      "\n",
      "Confusion_matrix\n",
      "[[2663    2]\n",
      " [ 221    3]]\n",
      "done in 1.161710s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.95     20006\n",
      "           1       0.42      0.02      0.04      1892\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.88     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19951    55]\n",
      " [ 1852    40]]\n",
      "done in 87.432633s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19975\n",
      "           1       0.48      0.02      0.05      1923\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.70      0.51      0.50     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19923    52]\n",
      " [ 1875    48]]\n",
      "done in 48.475622s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17241\n",
      "           1       0.38      0.02      0.04      1634\n",
      "\n",
      "    accuracy                           0.91     18875\n",
      "   macro avg       0.65      0.51      0.49     18875\n",
      "weighted avg       0.87      0.91      0.87     18875\n",
      "\n",
      "Confusion_matrix\n",
      "[[17193    48]\n",
      " [ 1604    30]]\n",
      "done in 36.227233s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17310\n",
      "           1       0.48      0.02      0.04      1699\n",
      "\n",
      "    accuracy                           0.91     19009\n",
      "   macro avg       0.70      0.51      0.50     19009\n",
      "weighted avg       0.87      0.91      0.87     19009\n",
      "\n",
      "Confusion_matrix\n",
      "[[17270    40]\n",
      " [ 1662    37]]\n",
      "done in 36.420593s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2765\n",
      "           1       0.55      0.04      0.08       258\n",
      "\n",
      "    accuracy                           0.92      3023\n",
      "   macro avg       0.73      0.52      0.52      3023\n",
      "weighted avg       0.89      0.92      0.88      3023\n",
      "\n",
      "Confusion_matrix\n",
      "[[2756    9]\n",
      " [ 247   11]]\n",
      "done in 38.687498s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96      2665\n",
      "           1       0.50      0.05      0.09       224\n",
      "\n",
      "    accuracy                           0.92      2889\n",
      "   macro avg       0.71      0.52      0.52      2889\n",
      "weighted avg       0.89      0.92      0.89      2889\n",
      "\n",
      "Confusion_matrix\n",
      "[[2654   11]\n",
      " [ 213   11]]\n",
      "done in 37.595302s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.401\n",
      "threshold:0.2, J-value:0.268\n",
      "threshold:0.30000000000000004, J-value:0.149\n",
      "threshold:0.4, J-value:0.068\n",
      "threshold:0.5, J-value:0.028\n",
      "threshold:0.6000000000000001, J-value:0.013\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7007525913473316\n",
      "Balanced accuracy score of test is  0.7051909530699125\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.398\n",
      "threshold:0.2, J-value:0.26499999999999996\n",
      "threshold:0.30000000000000004, J-value:0.14200000000000002\n",
      "threshold:0.4, J-value:0.062\n",
      "threshold:0.5, J-value:0.024999999999999998\n",
      "threshold:0.6000000000000001, J-value:0.011\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6986564469412206\n",
      "Balanced accuracy score of test is  0.7022590343522832\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.42800000000000005\n",
      "threshold:0.2, J-value:0.29400000000000004\n",
      "threshold:0.30000000000000004, J-value:0.191\n",
      "threshold:0.4, J-value:0.103\n",
      "threshold:0.5, J-value:0.046\n",
      "threshold:0.6000000000000001, J-value:0.023\n",
      "threshold:0.7000000000000001, J-value:0.003\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7139604973576125\n",
      "Balanced accuracy score of test is  0.7264314191905655\n",
      "True positive rate of class 1 is  0.666\n",
      "True positive rate of class 2 is  0.701\n",
      "Positive prediction rate of class 1 is  0.298\n",
      "Positive prediction rate of class 2 is  0.283\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.384\n",
      "threshold:0.2, J-value:0.281\n",
      "threshold:0.30000000000000004, J-value:0.11399999999999999\n",
      "threshold:0.4, J-value:0.027\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6919313740761492\n",
      "Balanced accuracy score of test is  0.6962228656855911\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.391\n",
      "threshold:0.2, J-value:0.28800000000000003\n",
      "threshold:0.30000000000000004, J-value:0.11200000000000002\n",
      "threshold:0.4, J-value:0.021\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.695631186995049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy score of test is  0.6935820132752164\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.429\n",
      "threshold:0.2, J-value:0.272\n",
      "threshold:0.30000000000000004, J-value:0.12\n",
      "threshold:0.4, J-value:0.031000000000000003\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7145920069529137\n",
      "Balanced accuracy score of test is  0.7151643326186009\n",
      "True positive rate of class 1 is  0.737\n",
      "True positive rate of class 2 is  0.79\n",
      "Positive prediction rate of class 1 is  0.384\n",
      "Positive prediction rate of class 2 is  0.393\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.35500000000000004\n",
      "threshold:0.2, J-value:0.216\n",
      "threshold:0.30000000000000004, J-value:0.053000000000000005\n",
      "threshold:0.4, J-value:0.049999999999999996\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.005\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.001\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6775105681826108\n",
      "Balanced accuracy score of test is  0.6876722007553644\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.35600000000000004\n",
      "threshold:0.2, J-value:0.215\n",
      "threshold:0.30000000000000004, J-value:0.051000000000000004\n",
      "threshold:0.4, J-value:0.049999999999999996\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6776041490293447\n",
      "Balanced accuracy score of test is  0.6872136870534847\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.353\n",
      "threshold:0.2, J-value:0.221\n",
      "threshold:0.30000000000000004, J-value:0.064\n",
      "threshold:0.4, J-value:0.05\n",
      "threshold:0.5, J-value:0.007\n",
      "threshold:0.6000000000000001, J-value:0.008\n",
      "threshold:0.7000000000000001, J-value:0.004\n",
      "threshold:0.8, J-value:0.004\n",
      "threshold:0.9, J-value:0.004\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6765689614085257\n",
      "Balanced accuracy score of test is  0.688090491825248\n",
      "True positive rate of class 1 is  0.67\n",
      "True positive rate of class 2 is  0.629\n",
      "Positive prediction rate of class 1 is  0.329\n",
      "Positive prediction rate of class 2 is  0.282\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.4119999999999999\n",
      "threshold:0.2, J-value:0.267\n",
      "threshold:0.30000000000000004, J-value:0.149\n",
      "threshold:0.4, J-value:0.066\n",
      "threshold:0.5, J-value:0.018000000000000002\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7060897851152054\n",
      "Balanced accuracy score of test is  0.7088604385226723\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.407\n",
      "threshold:0.2, J-value:0.269\n",
      "threshold:0.30000000000000004, J-value:0.148\n",
      "threshold:0.4, J-value:0.063\n",
      "threshold:0.5, J-value:0.015\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7035231409117928\n",
      "Balanced accuracy score of test is  0.7077303602996154\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.44499999999999995\n",
      "threshold:0.2, J-value:0.251\n",
      "threshold:0.30000000000000004, J-value:0.152\n",
      "threshold:0.4, J-value:0.078\n",
      "threshold:0.5, J-value:0.039999999999999994\n",
      "threshold:0.6000000000000001, J-value:0.015\n",
      "threshold:0.7000000000000001, J-value:0.004\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7223060964156048\n",
      "Balanced accuracy score of test is  0.7159633811310641\n",
      "True positive rate of class 1 is  0.696\n",
      "True positive rate of class 2 is  0.692\n",
      "Positive prediction rate of class 1 is  0.317\n",
      "Positive prediction rate of class 2 is  0.294\n",
      "(9050, 88)\n",
      "(56644, 88)\n",
      "0.09418450006045219 0.09866749422968753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lifuchen/Desktop/research/CVDPrediction-master/src/lib/fairness_tests.py:125: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train ['Class'] = y_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09865796155241205\n",
      "(65731, 87)\n",
      "X train 65731\n",
      "Y train 65731\n",
      "21898 18970 2928\n",
      "21898 18970 2928\n",
      "21898 18892 3006\n",
      "21898 18892 3006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2598358182856293\n",
      "0.2641010244032931\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19911\n",
      "           1       0.43      0.03      0.06      1987\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.52      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19820    91]\n",
      " [ 1918    69]]\n",
      "done in 1.200746s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2598358182856293\n",
      "0.2609736692584873\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19927\n",
      "           1       0.44      0.03      0.06      1971\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19850    77]\n",
      " [ 1911    60]]\n",
      "done in 1.194408s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2598358182856293\n",
      "0.2660176601109082\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17229\n",
      "           1       0.42      0.03      0.06      1741\n",
      "\n",
      "    accuracy                           0.91     18970\n",
      "   macro avg       0.66      0.51      0.50     18970\n",
      "weighted avg       0.87      0.91      0.87     18970\n",
      "\n",
      "Confusion_matrix\n",
      "[[17152    77]\n",
      " [ 1686    55]]\n",
      "done in 1.225098s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2598358182856293\n",
      "0.2606531919068507\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17198\n",
      "           1       0.44      0.03      0.05      1694\n",
      "\n",
      "    accuracy                           0.91     18892\n",
      "   macro avg       0.68      0.51      0.50     18892\n",
      "weighted avg       0.87      0.91      0.87     18892\n",
      "\n",
      "Confusion_matrix\n",
      "[[17143    55]\n",
      " [ 1651    43]]\n",
      "done in 1.343849s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2598358182856293\n",
      "0.25168347680306796\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96      2682\n",
      "           1       0.50      0.06      0.10       246\n",
      "\n",
      "    accuracy                           0.92      2928\n",
      "   macro avg       0.71      0.53      0.53      2928\n",
      "weighted avg       0.88      0.92      0.88      2928\n",
      "\n",
      "Confusion_matrix\n",
      "[[2668   14]\n",
      " [ 232   14]]\n",
      "done in 1.443593s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2598358182856293\n",
      "0.2629877937186066\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95      2729\n",
      "           1       0.44      0.06      0.11       277\n",
      "\n",
      "    accuracy                           0.91      3006\n",
      "   macro avg       0.67      0.53      0.53      3006\n",
      "weighted avg       0.87      0.91      0.87      3006\n",
      "\n",
      "Confusion_matrix\n",
      "[[2707   22]\n",
      " [ 260   17]]\n",
      "done in 1.112765s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19911\n",
      "           1       0.36      0.00      0.00      1987\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.63      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19902     9]\n",
      " [ 1982     5]]\n",
      "done in 22.579595s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19927\n",
      "           1       0.80      0.00      0.01      1971\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.86      0.50      0.48     21898\n",
      "weighted avg       0.90      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19925     2]\n",
      " [ 1963     8]]\n",
      "done in 22.270507s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17229\n",
      "           1       0.38      0.00      0.00      1741\n",
      "\n",
      "    accuracy                           0.91     18970\n",
      "   macro avg       0.64      0.50      0.48     18970\n",
      "weighted avg       0.86      0.91      0.86     18970\n",
      "\n",
      "Confusion_matrix\n",
      "[[17224     5]\n",
      " [ 1738     3]]\n",
      "done in 22.179871s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17198\n",
      "           1       0.78      0.00      0.01      1694\n",
      "\n",
      "    accuracy                           0.91     18892\n",
      "   macro avg       0.84      0.50      0.48     18892\n",
      "weighted avg       0.90      0.91      0.87     18892\n",
      "\n",
      "Confusion_matrix\n",
      "[[17196     2]\n",
      " [ 1687     7]]\n",
      "done in 22.692979s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2682\n",
      "           1       0.40      0.01      0.02       246\n",
      "\n",
      "    accuracy                           0.92      2928\n",
      "   macro avg       0.66      0.50      0.49      2928\n",
      "weighted avg       0.87      0.92      0.88      2928\n",
      "\n",
      "Confusion_matrix\n",
      "[[2679    3]\n",
      " [ 244    2]]\n",
      "done in 21.927702s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2729\n",
      "           1       0.00      0.00      0.00       277\n",
      "\n",
      "    accuracy                           0.91      3006\n",
      "   macro avg       0.45      0.50      0.48      3006\n",
      "weighted avg       0.82      0.91      0.86      3006\n",
      "\n",
      "Confusion_matrix\n",
      "[[2729    0]\n",
      " [ 277    0]]\n",
      "done in 21.717210s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2655504065465148\n",
      "0.27059828342160114\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19911\n",
      "           1       0.32      0.00      0.01      1987\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.61      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19898    13]\n",
      " [ 1981     6]]\n",
      "done in 0.659331s\n",
      "0.2655504065465148\n",
      "0.268983489796189\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19927\n",
      "           1       0.30      0.00      0.01      1971\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.61      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19913    14]\n",
      " [ 1965     6]]\n",
      "done in 0.690035s\n",
      "0.2655504065465148\n",
      "0.27302170531286035\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17229\n",
      "           1       0.31      0.00      0.00      1741\n",
      "\n",
      "    accuracy                           0.91     18970\n",
      "   macro avg       0.61      0.50      0.48     18970\n",
      "weighted avg       0.85      0.91      0.86     18970\n",
      "\n",
      "Confusion_matrix\n",
      "[[17220     9]\n",
      " [ 1737     4]]\n",
      "done in 0.691178s\n",
      "0.2655504065465148\n",
      "0.2688342860770322\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17198\n",
      "           1       0.25      0.00      0.00      1694\n",
      "\n",
      "    accuracy                           0.91     18892\n",
      "   macro avg       0.58      0.50      0.48     18892\n",
      "weighted avg       0.85      0.91      0.87     18892\n",
      "\n",
      "Confusion_matrix\n",
      "[[17189     9]\n",
      " [ 1691     3]]\n",
      "done in 0.662454s\n",
      "0.2655504065465148\n",
      "0.25489735675589476\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2682\n",
      "           1       0.33      0.01      0.02       246\n",
      "\n",
      "    accuracy                           0.92      2928\n",
      "   macro avg       0.62      0.50      0.49      2928\n",
      "weighted avg       0.87      0.92      0.88      2928\n",
      "\n",
      "Confusion_matrix\n",
      "[[2678    4]\n",
      " [ 244    2]]\n",
      "done in 0.681184s\n",
      "0.2655504065465148\n",
      "0.2699211999300251\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2729\n",
      "           1       0.38      0.01      0.02       277\n",
      "\n",
      "    accuracy                           0.91      3006\n",
      "   macro avg       0.64      0.50      0.49      3006\n",
      "weighted avg       0.86      0.91      0.87      3006\n",
      "\n",
      "Confusion_matrix\n",
      "[[2724    5]\n",
      " [ 274    3]]\n",
      "done in 0.686157s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19911\n",
      "           1       0.40      0.02      0.04      1987\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.66      0.51      0.49     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19855    56]\n",
      " [ 1949    38]]\n",
      "done in 36.389999s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19927\n",
      "           1       0.48      0.02      0.04      1971\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.70      0.51      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19888    39]\n",
      " [ 1935    36]]\n",
      "done in 36.740397s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17229\n",
      "           1       0.39      0.02      0.03      1741\n",
      "\n",
      "    accuracy                           0.91     18970\n",
      "   macro avg       0.65      0.51      0.49     18970\n",
      "weighted avg       0.86      0.91      0.87     18970\n",
      "\n",
      "Confusion_matrix\n",
      "[[17183    46]\n",
      " [ 1712    29]]\n",
      "done in 36.292208s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17198\n",
      "           1       0.47      0.02      0.03      1694\n",
      "\n",
      "    accuracy                           0.91     18892\n",
      "   macro avg       0.69      0.51      0.49     18892\n",
      "weighted avg       0.87      0.91      0.87     18892\n",
      "\n",
      "Confusion_matrix\n",
      "[[17168    30]\n",
      " [ 1667    27]]\n",
      "done in 36.334405s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2682\n",
      "           1       0.45      0.04      0.07       246\n",
      "\n",
      "    accuracy                           0.92      2928\n",
      "   macro avg       0.68      0.52      0.51      2928\n",
      "weighted avg       0.88      0.92      0.88      2928\n",
      "\n",
      "Confusion_matrix\n",
      "[[2671   11]\n",
      " [ 237    9]]\n",
      "done in 35.938861s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2729\n",
      "           1       0.50      0.03      0.06       277\n",
      "\n",
      "    accuracy                           0.91      3006\n",
      "   macro avg       0.71      0.51      0.51      3006\n",
      "weighted avg       0.87      0.91      0.87      3006\n",
      "\n",
      "Confusion_matrix\n",
      "[[2720    9]\n",
      " [ 268    9]]\n",
      "done in 35.791142s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.391\n",
      "threshold:0.2, J-value:0.249\n",
      "threshold:0.30000000000000004, J-value:0.143\n",
      "threshold:0.4, J-value:0.07100000000000001\n",
      "threshold:0.5, J-value:0.030000000000000002\n",
      "threshold:0.6000000000000001, J-value:0.013\n",
      "threshold:0.7000000000000001, J-value:0.006\n",
      "threshold:0.8, J-value:0.002\n",
      "threshold:0.9, J-value:0.001\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6956611425119588\n",
      "Balanced accuracy score of test is  0.7075241297402184\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.391\n",
      "threshold:0.2, J-value:0.246\n",
      "threshold:0.30000000000000004, J-value:0.139\n",
      "threshold:0.4, J-value:0.065\n",
      "threshold:0.5, J-value:0.028\n",
      "threshold:0.6000000000000001, J-value:0.012\n",
      "threshold:0.7000000000000001, J-value:0.005\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6955805215876187\n",
      "Balanced accuracy score of test is  0.7072319232639143\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.391\n",
      "threshold:0.2, J-value:0.271\n",
      "threshold:0.30000000000000004, J-value:0.16999999999999998\n",
      "threshold:0.4, J-value:0.11\n",
      "threshold:0.5, J-value:0.052000000000000005\n",
      "threshold:0.6000000000000001, J-value:0.026000000000000002\n",
      "threshold:0.7000000000000001, J-value:0.015\n",
      "threshold:0.8, J-value:0.007\n",
      "threshold:0.9, J-value:0.004\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6958585693239483\n",
      "Balanced accuracy score of test is  0.7093472569658952\n",
      "True positive rate of class 1 is  0.666\n",
      "True positive rate of class 2 is  0.668\n",
      "Positive prediction rate of class 1 is  0.289\n",
      "Positive prediction rate of class 2 is  0.288\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.393\n",
      "threshold:0.2, J-value:0.28300000000000003\n",
      "threshold:0.30000000000000004, J-value:0.11000000000000001\n",
      "threshold:0.4, J-value:0.022\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6962074588739215\n",
      "Balanced accuracy score of test is  0.7017351282460025\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.395\n",
      "threshold:0.2, J-value:0.274\n",
      "threshold:0.30000000000000004, J-value:0.10900000000000001\n",
      "threshold:0.4, J-value:0.025\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6973674450351849\n",
      "Balanced accuracy score of test is  0.7018431277462454\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.39\n",
      "threshold:0.2, J-value:0.312\n",
      "threshold:0.30000000000000004, J-value:0.10400000000000001\n",
      "threshold:0.4, J-value:0.039\n",
      "threshold:0.5, J-value:0.007\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy score of val is  0.6951992506502246\n",
      "Balanced accuracy score of test is  0.7090086026142528\n",
      "True positive rate of class 1 is  0.743\n",
      "True positive rate of class 2 is  0.762\n",
      "Positive prediction rate of class 1 is  0.375\n",
      "Positive prediction rate of class 2 is  0.382\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.348\n",
      "threshold:0.2, J-value:0.20400000000000001\n",
      "threshold:0.30000000000000004, J-value:0.10600000000000001\n",
      "threshold:0.4, J-value:0.004\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.002\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6740769195946623\n",
      "Balanced accuracy score of test is  0.6700628399696437\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.347\n",
      "threshold:0.2, J-value:0.20899999999999996\n",
      "threshold:0.30000000000000004, J-value:0.10700000000000001\n",
      "threshold:0.4, J-value:0.003\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6735025656520175\n",
      "Balanced accuracy score of test is  0.6690458364437368\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.353\n",
      "threshold:0.2, J-value:0.164\n",
      "threshold:0.30000000000000004, J-value:0.09699999999999999\n",
      "threshold:0.4, J-value:0.006\n",
      "threshold:0.5, J-value:0.007\n",
      "threshold:0.6000000000000001, J-value:0.007\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6765382586711772\n",
      "Balanced accuracy score of test is  0.6765169664507305\n",
      "True positive rate of class 1 is  0.603\n",
      "True positive rate of class 2 is  0.599\n",
      "Positive prediction rate of class 1 is  0.295\n",
      "Positive prediction rate of class 2 is  0.279\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.405\n",
      "threshold:0.2, J-value:0.258\n",
      "threshold:0.30000000000000004, J-value:0.14\n",
      "threshold:0.4, J-value:0.049999999999999996\n",
      "threshold:0.5, J-value:0.016\n",
      "threshold:0.6000000000000001, J-value:0.005\n",
      "threshold:0.7000000000000001, J-value:0.003\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7025744052730676\n",
      "Balanced accuracy score of test is  0.712027960910698\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.405\n",
      "threshold:0.2, J-value:0.258\n",
      "threshold:0.30000000000000004, J-value:0.137\n",
      "threshold:0.4, J-value:0.047\n",
      "threshold:0.5, J-value:0.014000000000000002\n",
      "threshold:0.6000000000000001, J-value:0.005\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7023384927080688\n",
      "Balanced accuracy score of test is  0.7110963178634895\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.40700000000000003\n",
      "threshold:0.2, J-value:0.261\n",
      "threshold:0.30000000000000004, J-value:0.159\n",
      "threshold:0.4, J-value:0.066\n",
      "threshold:0.5, J-value:0.033\n",
      "threshold:0.6000000000000001, J-value:0.015\n",
      "threshold:0.7000000000000001, J-value:0.008\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7032429384696532\n",
      "Balanced accuracy score of test is  0.7181350728172999\n",
      "True positive rate of class 1 is  0.697\n",
      "True positive rate of class 2 is  0.693\n",
      "Positive prediction rate of class 1 is  0.313\n",
      "Positive prediction rate of class 2 is  0.297\n",
      "(8944, 88)\n",
      "(56750, 88)\n",
      "0.09594412449454724 0.09967833197690192\n",
      "0.09962014459012376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lifuchen/Desktop/research/CVDPrediction-master/src/lib/fairness_tests.py:125: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train ['Class'] = y_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65724, 87)\n",
      "X train 65724\n",
      "Y train 65724\n",
      "21898 18842 3056\n",
      "21898 18842 3056\n",
      "21898 18914 2984\n",
      "21898 18914 2984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.262571921734257\n",
      "0.2575944814978284\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19944\n",
      "           1       0.43      0.03      0.06      1954\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19863    81]\n",
      " [ 1892    62]]\n",
      "done in 1.171351s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.262571921734257\n",
      "0.2583033257535221\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19955\n",
      "           1       0.48      0.04      0.07      1943\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.70      0.52      0.51     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19880    75]\n",
      " [ 1873    70]]\n",
      "done in 1.138417s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.262571921734257\n",
      "0.25828492523572344\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17147\n",
      "           1       0.45      0.03      0.06      1695\n",
      "\n",
      "    accuracy                           0.91     18842\n",
      "   macro avg       0.68      0.51      0.51     18842\n",
      "weighted avg       0.87      0.91      0.87     18842\n",
      "\n",
      "Confusion_matrix\n",
      "[[17080    67]\n",
      " [ 1641    54]]\n",
      "done in 1.718944s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.262571921734257\n",
      "0.2598675641915402\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17231\n",
      "           1       0.44      0.03      0.06      1683\n",
      "\n",
      "    accuracy                           0.91     18914\n",
      "   macro avg       0.68      0.51      0.50     18914\n",
      "weighted avg       0.87      0.91      0.87     18914\n",
      "\n",
      "Confusion_matrix\n",
      "[[17166    65]\n",
      " [ 1632    51]]\n",
      "done in 1.143627s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.262571921734257\n",
      "0.2533374982159503\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95      2797\n",
      "           1       0.36      0.03      0.06       259\n",
      "\n",
      "    accuracy                           0.91      3056\n",
      "   macro avg       0.64      0.51      0.51      3056\n",
      "weighted avg       0.87      0.91      0.88      3056\n",
      "\n",
      "Confusion_matrix\n",
      "[[2783   14]\n",
      " [ 251    8]]\n",
      "done in 1.101697s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.262571921734257\n",
      "0.24838844444766595\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2724\n",
      "           1       0.66      0.07      0.13       260\n",
      "\n",
      "    accuracy                           0.92      2984\n",
      "   macro avg       0.79      0.53      0.54      2984\n",
      "weighted avg       0.90      0.92      0.88      2984\n",
      "\n",
      "Confusion_matrix\n",
      "[[2714   10]\n",
      " [ 241   19]]\n",
      "done in 1.188740s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19944\n",
      "           1       0.60      0.00      0.01      1954\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.76      0.50      0.48     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19940     4]\n",
      " [ 1948     6]]\n",
      "done in 22.040329s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19955\n",
      "           1       0.38      0.00      0.01      1943\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.65      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19947     8]\n",
      " [ 1938     5]]\n",
      "done in 21.919125s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17147\n",
      "           1       0.38      0.00      0.00      1695\n",
      "\n",
      "    accuracy                           0.91     18842\n",
      "   macro avg       0.64      0.50      0.48     18842\n",
      "weighted avg       0.86      0.91      0.87     18842\n",
      "\n",
      "Confusion_matrix\n",
      "[[17142     5]\n",
      " [ 1692     3]]\n",
      "done in 21.564958s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17231\n",
      "           1       0.42      0.00      0.01      1683\n",
      "\n",
      "    accuracy                           0.91     18914\n",
      "   macro avg       0.66      0.50      0.48     18914\n",
      "weighted avg       0.87      0.91      0.87     18914\n",
      "\n",
      "Confusion_matrix\n",
      "[[17224     7]\n",
      " [ 1678     5]]\n",
      "done in 21.694556s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2797\n",
      "           1       0.00      0.00      0.00       259\n",
      "\n",
      "    accuracy                           0.91      3056\n",
      "   macro avg       0.46      0.50      0.48      3056\n",
      "weighted avg       0.84      0.91      0.87      3056\n",
      "\n",
      "Confusion_matrix\n",
      "[[2796    1]\n",
      " [ 259    0]]\n",
      "done in 21.983531s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2724\n",
      "           1       0.00      0.00      0.00       260\n",
      "\n",
      "    accuracy                           0.91      2984\n",
      "   macro avg       0.46      0.50      0.48      2984\n",
      "weighted avg       0.83      0.91      0.87      2984\n",
      "\n",
      "Confusion_matrix\n",
      "[[2723    1]\n",
      " [ 260    0]]\n",
      "done in 21.907404s\n",
      "0.2679744895384517\n",
      "0.27232885676708357\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19944\n",
      "           1       0.38      0.01      0.02      1954\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.65      0.51      0.49     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19903    41]\n",
      " [ 1929    25]]\n",
      "done in 0.688793s\n",
      "0.2679744895384517\n",
      "0.27450815380961796\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19955\n",
      "           1       0.42      0.01      0.02      1943\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19921    34]\n",
      " [ 1918    25]]\n",
      "done in 0.718439s\n",
      "0.2679744895384517\n",
      "0.27131781936306565\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17147\n",
      "           1       0.38      0.01      0.02      1695\n",
      "\n",
      "    accuracy                           0.91     18842\n",
      "   macro avg       0.64      0.51      0.49     18842\n",
      "weighted avg       0.86      0.91      0.87     18842\n",
      "\n",
      "Confusion_matrix\n",
      "[[17112    35]\n",
      " [ 1674    21]]\n",
      "done in 0.655167s\n",
      "0.2679744895384517\n",
      "0.27459069608508674\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17231\n",
      "           1       0.43      0.01      0.03      1683\n",
      "\n",
      "    accuracy                           0.91     18914\n",
      "   macro avg       0.67      0.51      0.49     18914\n",
      "weighted avg       0.87      0.91      0.87     18914\n",
      "\n",
      "Confusion_matrix\n",
      "[[17201    30]\n",
      " [ 1660    23]]\n",
      "done in 0.680293s\n",
      "0.2679744895384517\n",
      "0.2785624846357044\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2797\n",
      "           1       0.40      0.02      0.03       259\n",
      "\n",
      "    accuracy                           0.91      3056\n",
      "   macro avg       0.66      0.51      0.49      3056\n",
      "weighted avg       0.87      0.91      0.88      3056\n",
      "\n",
      "Confusion_matrix\n",
      "[[2791    6]\n",
      " [ 255    4]]\n",
      "done in 0.621937s\n",
      "0.2679744895384517\n",
      "0.26245521751117235\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2724\n",
      "           1       0.40      0.01      0.02       260\n",
      "\n",
      "    accuracy                           0.91      2984\n",
      "   macro avg       0.66      0.50      0.48      2984\n",
      "weighted avg       0.87      0.91      0.87      2984\n",
      "\n",
      "Confusion_matrix\n",
      "[[2721    3]\n",
      " [ 258    2]]\n",
      "done in 0.655141s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19944\n",
      "           1       0.38      0.01      0.02      1954\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.64      0.51      0.49     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19904    40]\n",
      " [ 1930    24]]\n",
      "done in 35.700603s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19955\n",
      "           1       0.53      0.02      0.04      1943\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.72      0.51      0.50     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19916    39]\n",
      " [ 1899    44]]\n",
      "done in 34.033688s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17147\n",
      "           1       0.38      0.01      0.03      1695\n",
      "\n",
      "    accuracy                           0.91     18842\n",
      "   macro avg       0.65      0.51      0.49     18842\n",
      "weighted avg       0.86      0.91      0.87     18842\n",
      "\n",
      "Confusion_matrix\n",
      "[[17111    36]\n",
      " [ 1673    22]]\n",
      "done in 33.324466s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17231\n",
      "           1       0.53      0.02      0.04      1683\n",
      "\n",
      "    accuracy                           0.91     18914\n",
      "   macro avg       0.72      0.51      0.50     18914\n",
      "weighted avg       0.88      0.91      0.87     18914\n",
      "\n",
      "Confusion_matrix\n",
      "[[17202    29]\n",
      " [ 1650    33]]\n",
      "done in 33.708547s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2797\n",
      "           1       0.33      0.01      0.02       259\n",
      "\n",
      "    accuracy                           0.91      3056\n",
      "   macro avg       0.62      0.50      0.49      3056\n",
      "weighted avg       0.87      0.91      0.88      3056\n",
      "\n",
      "Confusion_matrix\n",
      "[[2793    4]\n",
      " [ 257    2]]\n",
      "done in 33.325596s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.95      2724\n",
      "           1       0.50      0.03      0.06       260\n",
      "\n",
      "    accuracy                           0.91      2984\n",
      "   macro avg       0.71      0.52      0.51      2984\n",
      "weighted avg       0.88      0.91      0.88      2984\n",
      "\n",
      "Confusion_matrix\n",
      "[[2715    9]\n",
      " [ 251    9]]\n",
      "done in 32.895934s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41400000000000003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.2, J-value:0.26899999999999996\n",
      "threshold:0.30000000000000004, J-value:0.142\n",
      "threshold:0.4, J-value:0.069\n",
      "threshold:0.5, J-value:0.028\n",
      "threshold:0.6000000000000001, J-value:0.012\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7070112076352169\n",
      "Balanced accuracy score of test is  0.7048491891109088\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41500000000000004\n",
      "threshold:0.2, J-value:0.26899999999999996\n",
      "threshold:0.30000000000000004, J-value:0.144\n",
      "threshold:0.4, J-value:0.07100000000000001\n",
      "threshold:0.5, J-value:0.028\n",
      "threshold:0.6000000000000001, J-value:0.013000000000000001\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.707709597024377\n",
      "Balanced accuracy score of test is  0.7007828992316596\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.404\n",
      "threshold:0.2, J-value:0.27299999999999996\n",
      "threshold:0.30000000000000004, J-value:0.133\n",
      "threshold:0.4, J-value:0.059\n",
      "threshold:0.5, J-value:0.026\n",
      "threshold:0.6000000000000001, J-value:0.006\n",
      "threshold:0.7000000000000001, J-value:-0.001\n",
      "threshold:0.8, J-value:-0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7017647148144109\n",
      "Balanced accuracy score of test is  0.7309612560713883\n",
      "True positive rate of class 1 is  0.664\n",
      "True positive rate of class 2 is  0.704\n",
      "Positive prediction rate of class 1 is  0.298\n",
      "Positive prediction rate of class 2 is  0.282\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.403\n",
      "threshold:0.2, J-value:0.29200000000000004\n",
      "threshold:0.30000000000000004, J-value:0.11200000000000002\n",
      "threshold:0.4, J-value:0.015\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.70187818111798\n",
      "Balanced accuracy score of test is  0.7011419156818746\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.404\n",
      "threshold:0.2, J-value:0.277\n",
      "threshold:0.30000000000000004, J-value:0.11200000000000002\n",
      "threshold:0.4, J-value:0.018000000000000002\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7017520028529978\n",
      "Balanced accuracy score of test is  0.6986044856282151\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.379\n",
      "threshold:0.2, J-value:0.28400000000000003\n",
      "threshold:0.30000000000000004, J-value:0.101\n",
      "threshold:0.4, J-value:0.009000000000000001\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6891049842426318\n",
      "Balanced accuracy score of test is  0.7192081780187507\n",
      "True positive rate of class 1 is  0.744\n",
      "True positive rate of class 2 is  0.792\n",
      "Positive prediction rate of class 1 is  0.382\n",
      "Positive prediction rate of class 2 is  0.392\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.368\n",
      "threshold:0.2, J-value:0.232\n",
      "threshold:0.30000000000000004, J-value:0.143\n",
      "threshold:0.4, J-value:0.011\n",
      "threshold:0.5, J-value:0.011\n",
      "threshold:0.6000000000000001, J-value:0.002\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6838966916988858\n",
      "Balanced accuracy score of test is  0.6779069427054929\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.36800000000000005\n",
      "threshold:0.2, J-value:0.23500000000000001\n",
      "threshold:0.30000000000000004, J-value:0.148\n",
      "threshold:0.4, J-value:0.01\n",
      "threshold:0.5, J-value:0.01\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.683798777635621\n",
      "Balanced accuracy score of test is  0.6767645043290511\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.365\n",
      "threshold:0.2, J-value:0.21299999999999997\n",
      "threshold:0.30000000000000004, J-value:0.10500000000000001\n",
      "threshold:0.4, J-value:0.013\n",
      "threshold:0.5, J-value:0.013\n",
      "threshold:0.6000000000000001, J-value:0.011\n",
      "threshold:0.7000000000000001, J-value:-0.001\n",
      "threshold:0.8, J-value:-0.001\n",
      "threshold:0.9, J-value:-0.001\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6826391486741862\n",
      "Balanced accuracy score of test is  0.6846492714334125\n",
      "True positive rate of class 1 is  0.638\n",
      "True positive rate of class 2 is  0.588\n",
      "Positive prediction rate of class 1 is  0.315\n",
      "Positive prediction rate of class 2 is  0.251\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.42799999999999994\n",
      "threshold:0.2, J-value:0.27599999999999997\n",
      "threshold:0.30000000000000004, J-value:0.136\n",
      "threshold:0.4, J-value:0.045\n",
      "threshold:0.5, J-value:0.01\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7138205758108374\n",
      "Balanced accuracy score of test is  0.7096883582502215\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.42699999999999994\n",
      "threshold:0.2, J-value:0.27699999999999997\n",
      "threshold:0.30000000000000004, J-value:0.14100000000000001\n",
      "threshold:0.4, J-value:0.048\n",
      "threshold:0.5, J-value:0.011\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.71315694085827\n",
      "Balanced accuracy score of test is  0.7071117418746692\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.43500000000000005\n",
      "threshold:0.2, J-value:0.27099999999999996\n",
      "threshold:0.30000000000000004, J-value:0.10200000000000001\n",
      "threshold:0.4, J-value:0.019\n",
      "threshold:0.5, J-value:0.007\n",
      "threshold:0.6000000000000001, J-value:-0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.717816110200808\n",
      "Balanced accuracy score of test is  0.7255421890884446\n",
      "True positive rate of class 1 is  0.697\n",
      "True positive rate of class 2 is  0.708\n",
      "Positive prediction rate of class 1 is  0.32\n",
      "Positive prediction rate of class 2 is  0.296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lifuchen/Desktop/research/CVDPrediction-master/src/lib/fairness_tests.py:125: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train ['Class'] = y_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8973, 88)\n",
      "(56721, 88)\n",
      "0.09320175438596491 0.0980099887723102\n",
      "0.097953216374269\n",
      "(65733, 87)\n",
      "X train 65733\n",
      "Y train 65733\n",
      "21898 18920 2978\n",
      "21898 18920 2978\n",
      "21898 18865 3033\n",
      "21898 18865 3033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2595395326493107\n",
      "0.26320790039113456\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19893\n",
      "           1       0.42      0.03      0.06      2005\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.66      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19807    86]\n",
      " [ 1943    62]]\n",
      "done in 1.154223s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2595395326493107\n",
      "0.26226383268674364\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19907\n",
      "           1       0.50      0.03      0.06      1991\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.70      0.51      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19840    67]\n",
      " [ 1925    66]]\n",
      "done in 1.047240s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2595395326493107\n",
      "0.2618165843439168\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17191\n",
      "           1       0.43      0.03      0.06      1729\n",
      "\n",
      "    accuracy                           0.91     18920\n",
      "   macro avg       0.67      0.51      0.50     18920\n",
      "weighted avg       0.87      0.91      0.87     18920\n",
      "\n",
      "Confusion_matrix\n",
      "[[17118    73]\n",
      " [ 1675    54]]\n",
      "done in 1.542957s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2595395326493107\n",
      "0.2643483883870174\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17135\n",
      "           1       0.46      0.03      0.05      1730\n",
      "\n",
      "    accuracy                           0.91     18865\n",
      "   macro avg       0.69      0.51      0.50     18865\n",
      "weighted avg       0.87      0.91      0.87     18865\n",
      "\n",
      "Confusion_matrix\n",
      "[[17082    53]\n",
      " [ 1684    46]]\n",
      "done in 1.132809s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2595395326493107\n",
      "0.27204728911288084\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2702\n",
      "           1       0.38      0.03      0.05       276\n",
      "\n",
      "    accuracy                           0.91      2978\n",
      "   macro avg       0.65      0.51      0.50      2978\n",
      "weighted avg       0.86      0.91      0.87      2978\n",
      "\n",
      "Confusion_matrix\n",
      "[[2689   13]\n",
      " [ 268    8]]\n",
      "done in 1.085877s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2595395326493107\n",
      "0.2492980749268803\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96      2772\n",
      "           1       0.59      0.08      0.14       261\n",
      "\n",
      "    accuracy                           0.92      3033\n",
      "   macro avg       0.75      0.54      0.55      3033\n",
      "weighted avg       0.89      0.92      0.89      3033\n",
      "\n",
      "Confusion_matrix\n",
      "[[2758   14]\n",
      " [ 241   20]]\n",
      "done in 1.006927s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19893\n",
      "           1       0.60      0.00      0.01      2005\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.75      0.50      0.48     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19889     4]\n",
      " [ 1999     6]]\n",
      "done in 19.975559s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19907\n",
      "           1       0.40      0.00      0.00      1991\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.65      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19901     6]\n",
      " [ 1987     4]]\n",
      "done in 20.095671s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17191\n",
      "           1       0.43      0.00      0.01      1729\n",
      "\n",
      "    accuracy                           0.91     18920\n",
      "   macro avg       0.67      0.50      0.48     18920\n",
      "weighted avg       0.86      0.91      0.87     18920\n",
      "\n",
      "Confusion_matrix\n",
      "[[17183     8]\n",
      " [ 1723     6]]\n",
      "done in 19.451126s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17135\n",
      "           1       0.25      0.00      0.00      1730\n",
      "\n",
      "    accuracy                           0.91     18865\n",
      "   macro avg       0.58      0.50      0.48     18865\n",
      "weighted avg       0.85      0.91      0.86     18865\n",
      "\n",
      "Confusion_matrix\n",
      "[[17129     6]\n",
      " [ 1728     2]]\n",
      "done in 19.626041s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2702\n",
      "           1       0.50      0.00      0.01       276\n",
      "\n",
      "    accuracy                           0.91      2978\n",
      "   macro avg       0.70      0.50      0.48      2978\n",
      "weighted avg       0.87      0.91      0.86      2978\n",
      "\n",
      "Confusion_matrix\n",
      "[[2701    1]\n",
      " [ 275    1]]\n",
      "done in 19.786661s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2772\n",
      "           1       0.00      0.00      0.00       261\n",
      "\n",
      "    accuracy                           0.91      3033\n",
      "   macro avg       0.46      0.50      0.48      3033\n",
      "weighted avg       0.84      0.91      0.87      3033\n",
      "\n",
      "Confusion_matrix\n",
      "[[2771    1]\n",
      " [ 261    0]]\n",
      "done in 19.782953s\n",
      "0.26501163666326666\n",
      "0.2708782109485407\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19893\n",
      "           1       0.08      0.00      0.00      2005\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.50      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.86     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19882    11]\n",
      " [ 2004     1]]\n",
      "done in 0.639323s\n",
      "0.26501163666326666\n",
      "0.2708912416263626\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19907\n",
      "           1       0.40      0.00      0.00      1991\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.65      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19904     3]\n",
      " [ 1989     2]]\n",
      "done in 0.664554s\n",
      "0.26501163666326666\n",
      "0.26964131309983286\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17191\n",
      "           1       0.10      0.00      0.00      1729\n",
      "\n",
      "    accuracy                           0.91     18920\n",
      "   macro avg       0.50      0.50      0.48     18920\n",
      "weighted avg       0.83      0.91      0.87     18920\n",
      "\n",
      "Confusion_matrix\n",
      "[[17182     9]\n",
      " [ 1728     1]]\n",
      "done in 0.684140s\n",
      "0.26501163666326666\n",
      "0.27281628678083764\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17135\n",
      "           1       0.33      0.00      0.00      1730\n",
      "\n",
      "    accuracy                           0.91     18865\n",
      "   macro avg       0.62      0.50      0.48     18865\n",
      "weighted avg       0.86      0.91      0.86     18865\n",
      "\n",
      "Confusion_matrix\n",
      "[[17133     2]\n",
      " [ 1729     1]]\n",
      "done in 0.633236s\n",
      "0.26501163666326666\n",
      "0.2787365411357644\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2702\n",
      "           1       0.00      0.00      0.00       276\n",
      "\n",
      "    accuracy                           0.91      2978\n",
      "   macro avg       0.45      0.50      0.48      2978\n",
      "weighted avg       0.82      0.91      0.86      2978\n",
      "\n",
      "Confusion_matrix\n",
      "[[2700    2]\n",
      " [ 276    0]]\n",
      "done in 0.601926s\n",
      "0.26501163666326666\n",
      "0.25891762578753225\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.96      2772\n",
      "           1       0.50      0.00      0.01       261\n",
      "\n",
      "    accuracy                           0.91      3033\n",
      "   macro avg       0.71      0.50      0.48      3033\n",
      "weighted avg       0.88      0.91      0.87      3033\n",
      "\n",
      "Confusion_matrix\n",
      "[[2771    1]\n",
      " [ 260    1]]\n",
      "done in 0.620747s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19893\n",
      "           1       0.44      0.02      0.04      2005\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19839    54]\n",
      " [ 1962    43]]\n",
      "done in 33.571175s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19907\n",
      "           1       0.48      0.02      0.03      1991\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.69      0.51      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19873    34]\n",
      " [ 1960    31]]\n",
      "done in 34.857535s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17191\n",
      "           1       0.46      0.02      0.04      1729\n",
      "\n",
      "    accuracy                           0.91     18920\n",
      "   macro avg       0.69      0.51      0.50     18920\n",
      "weighted avg       0.87      0.91      0.87     18920\n",
      "\n",
      "Confusion_matrix\n",
      "[[17148    43]\n",
      " [ 1692    37]]\n",
      "done in 33.439977s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17135\n",
      "           1       0.44      0.01      0.03      1730\n",
      "\n",
      "    accuracy                           0.91     18865\n",
      "   macro avg       0.68      0.51      0.49     18865\n",
      "weighted avg       0.87      0.91      0.87     18865\n",
      "\n",
      "Confusion_matrix\n",
      "[[17105    30]\n",
      " [ 1706    24]]\n",
      "done in 33.605825s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2702\n",
      "           1       0.35      0.02      0.04       276\n",
      "\n",
      "    accuracy                           0.91      2978\n",
      "   macro avg       0.63      0.51      0.50      2978\n",
      "weighted avg       0.86      0.91      0.87      2978\n",
      "\n",
      "Confusion_matrix\n",
      "[[2691   11]\n",
      " [ 270    6]]\n",
      "done in 33.487474s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2772\n",
      "           1       0.64      0.03      0.05       261\n",
      "\n",
      "    accuracy                           0.91      3033\n",
      "   macro avg       0.78      0.51      0.50      3033\n",
      "weighted avg       0.89      0.91      0.88      3033\n",
      "\n",
      "Confusion_matrix\n",
      "[[2768    4]\n",
      " [ 254    7]]\n",
      "done in 32.861814s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41000000000000003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.2, J-value:0.26699999999999996\n",
      "threshold:0.30000000000000004, J-value:0.145\n",
      "threshold:0.4, J-value:0.069\n",
      "threshold:0.5, J-value:0.027\n",
      "threshold:0.6000000000000001, J-value:0.006999999999999999\n",
      "threshold:0.7000000000000001, J-value:0.004\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7049561538269643\n",
      "Balanced accuracy score of test is  0.6983989236539563\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41200000000000003\n",
      "threshold:0.2, J-value:0.27199999999999996\n",
      "threshold:0.30000000000000004, J-value:0.147\n",
      "threshold:0.4, J-value:0.067\n",
      "threshold:0.5, J-value:0.027\n",
      "threshold:0.6000000000000001, J-value:0.008\n",
      "threshold:0.7000000000000001, J-value:0.005\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7062568450228456\n",
      "Balanced accuracy score of test is  0.6983336172624399\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.394\n",
      "threshold:0.2, J-value:0.237\n",
      "threshold:0.30000000000000004, J-value:0.133\n",
      "threshold:0.4, J-value:0.076\n",
      "threshold:0.5, J-value:0.024\n",
      "threshold:0.6000000000000001, J-value:0.002\n",
      "threshold:0.7000000000000001, J-value:-0.001\n",
      "threshold:0.8, J-value:-0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6969327604887416\n",
      "Balanced accuracy score of test is  0.6986428322635219\n",
      "True positive rate of class 1 is  0.649\n",
      "True positive rate of class 2 is  0.644\n",
      "Positive prediction rate of class 1 is  0.289\n",
      "Positive prediction rate of class 2 is  0.281\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.401\n",
      "threshold:0.2, J-value:0.301\n",
      "threshold:0.30000000000000004, J-value:0.11100000000000002\n",
      "threshold:0.4, J-value:0.023\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7006251901538568\n",
      "Balanced accuracy score of test is  0.6966595447333365\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.408\n",
      "threshold:0.2, J-value:0.302\n",
      "threshold:0.30000000000000004, J-value:0.11400000000000002\n",
      "threshold:0.4, J-value:0.027\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.703963656181616\n",
      "Balanced accuracy score of test is  0.700966146092489\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.401\n",
      "threshold:0.2, J-value:0.262\n",
      "threshold:0.30000000000000004, J-value:0.08\n",
      "threshold:0.4, J-value:0.013999999999999999\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.700460742981581\n",
      "Balanced accuracy score of test is  0.7009192914365328\n",
      "True positive rate of class 1 is  0.739\n",
      "True positive rate of class 2 is  0.759\n",
      "Positive prediction rate of class 1 is  0.374\n",
      "Positive prediction rate of class 2 is  0.391\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.37400000000000005\n",
      "threshold:0.2, J-value:0.21799999999999997\n",
      "threshold:0.30000000000000004, J-value:0.093\n",
      "threshold:0.4, J-value:0.008\n",
      "threshold:0.5, J-value:-0.001\n",
      "threshold:0.6000000000000001, J-value:-0.001\n",
      "threshold:0.7000000000000001, J-value:-0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6868007430777101\n",
      "Balanced accuracy score of test is  0.6863412734610213\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.37799999999999995\n",
      "threshold:0.2, J-value:0.21799999999999997\n",
      "threshold:0.30000000000000004, J-value:0.10099999999999999\n",
      "threshold:0.4, J-value:0.008\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6892229174619899\n",
      "Balanced accuracy score of test is  0.685316367304186\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.345\n",
      "threshold:0.2, J-value:0.21100000000000002\n",
      "threshold:0.30000000000000004, J-value:0.043\n",
      "threshold:0.4, J-value:0.005\n",
      "threshold:0.5, J-value:-0.001\n",
      "threshold:0.6000000000000001, J-value:-0.001\n",
      "threshold:0.7000000000000001, J-value:-0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6720478121413016\n",
      "Balanced accuracy score of test is  0.6916766184007563\n",
      "True positive rate of class 1 is  0.674\n",
      "True positive rate of class 2 is  0.64\n",
      "Positive prediction rate of class 1 is  0.337\n",
      "Positive prediction rate of class 2 is  0.289\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.42199999999999993\n",
      "threshold:0.2, J-value:0.283\n",
      "threshold:0.30000000000000004, J-value:0.144\n",
      "threshold:0.4, J-value:0.056\n",
      "threshold:0.5, J-value:0.018000000000000002\n",
      "threshold:0.6000000000000001, J-value:0.006\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.711123651184711\n",
      "Balanced accuracy score of test is  0.7066848161883446\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.42799999999999994\n",
      "threshold:0.2, J-value:0.286\n",
      "threshold:0.30000000000000004, J-value:0.145\n",
      "threshold:0.4, J-value:0.057\n",
      "threshold:0.5, J-value:0.018000000000000002\n",
      "threshold:0.6000000000000001, J-value:0.008\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7140132002437554\n",
      "Balanced accuracy score of test is  0.7043167063324062\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.387\n",
      "threshold:0.2, J-value:0.264\n",
      "threshold:0.30000000000000004, J-value:0.133\n",
      "threshold:0.4, J-value:0.052000000000000005\n",
      "threshold:0.5, J-value:0.018\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:-0.001\n",
      "threshold:0.8, J-value:-0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6931929113163625\n",
      "Balanced accuracy score of test is  0.7223030800617007\n",
      "True positive rate of class 1 is  0.679\n",
      "True positive rate of class 2 is  0.713\n",
      "Positive prediction rate of class 1 is  0.308\n",
      "Positive prediction rate of class 2 is  0.306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lifuchen/Desktop/research/CVDPrediction-master/src/lib/fairness_tests.py:125: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train ['Class'] = y_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9011, 88)\n",
      "(56683, 88)\n",
      "0.09316996239233288 0.09987193418193108\n",
      "0.09984229042824215\n",
      "(65749, 87)\n",
      "X train 65749\n",
      "Y train 65749\n",
      "21898 18905 2993\n",
      "21898 18905 2993\n",
      "21898 18918 2980\n",
      "21898 18918 2980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26151932101491215\n",
      "0.26203843910485985\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19931\n",
      "           1       0.51      0.04      0.08      1967\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.71      0.52      0.51     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19853    78]\n",
      " [ 1886    81]]\n",
      "done in 1.250330s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26151932101491215\n",
      "0.25905267214653277\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19956\n",
      "           1       0.46      0.04      0.07      1942\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.69      0.52      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19876    80]\n",
      " [ 1873    69]]\n",
      "done in 1.074485s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26151932101491215\n",
      "0.2604508455560751\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17217\n",
      "           1       0.53      0.04      0.07      1688\n",
      "\n",
      "    accuracy                           0.91     18905\n",
      "   macro avg       0.72      0.52      0.51     18905\n",
      "weighted avg       0.88      0.91      0.87     18905\n",
      "\n",
      "Confusion_matrix\n",
      "[[17157    60]\n",
      " [ 1620    68]]\n",
      "done in 1.029674s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26151932101491215\n",
      "0.2601346174858\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17231\n",
      "           1       0.44      0.03      0.06      1687\n",
      "\n",
      "    accuracy                           0.91     18918\n",
      "   macro avg       0.68      0.51      0.50     18918\n",
      "weighted avg       0.87      0.91      0.87     18918\n",
      "\n",
      "Confusion_matrix\n",
      "[[17166    65]\n",
      " [ 1636    51]]\n",
      "done in 0.983116s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26151932101491215\n",
      "0.27206632284684995\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95      2714\n",
      "           1       0.42      0.05      0.08       279\n",
      "\n",
      "    accuracy                           0.91      2993\n",
      "   macro avg       0.66      0.52      0.52      2993\n",
      "weighted avg       0.86      0.91      0.87      2993\n",
      "\n",
      "Confusion_matrix\n",
      "[[2696   18]\n",
      " [ 266   13]]\n",
      "done in 1.016968s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26151932101491215\n",
      "0.25218413458671396\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96      2725\n",
      "           1       0.55      0.07      0.12       255\n",
      "\n",
      "    accuracy                           0.92      2980\n",
      "   macro avg       0.73      0.53      0.54      2980\n",
      "weighted avg       0.89      0.92      0.88      2980\n",
      "\n",
      "Confusion_matrix\n",
      "[[2710   15]\n",
      " [ 237   18]]\n",
      "done in 0.977593s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19931\n",
      "           1       0.43      0.00      0.01      1967\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19923     8]\n",
      " [ 1961     6]]\n",
      "done in 20.163188s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19956\n",
      "           1       0.73      0.00      0.01      1942\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.82      0.50      0.48     21898\n",
      "weighted avg       0.90      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19953     3]\n",
      " [ 1934     8]]\n",
      "done in 21.176207s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17217\n",
      "           1       0.44      0.00      0.00      1688\n",
      "\n",
      "    accuracy                           0.91     18905\n",
      "   macro avg       0.68      0.50      0.48     18905\n",
      "weighted avg       0.87      0.91      0.87     18905\n",
      "\n",
      "Confusion_matrix\n",
      "[[17212     5]\n",
      " [ 1684     4]]\n",
      "done in 20.253014s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17231\n",
      "           1       0.43      0.00      0.00      1687\n",
      "\n",
      "    accuracy                           0.91     18918\n",
      "   macro avg       0.67      0.50      0.48     18918\n",
      "weighted avg       0.87      0.91      0.87     18918\n",
      "\n",
      "Confusion_matrix\n",
      "[[17227     4]\n",
      " [ 1684     3]]\n",
      "done in 19.809881s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2714\n",
      "           1       0.25      0.00      0.01       279\n",
      "\n",
      "    accuracy                           0.91      2993\n",
      "   macro avg       0.58      0.50      0.48      2993\n",
      "weighted avg       0.85      0.91      0.86      2993\n",
      "\n",
      "Confusion_matrix\n",
      "[[2711    3]\n",
      " [ 278    1]]\n",
      "done in 19.698059s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2725\n",
      "           1       0.00      0.00      0.00       255\n",
      "\n",
      "    accuracy                           0.91      2980\n",
      "   macro avg       0.46      0.50      0.48      2980\n",
      "weighted avg       0.84      0.91      0.87      2980\n",
      "\n",
      "Confusion_matrix\n",
      "[[2723    2]\n",
      " [ 255    0]]\n",
      "done in 19.803042s\n",
      "0.2668518868671184\n",
      "0.2701564616038367\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19931\n",
      "           1       0.33      0.00      0.01      1967\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.62      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19921    10]\n",
      " [ 1962     5]]\n",
      "done in 0.704874s\n",
      "0.2668518868671184\n",
      "0.26738474140504337\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19956\n",
      "           1       0.35      0.00      0.01      1942\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.63      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19943    13]\n",
      " [ 1935     7]]\n",
      "done in 0.656889s\n",
      "0.2668518868671184\n",
      "0.26948722605743847\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17217\n",
      "           1       0.29      0.00      0.00      1688\n",
      "\n",
      "    accuracy                           0.91     18905\n",
      "   macro avg       0.60      0.50      0.48     18905\n",
      "weighted avg       0.85      0.91      0.87     18905\n",
      "\n",
      "Confusion_matrix\n",
      "[[17212     5]\n",
      " [ 1686     2]]\n",
      "done in 0.633092s\n",
      "0.2668518868671184\n",
      "0.26907535488005696\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17231\n",
      "           1       0.44      0.00      0.00      1687\n",
      "\n",
      "    accuracy                           0.91     18918\n",
      "   macro avg       0.68      0.50      0.48     18918\n",
      "weighted avg       0.87      0.91      0.87     18918\n",
      "\n",
      "Confusion_matrix\n",
      "[[17226     5]\n",
      " [ 1683     4]]\n",
      "done in 0.652329s\n",
      "0.2668518868671184\n",
      "0.27438362431839003\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2714\n",
      "           1       0.38      0.01      0.02       279\n",
      "\n",
      "    accuracy                           0.91      2993\n",
      "   macro avg       0.64      0.50      0.49      2993\n",
      "weighted avg       0.86      0.91      0.86      2993\n",
      "\n",
      "Confusion_matrix\n",
      "[[2709    5]\n",
      " [ 276    3]]\n",
      "done in 0.580152s\n",
      "0.2668518868671184\n",
      "0.25665218243849713\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.95      2725\n",
      "           1       0.27      0.01      0.02       255\n",
      "\n",
      "    accuracy                           0.91      2980\n",
      "   macro avg       0.59      0.50      0.49      2980\n",
      "weighted avg       0.86      0.91      0.87      2980\n",
      "\n",
      "Confusion_matrix\n",
      "[[2717    8]\n",
      " [ 252    3]]\n",
      "done in 0.593812s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19931\n",
      "           1       0.41      0.02      0.03      1967\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.66      0.51      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19883    48]\n",
      " [ 1933    34]]\n",
      "done in 33.467239s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19956\n",
      "           1       0.42      0.02      0.03      1942\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19911    45]\n",
      " [ 1909    33]]\n",
      "done in 33.611257s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17217\n",
      "           1       0.40      0.02      0.03      1688\n",
      "\n",
      "    accuracy                           0.91     18905\n",
      "   macro avg       0.66      0.51      0.49     18905\n",
      "weighted avg       0.87      0.91      0.87     18905\n",
      "\n",
      "Confusion_matrix\n",
      "[[17177    40]\n",
      " [ 1661    27]]\n",
      "done in 33.296578s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17231\n",
      "           1       0.40      0.02      0.03      1687\n",
      "\n",
      "    accuracy                           0.91     18918\n",
      "   macro avg       0.66      0.51      0.49     18918\n",
      "weighted avg       0.87      0.91      0.87     18918\n",
      "\n",
      "Confusion_matrix\n",
      "[[17192    39]\n",
      " [ 1661    26]]\n",
      "done in 33.182268s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2714\n",
      "           1       0.44      0.03      0.05       279\n",
      "\n",
      "    accuracy                           0.91      2993\n",
      "   macro avg       0.67      0.51      0.50      2993\n",
      "weighted avg       0.86      0.91      0.87      2993\n",
      "\n",
      "Confusion_matrix\n",
      "[[2705    9]\n",
      " [ 272    7]]\n",
      "done in 33.253454s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2725\n",
      "           1       0.54      0.03      0.05       255\n",
      "\n",
      "    accuracy                           0.91      2980\n",
      "   macro avg       0.73      0.51      0.50      2980\n",
      "weighted avg       0.88      0.91      0.88      2980\n",
      "\n",
      "Confusion_matrix\n",
      "[[2719    6]\n",
      " [ 248    7]]\n",
      "done in 32.900597s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.2, J-value:0.256\n",
      "threshold:0.30000000000000004, J-value:0.148\n",
      "threshold:0.4, J-value:0.069\n",
      "threshold:0.5, J-value:0.037000000000000005\n",
      "threshold:0.6000000000000001, J-value:0.011\n",
      "threshold:0.7000000000000001, J-value:0.003\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6980308041390484\n",
      "Balanced accuracy score of test is  0.7009267711312983\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.395\n",
      "threshold:0.2, J-value:0.24900000000000003\n",
      "threshold:0.30000000000000004, J-value:0.149\n",
      "threshold:0.4, J-value:0.068\n",
      "threshold:0.5, J-value:0.037\n",
      "threshold:0.6000000000000001, J-value:0.011\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6976362259884765\n",
      "Balanced accuracy score of test is  0.7008078483875627\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.402\n",
      "threshold:0.2, J-value:0.30100000000000005\n",
      "threshold:0.30000000000000004, J-value:0.144\n",
      "threshold:0.4, J-value:0.072\n",
      "threshold:0.5, J-value:0.04\n",
      "threshold:0.6000000000000001, J-value:0.009\n",
      "threshold:0.7000000000000001, J-value:0.006\n",
      "threshold:0.8, J-value:0.003\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7008548532367678\n",
      "Balanced accuracy score of test is  0.7014534988307249\n",
      "True positive rate of class 1 is  0.663\n",
      "True positive rate of class 2 is  0.651\n",
      "Positive prediction rate of class 1 is  0.297\n",
      "Positive prediction rate of class 2 is  0.283\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.385\n",
      "threshold:0.2, J-value:0.295\n",
      "threshold:0.30000000000000004, J-value:0.118\n",
      "threshold:0.4, J-value:0.028\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6925175408795321\n",
      "Balanced accuracy score of test is  0.6971181088611216\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.376\n",
      "threshold:0.2, J-value:0.271\n",
      "threshold:0.30000000000000004, J-value:0.11599999999999999\n",
      "threshold:0.4, J-value:0.026\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6884521615222693\n",
      "Balanced accuracy score of test is  0.6946322533823928\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.43700000000000006\n",
      "threshold:0.2, J-value:0.358\n",
      "threshold:0.30000000000000004, J-value:0.13999999999999999\n",
      "threshold:0.4, J-value:0.034\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7183758448823702\n",
      "Balanced accuracy score of test is  0.7051160280626012\n",
      "True positive rate of class 1 is  0.738\n",
      "True positive rate of class 2 is  0.776\n",
      "Positive prediction rate of class 1 is  0.383\n",
      "Positive prediction rate of class 2 is  0.401\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.36000000000000004\n",
      "threshold:0.2, J-value:0.20099999999999996\n",
      "threshold:0.30000000000000004, J-value:0.093\n",
      "threshold:0.4, J-value:0.012\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6803171883516689\n",
      "Balanced accuracy score of test is  0.6824673653820073\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.35800000000000004\n",
      "threshold:0.2, J-value:0.20299999999999996\n",
      "threshold:0.30000000000000004, J-value:0.095\n",
      "threshold:0.4, J-value:0.012\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6792585141930975\n",
      "Balanced accuracy score of test is  0.6811004462979542\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.376\n",
      "threshold:0.2, J-value:0.184\n",
      "threshold:0.30000000000000004, J-value:0.07899999999999999\n",
      "threshold:0.4, J-value:0.018000000000000002\n",
      "threshold:0.5, J-value:0.012\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6879085744170015\n",
      "Balanced accuracy score of test is  0.6905126821370751\n",
      "True positive rate of class 1 is  0.69\n",
      "True positive rate of class 2 is  0.659\n",
      "Positive prediction rate of class 1 is  0.36\n",
      "Positive prediction rate of class 2 is  0.31\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.399\n",
      "threshold:0.2, J-value:0.269\n",
      "threshold:0.30000000000000004, J-value:0.134\n",
      "threshold:0.4, J-value:0.061000000000000006\n",
      "threshold:0.5, J-value:0.015000000000000001\n",
      "threshold:0.6000000000000001, J-value:0.004\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.699443366855101\n",
      "Balanced accuracy score of test is  0.7084945273009478\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.394\n",
      "threshold:0.2, J-value:0.269\n",
      "threshold:0.30000000000000004, J-value:0.136\n",
      "threshold:0.4, J-value:0.061000000000000006\n",
      "threshold:0.5, J-value:0.014\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6969098897072689\n",
      "Balanced accuracy score of test is  0.7084824269901056\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.43500000000000005\n",
      "threshold:0.2, J-value:0.275\n",
      "threshold:0.30000000000000004, J-value:0.123\n",
      "threshold:0.4, J-value:0.063\n",
      "threshold:0.5, J-value:0.022000000000000002\n",
      "threshold:0.6000000000000001, J-value:0.007\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7174362062635531\n",
      "Balanced accuracy score of test is  0.7080805900341789\n",
      "True positive rate of class 1 is  0.7\n",
      "True positive rate of class 2 is  0.675\n",
      "Positive prediction rate of class 1 is  0.32\n",
      "Positive prediction rate of class 2 is  0.294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lifuchen/Desktop/research/CVDPrediction-master/src/lib/fairness_tests.py:125: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train ['Class'] = y_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8852, 88)\n",
      "(56842, 88)\n",
      "0.09297444128904803 0.09886328487472935\n",
      "0.09877762686751451\n",
      "(65741, 87)\n",
      "X train 65741\n",
      "Y train 65741\n",
      "21898 18847 3051\n",
      "21898 18847 3051\n",
      "21898 18817 3081\n",
      "21898 18817 3081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2617168716935776\n",
      "0.25522205244473595\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19973\n",
      "           1       0.51      0.04      0.07      1925\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.71      0.52      0.51     21898\n",
      "weighted avg       0.88      0.91      0.88     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19905    68]\n",
      " [ 1855    70]]\n",
      "done in 1.157667s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2617168716935776\n",
      "0.26502121084684266\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19866\n",
      "           1       0.44      0.03      0.06      2032\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19782    84]\n",
      " [ 1966    66]]\n",
      "done in 1.027222s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2617168716935776\n",
      "0.2551576320881057\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17189\n",
      "           1       0.49      0.03      0.06      1658\n",
      "\n",
      "    accuracy                           0.91     18847\n",
      "   macro avg       0.70      0.51      0.51     18847\n",
      "weighted avg       0.88      0.91      0.88     18847\n",
      "\n",
      "Confusion_matrix\n",
      "[[17132    57]\n",
      " [ 1603    55]]\n",
      "done in 1.078338s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2617168716935776\n",
      "0.26590495315534435\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17067\n",
      "           1       0.42      0.03      0.05      1750\n",
      "\n",
      "    accuracy                           0.91     18817\n",
      "   macro avg       0.66      0.51      0.50     18817\n",
      "weighted avg       0.86      0.91      0.87     18817\n",
      "\n",
      "Confusion_matrix\n",
      "[[17002    65]\n",
      " [ 1703    47]]\n",
      "done in 1.036468s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2617168716935776\n",
      "0.2556199975320547\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.95      2784\n",
      "           1       0.58      0.06      0.10       267\n",
      "\n",
      "    accuracy                           0.91      3051\n",
      "   macro avg       0.75      0.53      0.53      3051\n",
      "weighted avg       0.89      0.91      0.88      3051\n",
      "\n",
      "Confusion_matrix\n",
      "[[2773   11]\n",
      " [ 252   15]]\n",
      "done in 1.032419s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2617168716935776\n",
      "0.2596238142161781\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95      2799\n",
      "           1       0.50      0.07      0.12       282\n",
      "\n",
      "    accuracy                           0.91      3081\n",
      "   macro avg       0.71      0.53      0.54      3081\n",
      "weighted avg       0.88      0.91      0.88      3081\n",
      "\n",
      "Confusion_matrix\n",
      "[[2780   19]\n",
      " [ 263   19]]\n",
      "done in 1.054105s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19973\n",
      "           1       0.38      0.00      0.01      1925\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.65      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19965     8]\n",
      " [ 1920     5]]\n",
      "done in 19.901672s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19866\n",
      "           1       0.50      0.00      0.00      2032\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.70      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.86     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19862     4]\n",
      " [ 2028     4]]\n",
      "done in 19.850409s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17189\n",
      "           1       0.42      0.00      0.01      1658\n",
      "\n",
      "    accuracy                           0.91     18847\n",
      "   macro avg       0.66      0.50      0.48     18847\n",
      "weighted avg       0.87      0.91      0.87     18847\n",
      "\n",
      "Confusion_matrix\n",
      "[[17182     7]\n",
      " [ 1653     5]]\n",
      "done in 19.717918s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17067\n",
      "           1       0.50      0.00      0.01      1750\n",
      "\n",
      "    accuracy                           0.91     18817\n",
      "   macro avg       0.70      0.50      0.48     18817\n",
      "weighted avg       0.87      0.91      0.86     18817\n",
      "\n",
      "Confusion_matrix\n",
      "[[17059     8]\n",
      " [ 1742     8]]\n",
      "done in 19.644174s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2784\n",
      "           1       0.50      0.00      0.01       267\n",
      "\n",
      "    accuracy                           0.91      3051\n",
      "   macro avg       0.71      0.50      0.48      3051\n",
      "weighted avg       0.88      0.91      0.87      3051\n",
      "\n",
      "Confusion_matrix\n",
      "[[2783    1]\n",
      " [ 266    1]]\n",
      "done in 19.098351s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2799\n",
      "           1       1.00      0.01      0.01       282\n",
      "\n",
      "    accuracy                           0.91      3081\n",
      "   macro avg       0.95      0.50      0.48      3081\n",
      "weighted avg       0.92      0.91      0.87      3081\n",
      "\n",
      "Confusion_matrix\n",
      "[[2799    0]\n",
      " [ 280    2]]\n",
      "done in 19.618865s\n",
      "0.2668440942431764\n",
      "0.26919985202151325\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19973\n",
      "           1       0.00      0.00      0.00      1925\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.46      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19960    13]\n",
      " [ 1925     0]]\n",
      "done in 0.659752s\n",
      "0.2668440942431764\n",
      "0.27819475725371184\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19866\n",
      "           1       0.11      0.00      0.00      2032\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.51      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.86     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19858     8]\n",
      " [ 2031     1]]\n",
      "done in 0.637657s\n",
      "0.2668440942431764\n",
      "0.26911458023867\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17189\n",
      "           1       0.00      0.00      0.00      1658\n",
      "\n",
      "    accuracy                           0.91     18847\n",
      "   macro avg       0.46      0.50      0.48     18847\n",
      "weighted avg       0.83      0.91      0.87     18847\n",
      "\n",
      "Confusion_matrix\n",
      "[[17179    10]\n",
      " [ 1658     0]]\n",
      "done in 0.634358s\n",
      "0.2668440942431764\n",
      "0.2794101604581766\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17067\n",
      "           1       0.12      0.00      0.00      1750\n",
      "\n",
      "    accuracy                           0.91     18817\n",
      "   macro avg       0.52      0.50      0.48     18817\n",
      "weighted avg       0.83      0.91      0.86     18817\n",
      "\n",
      "Confusion_matrix\n",
      "[[17060     7]\n",
      " [ 1749     1]]\n",
      "done in 0.621142s\n",
      "0.2668440942431764\n",
      "0.2697266030183164\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2784\n",
      "           1       0.00      0.00      0.00       267\n",
      "\n",
      "    accuracy                           0.91      3051\n",
      "   macro avg       0.46      0.50      0.48      3051\n",
      "weighted avg       0.83      0.91      0.87      3051\n",
      "\n",
      "Confusion_matrix\n",
      "[[2781    3]\n",
      " [ 267    0]]\n",
      "done in 0.598780s\n",
      "0.2668440942431764\n",
      "0.2707717640377385\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2799\n",
      "           1       0.00      0.00      0.00       282\n",
      "\n",
      "    accuracy                           0.91      3081\n",
      "   macro avg       0.45      0.50      0.48      3081\n",
      "weighted avg       0.83      0.91      0.86      3081\n",
      "\n",
      "Confusion_matrix\n",
      "[[2798    1]\n",
      " [ 282    0]]\n",
      "done in 0.596910s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19973\n",
      "           1       0.52      0.02      0.03      1925\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.72      0.51      0.49     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19943    30]\n",
      " [ 1892    33]]\n",
      "done in 33.458736s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19866\n",
      "           1       0.49      0.02      0.04      2032\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.70      0.51      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19827    39]\n",
      " [ 1994    38]]\n",
      "done in 33.576140s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17189\n",
      "           1       0.51      0.02      0.03      1658\n",
      "\n",
      "    accuracy                           0.91     18847\n",
      "   macro avg       0.71      0.51      0.49     18847\n",
      "weighted avg       0.88      0.91      0.87     18847\n",
      "\n",
      "Confusion_matrix\n",
      "[[17165    24]\n",
      " [ 1633    25]]\n",
      "done in 33.680497s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17067\n",
      "           1       0.52      0.02      0.04      1750\n",
      "\n",
      "    accuracy                           0.91     18817\n",
      "   macro avg       0.72      0.51      0.49     18817\n",
      "weighted avg       0.87      0.91      0.87     18817\n",
      "\n",
      "Confusion_matrix\n",
      "[[17038    29]\n",
      " [ 1718    32]]\n",
      "done in 33.614829s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2784\n",
      "           1       0.57      0.03      0.06       267\n",
      "\n",
      "    accuracy                           0.91      3051\n",
      "   macro avg       0.74      0.51      0.51      3051\n",
      "weighted avg       0.88      0.91      0.88      3051\n",
      "\n",
      "Confusion_matrix\n",
      "[[2778    6]\n",
      " [ 259    8]]\n",
      "done in 33.389559s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2799\n",
      "           1       0.38      0.02      0.04       282\n",
      "\n",
      "    accuracy                           0.91      3081\n",
      "   macro avg       0.64      0.51      0.50      3081\n",
      "weighted avg       0.86      0.91      0.87      3081\n",
      "\n",
      "Confusion_matrix\n",
      "[[2789   10]\n",
      " [ 276    6]]\n",
      "done in 31.299952s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.40800000000000003\n",
      "threshold:0.2, J-value:0.26599999999999996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.30000000000000004, J-value:0.156\n",
      "threshold:0.4, J-value:0.078\n",
      "threshold:0.5, J-value:0.032999999999999995\n",
      "threshold:0.6000000000000001, J-value:0.011\n",
      "threshold:0.7000000000000001, J-value:0.003\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7040347586124385\n",
      "Balanced accuracy score of test is  0.7064896816544867\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.40700000000000003\n",
      "threshold:0.2, J-value:0.262\n",
      "threshold:0.30000000000000004, J-value:0.151\n",
      "threshold:0.4, J-value:0.07300000000000001\n",
      "threshold:0.5, J-value:0.030000000000000002\n",
      "threshold:0.6000000000000001, J-value:0.012\n",
      "threshold:0.7000000000000001, J-value:0.004\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7039884261268725\n",
      "Balanced accuracy score of test is  0.7059168654630071\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.40900000000000003\n",
      "threshold:0.2, J-value:0.29200000000000004\n",
      "threshold:0.30000000000000004, J-value:0.19\n",
      "threshold:0.4, J-value:0.106\n",
      "threshold:0.5, J-value:0.052000000000000005\n",
      "threshold:0.6000000000000001, J-value:0.006\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7042308375306728\n",
      "Balanced accuracy score of test is  0.7100351189254521\n",
      "True positive rate of class 1 is  0.67\n",
      "True positive rate of class 2 is  0.677\n",
      "Positive prediction rate of class 1 is  0.297\n",
      "Positive prediction rate of class 2 is  0.296\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.397\n",
      "threshold:0.2, J-value:0.28200000000000003\n",
      "threshold:0.30000000000000004, J-value:0.11300000000000002\n",
      "threshold:0.4, J-value:0.02\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6983512547133435\n",
      "Balanced accuracy score of test is  0.7052092028401312\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.405\n",
      "threshold:0.2, J-value:0.28300000000000003\n",
      "threshold:0.30000000000000004, J-value:0.10300000000000001\n",
      "threshold:0.4, J-value:0.018\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7022263515934146\n",
      "Balanced accuracy score of test is  0.700184734115126\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.40199999999999997\n",
      "threshold:0.2, J-value:0.271\n",
      "threshold:0.30000000000000004, J-value:0.11300000000000002\n",
      "threshold:0.4, J-value:0.016\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7008870915665764\n",
      "Balanced accuracy score of test is  0.6992029828282138\n",
      "True positive rate of class 1 is  0.746\n",
      "True positive rate of class 2 is  0.755\n",
      "Positive prediction rate of class 1 is  0.383\n",
      "Positive prediction rate of class 2 is  0.393\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.36900000000000005\n",
      "threshold:0.2, J-value:0.194\n",
      "threshold:0.30000000000000004, J-value:0.06899999999999999\n",
      "threshold:0.4, J-value:0.053\n",
      "threshold:0.5, J-value:-0.001\n",
      "threshold:0.6000000000000001, J-value:-0.001\n",
      "threshold:0.7000000000000001, J-value:-0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6843549050959055\n",
      "Balanced accuracy score of test is  0.6802567606506903\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.36800000000000005\n",
      "threshold:0.2, J-value:0.196\n",
      "threshold:0.30000000000000004, J-value:0.072\n",
      "threshold:0.4, J-value:0.058\n",
      "threshold:0.5, J-value:-0.001\n",
      "threshold:0.6000000000000001, J-value:-0.001\n",
      "threshold:0.7000000000000001, J-value:-0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6839144855242725\n",
      "Balanced accuracy score of test is  0.6789772576986499\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.374\n",
      "threshold:0.2, J-value:0.176\n",
      "threshold:0.30000000000000004, J-value:0.048999999999999995\n",
      "threshold:0.4, J-value:0.024\n",
      "threshold:0.5, J-value:-0.001\n",
      "threshold:0.6000000000000001, J-value:-0.001\n",
      "threshold:0.7000000000000001, J-value:-0.001\n",
      "threshold:0.8, J-value:-0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6869147940074907\n",
      "Balanced accuracy score of test is  0.6877532249359574\n",
      "True positive rate of class 1 is  0.658\n",
      "True positive rate of class 2 is  0.617\n",
      "Positive prediction rate of class 1 is  0.333\n",
      "Positive prediction rate of class 2 is  0.276\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.4159999999999999\n",
      "threshold:0.2, J-value:0.27199999999999996\n",
      "threshold:0.30000000000000004, J-value:0.149\n",
      "threshold:0.4, J-value:0.055\n",
      "threshold:0.5, J-value:0.015000000000000001\n",
      "threshold:0.6000000000000001, J-value:0.004\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7083037815336418\n",
      "Balanced accuracy score of test is  0.7071791187967255\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.4169999999999999\n",
      "threshold:0.2, J-value:0.27199999999999996\n",
      "threshold:0.30000000000000004, J-value:0.149\n",
      "threshold:0.4, J-value:0.054\n",
      "threshold:0.5, J-value:0.013999999999999999\n",
      "threshold:0.6000000000000001, J-value:0.004\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7081343610428893\n",
      "Balanced accuracy score of test is  0.7083593233391089\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41800000000000004\n",
      "threshold:0.2, J-value:0.26299999999999996\n",
      "threshold:0.30000000000000004, J-value:0.141\n",
      "threshold:0.4, J-value:0.067\n",
      "threshold:0.5, J-value:0.027999999999999997\n",
      "threshold:0.6000000000000001, J-value:0.004\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7092575552111584\n",
      "Balanced accuracy score of test is  0.6997274862602905\n",
      "True positive rate of class 1 is  0.697\n",
      "True positive rate of class 2 is  0.663\n",
      "Positive prediction rate of class 1 is  0.319\n",
      "Positive prediction rate of class 2 is  0.3\n"
     ]
    }
   ],
   "source": [
    "records_lr = []\n",
    "records_rf = []\n",
    "records_dt = []\n",
    "records_gbt = []\n",
    "for random_state in range(10):\n",
    "    fairness_metrics (X, y, \"Race_W\", random_state)\n",
    "\n",
    "result_lr = pd.DataFrame(records_lr)\n",
    "result_rf = pd.DataFrame(records_rf)\n",
    "result_dt = pd.DataFrame(records_dt)\n",
    "result_gbt = pd.DataFrame(records_gbt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def add_mean_sd(records, result_table, overall_records, type):\n",
    "    records.append({\n",
    "        'auroc': result_table[\"auroc\"].mean(),\n",
    "        'overall threshold': result_table[\"overall threshold\"].mean(),\n",
    "        'white threshold': result_table[\"white threshold\"].mean(),\n",
    "        'black threshold': result_table[\"black threshold\"].mean(),\n",
    "        'overall ba validation': result_table[\"overall ba validation\"].mean(),\n",
    "        'overall ba test': result_table[\"overall ba test\"].mean(),\n",
    "        'white ba validation': result_table[\"white ba validation\"].mean(),\n",
    "        'white ba test': result_table[\"white ba test\"].mean(),\n",
    "        'black ba validation': result_table[\"black ba validation\"].mean(),\n",
    "        'black ba test': result_table[\"black ba test\"].mean(),\n",
    "        'overall precision':result_table[\"overall precision\"].mean(),\n",
    "        'overall recall':result_table[\"overall recall\"].mean(),\n",
    "        'overall tpr':result_table[\"overall tpr\"].mean(),\n",
    "        'overall tnr':result_table[\"overall tnr\"].mean(),\n",
    "        'overall pd':result_table[\"overall pd\"].mean(),\n",
    "        'white precision':result_table[\"white precision\"].mean(),\n",
    "        'white recall':result_table[\"white recall\"].mean(),\n",
    "        'white tpr':result_table[\"white tpr\"].mean(),\n",
    "        'white tnr':result_table[\"white tnr\"].mean(),\n",
    "        'white pd':result_table[\"white pd\"].mean(),\n",
    "        'black precision':result_table[\"black precision\"].mean(),\n",
    "        'black recall':result_table[\"black recall\"].mean(),\n",
    "        'black tpr':result_table[\"black tpr\"].mean(),\n",
    "        'black tnr':result_table[\"black tnr\"].mean(),\n",
    "        'black pd':result_table[\"black pd\"].mean(),\n",
    "        'eod': result_table[\"eod\"].mean(),\n",
    "        'di': result_table[\"di\"].mean(),\n",
    "        })\n",
    "    records.append({\n",
    "        'auroc': result_table[\"auroc\"].std(),\n",
    "        'overall threshold': result_table[\"overall threshold\"].std(),\n",
    "        'white threshold': result_table[\"white threshold\"].std(),\n",
    "        'black threshold': result_table[\"black threshold\"].std(),\n",
    "        'overall ba validation': result_table[\"overall ba validation\"].std(),\n",
    "        'overall ba test': result_table[\"overall ba test\"].std(),\n",
    "        'white ba validation': result_table[\"white ba validation\"].std(),\n",
    "        'white ba test': result_table[\"white ba test\"].std(),\n",
    "        'black ba validation': result_table[\"black ba validation\"].std(),\n",
    "        'black ba test': result_table[\"black ba test\"].std(),\n",
    "        'overall precision':result_table[\"overall precision\"].std(),\n",
    "        'overall recall':result_table[\"overall recall\"].std(),\n",
    "        'overall tpr':result_table[\"overall tpr\"].std(),\n",
    "        'overall tnr':result_table[\"overall tnr\"].std(),\n",
    "        'overall pd':result_table[\"overall pd\"].std(),\n",
    "        'white precision':result_table[\"white precision\"].std(),\n",
    "        'white recall':result_table[\"white recall\"].std(),\n",
    "        'white tpr':result_table[\"white tpr\"].std(),\n",
    "        'white tnr':result_table[\"white tnr\"].std(),\n",
    "        'white pd':result_table[\"white pd\"].std(),\n",
    "        'black precision':result_table[\"black precision\"].std(),\n",
    "        'black recall':result_table[\"black recall\"].std(),\n",
    "        'black tpr':result_table[\"black tpr\"].std(),\n",
    "        'black tnr':result_table[\"black tnr\"].std(),\n",
    "        'black pd':result_table[\"black pd\"].std(),\n",
    "        'eod': result_table[\"eod\"].std(),\n",
    "        'di': result_table[\"di\"].std(),\n",
    "        })\n",
    "    overall_records.append({\n",
    "        'type': type,\n",
    "        'auroc': result_table[\"auroc\"].mean(),\n",
    "        'overall threshold': result_table[\"overall threshold\"].mean(),\n",
    "        'white threshold': result_table[\"white threshold\"].mean(),\n",
    "        'black threshold': result_table[\"black threshold\"].mean(),\n",
    "        'overall ba test': result_table[\"overall ba test\"].mean(),\n",
    "        'white ba test': result_table[\"white ba test\"].mean(),\n",
    "        'black ba test': result_table[\"black ba test\"].mean(),\n",
    "        'overall tpr':result_table[\"overall tpr\"].mean(),\n",
    "        'overall pd':result_table[\"overall pd\"].mean(),\n",
    "        'white tpr':result_table[\"white tpr\"].mean(),\n",
    "        'white pd':result_table[\"white pd\"].mean(),\n",
    "        'black tpr':result_table[\"black tpr\"].mean(),\n",
    "        'black pd':result_table[\"black pd\"].mean(),\n",
    "        'eod': result_table[\"eod\"].mean(),\n",
    "        'di': result_table[\"di\"].mean(),\n",
    "        })\n",
    "    pd_result = pd.DataFrame(records)\n",
    "    return pd_result, overall_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "overall_table = []\n",
    "result_lr, overall_records = add_mean_sd (records_lr, result_lr, overall_table, 'lr')\n",
    "result_rf, overall_records = add_mean_sd (records_rf, result_rf, overall_records, 'rf')\n",
    "result_dt, overall_records = add_mean_sd (records_dt, result_dt, overall_records, 'dt')\n",
    "result_gbt, overall_records = add_mean_sd (records_gbt, result_gbt, overall_records, 'gbt')\n",
    "\n",
    "result_path='/Users/lifuchen/Desktop/research/resample_data/'\n",
    "result_lr.to_csv(path.join(result_path,'race-lr-resample-proportion-result.csv'), index=False)\n",
    "result_rf.to_csv(path.join(result_path,'race-rf-resample-proportion-result.csv'), index=False)\n",
    "result_dt.to_csv(path.join(result_path,'race-dt-resample-proportion-result.csv'), index=False)\n",
    "result_gbt.to_csv(path.join(result_path,'race-gbt-resample-proportion-result.csv'), index=False)\n",
    "\n",
    "overall_result = pd.DataFrame(overall_table)\n",
    "result_path='/Users/lifuchen/Desktop/research/resample_result/'\n",
    "overall_result.to_csv(path.join(result_path,'race-resample-proportion.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
