{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "741e6f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from os import path\n",
    "\n",
    "import src.lib.utility_classfier_tuning as uclf\n",
    "import src.lib.optimal_threhold_related as thres\n",
    "import src.lib.fairness_tests as fair\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score\n",
    "import sklearn.preprocessing\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26c8d073",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_path='/Users/lifuchen/Desktop/Evaluating-and-Mitigating-Bias-in-ML-Models-for-CVD/deep learning/resample by size/'\n",
    "filename = \"LSTM resample_size gender prediction_0.csv\"\n",
    "prediction = pd.read_csv(path.join(result_path, filename))\n",
    "\n",
    "y_test_score = prediction['test_score'][prediction['test_score'].notna()]   \n",
    "y_test_score_male = prediction['test_male_score'][prediction['test_male_score'].notna()]   \n",
    "y_test_score_female = prediction['test_female_score'][prediction['test_female_score'].notna()]\n",
    "\n",
    "filename = \"LSTM resample_size gender result_0.csv\"\n",
    "result = pd.read_csv(path.join(result_path, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d4b3fb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.230625\n",
       "1       0.171617\n",
       "2       0.234792\n",
       "3       0.232877\n",
       "4       0.020797\n",
       "          ...   \n",
       "7702    0.188267\n",
       "7703    0.101517\n",
       "7704    0.031654\n",
       "7705    0.002719\n",
       "7706    0.039809\n",
       "Name: test_male_score, Length: 7707, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_score_male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97f50019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.0\n",
       "1       0.0\n",
       "2       0.0\n",
       "3       1.0\n",
       "4       0.0\n",
       "       ... \n",
       "7702    1.0\n",
       "7703    0.0\n",
       "7704    0.0\n",
       "7705    0.0\n",
       "7706    0.0\n",
       "Name: y_test_male, Length: 7707, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['y_test_male'][result['y_test_male'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "267c4991",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result (records, auc_vec, ba_vec, eod_vec, di_vec, y_test, y_score, y_test_1, y_score_1, y_test_2, y_score_2):    \n",
    "    threshold = 0.1\n",
    "    ba = thres.calculate_balanced_accuracy(y_test, y_score, threshold)\n",
    "    auroc = roc_auc_score(y_test, y_score)\n",
    "    precision, recall, tpr, tnr, pd_overall = thres.calculate_precision_metrics(y_test, y_score,threshold)\n",
    "    \n",
    "    ba_male = thres.calculate_balanced_accuracy(y_test_1, y_score_1, threshold)\n",
    "    precision_male, recall_male, tpr_male, tnr_male, pd_male = thres.calculate_precision_metrics(y_test_1, y_score_1,threshold)\n",
    "    \n",
    "    ba_female = thres.calculate_balanced_accuracy (y_test_2, y_score_2, threshold)\n",
    "    precision_female, recall_female, tpr_female, tnr_female, pd_female = thres.calculate_precision_metrics(y_test_2, y_score_2,threshold)\n",
    "\n",
    "    eod = fair.get_EOD(y_test_1, y_score_1,threshold, y_test_2, y_score_2, threshold)\n",
    "    di = fair.get_SP(y_test_1, y_score_1,threshold, y_test_2, y_score_2, threshold)\n",
    "    \n",
    "    auc_vec.append(auroc)\n",
    "    ba_vec.append(ba)\n",
    "    eod_vec.append(eod)\n",
    "    di_vec.append(di)\n",
    "\n",
    "    records.append({\n",
    "        'auroc': auroc,\n",
    "        'overall ba test': ba,\n",
    "        'male ba test': ba_male,\n",
    "        'female ba test': ba_female,\n",
    "        'overall precision':precision,\n",
    "        'overall recall':recall,\n",
    "        'overall tpr':tpr,\n",
    "        'overall tnr':tnr,\n",
    "        'overall pd':pd_overall,\n",
    "        'male precision':precision_male,\n",
    "        'male recall':recall_male,\n",
    "        'male tpr':tpr_male,\n",
    "        'male tnr':tnr_male,\n",
    "        'male pd':pd_male,\n",
    "        'female precision':precision_female,\n",
    "        'female recall':recall_female,\n",
    "        'female tpr':tpr_female,\n",
    "        'female tnr':tnr_female,\n",
    "        'female pd':pd_female,\n",
    "        'eod': eod,\n",
    "        'di': di,\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "804a7cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positive rate of class 1 is  0.784\n",
      "True positive rate of class 2 is  0.688\n",
      "Positive prediction rate of class 1 is  0.465\n",
      "Positive prediction rate of class 2 is  0.4\n",
      "True positive rate of class 1 is  0.746\n",
      "True positive rate of class 2 is  0.649\n",
      "Positive prediction rate of class 1 is  0.405\n",
      "Positive prediction rate of class 2 is  0.329\n",
      "True positive rate of class 1 is  0.751\n",
      "True positive rate of class 2 is  0.634\n",
      "Positive prediction rate of class 1 is  0.409\n",
      "Positive prediction rate of class 2 is  0.303\n",
      "True positive rate of class 1 is  0.669\n",
      "True positive rate of class 2 is  0.614\n",
      "Positive prediction rate of class 1 is  0.369\n",
      "Positive prediction rate of class 2 is  0.306\n",
      "True positive rate of class 1 is  0.72\n",
      "True positive rate of class 2 is  0.692\n",
      "Positive prediction rate of class 1 is  0.383\n",
      "Positive prediction rate of class 2 is  0.339\n"
     ]
    }
   ],
   "source": [
    "records_lstm_race = []\n",
    "auc_race = []\n",
    "ba_race = []\n",
    "eod_race = []\n",
    "di_race = []\n",
    "for i in range(5):\n",
    "    filename = \"LSTM resample_size race prediction_\" + str(i) + \".csv\"\n",
    "    prediction = pd.read_csv(path.join(result_path, filename))\n",
    "    \n",
    "    y_test_score = prediction['test_score'][prediction['test_score'].notna()]   \n",
    "    y_test_score_white = prediction['test_white_score'][prediction['test_white_score'].notna()]   \n",
    "    y_test_score_black = prediction['test_black_score'][prediction['test_black_score'].notna()]\n",
    "    \n",
    "    filename_2 = \"LSTM resample_size race result_\" + str(i) + \".csv\"\n",
    "    result = pd.read_csv(path.join(result_path, filename_2))\n",
    "    y_test = result['y_test'][result['y_test'].notna()] \n",
    "    y_test_white = result['y_test_white'][result['y_test_white'].notna()] \n",
    "    y_test_black = result['y_test_black'][result['y_test_black'].notna()] \n",
    "    \n",
    "    get_result(records_lstm_race, auc_race, ba_race, eod_race, di_race, y_test, y_test_score, y_test_white, y_test_score_white, y_test_black, y_test_score_black)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a366b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7253370695596897, 0.7493057778293556, 0.7489126152258704, 0.7298778400533095, 0.7537024114256184] 0.7414271428187688 0.011498384738811021\n",
      "[0.6730407135808861, 0.686078630539661, 0.6884397047791615, 0.6653798249591001, 0.6862542817106927] 0.6798386311139003 0.009048153312324192\n",
      "[0.09600000000000009, 0.09699999999999998, 0.11699999999999999, 0.05500000000000005, 0.028000000000000025] 0.07860000000000003 0.03235181602321575\n",
      "[1.1625, 1.2310030395136777, 1.3498349834983498, 1.2058823529411764, 1.1297935103244836] 1.2158027772555375 0.07554187601956906\n"
     ]
    }
   ],
   "source": [
    "print(auc_race, np.mean(auc_race), np.std(auc_race))\n",
    "print(ba_race, np.mean(ba_race), np.std(ba_race))\n",
    "print(eod_race, np.mean(eod_race), np.std(eod_race))\n",
    "print(di_race, np.mean(di_race), np.std(di_race))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b20fa64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positive rate of class 1 is  0.821\n",
      "True positive rate of class 2 is  0.649\n",
      "Positive prediction rate of class 1 is  0.536\n",
      "Positive prediction rate of class 2 is  0.316\n",
      "True positive rate of class 1 is  0.822\n",
      "True positive rate of class 2 is  0.66\n",
      "Positive prediction rate of class 1 is  0.567\n",
      "Positive prediction rate of class 2 is  0.33\n",
      "True positive rate of class 1 is  0.822\n",
      "True positive rate of class 2 is  0.666\n",
      "Positive prediction rate of class 1 is  0.518\n",
      "Positive prediction rate of class 2 is  0.318\n",
      "True positive rate of class 1 is  0.871\n",
      "True positive rate of class 2 is  0.652\n",
      "Positive prediction rate of class 1 is  0.628\n",
      "Positive prediction rate of class 2 is  0.357\n",
      "True positive rate of class 1 is  0.79\n",
      "True positive rate of class 2 is  0.602\n",
      "Positive prediction rate of class 1 is  0.48\n",
      "Positive prediction rate of class 2 is  0.292\n"
     ]
    }
   ],
   "source": [
    "records_lstm_gender = []\n",
    "auc_gender = []\n",
    "ba_gender = []\n",
    "eod_gender = []\n",
    "di_gender = []\n",
    "for i in range(5):\n",
    "    filename = \"LSTM resample_size gender prediction_\" + str(i) + \".csv\"\n",
    "    prediction = pd.read_csv(path.join(result_path, filename))\n",
    "    \n",
    "    y_test_score = prediction['test_score'][prediction['test_score'].notna()]   \n",
    "    y_test_score_male = prediction['test_male_score'][prediction['test_male_score'].notna()]   \n",
    "    y_test_score_female = prediction['test_female_score'][prediction['test_female_score'].notna()]\n",
    "    \n",
    "    filename_2 = \"LSTM resample_size gender result_\" + str(i) + \".csv\"\n",
    "    result = pd.read_csv(path.join(result_path, filename_2))\n",
    "    y_test = result['y_test'][result['y_test'].notna()] \n",
    "    y_test_male = result['y_test_male'][result['y_test_male'].notna()] \n",
    "    y_test_female = result['y_test_female'][result['y_test_female'].notna()] \n",
    "    \n",
    "    get_result(records_lstm_gender, auc_gender, ba_gender, eod_gender, di_gender, y_test, y_test_score, y_test_male, y_test_score_male, y_test_female, y_test_score_female)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "498fbb0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7403910501395952, 0.7331121046100055, 0.7415489796450676, 0.720356884945448, 0.7316901717370321] 0.7334198382154297 0.0075948394361804224\n",
      "[0.6810616582584035, 0.6727517954003726, 0.6900624484499833, 0.6618436093031936, 0.6770188164222439] 0.6765476655668394 0.009315206604812323\n",
      "[0.17199999999999993, 0.16199999999999992, 0.15599999999999992, 0.21899999999999997, 0.18800000000000006] 0.17939999999999995 0.022570777567465443\n",
      "[1.6962025316455698, 1.718181818181818, 1.628930817610063, 1.7591036414565828, 1.6438356164383563] 1.6892508850664778 0.04788692727434309\n"
     ]
    }
   ],
   "source": [
    "print(auc_gender, np.mean(auc_gender), np.std(auc_gender))\n",
    "print(ba_gender, np.mean(ba_gender), np.std(ba_gender))\n",
    "print(eod_gender, np.mean(eod_gender), np.std(eod_gender))\n",
    "print(di_gender, np.mean(di_gender), np.std(di_gender))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aafef75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (CVDPrediction-master)",
   "language": "python",
   "name": "pycharm-6defbc71"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
