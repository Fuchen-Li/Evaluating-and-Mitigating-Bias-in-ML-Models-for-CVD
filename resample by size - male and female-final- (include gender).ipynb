{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import imblearn\n",
    "from os import path\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score\n",
    "import sklearn.preprocessing\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import src.lib.utility_classfier as uclf\n",
    "import src.lib.optimal_threhold_related as thres\n",
    "import src.lib.fairness_tests as fair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109490, 89)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path='/Users/lifuchen/Desktop/research/data.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109490, 88)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df.Class.values\n",
    "X = df.drop(['GRID','Class'], axis=1)\n",
    "# copy this row to include the gender information\n",
    "X.loc[:,'gender_copy'] = X['GENDER']\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def save_prediction(classifier, characteristic, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_male_scaled, y_val_male, X_test_male_scaled, y_test_male, X_val_female_scaled, y_val_female, X_test_female_scaled, y_test_female):\n",
    "    method_to_call = getattr(uclf, classifier)\n",
    "    y_val_score = method_to_call(X_train_scaled, y_train,X_val_scaled, y_val)\n",
    "    y_test_score = method_to_call(X_train_scaled, y_train,X_test_scaled, y_test)\n",
    "\n",
    "    y_val_score_male = method_to_call(X_train_scaled, y_train, X_val_male_scaled, y_val_male)\n",
    "    y_test_score_male = method_to_call(X_train_scaled, y_train,X_test_male_scaled, y_test_male)\n",
    "\n",
    "    y_val_score_female = method_to_call(X_train_scaled, y_train, X_val_female_scaled, y_val_female)\n",
    "    y_test_score_female = method_to_call(X_train_scaled, y_train,X_test_female_scaled, y_test_female)\n",
    "\n",
    "    my_dict = dict(val_score = y_val_score, test_score = y_test_score, val_1_score = y_val_score_male, test_1_score = y_test_score_male, val_2_score = y_val_score_female, test_2_score = y_test_score_female)\n",
    "    overall_prediction = pd.DataFrame.from_dict(my_dict, orient='index')\n",
    "    overall_prediction = overall_prediction.transpose()\n",
    "\n",
    "    result_path='/Users/lifuchen/Desktop/research/predictions/'\n",
    "    filename = str(classifier) + str(characteristic) + \"prediction.csv\"\n",
    "    overall_prediction.to_csv(path.join(result_path, filename), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_result (classifier,characteristic, records, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_male_scaled, y_val_male, X_test_male_scaled, y_test_male, X_val_female_scaled, y_val_female, X_test_female_scaled, y_test_female):\n",
    "    result_path='/Users/lifuchen/Desktop/research/predictions/'\n",
    "    filename = str(classifier) + characteristic + \"prediction.csv\"\n",
    "    prediction = pd.read_csv(path.join(result_path, filename))\n",
    "    \n",
    "    y_val_score = prediction['val_score'][prediction['val_score'].notna()]\n",
    "    y_test_score = prediction['test_score'][prediction['test_score'].notna()]\n",
    "    \n",
    "    y_val_score_male = prediction['val_1_score'][prediction['val_1_score'].notna()]\n",
    "    y_test_score_male = prediction['test_1_score'][prediction['test_1_score'].notna()]\n",
    "    \n",
    "    y_val_score_female = prediction['val_2_score'][prediction['val_2_score'].notna()]\n",
    "    y_test_score_female = prediction['test_2_score'][prediction['test_2_score'].notna()]\n",
    "    \n",
    "    threshold, ba_val, ba_test = balance_accuracy (y_val, y_val_score,y_test, y_test_score)\n",
    "    auroc = roc_auc_score(y_test, y_test_score)\n",
    "    precision, recall, tpr, tnr, pd_overall = thres.calculate_precision_metrics(y_test, y_test_score,threshold)\n",
    "    \n",
    "    threshold_male, ba_val_male, ba_test_male = balance_accuracy (y_val_male, y_val_score_male,y_test_male, y_test_score_male)\n",
    "    precision_male, recall_male, tpr_male, tnr_male, pd_male = thres.calculate_precision_metrics(y_test_male, y_test_score_male,threshold_male)\n",
    "    \n",
    "    threshold_female, ba_val_female, ba_test_female = balance_accuracy (y_val_female, y_val_score_female, y_test_female, y_test_score_female)\n",
    "    precision_female, recall_female, tpr_female, tnr_female, pd_female = thres.calculate_precision_metrics(y_test_female, y_test_score_female,threshold_female)\n",
    "\n",
    "    eod = fair.get_EOD(y_test_male, y_test_score_male,threshold_male, y_test_female, y_test_score_female, threshold_female)\n",
    "    sp = fair.get_SP(y_test_male, y_test_score_male,threshold_male, y_test_female, y_test_score_female, threshold_female)\n",
    "\n",
    "    records.append({\n",
    "        'auroc': auroc,\n",
    "        'overall threshold': threshold,\n",
    "        'male threshold': threshold_male,\n",
    "        'female threshold': threshold_female,\n",
    "        'overall ba validation': ba_val,\n",
    "        'overall ba test': ba_test,\n",
    "        'male ba validation': ba_val_male,\n",
    "        'male ba test': ba_test_male,\n",
    "        'female ba validation': ba_val_female,\n",
    "        'female ba test': ba_test_female,\n",
    "        'overall precision':precision,\n",
    "        'overall recall':recall,\n",
    "        'overall tpr':tpr,\n",
    "        'overall tnr':tnr,\n",
    "        'overall pd':pd_overall,\n",
    "        'male precision':precision_male,\n",
    "        'male recall':recall_male,\n",
    "        'male tpr':tpr_male,\n",
    "        'male tnr':tnr_male,\n",
    "        'male pd':pd_male,\n",
    "        'female precision':precision_female,\n",
    "        'female recall':recall_female,\n",
    "        'female tpr':tpr_female,\n",
    "        'female tnr':tnr_female,\n",
    "        'female pd':pd_female,\n",
    "        'eod': eod,\n",
    "        'di': sp,\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def balance_accuracy (y_val, y_val_score,y_test, y_test_score):\n",
    "    \n",
    "    threshold, _ = thres.get_optimal_threshold_Jvalue (y_val, y_val_score)\n",
    "    print (\"Optimal threshold by J value is \",threshold)\n",
    "\n",
    "    ba_val = thres.calculate_balanced_accuracy(y_val, y_val_score, threshold)\n",
    "    print (\"Balanced accuracy score of val is \", ba_val)\n",
    "\n",
    "    ba_test = thres.calculate_balanced_accuracy(y_test, y_test_score, threshold)\n",
    "    print (\"Balanced accuracy score of test is \",ba_test)\n",
    "\n",
    "    return threshold, ba_val, ba_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def fairness_metrics (X, y, attribute, random_state):\n",
    "    # call this split method that resamples by size, and drop the \"attribute\"\n",
    "    # a copy of attribute is included in the data, so we still have them in out model\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, X_val_female, X_val_male, y_val_female, y_val_male, X_test_female, X_test_male, y_test_female, y_test_male \\\n",
    "        = fair.split_by_trait_balance_size(X, y, attribute, random_state)\n",
    "    \n",
    "    print(\"X train\", X_train.shape[0])\n",
    "    print(\"Y train\", y_train.shape[0])\n",
    "    print(X_val.shape[0], X_val_male.shape[0], X_val_female.shape[0])\n",
    "    print(y_val.shape[0], y_val_male.shape[0], y_val_female.shape[0])\n",
    "    print(X_test.shape[0], X_test_male.shape[0], X_test_female.shape[0])\n",
    "    print(y_test.shape[0], y_test_male.shape[0], y_test_female.shape[0])\n",
    "\n",
    "    max_abs_scaler = preprocessing.MaxAbsScaler()\n",
    "    X_train_scaled = max_abs_scaler.fit_transform(X_train)\n",
    "    X_test_scaled = max_abs_scaler.transform(X_test)\n",
    "    X_test_male_scaled = max_abs_scaler.transform(X_test_male)\n",
    "    X_test_female_scaled = max_abs_scaler.transform(X_test_female)\n",
    "    X_val_scaled = max_abs_scaler.transform(X_val)\n",
    "    X_val_male_scaled = max_abs_scaler.transform(X_val_male)\n",
    "    X_val_female_scaled = max_abs_scaler.transform(X_val_female)\n",
    "\n",
    "    characteristic = attribute + \"resample-by-size\" + str(random_state)\n",
    "    save_prediction (\"logic_regression\", characteristic, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_male_scaled, y_val_male, X_test_male_scaled, y_test_male, X_val_female_scaled, y_val_female, X_test_female_scaled, y_test_female)\n",
    "    save_prediction (\"random_forest\", characteristic, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_male_scaled, y_val_male, X_test_male_scaled, y_test_male, X_val_female_scaled, y_val_female, X_test_female_scaled, y_test_female)\n",
    "    save_prediction (\"decision_tree\", characteristic, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_male_scaled, y_val_male, X_test_male_scaled, y_test_male, X_val_female_scaled, y_val_female, X_test_female_scaled, y_test_female)\n",
    "    save_prediction (\"gradiant_boosting\", characteristic, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_male_scaled, y_val_male, X_test_male_scaled, y_test_male, X_val_female_scaled, y_val_female, X_test_female_scaled, y_test_female)\n",
    "\n",
    "    get_result (\"logic_regression\", characteristic, records_lr, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_male_scaled, y_val_male, X_test_male_scaled, y_test_male, X_val_female_scaled, y_val_female, X_test_female_scaled, y_test_female)\n",
    "    get_result (\"random_forest\", characteristic, records_rf, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_male_scaled, y_val_male, X_test_male_scaled, y_test_male, X_val_female_scaled, y_val_female, X_test_female_scaled, y_test_female)\n",
    "    get_result (\"decision_tree\", characteristic, records_dt, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_male_scaled, y_val_male, X_test_male_scaled, y_test_male, X_val_female_scaled, y_val_female, X_test_female_scaled, y_test_female)\n",
    "    get_result (\"gradiant_boosting\", characteristic, records_gbt, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_male_scaled, y_val_male, X_test_male_scaled, y_test_male, X_val_female_scaled, y_val_female, X_test_female_scaled, y_test_female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lifuchen/Desktop/research/CVDPrediction-master/src/lib/fairness_tests.py:112: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train ['Class'] = y_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42330,)\n",
      "(42330,)\n",
      "(84660, 88)\n",
      "X train 84660\n",
      "Y train 84660\n",
      "21898 7782 14116\n",
      "21898 7782 14116\n",
      "21898 7707 14191\n",
      "21898 7707 14191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2211159646901643\n",
      "0.2638848476879455\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95     19904\n",
      "           1       0.45      0.04      0.08      1994\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.52      0.52     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19797   107]\n",
      " [ 1907    87]]\n",
      "done in 0.664993s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2211159646901643\n",
      "0.26339766107062257\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95     19934\n",
      "           1       0.40      0.04      0.08      1964\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.66      0.52      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19809   125]\n",
      " [ 1880    84]]\n",
      "done in 0.655637s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2211159646901643\n",
      "0.31004486375897117\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94      6915\n",
      "           1       0.45      0.04      0.07       867\n",
      "\n",
      "    accuracy                           0.89      7782\n",
      "   macro avg       0.67      0.52      0.50      7782\n",
      "weighted avg       0.84      0.89      0.84      7782\n",
      "\n",
      "Confusion_matrix\n",
      "[[6877   38]\n",
      " [ 836   31]]\n",
      "done in 0.638693s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2211159646901643\n",
      "0.30438388697817514\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6860\n",
      "           1       0.49      0.04      0.07       847\n",
      "\n",
      "    accuracy                           0.89      7707\n",
      "   macro avg       0.69      0.52      0.50      7707\n",
      "weighted avg       0.85      0.89      0.85      7707\n",
      "\n",
      "Confusion_matrix\n",
      "[[6829   31]\n",
      " [ 817   30]]\n",
      "done in 0.816236s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2211159646901643\n",
      "0.23843732395142514\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96     12989\n",
      "           1       0.45      0.05      0.09      1127\n",
      "\n",
      "    accuracy                           0.92     14116\n",
      "   macro avg       0.69      0.52      0.52     14116\n",
      "weighted avg       0.89      0.92      0.89     14116\n",
      "\n",
      "Confusion_matrix\n",
      "[[12920    69]\n",
      " [ 1071    56]]\n",
      "done in 0.717617s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2211159646901643\n",
      "0.24113842330940016\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96     13074\n",
      "           1       0.36      0.05      0.09      1117\n",
      "\n",
      "    accuracy                           0.92     14191\n",
      "   macro avg       0.64      0.52      0.52     14191\n",
      "weighted avg       0.88      0.92      0.89     14191\n",
      "\n",
      "Confusion_matrix\n",
      "[[12980    94]\n",
      " [ 1063    54]]\n",
      "done in 0.658634s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19904\n",
      "           1       0.40      0.00      0.00      1994\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.65      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19898     6]\n",
      " [ 1990     4]]\n",
      "done in 26.518023s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19934\n",
      "           1       0.56      0.00      0.01      1964\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.73      0.50      0.48     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19930     4]\n",
      " [ 1959     5]]\n",
      "done in 25.300741s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6915\n",
      "           1       0.50      0.00      0.01       867\n",
      "\n",
      "    accuracy                           0.89      7782\n",
      "   macro avg       0.69      0.50      0.47      7782\n",
      "weighted avg       0.85      0.89      0.84      7782\n",
      "\n",
      "Confusion_matrix\n",
      "[[6912    3]\n",
      " [ 864    3]]\n",
      "done in 24.950044s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6860\n",
      "           1       1.00      0.00      0.00       847\n",
      "\n",
      "    accuracy                           0.89      7707\n",
      "   macro avg       0.95      0.50      0.47      7707\n",
      "weighted avg       0.90      0.89      0.84      7707\n",
      "\n",
      "Confusion_matrix\n",
      "[[6860    0]\n",
      " [ 846    1]]\n",
      "done in 24.836942s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12989\n",
      "           1       0.17      0.00      0.00      1127\n",
      "\n",
      "    accuracy                           0.92     14116\n",
      "   macro avg       0.54      0.50      0.48     14116\n",
      "weighted avg       0.86      0.92      0.88     14116\n",
      "\n",
      "Confusion_matrix\n",
      "[[12984     5]\n",
      " [ 1126     1]]\n",
      "done in 25.058441s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13074\n",
      "           1       0.80      0.00      0.01      1117\n",
      "\n",
      "    accuracy                           0.92     14191\n",
      "   macro avg       0.86      0.50      0.48     14191\n",
      "weighted avg       0.91      0.92      0.88     14191\n",
      "\n",
      "Confusion_matrix\n",
      "[[13073     1]\n",
      " [ 1113     4]]\n",
      "done in 24.923417s\n",
      "0.2279434818472589\n",
      "0.2731708525022863\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19904\n",
      "           1       0.00      0.00      0.00      1994\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.45      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19903     1]\n",
      " [ 1994     0]]\n",
      "done in 0.853471s\n",
      "0.2279434818472589\n",
      "0.27301248058762256\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19934\n",
      "           1       0.00      0.00      0.00      1964\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.46      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19933     1]\n",
      " [ 1964     0]]\n",
      "done in 0.855035s\n",
      "0.2279434818472589\n",
      "0.31922228995838925\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6915\n",
      "           1       0.00      0.00      0.00       867\n",
      "\n",
      "    accuracy                           0.89      7782\n",
      "   macro avg       0.44      0.50      0.47      7782\n",
      "weighted avg       0.79      0.89      0.84      7782\n",
      "\n",
      "Confusion_matrix\n",
      "[[6915    0]\n",
      " [ 867    0]]\n",
      "done in 0.836470s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2279434818472589\n",
      "0.3189396784660774\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6860\n",
      "           1       0.00      0.00      0.00       847\n",
      "\n",
      "    accuracy                           0.89      7707\n",
      "   macro avg       0.45      0.50      0.47      7707\n",
      "weighted avg       0.79      0.89      0.84      7707\n",
      "\n",
      "Confusion_matrix\n",
      "[[6859    1]\n",
      " [ 847    0]]\n",
      "done in 0.830851s\n",
      "0.2279434818472589\n",
      "0.24534045517840228\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12989\n",
      "           1       0.00      0.00      0.00      1127\n",
      "\n",
      "    accuracy                           0.92     14116\n",
      "   macro avg       0.46      0.50      0.48     14116\n",
      "weighted avg       0.85      0.92      0.88     14116\n",
      "\n",
      "Confusion_matrix\n",
      "[[12989     0]\n",
      " [ 1127     0]]\n",
      "done in 0.843870s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2279434818472589\n",
      "0.2480698469431118\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13074\n",
      "           1       0.00      0.00      0.00      1117\n",
      "\n",
      "    accuracy                           0.92     14191\n",
      "   macro avg       0.46      0.50      0.48     14191\n",
      "weighted avg       0.85      0.92      0.88     14191\n",
      "\n",
      "Confusion_matrix\n",
      "[[13074     0]\n",
      " [ 1117     0]]\n",
      "done in 0.844304s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19904\n",
      "           1       0.44      0.02      0.05      1994\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19842    62]\n",
      " [ 1946    48]]\n",
      "done in 46.861980s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19934\n",
      "           1       0.46      0.03      0.06      1964\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.69      0.52      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19855    79]\n",
      " [ 1897    67]]\n",
      "done in 46.710815s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6915\n",
      "           1       0.37      0.02      0.04       867\n",
      "\n",
      "    accuracy                           0.89      7782\n",
      "   macro avg       0.63      0.51      0.49      7782\n",
      "weighted avg       0.83      0.89      0.84      7782\n",
      "\n",
      "Confusion_matrix\n",
      "[[6886   29]\n",
      " [ 850   17]]\n",
      "done in 46.660813s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6860\n",
      "           1       0.55      0.04      0.07       847\n",
      "\n",
      "    accuracy                           0.89      7707\n",
      "   macro avg       0.72      0.52      0.50      7707\n",
      "weighted avg       0.86      0.89      0.85      7707\n",
      "\n",
      "Confusion_matrix\n",
      "[[6835   25]\n",
      " [ 817   30]]\n",
      "done in 47.530941s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12989\n",
      "           1       0.48      0.03      0.05      1127\n",
      "\n",
      "    accuracy                           0.92     14116\n",
      "   macro avg       0.70      0.51      0.50     14116\n",
      "weighted avg       0.89      0.92      0.89     14116\n",
      "\n",
      "Confusion_matrix\n",
      "[[12956    33]\n",
      " [ 1097    30]]\n",
      "done in 46.939634s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13074\n",
      "           1       0.41      0.03      0.06      1117\n",
      "\n",
      "    accuracy                           0.92     14191\n",
      "   macro avg       0.67      0.51      0.51     14191\n",
      "weighted avg       0.88      0.92      0.89     14191\n",
      "\n",
      "Confusion_matrix\n",
      "[[13020    54]\n",
      " [ 1079    38]]\n",
      "done in 47.094632s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.389\n",
      "threshold:0.2, J-value:0.249\n",
      "threshold:0.30000000000000004, J-value:0.144\n",
      "threshold:0.4, J-value:0.081\n",
      "threshold:0.5, J-value:0.039\n",
      "threshold:0.6000000000000001, J-value:0.015\n",
      "threshold:0.7000000000000001, J-value:0.004\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6948601280126554\n",
      "Balanced accuracy score of test is  0.6868601721730591\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.358\n",
      "threshold:0.2, J-value:0.22199999999999998\n",
      "threshold:0.30000000000000004, J-value:0.12\n",
      "threshold:0.4, J-value:0.054000000000000006\n",
      "threshold:0.5, J-value:0.030999999999999996\n",
      "threshold:0.6000000000000001, J-value:0.008\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6788399422548144\n",
      "Balanced accuracy score of test is  0.6810326964315833\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.40900000000000003\n",
      "threshold:0.2, J-value:0.267\n",
      "threshold:0.30000000000000004, J-value:0.163\n",
      "threshold:0.4, J-value:0.10200000000000001\n",
      "threshold:0.5, J-value:0.045000000000000005\n",
      "threshold:0.6000000000000001, J-value:0.019\n",
      "threshold:0.7000000000000001, J-value:0.005\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.704485564640287\n",
      "Balanced accuracy score of test is  0.687753438213905\n",
      "True positive rate of class 1 is  0.616\n",
      "True positive rate of class 2 is  0.584\n",
      "Positive prediction rate of class 1 is  0.294\n",
      "Positive prediction rate of class 2 is  0.238\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.39299999999999996\n",
      "threshold:0.2, J-value:0.276\n",
      "threshold:0.30000000000000004, J-value:0.099\n",
      "threshold:0.4, J-value:0.022000000000000002\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6966502905017302\n",
      "Balanced accuracy score of test is  0.6899023651777955\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.4\n",
      "threshold:0.2, J-value:0.236\n",
      "threshold:0.30000000000000004, J-value:0.091\n",
      "threshold:0.4, J-value:0.024999999999999998\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7002196718932565\n",
      "Balanced accuracy score of test is  0.6752397417054189\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.414\n",
      "threshold:0.2, J-value:0.28\n",
      "threshold:0.30000000000000004, J-value:0.091\n",
      "threshold:0.4, J-value:0.013\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7071698030201379\n",
      "Balanced accuracy score of test is  0.6953379762796417\n",
      "True positive rate of class 1 is  0.73\n",
      "True positive rate of class 2 is  0.686\n",
      "Positive prediction rate of class 1 is  0.418\n",
      "Positive prediction rate of class 2 is  0.326\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.37600000000000006\n",
      "threshold:0.2, J-value:0.20599999999999996\n",
      "threshold:0.30000000000000004, J-value:0.1\n",
      "threshold:0.4, J-value:0.006999999999999999\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6875646281690732\n",
      "Balanced accuracy score of test is  0.6818149077291109\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.347\n",
      "threshold:0.2, J-value:0.171\n",
      "threshold:0.30000000000000004, J-value:0.089\n",
      "threshold:0.4, J-value:0.006\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6735660654462117\n",
      "Balanced accuracy score of test is  0.6742783654193673\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.386\n",
      "threshold:0.2, J-value:0.23099999999999998\n",
      "threshold:0.30000000000000004, J-value:0.10700000000000001\n",
      "threshold:0.4, J-value:0.009\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6931823685634484\n",
      "Balanced accuracy score of test is  0.6807044508985352\n",
      "True positive rate of class 1 is  0.715\n",
      "True positive rate of class 2 is  0.639\n",
      "Positive prediction rate of class 1 is  0.405\n",
      "Positive prediction rate of class 2 is  0.306\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41200000000000003\n",
      "threshold:0.2, J-value:0.247\n",
      "threshold:0.30000000000000004, J-value:0.135\n",
      "threshold:0.4, J-value:0.063\n",
      "threshold:0.5, J-value:0.021\n",
      "threshold:0.6000000000000001, J-value:0.006\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7059667749228393\n",
      "Balanced accuracy score of test is  0.6929713523057863\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.386\n",
      "threshold:0.2, J-value:0.223\n",
      "threshold:0.30000000000000004, J-value:0.118\n",
      "threshold:0.4, J-value:0.054000000000000006\n",
      "threshold:0.5, J-value:0.016\n",
      "threshold:0.6000000000000001, J-value:0.008\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6929594908015522\n",
      "Balanced accuracy score of test is  0.6900838493602872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.42500000000000004\n",
      "threshold:0.2, J-value:0.264\n",
      "threshold:0.30000000000000004, J-value:0.147\n",
      "threshold:0.4, J-value:0.07\n",
      "threshold:0.5, J-value:0.024\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7127408264299537\n",
      "Balanced accuracy score of test is  0.6910936972092883\n",
      "True positive rate of class 1 is  0.642\n",
      "True positive rate of class 2 is  0.592\n",
      "Positive prediction rate of class 1 is  0.304\n",
      "Positive prediction rate of class 2 is  0.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lifuchen/Desktop/research/CVDPrediction-master/src/lib/fairness_tests.py:112: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train ['Class'] = y_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42313,)\n",
      "(42313,)\n",
      "(84626, 88)\n",
      "X train 84626\n",
      "Y train 84626\n",
      "21898 7665 14233\n",
      "21898 7665 14233\n",
      "21898 7807 14091\n",
      "21898 7807 14091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22395623753595287\n",
      "0.2574016970759688\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95     19980\n",
      "           1       0.45      0.05      0.08      1918\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.52      0.52     21898\n",
      "weighted avg       0.87      0.91      0.88     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19873   107]\n",
      " [ 1831    87]]\n",
      "done in 0.628504s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22395623753595287\n",
      "0.25934955502292095\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95     19972\n",
      "           1       0.45      0.04      0.08      1926\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.52      0.52     21898\n",
      "weighted avg       0.87      0.91      0.88     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19867   105]\n",
      " [ 1840    86]]\n",
      "done in 0.619321s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22395623753595287\n",
      "0.2993283026023977\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94      6836\n",
      "           1       0.51      0.04      0.08       829\n",
      "\n",
      "    accuracy                           0.89      7665\n",
      "   macro avg       0.70      0.52      0.51      7665\n",
      "weighted avg       0.85      0.89      0.85      7665\n",
      "\n",
      "Confusion_matrix\n",
      "[[6801   35]\n",
      " [ 792   37]]\n",
      "done in 0.611958s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22395623753595287\n",
      "0.3000982378133813\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94      6982\n",
      "           1       0.40      0.04      0.06       825\n",
      "\n",
      "    accuracy                           0.89      7807\n",
      "   macro avg       0.65      0.51      0.50      7807\n",
      "weighted avg       0.84      0.89      0.85      7807\n",
      "\n",
      "Confusion_matrix\n",
      "[[6939   43]\n",
      " [ 796   29]]\n",
      "done in 0.613082s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22395623753595287\n",
      "0.2348226602348195\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96     13144\n",
      "           1       0.41      0.05      0.08      1089\n",
      "\n",
      "    accuracy                           0.92     14233\n",
      "   macro avg       0.67      0.52      0.52     14233\n",
      "weighted avg       0.89      0.92      0.89     14233\n",
      "\n",
      "Confusion_matrix\n",
      "[[13072    72]\n",
      " [ 1039    50]]\n",
      "done in 0.615082s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22395623753595287\n",
      "0.23677309014852424\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96     12990\n",
      "           1       0.48      0.05      0.09      1101\n",
      "\n",
      "    accuracy                           0.92     14091\n",
      "   macro avg       0.70      0.52      0.53     14091\n",
      "weighted avg       0.89      0.92      0.89     14091\n",
      "\n",
      "Confusion_matrix\n",
      "[[12928    62]\n",
      " [ 1044    57]]\n",
      "done in 0.620571s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19980\n",
      "           1       0.00      0.00      0.00      1918\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.46      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19980     0]\n",
      " [ 1918     0]]\n",
      "done in 25.982166s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19972\n",
      "           1       0.50      0.00      0.00      1926\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.71      0.50      0.48     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19970     2]\n",
      " [ 1924     2]]\n",
      "done in 25.817233s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6836\n",
      "           1       0.00      0.00      0.00       829\n",
      "\n",
      "    accuracy                           0.89      7665\n",
      "   macro avg       0.45      0.50      0.47      7665\n",
      "weighted avg       0.80      0.89      0.84      7665\n",
      "\n",
      "Confusion_matrix\n",
      "[[6834    2]\n",
      " [ 829    0]]\n",
      "done in 25.500187s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6982\n",
      "           1       1.00      0.00      0.00       825\n",
      "\n",
      "    accuracy                           0.89      7807\n",
      "   macro avg       0.95      0.50      0.47      7807\n",
      "weighted avg       0.91      0.89      0.84      7807\n",
      "\n",
      "Confusion_matrix\n",
      "[[6982    0]\n",
      " [ 824    1]]\n",
      "done in 25.070601s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13144\n",
      "           1       0.75      0.00      0.01      1089\n",
      "\n",
      "    accuracy                           0.92     14233\n",
      "   macro avg       0.84      0.50      0.48     14233\n",
      "weighted avg       0.91      0.92      0.89     14233\n",
      "\n",
      "Confusion_matrix\n",
      "[[13143     1]\n",
      " [ 1086     3]]\n",
      "done in 24.877634s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12990\n",
      "           1       1.00      0.00      0.00      1101\n",
      "\n",
      "    accuracy                           0.92     14091\n",
      "   macro avg       0.96      0.50      0.48     14091\n",
      "weighted avg       0.93      0.92      0.88     14091\n",
      "\n",
      "Confusion_matrix\n",
      "[[12990     0]\n",
      " [ 1099     2]]\n",
      "done in 25.329645s\n",
      "0.23099143117724047\n",
      "0.2656832587754764\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19980\n",
      "           1       0.25      0.00      0.00      1918\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.58      0.50      0.48     21898\n",
      "weighted avg       0.85      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19974     6]\n",
      " [ 1916     2]]\n",
      "done in 0.866598s\n",
      "0.23099143117724047\n",
      "0.2699079054329293\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19972\n",
      "           1       0.12      0.00      0.00      1926\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.52      0.50      0.48     21898\n",
      "weighted avg       0.84      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19965     7]\n",
      " [ 1925     1]]\n",
      "done in 0.852908s\n",
      "0.23099143117724047\n",
      "0.30949497850113417\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6836\n",
      "           1       0.20      0.00      0.00       829\n",
      "\n",
      "    accuracy                           0.89      7665\n",
      "   macro avg       0.55      0.50      0.47      7665\n",
      "weighted avg       0.82      0.89      0.84      7665\n",
      "\n",
      "Confusion_matrix\n",
      "[[6832    4]\n",
      " [ 828    1]]\n",
      "done in 0.843017s\n",
      "0.23099143117724047\n",
      "0.3163416554787515\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6982\n",
      "           1       0.14      0.00      0.00       825\n",
      "\n",
      "    accuracy                           0.89      7807\n",
      "   macro avg       0.52      0.50      0.47      7807\n",
      "weighted avg       0.81      0.89      0.84      7807\n",
      "\n",
      "Confusion_matrix\n",
      "[[6976    6]\n",
      " [ 824    1]]\n",
      "done in 0.839941s\n",
      "0.23099143117724047\n",
      "0.2420890178075029\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13144\n",
      "           1       0.33      0.00      0.00      1089\n",
      "\n",
      "    accuracy                           0.92     14233\n",
      "   macro avg       0.63      0.50      0.48     14233\n",
      "weighted avg       0.88      0.92      0.89     14233\n",
      "\n",
      "Confusion_matrix\n",
      "[[13142     2]\n",
      " [ 1088     1]]\n",
      "done in 0.854394s\n",
      "0.23099143117724047\n",
      "0.24418167687514533\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12990\n",
      "           1       0.00      0.00      0.00      1101\n",
      "\n",
      "    accuracy                           0.92     14091\n",
      "   macro avg       0.46      0.50      0.48     14091\n",
      "weighted avg       0.85      0.92      0.88     14091\n",
      "\n",
      "Confusion_matrix\n",
      "[[12989     1]\n",
      " [ 1101     0]]\n",
      "done in 0.850709s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19980\n",
      "           1       0.42      0.02      0.05      1918\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19917    63]\n",
      " [ 1872    46]]\n",
      "done in 46.866882s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19972\n",
      "           1       0.47      0.03      0.06      1926\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.69      0.51      0.51     21898\n",
      "weighted avg       0.88      0.91      0.88     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19904    68]\n",
      " [ 1865    61]]\n",
      "done in 46.753829s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6836\n",
      "           1       0.61      0.03      0.05       829\n",
      "\n",
      "    accuracy                           0.89      7665\n",
      "   macro avg       0.75      0.51      0.50      7665\n",
      "weighted avg       0.86      0.89      0.85      7665\n",
      "\n",
      "Confusion_matrix\n",
      "[[6822   14]\n",
      " [ 807   22]]\n",
      "done in 46.695086s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.94      6982\n",
      "           1       0.41      0.02      0.05       825\n",
      "\n",
      "    accuracy                           0.89      7807\n",
      "   macro avg       0.65      0.51      0.49      7807\n",
      "weighted avg       0.84      0.89      0.85      7807\n",
      "\n",
      "Confusion_matrix\n",
      "[[6953   29]\n",
      " [ 805   20]]\n",
      "done in 46.678208s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13144\n",
      "           1       0.33      0.02      0.04      1089\n",
      "\n",
      "    accuracy                           0.92     14233\n",
      "   macro avg       0.63      0.51      0.50     14233\n",
      "weighted avg       0.88      0.92      0.89     14233\n",
      "\n",
      "Confusion_matrix\n",
      "[[13096    48]\n",
      " [ 1065    24]]\n",
      "done in 46.857935s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12990\n",
      "           1       0.51      0.04      0.07      1101\n",
      "\n",
      "    accuracy                           0.92     14091\n",
      "   macro avg       0.72      0.52      0.51     14091\n",
      "weighted avg       0.89      0.92      0.89     14091\n",
      "\n",
      "Confusion_matrix\n",
      "[[12951    39]\n",
      " [ 1060    41]]\n",
      "done in 46.737827s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.391\n",
      "threshold:0.2, J-value:0.261\n",
      "threshold:0.30000000000000004, J-value:0.14\n",
      "threshold:0.4, J-value:0.076\n",
      "threshold:0.5, J-value:0.04\n",
      "threshold:0.6000000000000001, J-value:0.017\n",
      "threshold:0.7000000000000001, J-value:0.006\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.001\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6957293581381172\n",
      "Balanced accuracy score of test is  0.6886053247131654\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.387\n",
      "threshold:0.2, J-value:0.27499999999999997\n",
      "threshold:0.30000000000000004, J-value:0.13899999999999998\n",
      "threshold:0.4, J-value:0.07\n",
      "threshold:0.5, J-value:0.04\n",
      "threshold:0.6000000000000001, J-value:0.015000000000000001\n",
      "threshold:0.7000000000000001, J-value:0.005\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.001\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6933096866726286\n",
      "Balanced accuracy score of test is  0.6764627657265869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.389\n",
      "threshold:0.2, J-value:0.25\n",
      "threshold:0.30000000000000004, J-value:0.14\n",
      "threshold:0.4, J-value:0.08\n",
      "threshold:0.5, J-value:0.041\n",
      "threshold:0.6000000000000001, J-value:0.019000000000000003\n",
      "threshold:0.7000000000000001, J-value:0.007\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6942469080222912\n",
      "Balanced accuracy score of test is  0.6943471502916727\n",
      "True positive rate of class 1 is  0.602\n",
      "True positive rate of class 2 is  0.589\n",
      "Positive prediction rate of class 1 is  0.287\n",
      "Positive prediction rate of class 2 is  0.231\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.39199999999999996\n",
      "threshold:0.2, J-value:0.28700000000000003\n",
      "threshold:0.30000000000000004, J-value:0.09699999999999999\n",
      "threshold:0.4, J-value:0.016\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6957836355646574\n",
      "Balanced accuracy score of test is  0.6945033275037805\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.391\n",
      "threshold:0.2, J-value:0.28800000000000003\n",
      "threshold:0.30000000000000004, J-value:0.10900000000000001\n",
      "threshold:0.4, J-value:0.013999999999999999\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6954189873944865\n",
      "Balanced accuracy score of test is  0.6811075232415822\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.38599999999999995\n",
      "threshold:0.2, J-value:0.257\n",
      "threshold:0.30000000000000004, J-value:0.08499999999999999\n",
      "threshold:0.4, J-value:0.015000000000000001\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6927218430081817\n",
      "Balanced accuracy score of test is  0.7022305986789251\n",
      "True positive rate of class 1 is  0.738\n",
      "True positive rate of class 2 is  0.694\n",
      "Positive prediction rate of class 1 is  0.414\n",
      "Positive prediction rate of class 2 is  0.321\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.36700000000000005\n",
      "threshold:0.2, J-value:0.175\n",
      "threshold:0.30000000000000004, J-value:0.068\n",
      "threshold:0.4, J-value:0.001\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6836827964565191\n",
      "Balanced accuracy score of test is  0.6794166557999475\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.35300000000000004\n",
      "threshold:0.2, J-value:0.187\n",
      "threshold:0.30000000000000004, J-value:0.083\n",
      "threshold:0.4, J-value:0.0\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6764946592968044\n",
      "Balanced accuracy score of test is  0.6646190637396595\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.369\n",
      "threshold:0.2, J-value:0.164\n",
      "threshold:0.30000000000000004, J-value:0.057999999999999996\n",
      "threshold:0.4, J-value:0.001\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6845166236592675\n",
      "Balanced accuracy score of test is  0.6855372923628111\n",
      "True positive rate of class 1 is  0.664\n",
      "True positive rate of class 2 is  0.634\n",
      "Positive prediction rate of class 1 is  0.37\n",
      "Positive prediction rate of class 2 is  0.292\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.404\n",
      "threshold:0.2, J-value:0.254\n",
      "threshold:0.30000000000000004, J-value:0.139\n",
      "threshold:0.4, J-value:0.063\n",
      "threshold:0.5, J-value:0.021\n",
      "threshold:0.6000000000000001, J-value:0.006\n",
      "threshold:0.7000000000000001, J-value:0.003\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7018525825095168\n",
      "Balanced accuracy score of test is  0.6937572154495005\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.402\n",
      "threshold:0.2, J-value:0.256\n",
      "threshold:0.30000000000000004, J-value:0.149\n",
      "threshold:0.4, J-value:0.065\n",
      "threshold:0.5, J-value:0.025\n",
      "threshold:0.6000000000000001, J-value:0.009000000000000001\n",
      "threshold:0.7000000000000001, J-value:0.005\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7010210261293189\n",
      "Balanced accuracy score of test is  0.6842156020242529\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.399\n",
      "threshold:0.2, J-value:0.251\n",
      "threshold:0.30000000000000004, J-value:0.132\n",
      "threshold:0.4, J-value:0.06099999999999999\n",
      "threshold:0.5, J-value:0.018\n",
      "threshold:0.6000000000000001, J-value:0.005\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6994407361391259\n",
      "Balanced accuracy score of test is  0.697733112664741\n",
      "True positive rate of class 1 is  0.627\n",
      "True positive rate of class 2 is  0.608\n",
      "Positive prediction rate of class 1 is  0.297\n",
      "Positive prediction rate of class 2 is  0.243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lifuchen/Desktop/research/CVDPrediction-master/src/lib/fairness_tests.py:112: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train ['Class'] = y_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42324,)\n",
      "(42324,)\n",
      "(84648, 88)\n",
      "X train 84648\n",
      "Y train 84648\n",
      "21898 7743 14155\n",
      "21898 7743 14155\n",
      "21898 7740 14158\n",
      "21898 7740 14158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22135260162616016\n",
      "0.2620542652277454\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19950\n",
      "           1       0.46      0.04      0.07      1948\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.69      0.52      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19861    89]\n",
      " [ 1871    77]]\n",
      "done in 0.632555s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22135260162616016\n",
      "0.2643760709996185\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19883\n",
      "           1       0.45      0.03      0.06      2015\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.51      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19801    82]\n",
      " [ 1947    68]]\n",
      "done in 0.643028s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22135260162616016\n",
      "0.30552468199496025\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6895\n",
      "           1       0.45      0.03      0.06       848\n",
      "\n",
      "    accuracy                           0.89      7743\n",
      "   macro avg       0.67      0.51      0.50      7743\n",
      "weighted avg       0.84      0.89      0.84      7743\n",
      "\n",
      "Confusion_matrix\n",
      "[[6865   30]\n",
      " [ 823   25]]\n",
      "done in 0.628009s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22135260162616016\n",
      "0.30985204808104294\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6860\n",
      "           1       0.43      0.03      0.05       880\n",
      "\n",
      "    accuracy                           0.89      7740\n",
      "   macro avg       0.66      0.51      0.49      7740\n",
      "weighted avg       0.84      0.89      0.84      7740\n",
      "\n",
      "Confusion_matrix\n",
      "[[6829   31]\n",
      " [ 857   23]]\n",
      "done in 0.624664s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22135260162616016\n",
      "0.23827528698482442\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96     13055\n",
      "           1       0.47      0.05      0.09      1100\n",
      "\n",
      "    accuracy                           0.92     14155\n",
      "   macro avg       0.70      0.52      0.52     14155\n",
      "weighted avg       0.89      0.92      0.89     14155\n",
      "\n",
      "Confusion_matrix\n",
      "[[12996    59]\n",
      " [ 1048    52]]\n",
      "done in 0.635705s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22135260162616016\n",
      "0.23951492799847254\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13023\n",
      "           1       0.47      0.04      0.07      1135\n",
      "\n",
      "    accuracy                           0.92     14158\n",
      "   macro avg       0.70      0.52      0.52     14158\n",
      "weighted avg       0.89      0.92      0.89     14158\n",
      "\n",
      "Confusion_matrix\n",
      "[[12972    51]\n",
      " [ 1090    45]]\n",
      "done in 0.636587s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19950\n",
      "           1       0.50      0.00      0.00      1948\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.71      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19947     3]\n",
      " [ 1945     3]]\n",
      "done in 25.198119s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19883\n",
      "           1       0.40      0.00      0.00      2015\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.65      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.86     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19880     3]\n",
      " [ 2013     2]]\n",
      "done in 25.186960s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6895\n",
      "           1       0.40      0.00      0.00       848\n",
      "\n",
      "    accuracy                           0.89      7743\n",
      "   macro avg       0.65      0.50      0.47      7743\n",
      "weighted avg       0.84      0.89      0.84      7743\n",
      "\n",
      "Confusion_matrix\n",
      "[[6892    3]\n",
      " [ 846    2]]\n",
      "done in 25.110259s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6860\n",
      "           1       0.67      0.00      0.00       880\n",
      "\n",
      "    accuracy                           0.89      7740\n",
      "   macro avg       0.78      0.50      0.47      7740\n",
      "weighted avg       0.86      0.89      0.83      7740\n",
      "\n",
      "Confusion_matrix\n",
      "[[6859    1]\n",
      " [ 878    2]]\n",
      "done in 25.154770s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13055\n",
      "           1       0.43      0.00      0.01      1100\n",
      "\n",
      "    accuracy                           0.92     14155\n",
      "   macro avg       0.68      0.50      0.48     14155\n",
      "weighted avg       0.88      0.92      0.89     14155\n",
      "\n",
      "Confusion_matrix\n",
      "[[13051     4]\n",
      " [ 1097     3]]\n",
      "done in 26.117182s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13023\n",
      "           1       0.33      0.00      0.00      1135\n",
      "\n",
      "    accuracy                           0.92     14158\n",
      "   macro avg       0.63      0.50      0.48     14158\n",
      "weighted avg       0.87      0.92      0.88     14158\n",
      "\n",
      "Confusion_matrix\n",
      "[[13021     2]\n",
      " [ 1134     1]]\n",
      "done in 25.304513s\n",
      "0.22713772209577116\n",
      "0.2707208462186693\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19950\n",
      "           1       0.30      0.00      0.01      1948\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.60      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19931    19]\n",
      " [ 1940     8]]\n",
      "done in 0.854339s\n",
      "0.22713772209577116\n",
      "0.2816608864343069\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19883\n",
      "           1       0.37      0.00      0.01      2015\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.64      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.86     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19866    17]\n",
      " [ 2005    10]]\n",
      "done in 0.860454s\n",
      "0.22713772209577116\n",
      "0.31745801251355504\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6895\n",
      "           1       0.44      0.00      0.01       848\n",
      "\n",
      "    accuracy                           0.89      7743\n",
      "   macro avg       0.67      0.50      0.48      7743\n",
      "weighted avg       0.84      0.89      0.84      7743\n",
      "\n",
      "Confusion_matrix\n",
      "[[6890    5]\n",
      " [ 844    4]]\n",
      "done in 0.833366s\n",
      "0.22713772209577116\n",
      "0.3396110034411939\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6860\n",
      "           1       0.30      0.00      0.01       880\n",
      "\n",
      "    accuracy                           0.89      7740\n",
      "   macro avg       0.59      0.50      0.47      7740\n",
      "weighted avg       0.82      0.89      0.83      7740\n",
      "\n",
      "Confusion_matrix\n",
      "[[6853    7]\n",
      " [ 877    3]]\n",
      "done in 0.831761s\n",
      "0.22713772209577116\n",
      "0.24515490636552198\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13055\n",
      "           1       0.22      0.00      0.01      1100\n",
      "\n",
      "    accuracy                           0.92     14155\n",
      "   macro avg       0.57      0.50      0.48     14155\n",
      "weighted avg       0.87      0.92      0.89     14155\n",
      "\n",
      "Confusion_matrix\n",
      "[[13041    14]\n",
      " [ 1096     4]]\n",
      "done in 0.841594s\n",
      "0.22713772209577116\n",
      "0.24998028849439274\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13023\n",
      "           1       0.41      0.01      0.01      1135\n",
      "\n",
      "    accuracy                           0.92     14158\n",
      "   macro avg       0.67      0.50      0.49     14158\n",
      "weighted avg       0.88      0.92      0.88     14158\n",
      "\n",
      "Confusion_matrix\n",
      "[[13013    10]\n",
      " [ 1128     7]]\n",
      "done in 0.842819s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19950\n",
      "           1       0.40      0.02      0.04      1948\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.66      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19886    64]\n",
      " [ 1905    43]]\n",
      "done in 46.838505s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19883\n",
      "           1       0.44      0.02      0.04      2015\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19827    56]\n",
      " [ 1971    44]]\n",
      "done in 117.909525s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6895\n",
      "           1       0.44      0.02      0.04       848\n",
      "\n",
      "    accuracy                           0.89      7743\n",
      "   macro avg       0.67      0.51      0.49      7743\n",
      "weighted avg       0.84      0.89      0.84      7743\n",
      "\n",
      "Confusion_matrix\n",
      "[[6875   20]\n",
      " [ 832   16]]\n",
      "done in 47.109558s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6860\n",
      "           1       0.44      0.02      0.04       880\n",
      "\n",
      "    accuracy                           0.89      7740\n",
      "   macro avg       0.67      0.51      0.49      7740\n",
      "weighted avg       0.84      0.89      0.84      7740\n",
      "\n",
      "Confusion_matrix\n",
      "[[6835   25]\n",
      " [ 860   20]]\n",
      "done in 47.009743s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13055\n",
      "           1       0.39      0.02      0.05      1100\n",
      "\n",
      "    accuracy                           0.92     14155\n",
      "   macro avg       0.65      0.51      0.50     14155\n",
      "weighted avg       0.88      0.92      0.89     14155\n",
      "\n",
      "Confusion_matrix\n",
      "[[13012    43]\n",
      " [ 1073    27]]\n",
      "done in 46.723293s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13023\n",
      "           1       0.45      0.02      0.04      1135\n",
      "\n",
      "    accuracy                           0.92     14158\n",
      "   macro avg       0.68      0.51      0.50     14158\n",
      "weighted avg       0.88      0.92      0.88     14158\n",
      "\n",
      "Confusion_matrix\n",
      "[[12992    31]\n",
      " [ 1110    25]]\n",
      "done in 46.722772s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.378\n",
      "threshold:0.2, J-value:0.237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.30000000000000004, J-value:0.133\n",
      "threshold:0.4, J-value:0.076\n",
      "threshold:0.5, J-value:0.036000000000000004\n",
      "threshold:0.6000000000000001, J-value:0.016\n",
      "threshold:0.7000000000000001, J-value:0.003\n",
      "threshold:0.8, J-value:0.002\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6888008265015721\n",
      "Balanced accuracy score of test is  0.696947452772416\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.373\n",
      "threshold:0.2, J-value:0.22799999999999998\n",
      "threshold:0.30000000000000004, J-value:0.11499999999999999\n",
      "threshold:0.4, J-value:0.064\n",
      "threshold:0.5, J-value:0.025\n",
      "threshold:0.6000000000000001, J-value:0.013\n",
      "threshold:0.7000000000000001, J-value:0.003\n",
      "threshold:0.8, J-value:0.004\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6867343029540137\n",
      "Balanced accuracy score of test is  0.6937417174662073\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.375\n",
      "threshold:0.2, J-value:0.243\n",
      "threshold:0.30000000000000004, J-value:0.146\n",
      "threshold:0.4, J-value:0.08600000000000001\n",
      "threshold:0.5, J-value:0.042\n",
      "threshold:0.6000000000000001, J-value:0.019000000000000003\n",
      "threshold:0.7000000000000001, J-value:0.004\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.687553880435918\n",
      "Balanced accuracy score of test is  0.6975840439534121\n",
      "True positive rate of class 1 is  0.616\n",
      "True positive rate of class 2 is  0.601\n",
      "Positive prediction rate of class 1 is  0.272\n",
      "Positive prediction rate of class 2 is  0.237\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.37999999999999995\n",
      "threshold:0.2, J-value:0.266\n",
      "threshold:0.30000000000000004, J-value:0.10099999999999999\n",
      "threshold:0.4, J-value:0.019\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6899583404095455\n",
      "Balanced accuracy score of test is  0.6977383574805915\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.359\n",
      "threshold:0.2, J-value:0.256\n",
      "threshold:0.30000000000000004, J-value:0.092\n",
      "threshold:0.4, J-value:0.009\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6797222830325502\n",
      "Balanced accuracy score of test is  0.6927295918367347\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.39599999999999996\n",
      "threshold:0.2, J-value:0.258\n",
      "threshold:0.30000000000000004, J-value:0.087\n",
      "threshold:0.4, J-value:0.019\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6979097176282163\n",
      "Balanced accuracy score of test is  0.6977268275950952\n",
      "True positive rate of class 1 is  0.738\n",
      "True positive rate of class 2 is  0.695\n",
      "Positive prediction rate of class 1 is  0.396\n",
      "Positive prediction rate of class 2 is  0.331\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.36800000000000005\n",
      "threshold:0.2, J-value:0.196\n",
      "threshold:0.30000000000000004, J-value:0.073\n",
      "threshold:0.4, J-value:0.013\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6843764441905585\n",
      "Balanced accuracy score of test is  0.6839570669558356\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.354\n",
      "threshold:0.2, J-value:0.187\n",
      "threshold:0.30000000000000004, J-value:0.081\n",
      "threshold:0.4, J-value:0.011\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6768432655602228\n",
      "Balanced accuracy score of test is  0.6736764510999205\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.367\n",
      "threshold:0.2, J-value:0.203\n",
      "threshold:0.30000000000000004, J-value:0.067\n",
      "threshold:0.4, J-value:0.014\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6835822220674768\n",
      "Balanced accuracy score of test is  0.6859250712311428\n",
      "True positive rate of class 1 is  0.69\n",
      "True positive rate of class 2 is  0.641\n",
      "Positive prediction rate of class 1 is  0.382\n",
      "Positive prediction rate of class 2 is  0.298\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.398\n",
      "threshold:0.2, J-value:0.244\n",
      "threshold:0.30000000000000004, J-value:0.125\n",
      "threshold:0.4, J-value:0.054\n",
      "threshold:0.5, J-value:0.019\n",
      "threshold:0.6000000000000001, J-value:0.005\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6991065960589358\n",
      "Balanced accuracy score of test is  0.7064643050181028\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.39\n",
      "threshold:0.2, J-value:0.23299999999999998\n",
      "threshold:0.30000000000000004, J-value:0.11499999999999999\n",
      "threshold:0.4, J-value:0.041999999999999996\n",
      "threshold:0.5, J-value:0.016\n",
      "threshold:0.6000000000000001, J-value:0.005\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6950019326282375\n",
      "Balanced accuracy score of test is  0.7064868804664723\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.399\n",
      "threshold:0.2, J-value:0.251\n",
      "threshold:0.30000000000000004, J-value:0.133\n",
      "threshold:0.4, J-value:0.065\n",
      "threshold:0.5, J-value:0.022000000000000002\n",
      "threshold:0.6000000000000001, J-value:0.005\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6996077782807005\n",
      "Balanced accuracy score of test is  0.7046407220569775\n",
      "True positive rate of class 1 is  0.65\n",
      "True positive rate of class 2 is  0.625\n",
      "Positive prediction rate of class 1 is  0.284\n",
      "Positive prediction rate of class 2 is  0.248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lifuchen/Desktop/research/CVDPrediction-master/src/lib/fairness_tests.py:112: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train ['Class'] = y_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42349,)\n",
      "(42349,)\n",
      "(84698, 88)\n",
      "X train 84698\n",
      "Y train 84698\n",
      "21898 7751 14147\n",
      "21898 7751 14147\n",
      "21898 7757 14141\n",
      "21898 7757 14141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22053116933271968\n",
      "0.2649419071406302\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95     19908\n",
      "           1       0.43      0.04      0.08      1990\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.52      0.52     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19795   113]\n",
      " [ 1903    87]]\n",
      "done in 0.619980s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22053116933271968\n",
      "0.2626009795074523\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95     19918\n",
      "           1       0.44      0.04      0.07      1980\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.52      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19818   100]\n",
      " [ 1903    77]]\n",
      "done in 0.631037s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22053116933271968\n",
      "0.3047093388682754\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94      6908\n",
      "           1       0.44      0.04      0.07       843\n",
      "\n",
      "    accuracy                           0.89      7751\n",
      "   macro avg       0.67      0.52      0.51      7751\n",
      "weighted avg       0.84      0.89      0.85      7751\n",
      "\n",
      "Confusion_matrix\n",
      "[[6867   41]\n",
      " [ 811   32]]\n",
      "done in 0.607563s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22053116933271968\n",
      "0.30597312232704654\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94      6894\n",
      "           1       0.42      0.04      0.07       863\n",
      "\n",
      "    accuracy                           0.89      7757\n",
      "   macro avg       0.66      0.52      0.51      7757\n",
      "weighted avg       0.84      0.89      0.84      7757\n",
      "\n",
      "Confusion_matrix\n",
      "[[6849   45]\n",
      " [ 830   33]]\n",
      "done in 0.614925s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22053116933271968\n",
      "0.24315372849349806\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96     13000\n",
      "           1       0.43      0.05      0.09      1147\n",
      "\n",
      "    accuracy                           0.92     14147\n",
      "   macro avg       0.68      0.52      0.52     14147\n",
      "weighted avg       0.88      0.92      0.89     14147\n",
      "\n",
      "Confusion_matrix\n",
      "[[12928    72]\n",
      " [ 1092    55]]\n",
      "done in 0.623975s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22053116933271968\n",
      "0.23880933027107643\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13024\n",
      "           1       0.44      0.04      0.07      1117\n",
      "\n",
      "    accuracy                           0.92     14141\n",
      "   macro avg       0.68      0.52      0.52     14141\n",
      "weighted avg       0.89      0.92      0.89     14141\n",
      "\n",
      "Confusion_matrix\n",
      "[[12969    55]\n",
      " [ 1073    44]]\n",
      "done in 0.617126s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19908\n",
      "           1       0.42      0.00      0.00      1990\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.66      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19901     7]\n",
      " [ 1985     5]]\n",
      "done in 25.476221s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19918\n",
      "           1       1.00      0.00      0.00      1980\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.95      0.50      0.48     21898\n",
      "weighted avg       0.92      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19918     0]\n",
      " [ 1979     1]]\n",
      "done in 25.529150s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6908\n",
      "           1       0.57      0.00      0.01       843\n",
      "\n",
      "    accuracy                           0.89      7751\n",
      "   macro avg       0.73      0.50      0.48      7751\n",
      "weighted avg       0.86      0.89      0.84      7751\n",
      "\n",
      "Confusion_matrix\n",
      "[[6905    3]\n",
      " [ 839    4]]\n",
      "done in 25.371249s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6894\n",
      "           1       0.75      0.00      0.01       863\n",
      "\n",
      "    accuracy                           0.89      7757\n",
      "   macro avg       0.82      0.50      0.47      7757\n",
      "weighted avg       0.87      0.89      0.84      7757\n",
      "\n",
      "Confusion_matrix\n",
      "[[6893    1]\n",
      " [ 860    3]]\n",
      "done in 25.126566s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13000\n",
      "           1       0.75      0.00      0.01      1147\n",
      "\n",
      "    accuracy                           0.92     14147\n",
      "   macro avg       0.83      0.50      0.48     14147\n",
      "weighted avg       0.91      0.92      0.88     14147\n",
      "\n",
      "Confusion_matrix\n",
      "[[12999     1]\n",
      " [ 1144     3]]\n",
      "done in 25.246124s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13024\n",
      "           1       0.00      0.00      0.00      1117\n",
      "\n",
      "    accuracy                           0.92     14141\n",
      "   macro avg       0.46      0.50      0.48     14141\n",
      "weighted avg       0.85      0.92      0.88     14141\n",
      "\n",
      "Confusion_matrix\n",
      "[[13022     2]\n",
      " [ 1117     0]]\n",
      "done in 25.288417s\n",
      "0.22634199905412541\n",
      "0.2777852984302499\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19908\n",
      "           1       0.07      0.00      0.00      1990\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.49      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19895    13]\n",
      " [ 1989     1]]\n",
      "done in 0.850386s\n",
      "0.22634199905412541\n",
      "0.27112850087768686\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19918\n",
      "           1       0.20      0.00      0.00      1980\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.55      0.50      0.48     21898\n",
      "weighted avg       0.85      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19906    12]\n",
      " [ 1977     3]]\n",
      "done in 0.853860s\n",
      "0.22634199905412541\n",
      "0.31937318983240937\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6908\n",
      "           1       0.00      0.00      0.00       843\n",
      "\n",
      "    accuracy                           0.89      7751\n",
      "   macro avg       0.45      0.50      0.47      7751\n",
      "weighted avg       0.79      0.89      0.84      7751\n",
      "\n",
      "Confusion_matrix\n",
      "[[6902    6]\n",
      " [ 843    0]]\n",
      "done in 0.829693s\n",
      "0.22634199905412541\n",
      "0.31262758930415674\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6894\n",
      "           1       0.11      0.00      0.00       863\n",
      "\n",
      "    accuracy                           0.89      7757\n",
      "   macro avg       0.50      0.50      0.47      7757\n",
      "weighted avg       0.80      0.89      0.84      7757\n",
      "\n",
      "Confusion_matrix\n",
      "[[6886    8]\n",
      " [ 862    1]]\n",
      "done in 0.831968s\n",
      "0.22634199905412541\n",
      "0.2549997081101723\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13000\n",
      "           1       0.12      0.00      0.00      1147\n",
      "\n",
      "    accuracy                           0.92     14147\n",
      "   macro avg       0.52      0.50      0.48     14147\n",
      "weighted avg       0.85      0.92      0.88     14147\n",
      "\n",
      "Confusion_matrix\n",
      "[[12993     7]\n",
      " [ 1146     1]]\n",
      "done in 0.842419s\n",
      "0.22634199905412541\n",
      "0.2483643095953075\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13024\n",
      "           1       0.33      0.00      0.00      1117\n",
      "\n",
      "    accuracy                           0.92     14141\n",
      "   macro avg       0.63      0.50      0.48     14141\n",
      "weighted avg       0.87      0.92      0.88     14141\n",
      "\n",
      "Confusion_matrix\n",
      "[[13020     4]\n",
      " [ 1115     2]]\n",
      "done in 0.841658s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19908\n",
      "           1       0.50      0.03      0.05      1990\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.71      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19854    54]\n",
      " [ 1935    55]]\n",
      "done in 46.860439s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19918\n",
      "           1       0.40      0.02      0.04      1980\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.65      0.51      0.50     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19856    62]\n",
      " [ 1939    41]]\n",
      "done in 46.732197s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6908\n",
      "           1       0.47      0.03      0.05       843\n",
      "\n",
      "    accuracy                           0.89      7751\n",
      "   macro avg       0.68      0.51      0.50      7751\n",
      "weighted avg       0.85      0.89      0.85      7751\n",
      "\n",
      "Confusion_matrix\n",
      "[[6881   27]\n",
      " [ 819   24]]\n",
      "done in 46.693751s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94      6894\n",
      "           1       0.36      0.02      0.05       863\n",
      "\n",
      "    accuracy                           0.89      7757\n",
      "   macro avg       0.63      0.51      0.49      7757\n",
      "weighted avg       0.83      0.89      0.84      7757\n",
      "\n",
      "Confusion_matrix\n",
      "[[6857   37]\n",
      " [ 842   21]]\n",
      "done in 47.406310s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13000\n",
      "           1       0.53      0.03      0.05      1147\n",
      "\n",
      "    accuracy                           0.92     14147\n",
      "   macro avg       0.72      0.51      0.50     14147\n",
      "weighted avg       0.89      0.92      0.88     14147\n",
      "\n",
      "Confusion_matrix\n",
      "[[12973    27]\n",
      " [ 1117    30]]\n",
      "done in 46.927870s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13024\n",
      "           1       0.47      0.02      0.04      1117\n",
      "\n",
      "    accuracy                           0.92     14141\n",
      "   macro avg       0.69      0.51      0.50     14141\n",
      "weighted avg       0.89      0.92      0.89     14141\n",
      "\n",
      "Confusion_matrix\n",
      "[[13000    24]\n",
      " [ 1096    21]]\n",
      "done in 46.929055s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.379\n",
      "threshold:0.2, J-value:0.247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.30000000000000004, J-value:0.145\n",
      "threshold:0.4, J-value:0.078\n",
      "threshold:0.5, J-value:0.038\n",
      "threshold:0.6000000000000001, J-value:0.019000000000000003\n",
      "threshold:0.7000000000000001, J-value:0.005\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.001\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6896155228624536\n",
      "Balanced accuracy score of test is  0.6938086558932025\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.36\n",
      "threshold:0.2, J-value:0.24100000000000002\n",
      "threshold:0.30000000000000004, J-value:0.131\n",
      "threshold:0.4, J-value:0.077\n",
      "threshold:0.5, J-value:0.032\n",
      "threshold:0.6000000000000001, J-value:0.018000000000000002\n",
      "threshold:0.7000000000000001, J-value:0.004\n",
      "threshold:0.8, J-value:0.002\n",
      "threshold:0.9, J-value:0.002\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6801370460504128\n",
      "Balanced accuracy score of test is  0.6869588851003492\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.38499999999999995\n",
      "threshold:0.2, J-value:0.248\n",
      "threshold:0.30000000000000004, J-value:0.155\n",
      "threshold:0.4, J-value:0.08\n",
      "threshold:0.5, J-value:0.042\n",
      "threshold:0.6000000000000001, J-value:0.019999999999999997\n",
      "threshold:0.7000000000000001, J-value:0.004\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6923096036483133\n",
      "Balanced accuracy score of test is  0.6946234786711509\n",
      "True positive rate of class 1 is  0.621\n",
      "True positive rate of class 2 is  0.58\n",
      "Positive prediction rate of class 1 is  0.289\n",
      "Positive prediction rate of class 2 is  0.222\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.37799999999999995\n",
      "threshold:0.2, J-value:0.261\n",
      "threshold:0.30000000000000004, J-value:0.092\n",
      "threshold:0.4, J-value:0.017\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.689057857097422\n",
      "Balanced accuracy score of test is  0.6978882610622745\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.352\n",
      "threshold:0.2, J-value:0.246\n",
      "threshold:0.30000000000000004, J-value:0.10400000000000001\n",
      "threshold:0.4, J-value:0.016\n",
      "threshold:0.5, J-value:0.005\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6760020359086478\n",
      "Balanced accuracy score of test is  0.680715946592012\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.398\n",
      "threshold:0.2, J-value:0.26999999999999996\n",
      "threshold:0.30000000000000004, J-value:0.099\n",
      "threshold:0.4, J-value:0.019000000000000003\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6991584400777949\n",
      "Balanced accuracy score of test is  0.69743513936945\n",
      "True positive rate of class 1 is  0.729\n",
      "True positive rate of class 2 is  0.679\n",
      "Positive prediction rate of class 1 is  0.408\n",
      "Positive prediction rate of class 2 is  0.316\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.32800000000000007\n",
      "threshold:0.2, J-value:0.14100000000000001\n",
      "threshold:0.30000000000000004, J-value:0.076\n",
      "threshold:0.4, J-value:0.0\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6643663364037387\n",
      "Balanced accuracy score of test is  0.6687647638144676\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.32399999999999995\n",
      "threshold:0.2, J-value:0.14\n",
      "threshold:0.30000000000000004, J-value:0.086\n",
      "threshold:0.4, J-value:-0.001\n",
      "threshold:0.5, J-value:-0.001\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6620519575701251\n",
      "Balanced accuracy score of test is  0.6666048969984479\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.325\n",
      "threshold:0.2, J-value:0.141\n",
      "threshold:0.30000000000000004, J-value:0.068\n",
      "threshold:0.4, J-value:0.0\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6621801690027497\n",
      "Balanced accuracy score of test is  0.6666746632894798\n",
      "True positive rate of class 1 is  0.585\n",
      "True positive rate of class 2 is  0.538\n",
      "Positive prediction rate of class 1 is  0.289\n",
      "Positive prediction rate of class 2 is  0.231\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.374\n",
      "threshold:0.2, J-value:0.252\n",
      "threshold:0.30000000000000004, J-value:0.14\n",
      "threshold:0.4, J-value:0.067\n",
      "threshold:0.5, J-value:0.025\n",
      "threshold:0.6000000000000001, J-value:0.007\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6874057599631673\n",
      "Balanced accuracy score of test is  0.7024656647811582\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.38\n",
      "threshold:0.2, J-value:0.24200000000000002\n",
      "threshold:0.30000000000000004, J-value:0.129\n",
      "threshold:0.4, J-value:0.064\n",
      "threshold:0.5, J-value:0.024\n",
      "threshold:0.6000000000000001, J-value:0.008\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6899285886496033\n",
      "Balanced accuracy score of test is  0.7036114834099276\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.36300000000000004\n",
      "threshold:0.2, J-value:0.255\n",
      "threshold:0.30000000000000004, J-value:0.14700000000000002\n",
      "threshold:0.4, J-value:0.069\n",
      "threshold:0.5, J-value:0.024\n",
      "threshold:0.6000000000000001, J-value:0.005\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6812707397223526\n",
      "Balanced accuracy score of test is  0.697319933009839\n",
      "True positive rate of class 1 is  0.66\n",
      "True positive rate of class 2 is  0.593\n",
      "Positive prediction rate of class 1 is  0.299\n",
      "Positive prediction rate of class 2 is  0.229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lifuchen/Desktop/research/CVDPrediction-master/src/lib/fairness_tests.py:112: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train ['Class'] = y_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42442,)\n",
      "(42442,)\n",
      "(84884, 88)\n",
      "X train 84884\n",
      "Y train 84884\n",
      "21898 7842 14056\n",
      "21898 7842 14056\n",
      "21898 7759 14139\n",
      "21898 7759 14139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2252408452125645\n",
      "0.2557495334973233\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95     20006\n",
      "           1       0.41      0.04      0.08      1892\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.66      0.52      0.52     21898\n",
      "weighted avg       0.87      0.91      0.88     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19889   117]\n",
      " [ 1810    82]]\n",
      "done in 0.638149s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2252408452125645\n",
      "0.25692384737393564\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95     19975\n",
      "           1       0.46      0.05      0.09      1923\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.69      0.52      0.52     21898\n",
      "weighted avg       0.88      0.91      0.88     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19867   108]\n",
      " [ 1830    93]]\n",
      "done in 0.634951s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2252408452125645\n",
      "0.2922321801989826\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94      7042\n",
      "           1       0.34      0.04      0.07       800\n",
      "\n",
      "    accuracy                           0.89      7842\n",
      "   macro avg       0.62      0.51      0.50      7842\n",
      "weighted avg       0.84      0.89      0.85      7842\n",
      "\n",
      "Confusion_matrix\n",
      "[[6985   57]\n",
      " [ 771   29]]\n",
      "done in 0.609076s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2252408452125645\n",
      "0.29295321579170447\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94      6943\n",
      "           1       0.48      0.05      0.09       816\n",
      "\n",
      "    accuracy                           0.89      7759\n",
      "   macro avg       0.69      0.52      0.52      7759\n",
      "weighted avg       0.85      0.89      0.85      7759\n",
      "\n",
      "Confusion_matrix\n",
      "[[6899   44]\n",
      " [ 776   40]]\n",
      "done in 0.605516s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2252408452125645\n",
      "0.2353954558483184\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96     12964\n",
      "           1       0.47      0.05      0.09      1092\n",
      "\n",
      "    accuracy                           0.92     14056\n",
      "   macro avg       0.70      0.52      0.52     14056\n",
      "weighted avg       0.89      0.92      0.89     14056\n",
      "\n",
      "Confusion_matrix\n",
      "[[12904    60]\n",
      " [ 1039    53]]\n",
      "done in 0.639200s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2252408452125645\n",
      "0.23715216128910158\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13032\n",
      "           1       0.45      0.05      0.09      1107\n",
      "\n",
      "    accuracy                           0.92     14139\n",
      "   macro avg       0.69      0.52      0.52     14139\n",
      "weighted avg       0.89      0.92      0.89     14139\n",
      "\n",
      "Confusion_matrix\n",
      "[[12968    64]\n",
      " [ 1054    53]]\n",
      "done in 0.618290s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     20006\n",
      "           1       0.67      0.00      0.01      1892\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.79      0.50      0.48     21898\n",
      "weighted avg       0.89      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[20003     3]\n",
      " [ 1886     6]]\n",
      "done in 25.901927s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19975\n",
      "           1       0.31      0.00      0.00      1923\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.61      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19966     9]\n",
      " [ 1919     4]]\n",
      "done in 25.670179s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      7042\n",
      "           1       1.00      0.00      0.01       800\n",
      "\n",
      "    accuracy                           0.90      7842\n",
      "   macro avg       0.95      0.50      0.48      7842\n",
      "weighted avg       0.91      0.90      0.85      7842\n",
      "\n",
      "Confusion_matrix\n",
      "[[7042    0]\n",
      " [ 797    3]]\n",
      "done in 25.614629s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.94      6943\n",
      "           1       0.50      0.00      0.00       816\n",
      "\n",
      "    accuracy                           0.89      7759\n",
      "   macro avg       0.70      0.50      0.47      7759\n",
      "weighted avg       0.85      0.89      0.85      7759\n",
      "\n",
      "Confusion_matrix\n",
      "[[6941    2]\n",
      " [ 814    2]]\n",
      "done in 25.426842s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12964\n",
      "           1       0.75      0.00      0.01      1092\n",
      "\n",
      "    accuracy                           0.92     14056\n",
      "   macro avg       0.84      0.50      0.48     14056\n",
      "weighted avg       0.91      0.92      0.89     14056\n",
      "\n",
      "Confusion_matrix\n",
      "[[12963     1]\n",
      " [ 1089     3]]\n",
      "done in 25.409860s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13032\n",
      "           1       0.50      0.00      0.00      1107\n",
      "\n",
      "    accuracy                           0.92     14139\n",
      "   macro avg       0.71      0.50      0.48     14139\n",
      "weighted avg       0.89      0.92      0.88     14139\n",
      "\n",
      "Confusion_matrix\n",
      "[[13030     2]\n",
      " [ 1105     2]]\n",
      "done in 25.199484s\n",
      "0.23158776624269897\n",
      "0.26491588275378214\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     20006\n",
      "           1       0.31      0.00      0.01      1892\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.61      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19995    11]\n",
      " [ 1887     5]]\n",
      "done in 0.849776s\n",
      "0.23158776624269897\n",
      "0.2666747143891459\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19975\n",
      "           1       0.57      0.00      0.01      1923\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.74      0.50      0.48     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19969     6]\n",
      " [ 1915     8]]\n",
      "done in 0.855416s\n",
      "0.23158776624269897\n",
      "0.30052888958984125\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      7042\n",
      "           1       0.40      0.00      0.00       800\n",
      "\n",
      "    accuracy                           0.90      7842\n",
      "   macro avg       0.65      0.50      0.48      7842\n",
      "weighted avg       0.85      0.90      0.85      7842\n",
      "\n",
      "Confusion_matrix\n",
      "[[7039    3]\n",
      " [ 798    2]]\n",
      "done in 0.827178s\n",
      "0.23158776624269897\n",
      "0.3083109338134892\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.94      6943\n",
      "           1       0.60      0.00      0.01       816\n",
      "\n",
      "    accuracy                           0.89      7759\n",
      "   macro avg       0.75      0.50      0.48      7759\n",
      "weighted avg       0.86      0.89      0.85      7759\n",
      "\n",
      "Confusion_matrix\n",
      "[[6941    2]\n",
      " [ 813    3]]\n",
      "done in 0.828846s\n",
      "0.23158776624269897\n",
      "0.24504698693645321\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12964\n",
      "           1       0.27      0.00      0.01      1092\n",
      "\n",
      "    accuracy                           0.92     14056\n",
      "   macro avg       0.60      0.50      0.48     14056\n",
      "weighted avg       0.87      0.92      0.89     14056\n",
      "\n",
      "Confusion_matrix\n",
      "[[12956     8]\n",
      " [ 1089     3]]\n",
      "done in 0.836357s\n",
      "0.23158776624269897\n",
      "0.24382618008590815\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13032\n",
      "           1       0.56      0.00      0.01      1107\n",
      "\n",
      "    accuracy                           0.92     14139\n",
      "   macro avg       0.74      0.50      0.48     14139\n",
      "weighted avg       0.89      0.92      0.88     14139\n",
      "\n",
      "Confusion_matrix\n",
      "[[13028     4]\n",
      " [ 1102     5]]\n",
      "done in 0.837215s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.95     20006\n",
      "           1       0.42      0.03      0.05      1892\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.88     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19939    67]\n",
      " [ 1843    49]]\n",
      "done in 46.916288s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19975\n",
      "           1       0.50      0.03      0.06      1923\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.71      0.52      0.51     21898\n",
      "weighted avg       0.88      0.91      0.88     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19909    66]\n",
      " [ 1857    66]]\n",
      "done in 358.168832s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94      7042\n",
      "           1       0.35      0.03      0.05       800\n",
      "\n",
      "    accuracy                           0.90      7842\n",
      "   macro avg       0.62      0.51      0.50      7842\n",
      "weighted avg       0.84      0.90      0.85      7842\n",
      "\n",
      "Confusion_matrix\n",
      "[[7001   41]\n",
      " [ 778   22]]\n",
      "done in 47.736028s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.94      6943\n",
      "           1       0.48      0.03      0.06       816\n",
      "\n",
      "    accuracy                           0.89      7759\n",
      "   macro avg       0.69      0.51      0.50      7759\n",
      "weighted avg       0.85      0.89      0.85      7759\n",
      "\n",
      "Confusion_matrix\n",
      "[[6914   29]\n",
      " [ 789   27]]\n",
      "done in 47.459164s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12964\n",
      "           1       0.51      0.02      0.05      1092\n",
      "\n",
      "    accuracy                           0.92     14056\n",
      "   macro avg       0.72      0.51      0.50     14056\n",
      "weighted avg       0.89      0.92      0.89     14056\n",
      "\n",
      "Confusion_matrix\n",
      "[[12938    26]\n",
      " [ 1065    27]]\n",
      "done in 48.760071s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13032\n",
      "           1       0.51      0.04      0.07      1107\n",
      "\n",
      "    accuracy                           0.92     14139\n",
      "   macro avg       0.72      0.52      0.51     14139\n",
      "weighted avg       0.89      0.92      0.89     14139\n",
      "\n",
      "Confusion_matrix\n",
      "[[12995    37]\n",
      " [ 1068    39]]\n",
      "done in 48.297798s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.385\n",
      "threshold:0.2, J-value:0.247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.30000000000000004, J-value:0.145\n",
      "threshold:0.4, J-value:0.077\n",
      "threshold:0.5, J-value:0.037\n",
      "threshold:0.6000000000000001, J-value:0.016\n",
      "threshold:0.7000000000000001, J-value:0.003\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6928875618498382\n",
      "Balanced accuracy score of test is  0.6961336095496385\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.367\n",
      "threshold:0.2, J-value:0.24100000000000002\n",
      "threshold:0.30000000000000004, J-value:0.131\n",
      "threshold:0.4, J-value:0.066\n",
      "threshold:0.5, J-value:0.027999999999999997\n",
      "threshold:0.6000000000000001, J-value:0.015\n",
      "threshold:0.7000000000000001, J-value:0.003\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6832332788980404\n",
      "Balanced accuracy score of test is  0.6947641580036883\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.39199999999999996\n",
      "threshold:0.2, J-value:0.249\n",
      "threshold:0.30000000000000004, J-value:0.154\n",
      "threshold:0.4, J-value:0.083\n",
      "threshold:0.5, J-value:0.044000000000000004\n",
      "threshold:0.6000000000000001, J-value:0.018\n",
      "threshold:0.7000000000000001, J-value:0.004\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6963000102848915\n",
      "Balanced accuracy score of test is  0.6940008833789996\n",
      "True positive rate of class 1 is  0.642\n",
      "True positive rate of class 2 is  0.593\n",
      "Positive prediction rate of class 1 is  0.294\n",
      "Positive prediction rate of class 2 is  0.236\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.38999999999999996\n",
      "threshold:0.2, J-value:0.276\n",
      "threshold:0.30000000000000004, J-value:0.10800000000000001\n",
      "threshold:0.4, J-value:0.02\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6948139131199329\n",
      "Balanced accuracy score of test is  0.6954157335254612\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.369\n",
      "threshold:0.2, J-value:0.28099999999999997\n",
      "threshold:0.30000000000000004, J-value:0.097\n",
      "threshold:0.4, J-value:0.023\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6844852314683328\n",
      "Balanced accuracy score of test is  0.6958341452669214\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.39699999999999996\n",
      "threshold:0.2, J-value:0.275\n",
      "threshold:0.30000000000000004, J-value:0.103\n",
      "threshold:0.4, J-value:0.019000000000000003\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6987406941510613\n",
      "Balanced accuracy score of test is  0.6867725848068793\n",
      "True positive rate of class 1 is  0.765\n",
      "True positive rate of class 2 is  0.678\n",
      "Positive prediction rate of class 1 is  0.414\n",
      "Positive prediction rate of class 2 is  0.334\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.34199999999999997\n",
      "threshold:0.2, J-value:0.16\n",
      "threshold:0.30000000000000004, J-value:0.063\n",
      "threshold:0.4, J-value:0.002\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.001\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6710331245235309\n",
      "Balanced accuracy score of test is  0.678088952844722\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.32499999999999996\n",
      "threshold:0.2, J-value:0.157\n",
      "threshold:0.30000000000000004, J-value:0.05600000000000001\n",
      "threshold:0.4, J-value:0.001\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6623260437375745\n",
      "Balanced accuracy score of test is  0.6712358229335231\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.3470000000000001\n",
      "threshold:0.2, J-value:0.16\n",
      "threshold:0.30000000000000004, J-value:0.067\n",
      "threshold:0.4, J-value:0.003\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.001\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6736505035641105\n",
      "Balanced accuracy score of test is  0.6798297000004991\n",
      "True positive rate of class 1 is  0.612\n",
      "True positive rate of class 2 is  0.579\n",
      "Positive prediction rate of class 1 is  0.305\n",
      "Positive prediction rate of class 2 is  0.248\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.396\n",
      "threshold:0.2, J-value:0.252\n",
      "threshold:0.30000000000000004, J-value:0.142\n",
      "threshold:0.4, J-value:0.07\n",
      "threshold:0.5, J-value:0.023\n",
      "threshold:0.6000000000000001, J-value:0.005\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6981238873581055\n",
      "Balanced accuracy score of test is  0.6983212765306608\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.382\n",
      "threshold:0.2, J-value:0.24100000000000002\n",
      "threshold:0.30000000000000004, J-value:0.134\n",
      "threshold:0.4, J-value:0.055999999999999994\n",
      "threshold:0.5, J-value:0.022\n",
      "threshold:0.6000000000000001, J-value:0.007\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6912732533371202\n",
      "Balanced accuracy score of test is  0.6912012698641318\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.401\n",
      "threshold:0.2, J-value:0.257\n",
      "threshold:0.30000000000000004, J-value:0.146\n",
      "threshold:0.4, J-value:0.07899999999999999\n",
      "threshold:0.5, J-value:0.023\n",
      "threshold:0.6000000000000001, J-value:0.004\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7000579514078434\n",
      "Balanced accuracy score of test is  0.7006153084090694\n",
      "True positive rate of class 1 is  0.646\n",
      "True positive rate of class 2 is  0.62\n",
      "Positive prediction rate of class 1 is  0.304\n",
      "Positive prediction rate of class 2 is  0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lifuchen/Desktop/research/CVDPrediction-master/src/lib/fairness_tests.py:112: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train ['Class'] = y_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42433,)\n",
      "(42433,)\n",
      "(84866, 88)\n",
      "X train 84866\n",
      "Y train 84866\n",
      "21898 7814 14084\n",
      "21898 7814 14084\n",
      "21898 7778 14120\n",
      "21898 7778 14120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22083003987003127\n",
      "0.2653232742786787\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95     19911\n",
      "           1       0.43      0.04      0.07      1987\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.52      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19805   106]\n",
      " [ 1908    79]]\n",
      "done in 0.625565s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22083003987003127\n",
      "0.2624720399619388\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19927\n",
      "           1       0.42      0.03      0.06      1971\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19836    91]\n",
      " [ 1905    66]]\n",
      "done in 0.610441s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22083003987003127\n",
      "0.3000591030983827\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94      6979\n",
      "           1       0.38      0.03      0.05       835\n",
      "\n",
      "    accuracy                           0.89      7814\n",
      "   macro avg       0.64      0.51      0.50      7814\n",
      "weighted avg       0.84      0.89      0.85      7814\n",
      "\n",
      "Confusion_matrix\n",
      "[[6939   40]\n",
      " [ 811   24]]\n",
      "done in 0.589842s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22083003987003127\n",
      "0.3060602060369958\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94      6927\n",
      "           1       0.43      0.03      0.06       851\n",
      "\n",
      "    accuracy                           0.89      7778\n",
      "   macro avg       0.66      0.51      0.50      7778\n",
      "weighted avg       0.84      0.89      0.84      7778\n",
      "\n",
      "Confusion_matrix\n",
      "[[6892   35]\n",
      " [ 825   26]]\n",
      "done in 0.604867s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22083003987003127\n",
      "0.2460513510752446\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96     12932\n",
      "           1       0.45      0.05      0.09      1152\n",
      "\n",
      "    accuracy                           0.92     14084\n",
      "   macro avg       0.69      0.52      0.52     14084\n",
      "weighted avg       0.88      0.92      0.89     14084\n",
      "\n",
      "Confusion_matrix\n",
      "[[12866    66]\n",
      " [ 1097    55]]\n",
      "done in 0.604765s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22083003987003127\n",
      "0.23846150485345488\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13000\n",
      "           1       0.42      0.04      0.07      1120\n",
      "\n",
      "    accuracy                           0.92     14120\n",
      "   macro avg       0.67      0.52      0.51     14120\n",
      "weighted avg       0.88      0.92      0.89     14120\n",
      "\n",
      "Confusion_matrix\n",
      "[[12944    56]\n",
      " [ 1080    40]]\n",
      "done in 0.604234s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19911\n",
      "           1       0.30      0.00      0.00      1987\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.60      0.50      0.48     21898\n",
      "weighted avg       0.85      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19904     7]\n",
      " [ 1984     3]]\n",
      "done in 25.286492s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19927\n",
      "           1       0.67      0.00      0.00      1971\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.79      0.50      0.48     21898\n",
      "weighted avg       0.89      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19926     1]\n",
      " [ 1969     2]]\n",
      "done in 25.580545s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6979\n",
      "           1       0.60      0.00      0.01       835\n",
      "\n",
      "    accuracy                           0.89      7814\n",
      "   macro avg       0.75      0.50      0.48      7814\n",
      "weighted avg       0.86      0.89      0.84      7814\n",
      "\n",
      "Confusion_matrix\n",
      "[[6977    2]\n",
      " [ 832    3]]\n",
      "done in 25.200102s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6927\n",
      "           1       1.00      0.00      0.00       851\n",
      "\n",
      "    accuracy                           0.89      7778\n",
      "   macro avg       0.95      0.50      0.47      7778\n",
      "weighted avg       0.90      0.89      0.84      7778\n",
      "\n",
      "Confusion_matrix\n",
      "[[6927    0]\n",
      " [ 850    1]]\n",
      "done in 25.221213s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12932\n",
      "           1       0.60      0.00      0.01      1152\n",
      "\n",
      "    accuracy                           0.92     14084\n",
      "   macro avg       0.76      0.50      0.48     14084\n",
      "weighted avg       0.89      0.92      0.88     14084\n",
      "\n",
      "Confusion_matrix\n",
      "[[12930     2]\n",
      " [ 1149     3]]\n",
      "done in 26.258912s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13000\n",
      "           1       0.50      0.00      0.00      1120\n",
      "\n",
      "    accuracy                           0.92     14120\n",
      "   macro avg       0.71      0.50      0.48     14120\n",
      "weighted avg       0.89      0.92      0.88     14120\n",
      "\n",
      "Confusion_matrix\n",
      "[[12999     1]\n",
      " [ 1119     1]]\n",
      "done in 25.712048s\n",
      "0.2275216882314428\n",
      "0.27519905472352285\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19911\n",
      "           1       0.43      0.00      0.00      1987\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19907     4]\n",
      " [ 1984     3]]\n",
      "done in 0.865365s\n",
      "0.2275216882314428\n",
      "0.27061342357237583\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19927\n",
      "           1       0.40      0.00      0.00      1971\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.66      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19924     3]\n",
      " [ 1969     2]]\n",
      "done in 0.859590s\n",
      "0.2275216882314428\n",
      "0.31739005085135014\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6979\n",
      "           1       0.00      0.00      0.00       835\n",
      "\n",
      "    accuracy                           0.89      7814\n",
      "   macro avg       0.45      0.50      0.47      7814\n",
      "weighted avg       0.80      0.89      0.84      7814\n",
      "\n",
      "Confusion_matrix\n",
      "[[6975    4]\n",
      " [ 835    0]]\n",
      "done in 0.841721s\n",
      "0.2275216882314428\n",
      "0.31358116277257375\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6927\n",
      "           1       0.33      0.00      0.00       851\n",
      "\n",
      "    accuracy                           0.89      7778\n",
      "   macro avg       0.61      0.50      0.47      7778\n",
      "weighted avg       0.83      0.89      0.84      7778\n",
      "\n",
      "Confusion_matrix\n",
      "[[6925    2]\n",
      " [ 850    1]]\n",
      "done in 0.838634s\n",
      "0.2275216882314428\n",
      "0.25179090052422987\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12932\n",
      "           1       1.00      0.00      0.01      1152\n",
      "\n",
      "    accuracy                           0.92     14084\n",
      "   macro avg       0.96      0.50      0.48     14084\n",
      "weighted avg       0.93      0.92      0.88     14084\n",
      "\n",
      "Confusion_matrix\n",
      "[[12932     0]\n",
      " [ 1149     3]]\n",
      "done in 0.849041s\n",
      "0.2275216882314428\n",
      "0.2469446505200288\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13000\n",
      "           1       0.50      0.00      0.00      1120\n",
      "\n",
      "    accuracy                           0.92     14120\n",
      "   macro avg       0.71      0.50      0.48     14120\n",
      "weighted avg       0.89      0.92      0.88     14120\n",
      "\n",
      "Confusion_matrix\n",
      "[[12999     1]\n",
      " [ 1119     1]]\n",
      "done in 0.845435s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19911\n",
      "           1       0.41      0.03      0.05      1987\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.66      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19838    73]\n",
      " [ 1936    51]]\n",
      "done in 47.218015s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19927\n",
      "           1       0.46      0.03      0.05      1971\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.69      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19867    60]\n",
      " [ 1919    52]]\n",
      "done in 47.372194s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6979\n",
      "           1       0.37      0.02      0.04       835\n",
      "\n",
      "    accuracy                           0.89      7814\n",
      "   macro avg       0.63      0.51      0.49      7814\n",
      "weighted avg       0.84      0.89      0.85      7814\n",
      "\n",
      "Confusion_matrix\n",
      "[[6947   32]\n",
      " [ 816   19]]\n",
      "done in 47.155190s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6927\n",
      "           1       0.45      0.02      0.05       851\n",
      "\n",
      "    accuracy                           0.89      7778\n",
      "   macro avg       0.67      0.51      0.49      7778\n",
      "weighted avg       0.84      0.89      0.84      7778\n",
      "\n",
      "Confusion_matrix\n",
      "[[6901   26]\n",
      " [ 830   21]]\n",
      "done in 47.132792s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12932\n",
      "           1       0.44      0.03      0.05      1152\n",
      "\n",
      "    accuracy                           0.92     14084\n",
      "   macro avg       0.68      0.51      0.50     14084\n",
      "weighted avg       0.88      0.92      0.88     14084\n",
      "\n",
      "Confusion_matrix\n",
      "[[12891    41]\n",
      " [ 1120    32]]\n",
      "done in 46.977457s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13000\n",
      "           1       0.48      0.03      0.05      1120\n",
      "\n",
      "    accuracy                           0.92     14120\n",
      "   macro avg       0.70      0.51      0.51     14120\n",
      "weighted avg       0.89      0.92      0.89     14120\n",
      "\n",
      "Confusion_matrix\n",
      "[[12966    34]\n",
      " [ 1089    31]]\n",
      "done in 47.181202s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.374\n",
      "threshold:0.2, J-value:0.241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.30000000000000004, J-value:0.138\n",
      "threshold:0.4, J-value:0.076\n",
      "threshold:0.5, J-value:0.035\n",
      "threshold:0.6000000000000001, J-value:0.017\n",
      "threshold:0.7000000000000001, J-value:0.008\n",
      "threshold:0.8, J-value:0.002\n",
      "threshold:0.9, J-value:0.001\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6867376256146596\n",
      "Balanced accuracy score of test is  0.6937801412497064\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.373\n",
      "threshold:0.2, J-value:0.24800000000000003\n",
      "threshold:0.30000000000000004, J-value:0.125\n",
      "threshold:0.4, J-value:0.065\n",
      "threshold:0.5, J-value:0.023\n",
      "threshold:0.6000000000000001, J-value:0.014\n",
      "threshold:0.7000000000000001, J-value:0.006\n",
      "threshold:0.8, J-value:0.002\n",
      "threshold:0.9, J-value:0.001\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6861903932498952\n",
      "Balanced accuracy score of test is  0.6846494846287717\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.36799999999999994\n",
      "threshold:0.2, J-value:0.23199999999999998\n",
      "threshold:0.30000000000000004, J-value:0.147\n",
      "threshold:0.4, J-value:0.083\n",
      "threshold:0.5, J-value:0.043000000000000003\n",
      "threshold:0.6000000000000001, J-value:0.019000000000000003\n",
      "threshold:0.7000000000000001, J-value:0.009\n",
      "threshold:0.8, J-value:0.002\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6842824485771729\n",
      "Balanced accuracy score of test is  0.696842032967033\n",
      "True positive rate of class 1 is  0.615\n",
      "True positive rate of class 2 is  0.587\n",
      "Positive prediction rate of class 1 is  0.286\n",
      "Positive prediction rate of class 2 is  0.224\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.39599999999999996\n",
      "threshold:0.2, J-value:0.266\n",
      "threshold:0.30000000000000004, J-value:0.09799999999999999\n",
      "threshold:0.4, J-value:0.019\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6979163341287451\n",
      "Balanced accuracy score of test is  0.7016807949726802\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.386\n",
      "threshold:0.2, J-value:0.261\n",
      "threshold:0.30000000000000004, J-value:0.097\n",
      "threshold:0.4, J-value:0.025\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6932499809093662\n",
      "Balanced accuracy score of test is  0.6910895681114297\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.38200000000000006\n",
      "threshold:0.2, J-value:0.264\n",
      "threshold:0.30000000000000004, J-value:0.10099999999999999\n",
      "threshold:0.4, J-value:0.017\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6908073641612538\n",
      "Balanced accuracy score of test is  0.7015192307692308\n",
      "True positive rate of class 1 is  0.751\n",
      "True positive rate of class 2 is  0.688\n",
      "Positive prediction rate of class 1 is  0.411\n",
      "Positive prediction rate of class 2 is  0.316\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.36200000000000004\n",
      "threshold:0.2, J-value:0.161\n",
      "threshold:0.30000000000000004, J-value:0.094\n",
      "threshold:0.4, J-value:0.009999999999999998\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.001\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6812612679013457\n",
      "Balanced accuracy score of test is  0.6839230823148836\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.33699999999999997\n",
      "threshold:0.2, J-value:0.157\n",
      "threshold:0.30000000000000004, J-value:0.086\n",
      "threshold:0.4, J-value:0.009999999999999998\n",
      "threshold:0.5, J-value:-0.001\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6685098065797048\n",
      "Balanced accuracy score of test is  0.6752157848246876\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.37100000000000005\n",
      "threshold:0.2, J-value:0.164\n",
      "threshold:0.30000000000000004, J-value:0.098\n",
      "threshold:0.4, J-value:0.009\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.002\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.002\n",
      "threshold:0.9, J-value:0.002\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6858185283276627\n",
      "Balanced accuracy score of test is  0.6850425824175824\n",
      "True positive rate of class 1 is  0.718\n",
      "True positive rate of class 2 is  0.663\n",
      "Positive prediction rate of class 1 is  0.406\n",
      "Positive prediction rate of class 2 is  0.323\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.385\n",
      "threshold:0.2, J-value:0.24\n",
      "threshold:0.30000000000000004, J-value:0.127\n",
      "threshold:0.4, J-value:0.066\n",
      "threshold:0.5, J-value:0.022\n",
      "threshold:0.6000000000000001, J-value:0.011\n",
      "threshold:0.7000000000000001, J-value:0.005\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6926590944195884\n",
      "Balanced accuracy score of test is  0.7036452839775378\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.372\n",
      "threshold:0.2, J-value:0.23600000000000002\n",
      "threshold:0.30000000000000004, J-value:0.10899999999999999\n",
      "threshold:0.4, J-value:0.054000000000000006\n",
      "threshold:0.5, J-value:0.018\n",
      "threshold:0.6000000000000001, J-value:0.009999999999999998\n",
      "threshold:0.7000000000000001, J-value:0.005\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6860117563983653\n",
      "Balanced accuracy score of test is  0.6996974661218547\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.389\n",
      "threshold:0.2, J-value:0.241\n",
      "threshold:0.30000000000000004, J-value:0.138\n",
      "threshold:0.4, J-value:0.07500000000000001\n",
      "threshold:0.5, J-value:0.025\n",
      "threshold:0.6000000000000001, J-value:0.011\n",
      "threshold:0.7000000000000001, J-value:0.004\n",
      "threshold:0.8, J-value:0.002\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6944982783878063\n",
      "Balanced accuracy score of test is  0.7029024725274725\n",
      "True positive rate of class 1 is  0.652\n",
      "True positive rate of class 2 is  0.608\n",
      "Positive prediction rate of class 1 is  0.296\n",
      "Positive prediction rate of class 2 is  0.234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lifuchen/Desktop/research/CVDPrediction-master/src/lib/fairness_tests.py:112: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train ['Class'] = y_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42366,)\n",
      "(42366,)\n",
      "(84732, 88)\n",
      "X train 84732\n",
      "Y train 84732\n",
      "21898 7644 14254\n",
      "21898 7644 14254\n",
      "21898 7881 14017\n",
      "21898 7881 14017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22323307696418437\n",
      "0.2590295274060498\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95     19944\n",
      "           1       0.43      0.04      0.08      1954\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.52      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19837   107]\n",
      " [ 1872    82]]\n",
      "done in 0.611741s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22323307696418437\n",
      "0.25977448995017227\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95     19955\n",
      "           1       0.44      0.04      0.08      1943\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.52      0.52     21898\n",
      "weighted avg       0.87      0.91      0.88     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19848   107]\n",
      " [ 1859    84]]\n",
      "done in 0.599841s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22323307696418437\n",
      "0.30464190856173173\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94      6814\n",
      "           1       0.35      0.03      0.05       830\n",
      "\n",
      "    accuracy                           0.89      7644\n",
      "   macro avg       0.62      0.51      0.49      7644\n",
      "weighted avg       0.83      0.89      0.84      7644\n",
      "\n",
      "Confusion_matrix\n",
      "[[6775   39]\n",
      " [ 809   21]]\n",
      "done in 0.583402s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22323307696418437\n",
      "0.29917661289027725\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94      7022\n",
      "           1       0.45      0.04      0.07       859\n",
      "\n",
      "    accuracy                           0.89      7881\n",
      "   macro avg       0.67      0.52      0.51      7881\n",
      "weighted avg       0.85      0.89      0.85      7881\n",
      "\n",
      "Confusion_matrix\n",
      "[[6979   43]\n",
      " [ 824   35]]\n",
      "done in 0.587618s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22323307696418437\n",
      "0.2345689520199102\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96     13130\n",
      "           1       0.47      0.05      0.10      1124\n",
      "\n",
      "    accuracy                           0.92     14254\n",
      "   macro avg       0.70      0.52      0.53     14254\n",
      "weighted avg       0.89      0.92      0.89     14254\n",
      "\n",
      "Confusion_matrix\n",
      "[[13062    68]\n",
      " [ 1063    61]]\n",
      "done in 0.597465s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22323307696418437\n",
      "0.2376208100692443\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96     12933\n",
      "           1       0.43      0.05      0.08      1084\n",
      "\n",
      "    accuracy                           0.92     14017\n",
      "   macro avg       0.68      0.52      0.52     14017\n",
      "weighted avg       0.89      0.92      0.89     14017\n",
      "\n",
      "Confusion_matrix\n",
      "[[12869    64]\n",
      " [ 1035    49]]\n",
      "done in 0.603894s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19944\n",
      "           1       0.45      0.00      0.01      1954\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19938     6]\n",
      " [ 1949     5]]\n",
      "done in 25.424137s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19955\n",
      "           1       0.33      0.00      0.00      1943\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.62      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19949     6]\n",
      " [ 1940     3]]\n",
      "done in 25.088069s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6814\n",
      "           1       0.20      0.00      0.00       830\n",
      "\n",
      "    accuracy                           0.89      7644\n",
      "   macro avg       0.55      0.50      0.47      7644\n",
      "weighted avg       0.82      0.89      0.84      7644\n",
      "\n",
      "Confusion_matrix\n",
      "[[6810    4]\n",
      " [ 829    1]]\n",
      "done in 25.349666s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      7022\n",
      "           1       0.33      0.00      0.00       859\n",
      "\n",
      "    accuracy                           0.89      7881\n",
      "   macro avg       0.61      0.50      0.47      7881\n",
      "weighted avg       0.83      0.89      0.84      7881\n",
      "\n",
      "Confusion_matrix\n",
      "[[7020    2]\n",
      " [ 858    1]]\n",
      "done in 25.268095s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13130\n",
      "           1       0.33      0.00      0.00      1124\n",
      "\n",
      "    accuracy                           0.92     14254\n",
      "   macro avg       0.63      0.50      0.48     14254\n",
      "weighted avg       0.87      0.92      0.88     14254\n",
      "\n",
      "Confusion_matrix\n",
      "[[13128     2]\n",
      " [ 1123     1]]\n",
      "done in 25.293550s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12933\n",
      "           1       0.25      0.00      0.00      1084\n",
      "\n",
      "    accuracy                           0.92     14017\n",
      "   macro avg       0.59      0.50      0.48     14017\n",
      "weighted avg       0.87      0.92      0.89     14017\n",
      "\n",
      "Confusion_matrix\n",
      "[[12930     3]\n",
      " [ 1083     1]]\n",
      "done in 25.573708s\n",
      "0.22970945069840465\n",
      "0.26993272958932635\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19944\n",
      "           1       0.40      0.01      0.02      1954\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.66      0.51      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19907    37]\n",
      " [ 1929    25]]\n",
      "done in 0.852202s\n",
      "0.22970945069840465\n",
      "0.2700711446562962\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19955\n",
      "           1       0.43      0.01      0.02      1943\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19924    31]\n",
      " [ 1920    23]]\n",
      "done in 0.848505s\n",
      "0.22970945069840465\n",
      "0.31984484447198874\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6814\n",
      "           1       0.41      0.01      0.02       830\n",
      "\n",
      "    accuracy                           0.89      7644\n",
      "   macro avg       0.65      0.50      0.48      7644\n",
      "weighted avg       0.84      0.89      0.84      7644\n",
      "\n",
      "Confusion_matrix\n",
      "[[6801   13]\n",
      " [ 821    9]]\n",
      "done in 0.828158s\n",
      "0.22970945069840465\n",
      "0.3148927815313804\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      7022\n",
      "           1       0.38      0.01      0.02       859\n",
      "\n",
      "    accuracy                           0.89      7881\n",
      "   macro avg       0.64      0.50      0.48      7881\n",
      "weighted avg       0.84      0.89      0.84      7881\n",
      "\n",
      "Confusion_matrix\n",
      "[[7009   13]\n",
      " [ 851    8]]\n",
      "done in 0.829495s\n",
      "0.22970945069840465\n",
      "0.2431663337591685\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13130\n",
      "           1       0.40      0.01      0.03      1124\n",
      "\n",
      "    accuracy                           0.92     14254\n",
      "   macro avg       0.66      0.51      0.49     14254\n",
      "weighted avg       0.88      0.92      0.89     14254\n",
      "\n",
      "Confusion_matrix\n",
      "[[13106    24]\n",
      " [ 1108    16]]\n",
      "done in 0.835189s\n",
      "0.22970945069840465\n",
      "0.2448703655871275\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12933\n",
      "           1       0.45      0.01      0.03      1084\n",
      "\n",
      "    accuracy                           0.92     14017\n",
      "   macro avg       0.69      0.51      0.49     14017\n",
      "weighted avg       0.89      0.92      0.89     14017\n",
      "\n",
      "Confusion_matrix\n",
      "[[12915    18]\n",
      " [ 1069    15]]\n",
      "done in 0.835694s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19944\n",
      "           1       0.46      0.03      0.05      1954\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.69      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19883    61]\n",
      " [ 1901    53]]\n",
      "done in 46.924233s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19955\n",
      "           1       0.49      0.02      0.05      1943\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.70      0.51      0.50     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19908    47]\n",
      " [ 1897    46]]\n",
      "done in 46.899988s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6814\n",
      "           1       0.42      0.02      0.04       830\n",
      "\n",
      "    accuracy                           0.89      7644\n",
      "   macro avg       0.66      0.51      0.49      7644\n",
      "weighted avg       0.84      0.89      0.84      7644\n",
      "\n",
      "Confusion_matrix\n",
      "[[6792   22]\n",
      " [ 814   16]]\n",
      "done in 47.128202s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      7022\n",
      "           1       0.49      0.02      0.05       859\n",
      "\n",
      "    accuracy                           0.89      7881\n",
      "   macro avg       0.69      0.51      0.49      7881\n",
      "weighted avg       0.85      0.89      0.84      7881\n",
      "\n",
      "Confusion_matrix\n",
      "[[7000   22]\n",
      " [ 838   21]]\n",
      "done in 46.764926s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13130\n",
      "           1       0.49      0.03      0.06      1124\n",
      "\n",
      "    accuracy                           0.92     14254\n",
      "   macro avg       0.71      0.51      0.51     14254\n",
      "weighted avg       0.89      0.92      0.89     14254\n",
      "\n",
      "Confusion_matrix\n",
      "[[13091    39]\n",
      " [ 1087    37]]\n",
      "done in 47.661723s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12933\n",
      "           1       0.48      0.02      0.04      1084\n",
      "\n",
      "    accuracy                           0.92     14017\n",
      "   macro avg       0.70      0.51      0.50     14017\n",
      "weighted avg       0.89      0.92      0.89     14017\n",
      "\n",
      "Confusion_matrix\n",
      "[[12907    26]\n",
      " [ 1060    24]]\n",
      "done in 47.008965s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.392\n",
      "threshold:0.2, J-value:0.247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.30000000000000004, J-value:0.14\n",
      "threshold:0.4, J-value:0.078\n",
      "threshold:0.5, J-value:0.037000000000000005\n",
      "threshold:0.6000000000000001, J-value:0.015000000000000001\n",
      "threshold:0.7000000000000001, J-value:0.003\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.696010138520919\n",
      "Balanced accuracy score of test is  0.6978586534060875\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.353\n",
      "threshold:0.2, J-value:0.22599999999999998\n",
      "threshold:0.30000000000000004, J-value:0.118\n",
      "threshold:0.4, J-value:0.064\n",
      "threshold:0.5, J-value:0.019000000000000003\n",
      "threshold:0.6000000000000001, J-value:0.009000000000000001\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6762533550698244\n",
      "Balanced accuracy score of test is  0.7058718499550225\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41500000000000004\n",
      "threshold:0.2, J-value:0.262\n",
      "threshold:0.30000000000000004, J-value:0.155\n",
      "threshold:0.4, J-value:0.08900000000000001\n",
      "threshold:0.5, J-value:0.049\n",
      "threshold:0.6000000000000001, J-value:0.020999999999999998\n",
      "threshold:0.7000000000000001, J-value:0.003\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.707628342905465\n",
      "Balanced accuracy score of test is  0.6890204853683888\n",
      "True positive rate of class 1 is  0.648\n",
      "True positive rate of class 2 is  0.584\n",
      "Positive prediction rate of class 1 is  0.282\n",
      "Positive prediction rate of class 2 is  0.235\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.40499999999999997\n",
      "threshold:0.2, J-value:0.264\n",
      "threshold:0.30000000000000004, J-value:0.10099999999999999\n",
      "threshold:0.4, J-value:0.015\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7024765813058549\n",
      "Balanced accuracy score of test is  0.6939942069863059\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.37\n",
      "threshold:0.2, J-value:0.246\n",
      "threshold:0.30000000000000004, J-value:0.091\n",
      "threshold:0.4, J-value:0.019\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6852903837245077\n",
      "Balanced accuracy score of test is  0.6975613645986719\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41\n",
      "threshold:0.2, J-value:0.28300000000000003\n",
      "threshold:0.30000000000000004, J-value:0.115\n",
      "threshold:0.4, J-value:0.023\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7051847389775934\n",
      "Balanced accuracy score of test is  0.6930723073758225\n",
      "True positive rate of class 1 is  0.764\n",
      "True positive rate of class 2 is  0.68\n",
      "Positive prediction rate of class 1 is  0.412\n",
      "Positive prediction rate of class 2 is  0.324\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.363\n",
      "threshold:0.2, J-value:0.21599999999999997\n",
      "threshold:0.30000000000000004, J-value:0.137\n",
      "threshold:0.4, J-value:0.015000000000000001\n",
      "threshold:0.5, J-value:0.011\n",
      "threshold:0.6000000000000001, J-value:0.002\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6813144614542007\n",
      "Balanced accuracy score of test is  0.6850046031259474\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.34600000000000003\n",
      "threshold:0.2, J-value:0.198\n",
      "threshold:0.30000000000000004, J-value:0.133\n",
      "threshold:0.4, J-value:0.009\n",
      "threshold:0.5, J-value:0.009\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6729783825645994\n",
      "Balanced accuracy score of test is  0.6846234800389529\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.365\n",
      "threshold:0.2, J-value:0.22699999999999998\n",
      "threshold:0.30000000000000004, J-value:0.139\n",
      "threshold:0.4, J-value:0.019\n",
      "threshold:0.5, J-value:0.012\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6826871579848923\n",
      "Balanced accuracy score of test is  0.6808280356637944\n",
      "True positive rate of class 1 is  0.686\n",
      "True positive rate of class 2 is  0.623\n",
      "Positive prediction rate of class 1 is  0.357\n",
      "Positive prediction rate of class 2 is  0.289\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41200000000000003\n",
      "threshold:0.2, J-value:0.255\n",
      "threshold:0.30000000000000004, J-value:0.14200000000000002\n",
      "threshold:0.4, J-value:0.06199999999999999\n",
      "threshold:0.5, J-value:0.024\n",
      "threshold:0.6000000000000001, J-value:0.004\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7061728828437126\n",
      "Balanced accuracy score of test is  0.6991236200132749\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.388\n",
      "threshold:0.2, J-value:0.236\n",
      "threshold:0.30000000000000004, J-value:0.138\n",
      "threshold:0.4, J-value:0.055\n",
      "threshold:0.5, J-value:0.016\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6940818159635902\n",
      "Balanced accuracy score of test is  0.7106527663431974\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.42300000000000004\n",
      "threshold:0.2, J-value:0.268\n",
      "threshold:0.30000000000000004, J-value:0.147\n",
      "threshold:0.4, J-value:0.067\n",
      "threshold:0.5, J-value:0.030000000000000002\n",
      "threshold:0.6000000000000001, J-value:0.004\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7118775968754828\n",
      "Balanced accuracy score of test is  0.6873033613773856\n",
      "True positive rate of class 1 is  0.669\n",
      "True positive rate of class 2 is  0.589\n",
      "Positive prediction rate of class 1 is  0.294\n",
      "Positive prediction rate of class 2 is  0.244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lifuchen/Desktop/research/CVDPrediction-master/src/lib/fairness_tests.py:112: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train ['Class'] = y_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42398,)\n",
      "(42398,)\n",
      "(84796, 88)\n",
      "X train 84796\n",
      "Y train 84796\n",
      "21898 7795 14103\n",
      "21898 7795 14103\n",
      "21898 7762 14136\n",
      "21898 7762 14136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2191308581807407\n",
      "0.2650543524397864\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95     19893\n",
      "           1       0.41      0.04      0.07      2005\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.66      0.52      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19775   118]\n",
      " [ 1924    81]]\n",
      "done in 0.612661s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2191308581807407\n",
      "0.2648123231051037\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19907\n",
      "           1       0.48      0.04      0.08      1991\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.70      0.52      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19816    91]\n",
      " [ 1907    84]]\n",
      "done in 0.619513s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2191308581807407\n",
      "0.3097026877692941\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94      6922\n",
      "           1       0.33      0.03      0.05       873\n",
      "\n",
      "    accuracy                           0.88      7795\n",
      "   macro avg       0.61      0.51      0.49      7795\n",
      "weighted avg       0.83      0.88      0.84      7795\n",
      "\n",
      "Confusion_matrix\n",
      "[[6875   47]\n",
      " [ 850   23]]\n",
      "done in 0.634855s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2191308581807407\n",
      "0.31063635087435204\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6882\n",
      "           1       0.49      0.04      0.07       880\n",
      "\n",
      "    accuracy                           0.89      7762\n",
      "   macro avg       0.69      0.52      0.50      7762\n",
      "weighted avg       0.84      0.89      0.84      7762\n",
      "\n",
      "Confusion_matrix\n",
      "[[6850   32]\n",
      " [ 849   31]]\n",
      "done in 0.633575s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2191308581807407\n",
      "0.2403763567017511\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96     12971\n",
      "           1       0.45      0.05      0.09      1132\n",
      "\n",
      "    accuracy                           0.92     14103\n",
      "   macro avg       0.69      0.52      0.52     14103\n",
      "weighted avg       0.89      0.92      0.89     14103\n",
      "\n",
      "Confusion_matrix\n",
      "[[12900    71]\n",
      " [ 1074    58]]\n",
      "done in 0.633599s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2191308581807407\n",
      "0.23965060100939736\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13025\n",
      "           1       0.47      0.05      0.09      1111\n",
      "\n",
      "    accuracy                           0.92     14136\n",
      "   macro avg       0.70      0.52      0.52     14136\n",
      "weighted avg       0.89      0.92      0.89     14136\n",
      "\n",
      "Confusion_matrix\n",
      "[[12966    59]\n",
      " [ 1058    53]]\n",
      "done in 0.643224s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19893\n",
      "           1       0.25      0.00      0.00      2005\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.58      0.50      0.48     21898\n",
      "weighted avg       0.85      0.91      0.86     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19890     3]\n",
      " [ 2004     1]]\n",
      "done in 27.558079s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19907\n",
      "           1       0.33      0.00      0.00      1991\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.62      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19903     4]\n",
      " [ 1989     2]]\n",
      "done in 27.221399s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6922\n",
      "           1       0.00      0.00      0.00       873\n",
      "\n",
      "    accuracy                           0.89      7795\n",
      "   macro avg       0.44      0.50      0.47      7795\n",
      "weighted avg       0.79      0.89      0.84      7795\n",
      "\n",
      "Confusion_matrix\n",
      "[[6922    0]\n",
      " [ 873    0]]\n",
      "done in 25.711318s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6882\n",
      "           1       1.00      0.00      0.00       880\n",
      "\n",
      "    accuracy                           0.89      7762\n",
      "   macro avg       0.94      0.50      0.47      7762\n",
      "weighted avg       0.90      0.89      0.83      7762\n",
      "\n",
      "Confusion_matrix\n",
      "[[6882    0]\n",
      " [ 879    1]]\n",
      "done in 25.972691s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12971\n",
      "           1       0.60      0.01      0.01      1132\n",
      "\n",
      "    accuracy                           0.92     14103\n",
      "   macro avg       0.76      0.50      0.48     14103\n",
      "weighted avg       0.89      0.92      0.88     14103\n",
      "\n",
      "Confusion_matrix\n",
      "[[12967     4]\n",
      " [ 1126     6]]\n",
      "done in 25.320403s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13025\n",
      "           1       0.33      0.00      0.00      1111\n",
      "\n",
      "    accuracy                           0.92     14136\n",
      "   macro avg       0.63      0.50      0.48     14136\n",
      "weighted avg       0.88      0.92      0.88     14136\n",
      "\n",
      "Confusion_matrix\n",
      "[[13023     2]\n",
      " [ 1110     1]]\n",
      "done in 25.074006s\n",
      "0.22657053063877128\n",
      "0.2724207522174975\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19893\n",
      "           1       0.18      0.00      0.00      2005\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.55      0.50      0.48     21898\n",
      "weighted avg       0.84      0.91      0.86     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19884     9]\n",
      " [ 2003     2]]\n",
      "done in 0.858024s\n",
      "0.22657053063877128\n",
      "0.27149225083484496\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19907\n",
      "           1       0.00      0.00      0.00      1991\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.45      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19902     5]\n",
      " [ 1991     0]]\n",
      "done in 0.865344s\n",
      "0.22657053063877128\n",
      "0.31728753394478754\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6922\n",
      "           1       0.00      0.00      0.00       873\n",
      "\n",
      "    accuracy                           0.89      7795\n",
      "   macro avg       0.44      0.50      0.47      7795\n",
      "weighted avg       0.79      0.89      0.84      7795\n",
      "\n",
      "Confusion_matrix\n",
      "[[6917    5]\n",
      " [ 873    0]]\n",
      "done in 0.853143s\n",
      "0.22657053063877128\n",
      "0.32015556904560205\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6882\n",
      "           1       0.00      0.00      0.00       880\n",
      "\n",
      "    accuracy                           0.89      7762\n",
      "   macro avg       0.44      0.50      0.47      7762\n",
      "weighted avg       0.79      0.89      0.83      7762\n",
      "\n",
      "Confusion_matrix\n",
      "[[6878    4]\n",
      " [ 880    0]]\n",
      "done in 0.852927s\n",
      "0.22657053063877128\n",
      "0.24762201694385177\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12971\n",
      "           1       0.33      0.00      0.00      1132\n",
      "\n",
      "    accuracy                           0.92     14103\n",
      "   macro avg       0.63      0.50      0.48     14103\n",
      "weighted avg       0.87      0.92      0.88     14103\n",
      "\n",
      "Confusion_matrix\n",
      "[[12967     4]\n",
      " [ 1130     2]]\n",
      "done in 0.859449s\n",
      "0.22657053063877128\n",
      "0.24477148994407685\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13025\n",
      "           1       0.00      0.00      0.00      1111\n",
      "\n",
      "    accuracy                           0.92     14136\n",
      "   macro avg       0.46      0.50      0.48     14136\n",
      "weighted avg       0.85      0.92      0.88     14136\n",
      "\n",
      "Confusion_matrix\n",
      "[[13024     1]\n",
      " [ 1111     0]]\n",
      "done in 0.856563s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19893\n",
      "           1       0.44      0.03      0.05      2005\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19820    73]\n",
      " [ 1948    57]]\n",
      "done in 48.446183s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19907\n",
      "           1       0.48      0.02      0.04      1991\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.70      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19856    51]\n",
      " [ 1944    47]]\n",
      "done in 182.200485s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6922\n",
      "           1       0.38      0.02      0.04       873\n",
      "\n",
      "    accuracy                           0.89      7795\n",
      "   macro avg       0.64      0.51      0.49      7795\n",
      "weighted avg       0.83      0.89      0.84      7795\n",
      "\n",
      "Confusion_matrix\n",
      "[[6893   29]\n",
      " [ 855   18]]\n",
      "done in 47.823597s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6882\n",
      "           1       0.50      0.03      0.05       880\n",
      "\n",
      "    accuracy                           0.89      7762\n",
      "   macro avg       0.69      0.51      0.49      7762\n",
      "weighted avg       0.84      0.89      0.84      7762\n",
      "\n",
      "Confusion_matrix\n",
      "[[6860   22]\n",
      " [ 858   22]]\n",
      "done in 46.886749s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12971\n",
      "           1       0.47      0.03      0.06      1132\n",
      "\n",
      "    accuracy                           0.92     14103\n",
      "   macro avg       0.70      0.52      0.51     14103\n",
      "weighted avg       0.89      0.92      0.89     14103\n",
      "\n",
      "Confusion_matrix\n",
      "[[12927    44]\n",
      " [ 1093    39]]\n",
      "done in 47.095265s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13025\n",
      "           1       0.47      0.02      0.04      1111\n",
      "\n",
      "    accuracy                           0.92     14136\n",
      "   macro avg       0.70      0.51      0.50     14136\n",
      "weighted avg       0.89      0.92      0.89     14136\n",
      "\n",
      "Confusion_matrix\n",
      "[[12997    28]\n",
      " [ 1086    25]]\n",
      "done in 46.876015s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.393\n",
      "threshold:0.2, J-value:0.251\n",
      "threshold:0.30000000000000004, J-value:0.141\n",
      "threshold:0.4, J-value:0.076\n",
      "threshold:0.5, J-value:0.034\n",
      "threshold:0.6000000000000001, J-value:0.013\n",
      "threshold:0.7000000000000001, J-value:0.007\n",
      "threshold:0.8, J-value:0.002\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6969364153081831\n",
      "Balanced accuracy score of test is  0.6843135118734057\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.367\n",
      "threshold:0.2, J-value:0.23399999999999999\n",
      "threshold:0.30000000000000004, J-value:0.125\n",
      "threshold:0.4, J-value:0.059\n",
      "threshold:0.5, J-value:0.019\n",
      "threshold:0.6000000000000001, J-value:0.008\n",
      "threshold:0.7000000000000001, J-value:0.003\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6833237187538579\n",
      "Balanced accuracy score of test is  0.6856772278143246\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.407\n",
      "threshold:0.2, J-value:0.261\n",
      "threshold:0.30000000000000004, J-value:0.153\n",
      "threshold:0.4, J-value:0.089\n",
      "threshold:0.5, J-value:0.046\n",
      "threshold:0.6000000000000001, J-value:0.016\n",
      "threshold:0.7000000000000001, J-value:0.009999999999999998\n",
      "threshold:0.8, J-value:0.004\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7036665510694828\n",
      "Balanced accuracy score of test is  0.6805871489260251\n",
      "True positive rate of class 1 is  0.603\n",
      "True positive rate of class 2 is  0.563\n",
      "Positive prediction rate of class 1 is  0.274\n",
      "Positive prediction rate of class 2 is  0.23\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.40199999999999997\n",
      "threshold:0.2, J-value:0.279\n",
      "threshold:0.30000000000000004, J-value:0.097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.4, J-value:0.025\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7007452464199677\n",
      "Balanced accuracy score of test is  0.6916638007114801\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.366\n",
      "threshold:0.2, J-value:0.266\n",
      "threshold:0.30000000000000004, J-value:0.092\n",
      "threshold:0.4, J-value:0.017\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6829551874545128\n",
      "Balanced accuracy score of test is  0.6895068822488177\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.425\n",
      "threshold:0.2, J-value:0.29300000000000004\n",
      "threshold:0.30000000000000004, J-value:0.095\n",
      "threshold:0.4, J-value:0.029\n",
      "threshold:0.5, J-value:0.005\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7126070579299895\n",
      "Balanced accuracy score of test is  0.6997016400296459\n",
      "True positive rate of class 1 is  0.732\n",
      "True positive rate of class 2 is  0.693\n",
      "Positive prediction rate of class 1 is  0.396\n",
      "Positive prediction rate of class 2 is  0.325\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.354\n",
      "threshold:0.2, J-value:0.20700000000000002\n",
      "threshold:0.30000000000000004, J-value:0.091\n",
      "threshold:0.4, J-value:0.016\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6769932605775061\n",
      "Balanced accuracy score of test is  0.6705506824715843\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.33999999999999997\n",
      "threshold:0.2, J-value:0.187\n",
      "threshold:0.30000000000000004, J-value:0.091\n",
      "threshold:0.4, J-value:0.011\n",
      "threshold:0.5, J-value:-0.001\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6698263219715812\n",
      "Balanced accuracy score of test is  0.6638794219439381\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.35500000000000004\n",
      "threshold:0.2, J-value:0.21899999999999997\n",
      "threshold:0.30000000000000004, J-value:0.089\n",
      "threshold:0.4, J-value:0.021\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6771198348694683\n",
      "Balanced accuracy score of test is  0.6706649436536745\n",
      "True positive rate of class 1 is  0.591\n",
      "True positive rate of class 2 is  0.545\n",
      "Positive prediction rate of class 1 is  0.3\n",
      "Positive prediction rate of class 2 is  0.23\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.406\n",
      "threshold:0.2, J-value:0.26\n",
      "threshold:0.30000000000000004, J-value:0.145\n",
      "threshold:0.4, J-value:0.07400000000000001\n",
      "threshold:0.5, J-value:0.024\n",
      "threshold:0.6000000000000001, J-value:0.009000000000000001\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7030890701662874\n",
      "Balanced accuracy score of test is  0.699405752570649\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.386\n",
      "threshold:0.2, J-value:0.231\n",
      "threshold:0.30000000000000004, J-value:0.131\n",
      "threshold:0.4, J-value:0.062\n",
      "threshold:0.5, J-value:0.017\n",
      "threshold:0.6000000000000001, J-value:0.008\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6929469861023818\n",
      "Balanced accuracy score of test is  0.6982386528757496\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41500000000000004\n",
      "threshold:0.2, J-value:0.27899999999999997\n",
      "threshold:0.30000000000000004, J-value:0.156\n",
      "threshold:0.4, J-value:0.083\n",
      "threshold:0.5, J-value:0.031000000000000003\n",
      "threshold:0.6000000000000001, J-value:0.009999999999999998\n",
      "threshold:0.7000000000000001, J-value:0.004\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.707436274668716\n",
      "Balanced accuracy score of test is  0.6970877855539872\n",
      "True positive rate of class 1 is  0.642\n",
      "True positive rate of class 2 is  0.602\n",
      "Positive prediction rate of class 1 is  0.291\n",
      "Positive prediction rate of class 2 is  0.239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lifuchen/Desktop/research/CVDPrediction-master/src/lib/fairness_tests.py:112: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train ['Class'] = y_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42494,)\n",
      "(42494,)\n",
      "(84988, 88)\n",
      "X train 84988\n",
      "Y train 84988\n",
      "21898 7804 14094\n",
      "21898 7804 14094\n",
      "21898 7849 14049\n",
      "21898 7849 14049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22152156177631513\n",
      "0.26436219660532567\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95     19931\n",
      "           1       0.45      0.05      0.08      1967\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.52      0.52     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19821   110]\n",
      " [ 1878    89]]\n",
      "done in 0.642579s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22152156177631513\n",
      "0.2609633191398929\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95     19956\n",
      "           1       0.46      0.05      0.08      1942\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.69      0.52      0.52     21898\n",
      "weighted avg       0.87      0.91      0.88     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19851   105]\n",
      " [ 1853    89]]\n",
      "done in 0.636858s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22152156177631513\n",
      "0.31133357600357214\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94      6937\n",
      "           1       0.46      0.05      0.08       867\n",
      "\n",
      "    accuracy                           0.89      7804\n",
      "   macro avg       0.68      0.52      0.51      7804\n",
      "weighted avg       0.84      0.89      0.85      7804\n",
      "\n",
      "Confusion_matrix\n",
      "[[6890   47]\n",
      " [ 827   40]]\n",
      "done in 0.616670s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22152156177631513\n",
      "0.3002687222736268\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94      7008\n",
      "           1       0.47      0.04      0.07       841\n",
      "\n",
      "    accuracy                           0.89      7849\n",
      "   macro avg       0.68      0.52      0.51      7849\n",
      "weighted avg       0.85      0.89      0.85      7849\n",
      "\n",
      "Confusion_matrix\n",
      "[[6969   39]\n",
      " [ 807   34]]\n",
      "done in 0.612222s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22152156177631513\n",
      "0.2383536365922764\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12994\n",
      "           1       0.44      0.04      0.08      1100\n",
      "\n",
      "    accuracy                           0.92     14094\n",
      "   macro avg       0.68      0.52      0.52     14094\n",
      "weighted avg       0.89      0.92      0.89     14094\n",
      "\n",
      "Confusion_matrix\n",
      "[[12931    63]\n",
      " [ 1051    49]]\n",
      "done in 0.627790s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22152156177631513\n",
      "0.2390038836500589\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96     12948\n",
      "           1       0.45      0.05      0.09      1101\n",
      "\n",
      "    accuracy                           0.92     14049\n",
      "   macro avg       0.69      0.52      0.52     14049\n",
      "weighted avg       0.89      0.92      0.89     14049\n",
      "\n",
      "Confusion_matrix\n",
      "[[12882    66]\n",
      " [ 1046    55]]\n",
      "done in 0.643748s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19931\n",
      "           1       0.17      0.00      0.00      1967\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.54      0.50      0.48     21898\n",
      "weighted avg       0.84      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19921    10]\n",
      " [ 1965     2]]\n",
      "done in 25.310008s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19956\n",
      "           1       0.67      0.00      0.00      1942\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.79      0.50      0.48     21898\n",
      "weighted avg       0.89      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19954     2]\n",
      " [ 1938     4]]\n",
      "done in 25.452209s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6937\n",
      "           1       0.00      0.00      0.00       867\n",
      "\n",
      "    accuracy                           0.89      7804\n",
      "   macro avg       0.44      0.50      0.47      7804\n",
      "weighted avg       0.79      0.89      0.84      7804\n",
      "\n",
      "Confusion_matrix\n",
      "[[6932    5]\n",
      " [ 867    0]]\n",
      "done in 25.072260s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      7008\n",
      "           1       1.00      0.00      0.00       841\n",
      "\n",
      "    accuracy                           0.89      7849\n",
      "   macro avg       0.95      0.50      0.47      7849\n",
      "weighted avg       0.90      0.89      0.84      7849\n",
      "\n",
      "Confusion_matrix\n",
      "[[7008    0]\n",
      " [ 839    2]]\n",
      "done in 25.230451s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12994\n",
      "           1       0.00      0.00      0.00      1100\n",
      "\n",
      "    accuracy                           0.92     14094\n",
      "   macro avg       0.46      0.50      0.48     14094\n",
      "weighted avg       0.85      0.92      0.88     14094\n",
      "\n",
      "Confusion_matrix\n",
      "[[12993     1]\n",
      " [ 1100     0]]\n",
      "done in 25.393329s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12948\n",
      "           1       0.50      0.00      0.00      1101\n",
      "\n",
      "    accuracy                           0.92     14049\n",
      "   macro avg       0.71      0.50      0.48     14049\n",
      "weighted avg       0.89      0.92      0.88     14049\n",
      "\n",
      "Confusion_matrix\n",
      "[[12947     1]\n",
      " [ 1100     1]]\n",
      "done in 26.318825s\n",
      "0.22720929335372964\n",
      "0.2730723472127573\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19931\n",
      "           1       0.00      0.00      0.00      1967\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.46      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19931     0]\n",
      " [ 1967     0]]\n",
      "done in 0.868293s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22720929335372964\n",
      "0.26937285642468783\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19956\n",
      "           1       0.33      0.00      0.00      1942\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.62      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19954     2]\n",
      " [ 1941     1]]\n",
      "done in 0.863272s\n",
      "0.22720929335372964\n",
      "0.3186263890614792\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6937\n",
      "           1       0.00      0.00      0.00       867\n",
      "\n",
      "    accuracy                           0.89      7804\n",
      "   macro avg       0.44      0.50      0.47      7804\n",
      "weighted avg       0.79      0.89      0.84      7804\n",
      "\n",
      "Confusion_matrix\n",
      "[[6937    0]\n",
      " [ 867    0]]\n",
      "done in 0.859683s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22720929335372964\n",
      "0.30860165613685986\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      7008\n",
      "           1       0.33      0.00      0.00       841\n",
      "\n",
      "    accuracy                           0.89      7849\n",
      "   macro avg       0.61      0.50      0.47      7849\n",
      "weighted avg       0.83      0.89      0.84      7849\n",
      "\n",
      "Confusion_matrix\n",
      "[[7006    2]\n",
      " [ 840    1]]\n",
      "done in 0.847022s\n",
      "0.22720929335372964\n",
      "0.24784858230659682\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12994\n",
      "           1       0.00      0.00      0.00      1100\n",
      "\n",
      "    accuracy                           0.92     14094\n",
      "   macro avg       0.46      0.50      0.48     14094\n",
      "weighted avg       0.85      0.92      0.88     14094\n",
      "\n",
      "Confusion_matrix\n",
      "[[12994     0]\n",
      " [ 1100     0]]\n",
      "done in 0.867600s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22720929335372964\n",
      "0.2474562183051891\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12948\n",
      "           1       0.00      0.00      0.00      1101\n",
      "\n",
      "    accuracy                           0.92     14049\n",
      "   macro avg       0.46      0.50      0.48     14049\n",
      "weighted avg       0.85      0.92      0.88     14049\n",
      "\n",
      "Confusion_matrix\n",
      "[[12948     0]\n",
      " [ 1101     0]]\n",
      "done in 0.864146s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19931\n",
      "           1       0.48      0.03      0.05      1967\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.70      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19871    60]\n",
      " [ 1911    56]]\n",
      "done in 47.201855s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19956\n",
      "           1       0.51      0.03      0.06      1942\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.71      0.51      0.50     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19902    54]\n",
      " [ 1885    57]]\n",
      "done in 47.294504s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6937\n",
      "           1       0.47      0.03      0.05       867\n",
      "\n",
      "    accuracy                           0.89      7804\n",
      "   macro avg       0.68      0.51      0.50      7804\n",
      "weighted avg       0.84      0.89      0.84      7804\n",
      "\n",
      "Confusion_matrix\n",
      "[[6909   28]\n",
      " [ 842   25]]\n",
      "done in 47.182633s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.94      7008\n",
      "           1       0.48      0.03      0.05       841\n",
      "\n",
      "    accuracy                           0.89      7849\n",
      "   macro avg       0.69      0.51      0.50      7849\n",
      "weighted avg       0.85      0.89      0.85      7849\n",
      "\n",
      "Confusion_matrix\n",
      "[[6982   26]\n",
      " [ 817   24]]\n",
      "done in 47.082892s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12994\n",
      "           1       0.49      0.03      0.05      1100\n",
      "\n",
      "    accuracy                           0.92     14094\n",
      "   macro avg       0.71      0.51      0.51     14094\n",
      "weighted avg       0.89      0.92      0.89     14094\n",
      "\n",
      "Confusion_matrix\n",
      "[[12962    32]\n",
      " [ 1069    31]]\n",
      "done in 46.960981s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12948\n",
      "           1       0.54      0.03      0.06      1101\n",
      "\n",
      "    accuracy                           0.92     14049\n",
      "   macro avg       0.73      0.51      0.51     14049\n",
      "weighted avg       0.89      0.92      0.89     14049\n",
      "\n",
      "Confusion_matrix\n",
      "[[12920    28]\n",
      " [ 1068    33]]\n",
      "done in 46.929438s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.369\n",
      "threshold:0.2, J-value:0.245\n",
      "threshold:0.30000000000000004, J-value:0.143\n",
      "threshold:0.4, J-value:0.074\n",
      "threshold:0.5, J-value:0.039\n",
      "threshold:0.6000000000000001, J-value:0.013\n",
      "threshold:0.7000000000000001, J-value:0.005\n",
      "threshold:0.8, J-value:0.002\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6845028923757477\n",
      "Balanced accuracy score of test is  0.6939524162219706\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.34199999999999997\n",
      "threshold:0.2, J-value:0.24000000000000002\n",
      "threshold:0.30000000000000004, J-value:0.143\n",
      "threshold:0.4, J-value:0.074\n",
      "threshold:0.5, J-value:0.039\n",
      "threshold:0.6000000000000001, J-value:0.01\n",
      "threshold:0.7000000000000001, J-value:0.005\n",
      "threshold:0.8, J-value:0.003\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6710102572518293\n",
      "Balanced accuracy score of test is  0.6916469507924357\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.38199999999999995\n",
      "threshold:0.2, J-value:0.245\n",
      "threshold:0.30000000000000004, J-value:0.14100000000000001\n",
      "threshold:0.4, J-value:0.07400000000000001\n",
      "threshold:0.5, J-value:0.04\n",
      "threshold:0.6000000000000001, J-value:0.016\n",
      "threshold:0.7000000000000001, J-value:0.004\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6907402717338073\n",
      "Balanced accuracy score of test is  0.6924753089069756\n",
      "True positive rate of class 1 is  0.629\n",
      "True positive rate of class 2 is  0.586\n",
      "Positive prediction rate of class 1 is  0.287\n",
      "Positive prediction rate of class 2 is  0.231\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.38099999999999995\n",
      "threshold:0.2, J-value:0.265\n",
      "threshold:0.30000000000000004, J-value:0.10700000000000001\n",
      "threshold:0.4, J-value:0.026\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6902724924630035\n",
      "Balanced accuracy score of test is  0.6979179632885448\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.35\n",
      "threshold:0.2, J-value:0.264\n",
      "threshold:0.30000000000000004, J-value:0.123\n",
      "threshold:0.4, J-value:0.027000000000000003\n",
      "threshold:0.5, J-value:-0.001\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.675344204281107\n",
      "Balanced accuracy score of test is  0.6900983554042535\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.38000000000000006\n",
      "threshold:0.2, J-value:0.251\n",
      "threshold:0.30000000000000004, J-value:0.099\n",
      "threshold:0.4, J-value:0.013999999999999999\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6898200568094366\n",
      "Balanced accuracy score of test is  0.7038604007309893\n",
      "True positive rate of class 1 is  0.744\n",
      "True positive rate of class 2 is  0.704\n",
      "Positive prediction rate of class 1 is  0.405\n",
      "Positive prediction rate of class 2 is  0.328\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.35700000000000004\n",
      "threshold:0.2, J-value:0.167\n",
      "threshold:0.30000000000000004, J-value:0.079\n",
      "threshold:0.4, J-value:0.052000000000000005\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6788946394802792\n",
      "Balanced accuracy score of test is  0.6807125005599342\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.3340000000000001\n",
      "threshold:0.2, J-value:0.169\n",
      "threshold:0.30000000000000004, J-value:0.099\n",
      "threshold:0.4, J-value:0.06999999999999999\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6667638504324387\n",
      "Balanced accuracy score of test is  0.6724768262125432\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.365\n",
      "threshold:0.2, J-value:0.163\n",
      "threshold:0.30000000000000004, J-value:0.06\n",
      "threshold:0.4, J-value:0.036\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6825375348062742\n",
      "Balanced accuracy score of test is  0.6819290366243848\n",
      "True positive rate of class 1 is  0.694\n",
      "True positive rate of class 2 is  0.643\n",
      "Positive prediction rate of class 1 is  0.386\n",
      "Positive prediction rate of class 2 is  0.308\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.383\n",
      "threshold:0.2, J-value:0.248\n",
      "threshold:0.30000000000000004, J-value:0.139\n",
      "threshold:0.4, J-value:0.066\n",
      "threshold:0.5, J-value:0.025\n",
      "threshold:0.6000000000000001, J-value:0.007\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.691074841145521\n",
      "Balanced accuracy score of test is  0.7002863560388983\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.365\n",
      "threshold:0.2, J-value:0.24499999999999997\n",
      "threshold:0.30000000000000004, J-value:0.151\n",
      "threshold:0.4, J-value:0.08\n",
      "threshold:0.5, J-value:0.025\n",
      "threshold:0.6000000000000001, J-value:0.007\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6827614289023023\n",
      "Balanced accuracy score of test is  0.696545548080943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.385\n",
      "threshold:0.2, J-value:0.245\n",
      "threshold:0.30000000000000004, J-value:0.127\n",
      "threshold:0.4, J-value:0.056\n",
      "threshold:0.5, J-value:0.026000000000000002\n",
      "threshold:0.6000000000000001, J-value:0.006\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6928711853023073\n",
      "Balanced accuracy score of test is  0.6998048787057684\n",
      "True positive rate of class 1 is  0.653\n",
      "True positive rate of class 2 is  0.613\n",
      "Positive prediction rate of class 1 is  0.302\n",
      "Positive prediction rate of class 2 is  0.245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lifuchen/Desktop/research/CVDPrediction-master/src/lib/fairness_tests.py:112: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train ['Class'] = y_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42377,)\n",
      "(42377,)\n",
      "(84754, 88)\n",
      "X train 84754\n",
      "Y train 84754\n",
      "21898 7696 14202\n",
      "21898 7696 14202\n",
      "21898 7840 14058\n",
      "21898 7840 14058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2215993150756223\n",
      "0.2554574796305997\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95     19973\n",
      "           1       0.47      0.05      0.08      1925\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.69      0.52      0.52     21898\n",
      "weighted avg       0.88      0.91      0.88     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19872   101]\n",
      " [ 1836    89]]\n",
      "done in 0.599941s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2215993150756223\n",
      "0.26678065921956223\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95     19866\n",
      "           1       0.46      0.04      0.08      2032\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.69      0.52      0.52     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19761   105]\n",
      " [ 1942    90]]\n",
      "done in 0.596011s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2215993150756223\n",
      "0.28501972051063745\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.95      6911\n",
      "           1       0.46      0.04      0.07       785\n",
      "\n",
      "    accuracy                           0.90      7696\n",
      "   macro avg       0.68      0.52      0.51      7696\n",
      "weighted avg       0.86      0.90      0.86      7696\n",
      "\n",
      "Confusion_matrix\n",
      "[[6874   37]\n",
      " [ 754   31]]\n",
      "done in 0.579568s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2215993150756223\n",
      "0.30879214166983937\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94      6966\n",
      "           1       0.41      0.04      0.07       874\n",
      "\n",
      "    accuracy                           0.89      7840\n",
      "   macro avg       0.65      0.52      0.51      7840\n",
      "weighted avg       0.84      0.89      0.84      7840\n",
      "\n",
      "Confusion_matrix\n",
      "[[6917   49]\n",
      " [ 840   34]]\n",
      "done in 0.595944s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2215993150756223\n",
      "0.23943783410090175\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13062\n",
      "           1       0.48      0.05      0.09      1140\n",
      "\n",
      "    accuracy                           0.92     14202\n",
      "   macro avg       0.70      0.52      0.52     14202\n",
      "weighted avg       0.89      0.92      0.89     14202\n",
      "\n",
      "Confusion_matrix\n",
      "[[12998    64]\n",
      " [ 1082    58]]\n",
      "done in 0.591454s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2215993150756223\n",
      "0.243351293562273\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12900\n",
      "           1       0.50      0.05      0.09      1158\n",
      "\n",
      "    accuracy                           0.92     14058\n",
      "   macro avg       0.71      0.52      0.52     14058\n",
      "weighted avg       0.89      0.92      0.89     14058\n",
      "\n",
      "Confusion_matrix\n",
      "[[12844    56]\n",
      " [ 1102    56]]\n",
      "done in 0.588954s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19973\n",
      "           1       0.57      0.00      0.00      1925\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.74      0.50      0.48     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19970     3]\n",
      " [ 1921     4]]\n",
      "done in 25.609205s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19866\n",
      "           1       0.80      0.00      0.00      2032\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.85      0.50      0.48     21898\n",
      "weighted avg       0.90      0.91      0.86     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19865     1]\n",
      " [ 2028     4]]\n",
      "done in 25.387203s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      6911\n",
      "           1       1.00      0.00      0.00       785\n",
      "\n",
      "    accuracy                           0.90      7696\n",
      "   macro avg       0.95      0.50      0.47      7696\n",
      "weighted avg       0.91      0.90      0.85      7696\n",
      "\n",
      "Confusion_matrix\n",
      "[[6911    0]\n",
      " [ 784    1]]\n",
      "done in 25.807505s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6966\n",
      "           1       0.67      0.00      0.01       874\n",
      "\n",
      "    accuracy                           0.89      7840\n",
      "   macro avg       0.78      0.50      0.48      7840\n",
      "weighted avg       0.86      0.89      0.84      7840\n",
      "\n",
      "Confusion_matrix\n",
      "[[6964    2]\n",
      " [ 870    4]]\n",
      "done in 25.128727s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13062\n",
      "           1       0.50      0.00      0.00      1140\n",
      "\n",
      "    accuracy                           0.92     14202\n",
      "   macro avg       0.71      0.50      0.48     14202\n",
      "weighted avg       0.89      0.92      0.88     14202\n",
      "\n",
      "Confusion_matrix\n",
      "[[13061     1]\n",
      " [ 1139     1]]\n",
      "done in 25.288777s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12900\n",
      "           1       0.50      0.00      0.00      1158\n",
      "\n",
      "    accuracy                           0.92     14058\n",
      "   macro avg       0.71      0.50      0.48     14058\n",
      "weighted avg       0.88      0.92      0.88     14058\n",
      "\n",
      "Confusion_matrix\n",
      "[[12899     1]\n",
      " [ 1157     1]]\n",
      "done in 25.192861s\n",
      "0.2278079986148982\n",
      "0.264853534499619\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19973\n",
      "           1       0.18      0.00      0.00      1925\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.54      0.50      0.48     21898\n",
      "weighted avg       0.85      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19959    14]\n",
      " [ 1922     3]]\n",
      "done in 0.854813s\n",
      "0.2278079986148982\n",
      "0.27632550080183665\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19866\n",
      "           1       0.24      0.00      0.00      2032\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.57      0.50      0.48     21898\n",
      "weighted avg       0.84      0.91      0.86     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19853    13]\n",
      " [ 2028     4]]\n",
      "done in 0.855831s\n",
      "0.2278079986148982\n",
      "0.2963324738038228\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      6911\n",
      "           1       0.25      0.00      0.01       785\n",
      "\n",
      "    accuracy                           0.90      7696\n",
      "   macro avg       0.57      0.50      0.48      7696\n",
      "weighted avg       0.83      0.90      0.85      7696\n",
      "\n",
      "Confusion_matrix\n",
      "[[6905    6]\n",
      " [ 783    2]]\n",
      "done in 0.829679s\n",
      "0.2278079986148982\n",
      "0.3186734531600463\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6966\n",
      "           1       0.20      0.00      0.00       874\n",
      "\n",
      "    accuracy                           0.89      7840\n",
      "   macro avg       0.54      0.50      0.47      7840\n",
      "weighted avg       0.81      0.89      0.84      7840\n",
      "\n",
      "Confusion_matrix\n",
      "[[6958    8]\n",
      " [ 872    2]]\n",
      "done in 0.837034s\n",
      "0.2278079986148982\n",
      "0.24779523870429773\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13062\n",
      "           1       0.11      0.00      0.00      1140\n",
      "\n",
      "    accuracy                           0.92     14202\n",
      "   macro avg       0.52      0.50      0.48     14202\n",
      "weighted avg       0.85      0.92      0.88     14202\n",
      "\n",
      "Confusion_matrix\n",
      "[[13054     8]\n",
      " [ 1139     1]]\n",
      "done in 0.842662s\n",
      "0.2278079986148982\n",
      "0.25270848938567764\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12900\n",
      "           1       0.29      0.00      0.00      1158\n",
      "\n",
      "    accuracy                           0.92     14058\n",
      "   macro avg       0.60      0.50      0.48     14058\n",
      "weighted avg       0.87      0.92      0.88     14058\n",
      "\n",
      "Confusion_matrix\n",
      "[[12895     5]\n",
      " [ 1156     2]]\n",
      "done in 0.837362s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19973\n",
      "           1       0.50      0.02      0.05      1925\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.71      0.51      0.50     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19925    48]\n",
      " [ 1877    48]]\n",
      "done in 46.877102s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19866\n",
      "           1       0.45      0.02      0.05      2032\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19805    61]\n",
      " [ 1982    50]]\n",
      "done in 46.763671s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      6911\n",
      "           1       0.60      0.03      0.06       785\n",
      "\n",
      "    accuracy                           0.90      7696\n",
      "   macro avg       0.75      0.52      0.50      7696\n",
      "weighted avg       0.87      0.90      0.86      7696\n",
      "\n",
      "Confusion_matrix\n",
      "[[6894   17]\n",
      " [ 759   26]]\n",
      "done in 46.784138s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6966\n",
      "           1       0.39      0.03      0.05       874\n",
      "\n",
      "    accuracy                           0.89      7840\n",
      "   macro avg       0.64      0.51      0.49      7840\n",
      "weighted avg       0.84      0.89      0.84      7840\n",
      "\n",
      "Confusion_matrix\n",
      "[[6932   34]\n",
      " [ 852   22]]\n",
      "done in 46.707383s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13062\n",
      "           1       0.41      0.02      0.04      1140\n",
      "\n",
      "    accuracy                           0.92     14202\n",
      "   macro avg       0.66      0.51      0.50     14202\n",
      "weighted avg       0.88      0.92      0.88     14202\n",
      "\n",
      "Confusion_matrix\n",
      "[[13030    32]\n",
      " [ 1118    22]]\n",
      "done in 47.749037s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12900\n",
      "           1       0.52      0.02      0.05      1158\n",
      "\n",
      "    accuracy                           0.92     14058\n",
      "   macro avg       0.72      0.51      0.50     14058\n",
      "weighted avg       0.89      0.92      0.88     14058\n",
      "\n",
      "Confusion_matrix\n",
      "[[12874    26]\n",
      " [ 1130    28]]\n",
      "done in 46.830550s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.385\n",
      "threshold:0.2, J-value:0.251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.30000000000000004, J-value:0.155\n",
      "threshold:0.4, J-value:0.08600000000000001\n",
      "threshold:0.5, J-value:0.041\n",
      "threshold:0.6000000000000001, J-value:0.016999999999999998\n",
      "threshold:0.7000000000000001, J-value:0.006\n",
      "threshold:0.8, J-value:0.002\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6922920358067808\n",
      "Balanced accuracy score of test is  0.6967449381327334\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.384\n",
      "threshold:0.2, J-value:0.246\n",
      "threshold:0.30000000000000004, J-value:0.152\n",
      "threshold:0.4, J-value:0.089\n",
      "threshold:0.5, J-value:0.034\n",
      "threshold:0.6000000000000001, J-value:0.015000000000000001\n",
      "threshold:0.7000000000000001, J-value:0.005\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6919907062220572\n",
      "Balanced accuracy score of test is  0.6905403887203685\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.37999999999999995\n",
      "threshold:0.2, J-value:0.253\n",
      "threshold:0.30000000000000004, J-value:0.156\n",
      "threshold:0.4, J-value:0.084\n",
      "threshold:0.5, J-value:0.046\n",
      "threshold:0.6000000000000001, J-value:0.016999999999999998\n",
      "threshold:0.7000000000000001, J-value:0.006\n",
      "threshold:0.8, J-value:0.002\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6897458678851469\n",
      "Balanced accuracy score of test is  0.6976623689601157\n",
      "True positive rate of class 1 is  0.63\n",
      "True positive rate of class 2 is  0.591\n",
      "Positive prediction rate of class 1 is  0.292\n",
      "Positive prediction rate of class 2 is  0.228\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.39399999999999996\n",
      "threshold:0.2, J-value:0.256\n",
      "threshold:0.30000000000000004, J-value:0.09899999999999999\n",
      "threshold:0.4, J-value:0.017\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6973647150926479\n",
      "Balanced accuracy score of test is  0.6961541689556248\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.383\n",
      "threshold:0.2, J-value:0.262\n",
      "threshold:0.30000000000000004, J-value:0.10400000000000001\n",
      "threshold:0.4, J-value:0.016\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6917019576471369\n",
      "Balanced accuracy score of test is  0.6824271009696656\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.38900000000000007\n",
      "threshold:0.2, J-value:0.245\n",
      "threshold:0.30000000000000004, J-value:0.096\n",
      "threshold:0.4, J-value:0.017\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6945111976081684\n",
      "Balanced accuracy score of test is  0.7096851026228059\n",
      "True positive rate of class 1 is  0.747\n",
      "True positive rate of class 2 is  0.703\n",
      "Positive prediction rate of class 1 is  0.423\n",
      "Positive prediction rate of class 2 is  0.318\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.358\n",
      "threshold:0.2, J-value:0.15900000000000003\n",
      "threshold:0.30000000000000004, J-value:0.106\n",
      "threshold:0.4, J-value:0.022\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6788245560077533\n",
      "Balanced accuracy score of test is  0.6808704689530087\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.35300000000000004\n",
      "threshold:0.2, J-value:0.14200000000000002\n",
      "threshold:0.30000000000000004, J-value:0.10200000000000001\n",
      "threshold:0.4, J-value:0.031\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6761803162501947\n",
      "Balanced accuracy score of test is  0.6691187533301666\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.355\n",
      "threshold:0.2, J-value:0.16899999999999998\n",
      "threshold:0.30000000000000004, J-value:0.107\n",
      "threshold:0.4, J-value:0.016\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6776779166565932\n",
      "Balanced accuracy score of test is  0.6854769650961963\n",
      "True positive rate of class 1 is  0.648\n",
      "True positive rate of class 2 is  0.619\n",
      "Positive prediction rate of class 1 is  0.347\n",
      "Positive prediction rate of class 2 is  0.279\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.402\n",
      "threshold:0.2, J-value:0.253\n",
      "threshold:0.30000000000000004, J-value:0.15\n",
      "threshold:0.4, J-value:0.069\n",
      "threshold:0.5, J-value:0.023\n",
      "threshold:0.6000000000000001, J-value:0.006\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7008981345595775\n",
      "Balanced accuracy score of test is  0.7049148091425147\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.401\n",
      "threshold:0.2, J-value:0.257\n",
      "threshold:0.30000000000000004, J-value:0.159\n",
      "threshold:0.4, J-value:0.07\n",
      "threshold:0.5, J-value:0.031\n",
      "threshold:0.6000000000000001, J-value:0.008\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7006936232923235\n",
      "Balanced accuracy score of test is  0.6974558019960961\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.39499999999999996\n",
      "threshold:0.2, J-value:0.247\n",
      "threshold:0.30000000000000004, J-value:0.14200000000000002\n",
      "threshold:0.4, J-value:0.068\n",
      "threshold:0.5, J-value:0.017\n",
      "threshold:0.6000000000000001, J-value:0.006\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6978956635962897\n",
      "Balanced accuracy score of test is  0.7065017873639394\n",
      "True positive rate of class 1 is  0.656\n",
      "True positive rate of class 2 is  0.616\n",
      "Positive prediction rate of class 1 is  0.305\n",
      "Positive prediction rate of class 2 is  0.237\n"
     ]
    }
   ],
   "source": [
    "records_lr = []\n",
    "records_rf = []\n",
    "records_dt = []\n",
    "records_gbt = []\n",
    "for random_state in range(10):\n",
    "    fairness_metrics (X, y, \"GENDER\", random_state)\n",
    "\n",
    "result_lr = pd.DataFrame(records_lr)\n",
    "result_rf = pd.DataFrame(records_rf)\n",
    "result_dt = pd.DataFrame(records_dt)\n",
    "result_gbt = pd.DataFrame(records_gbt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def add_mean_sd(records, result_table, overall_records, type):\n",
    "    records.append({\n",
    "        'auroc': result_table[\"auroc\"].mean(),\n",
    "        'overall threshold': result_table[\"overall threshold\"].mean(),\n",
    "        'male threshold': result_table[\"male threshold\"].mean(),\n",
    "        'female threshold': result_table[\"female threshold\"].mean(),\n",
    "        'overall ba validation': result_table[\"overall ba validation\"].mean(),\n",
    "        'overall ba test': result_table[\"overall ba test\"].mean(),\n",
    "        'male ba validation': result_table[\"male ba validation\"].mean(),\n",
    "        'male ba test': result_table[\"male ba test\"].mean(),\n",
    "        'female ba validation': result_table[\"female ba validation\"].mean(),\n",
    "        'female ba test': result_table[\"female ba test\"].mean(),\n",
    "        'overall precision':result_table[\"overall precision\"].mean(),\n",
    "        'overall recall':result_table[\"overall recall\"].mean(),\n",
    "        'overall tpr':result_table[\"overall tpr\"].mean(),\n",
    "        'overall tnr':result_table[\"overall tnr\"].mean(),\n",
    "        'overall pd':result_table[\"overall pd\"].mean(),\n",
    "        'male precision':result_table[\"male precision\"].mean(),\n",
    "        'male recall':result_table[\"male recall\"].mean(),\n",
    "        'male tpr':result_table[\"male tpr\"].mean(),\n",
    "        'male tnr':result_table[\"male tnr\"].mean(),\n",
    "        'male pd':result_table[\"male pd\"].mean(),\n",
    "        'female precision':result_table[\"female precision\"].mean(),\n",
    "        'female recall':result_table[\"female recall\"].mean(),\n",
    "        'female tpr':result_table[\"female tpr\"].mean(),\n",
    "        'female tnr':result_table[\"female tnr\"].mean(),\n",
    "        'female pd':result_table[\"female pd\"].mean(),\n",
    "        'eod': result_table[\"eod\"].mean(),\n",
    "        'di': result_table[\"di\"].mean(),\n",
    "        })\n",
    "    records.append({\n",
    "        'auroc': result_table[\"auroc\"].std(),\n",
    "        'overall threshold': result_table[\"overall threshold\"].std(),\n",
    "        'male threshold': result_table[\"male threshold\"].std(),\n",
    "        'female threshold': result_table[\"female threshold\"].std(),\n",
    "        'overall ba validation': result_table[\"overall ba validation\"].std(),\n",
    "        'overall ba test': result_table[\"overall ba test\"].std(),\n",
    "        'male ba validation': result_table[\"male ba validation\"].std(),\n",
    "        'male ba test': result_table[\"male ba test\"].std(),\n",
    "        'female ba validation': result_table[\"female ba validation\"].std(),\n",
    "        'female ba test': result_table[\"female ba test\"].std(),\n",
    "        'overall precision':result_table[\"overall precision\"].std(),\n",
    "        'overall recall':result_table[\"overall recall\"].std(),\n",
    "        'overall tpr':result_table[\"overall tpr\"].std(),\n",
    "        'overall tnr':result_table[\"overall tnr\"].std(),\n",
    "        'overall pd':result_table[\"overall pd\"].std(),\n",
    "        'male precision':result_table[\"male precision\"].std(),\n",
    "        'male recall':result_table[\"male recall\"].std(),\n",
    "        'male tpr':result_table[\"male tpr\"].std(),\n",
    "        'male tnr':result_table[\"male tnr\"].std(),\n",
    "        'male pd':result_table[\"male pd\"].std(),\n",
    "        'female precision':result_table[\"female precision\"].std(),\n",
    "        'female recall':result_table[\"female recall\"].std(),\n",
    "        'female tpr':result_table[\"female tpr\"].std(),\n",
    "        'female tnr':result_table[\"female tnr\"].std(),\n",
    "        'female pd':result_table[\"female pd\"].std(),\n",
    "        'eod': result_table[\"eod\"].std(),\n",
    "        'di': result_table[\"di\"].std(),\n",
    "        })\n",
    "    overall_records.append({\n",
    "        'type': type,\n",
    "        'auroc': result_table[\"auroc\"].mean(),\n",
    "        'overall threshold': result_table[\"overall threshold\"].mean(),\n",
    "        'male threshold': result_table[\"male threshold\"].mean(),\n",
    "        'female threshold': result_table[\"female threshold\"].mean(),\n",
    "        'overall ba test': result_table[\"overall ba test\"].mean(),\n",
    "        'male ba test': result_table[\"male ba test\"].mean(),\n",
    "        'female ba test': result_table[\"female ba test\"].mean(),\n",
    "        'overall tpr':result_table[\"overall tpr\"].mean(),\n",
    "        'overall pd':result_table[\"overall pd\"].mean(),\n",
    "        'male tpr':result_table[\"male tpr\"].mean(),\n",
    "        'male pd':result_table[\"male pd\"].mean(),\n",
    "        'female tpr':result_table[\"female tpr\"].mean(),\n",
    "        'female pd':result_table[\"female pd\"].mean(),\n",
    "        'eod': result_table[\"eod\"].mean(),\n",
    "        'di': result_table[\"di\"].mean(),\n",
    "        })\n",
    "    pd_result = pd.DataFrame(records)\n",
    "    return pd_result, overall_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_table = []\n",
    "result_lr, overall_records = add_mean_sd (records_lr, result_lr, overall_table, 'lr')\n",
    "result_rf, overall_records = add_mean_sd (records_rf, result_rf, overall_records, 'rf')\n",
    "result_dt, overall_records = add_mean_sd (records_dt, result_dt, overall_records, 'dt')\n",
    "result_gbt, overall_records = add_mean_sd (records_gbt, result_gbt, overall_records, 'gbt')\n",
    "\n",
    "result_path='/Users/lifuchen/Desktop/research/resample_data/'\n",
    "result_lr.to_csv(path.join(result_path,'gender-lr-resample-size-result.csv'), index=False)\n",
    "result_rf.to_csv(path.join(result_path,'gender-rf-resample-size-result.csv'), index=False)\n",
    "result_dt.to_csv(path.join(result_path,'gender-dt-resample-size-result.csv'), index=False)\n",
    "result_gbt.to_csv(path.join(result_path,'gender-gbt-resample-size-result.csv'), index=False)\n",
    "\n",
    "overall_result = pd.DataFrame(overall_table)\n",
    "result_path='/Users/lifuchen/Desktop/research/resample_result/'\n",
    "overall_result.to_csv(path.join(result_path,'gender-resample-size.csv'), index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
