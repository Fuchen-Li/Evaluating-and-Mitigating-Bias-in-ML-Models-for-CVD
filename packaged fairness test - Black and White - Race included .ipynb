{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from os import path\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score\n",
    "import sklearn.preprocessing\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import src.lib.utility_classfier as uclf\n",
    "import src.lib.optimal_threhold_related as thres\n",
    "import src.lib.fairness_tests as fair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_path='/Users/lifuchen/Desktop/research/data.csv'\n",
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109490, 87)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df.Class.values\n",
    "X = df.drop(['GRID','Class'], axis=1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def save_prediction(classifier, characteristic, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_white_scaled, y_val_white, X_test_white_scaled, y_test_white, X_val_black_scaled, y_val_black, X_test_black_scaled, y_test_black):\n",
    "    method_to_call = getattr(uclf, classifier)\n",
    "    y_val_score = method_to_call(X_train_scaled, y_train,X_val_scaled, y_val)\n",
    "    y_test_score = method_to_call(X_train_scaled, y_train,X_test_scaled, y_test)\n",
    "\n",
    "    y_val_score_white = method_to_call(X_train_scaled, y_train, X_val_white_scaled, y_val_white)\n",
    "    y_test_score_white = method_to_call(X_train_scaled, y_train,X_test_white_scaled, y_test_white)\n",
    "\n",
    "    y_val_score_black = method_to_call(X_train_scaled, y_train, X_val_black_scaled, y_val_black)\n",
    "    y_test_score_black = method_to_call(X_train_scaled, y_train,X_test_black_scaled, y_test_black)\n",
    "\n",
    "    my_dict = dict(val_score = y_val_score, test_score = y_test_score, val_1_score = y_val_score_white, test_1_score = y_test_score_white, val_2_score = y_val_score_black, test_2_score = y_test_score_black)\n",
    "    overall_prediction = pd.DataFrame.from_dict(my_dict, orient='index')\n",
    "    overall_prediction = overall_prediction.transpose()\n",
    "\n",
    "    result_path='/Users/lifuchen/Desktop/research/predictions/'\n",
    "    filename = str(classifier) + str(characteristic) + \"prediction.csv\"\n",
    "    overall_prediction.to_csv(path.join(result_path, filename), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_result (classifier, characteristic, records, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_white_scaled, y_val_white, X_test_white_scaled, y_test_white, X_val_black_scaled, y_val_black, X_test_black_scaled, y_test_black):\n",
    "    result_path='/Users/lifuchen/Desktop/research/predictions/'\n",
    "    filename = str(classifier) + characteristic + \"prediction.csv\"\n",
    "    prediction = pd.read_csv(path.join(result_path, filename))\n",
    "\n",
    "    y_val_score = prediction['val_score'][prediction['val_score'].notna()]\n",
    "    y_test_score = prediction['test_score'][prediction['test_score'].notna()]\n",
    "\n",
    "    y_val_score_white = prediction['val_1_score'][prediction['val_1_score'].notna()]\n",
    "    y_test_score_white = prediction['test_1_score'][prediction['test_1_score'].notna()]\n",
    "\n",
    "    y_val_score_black = prediction['val_2_score'][prediction['val_2_score'].notna()]\n",
    "    y_test_score_black = prediction['test_2_score'][prediction['test_2_score'].notna()]\n",
    "\n",
    "    threshold, ba_val, ba_test = balance_accuracy (y_val, y_val_score,y_test, y_test_score)\n",
    "    auroc = roc_auc_score(y_test, y_test_score)\n",
    "    precision, recall, tpr, tnr, pd_overall = thres.calculate_precision_metrics(y_test, y_test_score,threshold)\n",
    "\n",
    "    threshold_white, ba_val_white, ba_test_white = balance_accuracy (y_val_white, y_val_score_white,y_test_white, y_test_score_white)\n",
    "    precision_white, recall_white, tpr_white, tnr_white, pd_white = thres.calculate_precision_metrics(y_test_white, y_test_score_white,threshold_white)\n",
    "\n",
    "    threshold_black, ba_val_black, ba_test_black = balance_accuracy (y_val_black, y_val_score_black, y_test_black, y_test_score_black)\n",
    "    precision_black, recall_black, tpr_black, tnr_black, pd_black = thres.calculate_precision_metrics(y_test_black, y_test_score_black,threshold_black)\n",
    "\n",
    "    eod = fair.get_EOD(y_test_white, y_test_score_white,threshold_white, y_test_black, y_test_score_black, threshold_black)\n",
    "    sp = fair.get_SP(y_test_white, y_test_score_white,threshold_white, y_test_black, y_test_score_black, threshold_black)\n",
    "\n",
    "    records.append({\n",
    "        'auroc': auroc,\n",
    "        'overall threshold': threshold,\n",
    "        'white threshold': threshold_white,\n",
    "        'black threshold': threshold_black,\n",
    "        'overall ba validation': ba_val,\n",
    "        'overall ba test': ba_test,\n",
    "        'white ba validation': ba_val_white,\n",
    "        'white ba test': ba_test_white,\n",
    "        'black ba validation': ba_val_black,\n",
    "        'black ba test': ba_test_black,\n",
    "        'overall precision':precision,\n",
    "        'overall recall':recall,\n",
    "        'overall tpr':tpr,\n",
    "        'overall tnr':tnr,\n",
    "        'overall pd':pd_overall,\n",
    "        'white precision':precision_white,\n",
    "        'white recall':recall_white,\n",
    "        'white tpr':tpr_white,\n",
    "        'white tnr':tnr_white,\n",
    "        'white pd':pd_white,\n",
    "        'black precision':precision_black,\n",
    "        'black recall':recall_black,\n",
    "        'black tpr':tpr_black,\n",
    "        'black tnr':tnr_black,\n",
    "        'black pd':pd_black,\n",
    "        'eod': eod,\n",
    "        'di': sp,\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def balance_accuracy (y_val, y_val_score,y_test, y_test_score):\n",
    "    \n",
    "    threshold, _ = thres.get_optimal_threshold_Jvalue (y_val, y_val_score)\n",
    "    print (\"Optimal threshold by J value is \",threshold)\n",
    "\n",
    "    ba_val = thres.calculate_balanced_accuracy(y_val, y_val_score, threshold)\n",
    "    print (\"Balanced accuracy score of val is \", ba_val)\n",
    "\n",
    "    ba_test = thres.calculate_balanced_accuracy(y_test, y_test_score, threshold)\n",
    "    print (\"Balanced accuracy score of test is \",ba_test)\n",
    "\n",
    "    return threshold, ba_val, ba_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def fairness_metrics (X, y, attribute, random_state):\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, X_val_white, X_val_black, y_val_white, y_val_black, X_test_white, X_test_black, y_test_white, y_test_black \\\n",
    "        = fair.split_by_trait_no_protected_trait(X, y, attribute, random_state)\n",
    "    print(\"X train\", X_train.shape[0])\n",
    "    print(\"Y train\", y_train.shape[0])\n",
    "    print(X_val.shape[0], X_val_white.shape[0], X_val_black.shape[0])\n",
    "    print(y_val.shape[0], y_val_white.shape[0], y_val_black.shape[0])\n",
    "    print(X_test.shape[0], X_test_white.shape[0], X_test_black.shape[0])\n",
    "    print(y_test.shape[0], y_test_white.shape[0], y_test_black.shape[0])\n",
    "\n",
    "    max_abs_scaler = preprocessing.MaxAbsScaler()\n",
    "    X_train_scaled = max_abs_scaler.fit_transform(X_train)\n",
    "    X_test_scaled = max_abs_scaler.transform(X_test)\n",
    "    X_test_white_scaled = max_abs_scaler.transform(X_test_white)\n",
    "    X_test_black_scaled = max_abs_scaler.transform(X_test_black)\n",
    "    X_val_scaled = max_abs_scaler.transform(X_val)\n",
    "    X_val_white_scaled = max_abs_scaler.transform(X_val_white)\n",
    "    X_val_black_scaled = max_abs_scaler.transform(X_val_black)\n",
    "\n",
    "    characteristic = attribute + str(random_state)\n",
    "    save_prediction (\"logic_regression\", characteristic, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_white_scaled, y_val_white, X_test_white_scaled, y_test_white, X_val_black_scaled, y_val_black, X_test_black_scaled, y_test_black)\n",
    "    save_prediction (\"random_forest\", characteristic, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_white_scaled, y_val_white, X_test_white_scaled, y_test_white, X_val_black_scaled, y_val_black, X_test_black_scaled, y_test_black)\n",
    "    save_prediction (\"decision_tree\", characteristic, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_white_scaled, y_val_white, X_test_white_scaled, y_test_white, X_val_black_scaled, y_val_black, X_test_black_scaled, y_test_black)\n",
    "    save_prediction (\"gradiant_boosting\", characteristic, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_white_scaled, y_val_white, X_test_white_scaled, y_test_white, X_val_black_scaled, y_val_black, X_test_black_scaled, y_test_black)\n",
    "\n",
    "    get_result (\"logic_regression\", characteristic, records_lr, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_white_scaled, y_val_white, X_test_white_scaled, y_test_white, X_val_black_scaled, y_val_black, X_test_black_scaled, y_test_black)\n",
    "    get_result (\"random_forest\", characteristic, records_rf, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_white_scaled, y_val_white, X_test_white_scaled, y_test_white, X_val_black_scaled, y_val_black, X_test_black_scaled, y_test_black)\n",
    "    get_result (\"decision_tree\", characteristic, records_dt, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_white_scaled, y_val_white, X_test_white_scaled, y_test_white, X_val_black_scaled, y_val_black, X_test_black_scaled, y_test_black)\n",
    "    get_result (\"gradiant_boosting\", characteristic, records_gbt, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_white_scaled, y_val_white, X_test_white_scaled, y_test_white, X_val_black_scaled, y_val_black, X_test_black_scaled, y_test_black)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train 65694\n",
      "Y train 65694\n",
      "21898 18899 2999\n",
      "21898 18899 2999\n",
      "21898 18968 2930\n",
      "21898 18968 2930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2588873633479377\n",
      "0.26198310268376185\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19904\n",
      "           1       0.46      0.03      0.06      1994\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.69      0.51      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19825    79]\n",
      " [ 1927    67]]\n",
      "done in 0.581849s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2588873633479377\n",
      "0.2622422310280552\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19934\n",
      "           1       0.42      0.03      0.06      1964\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19848    86]\n",
      " [ 1901    63]]\n",
      "done in 0.572001s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2588873633479377\n",
      "0.2628451217946567\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17180\n",
      "           1       0.47      0.03      0.06      1719\n",
      "\n",
      "    accuracy                           0.91     18899\n",
      "   macro avg       0.69      0.51      0.51     18899\n",
      "weighted avg       0.87      0.91      0.87     18899\n",
      "\n",
      "Confusion_matrix\n",
      "[[17116    64]\n",
      " [ 1663    56]]\n",
      "done in 0.573609s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2588873633479377\n",
      "0.2627415373134105\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17260\n",
      "           1       0.42      0.03      0.06      1708\n",
      "\n",
      "    accuracy                           0.91     18968\n",
      "   macro avg       0.66      0.51      0.50     18968\n",
      "weighted avg       0.87      0.91      0.87     18968\n",
      "\n",
      "Confusion_matrix\n",
      "[[17187    73]\n",
      " [ 1656    52]]\n",
      "done in 0.621934s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2588873633479377\n",
      "0.2565508588768923\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95      2724\n",
      "           1       0.42      0.04      0.07       275\n",
      "\n",
      "    accuracy                           0.91      2999\n",
      "   macro avg       0.67      0.52      0.51      2999\n",
      "weighted avg       0.87      0.91      0.87      2999\n",
      "\n",
      "Confusion_matrix\n",
      "[[2709   15]\n",
      " [ 264   11]]\n",
      "done in 0.679354s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2588873633479377\n",
      "0.2590098618742601\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.95      2674\n",
      "           1       0.46      0.04      0.08       256\n",
      "\n",
      "    accuracy                           0.91      2930\n",
      "   macro avg       0.69      0.52      0.52      2930\n",
      "weighted avg       0.88      0.91      0.88      2930\n",
      "\n",
      "Confusion_matrix\n",
      "[[2661   13]\n",
      " [ 245   11]]\n",
      "done in 0.767632s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19904\n",
      "           1       0.50      0.00      0.00      1994\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.70      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19899     5]\n",
      " [ 1989     5]]\n",
      "done in 21.629770s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19934\n",
      "           1       0.56      0.01      0.01      1964\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.73      0.50      0.48     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19926     8]\n",
      " [ 1954    10]]\n",
      "done in 24.988601s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17180\n",
      "           1       0.60      0.01      0.01      1719\n",
      "\n",
      "    accuracy                           0.91     18899\n",
      "   macro avg       0.75      0.50      0.48     18899\n",
      "weighted avg       0.88      0.91      0.87     18899\n",
      "\n",
      "Confusion_matrix\n",
      "[[17174     6]\n",
      " [ 1710     9]]\n",
      "done in 24.625258s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17260\n",
      "           1       0.67      0.00      0.01      1708\n",
      "\n",
      "    accuracy                           0.91     18968\n",
      "   macro avg       0.79      0.50      0.48     18968\n",
      "weighted avg       0.89      0.91      0.87     18968\n",
      "\n",
      "Confusion_matrix\n",
      "[[17257     3]\n",
      " [ 1702     6]]\n",
      "done in 25.018812s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2724\n",
      "           1       0.25      0.00      0.01       275\n",
      "\n",
      "    accuracy                           0.91      2999\n",
      "   macro avg       0.58      0.50      0.48      2999\n",
      "weighted avg       0.85      0.91      0.86      2999\n",
      "\n",
      "Confusion_matrix\n",
      "[[2721    3]\n",
      " [ 274    1]]\n",
      "done in 25.309784s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2674\n",
      "           1       0.00      0.00      0.00       256\n",
      "\n",
      "    accuracy                           0.91      2930\n",
      "   macro avg       0.46      0.50      0.48      2930\n",
      "weighted avg       0.83      0.91      0.87      2930\n",
      "\n",
      "Confusion_matrix\n",
      "[[2673    1]\n",
      " [ 256    0]]\n",
      "done in 24.637841s\n",
      "0.26448598669059525\n",
      "0.2722330649120758\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19904\n",
      "           1       0.00      0.00      0.00      1994\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.45      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19903     1]\n",
      " [ 1994     0]]\n",
      "done in 0.691363s\n",
      "0.26448598669059525\n",
      "0.2769244924266795\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19934\n",
      "           1       0.00      0.00      0.00      1964\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.46      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19931     3]\n",
      " [ 1964     0]]\n",
      "done in 0.712925s\n",
      "0.26448598669059525\n",
      "0.2712860393477675\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17180\n",
      "           1       0.00      0.00      0.00      1719\n",
      "\n",
      "    accuracy                           0.91     18899\n",
      "   macro avg       0.45      0.50      0.48     18899\n",
      "weighted avg       0.83      0.91      0.87     18899\n",
      "\n",
      "Confusion_matrix\n",
      "[[17180     0]\n",
      " [ 1719     0]]\n",
      "done in 0.691959s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26448598669059525\n",
      "0.2778694234760347\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17260\n",
      "           1       0.00      0.00      0.00      1708\n",
      "\n",
      "    accuracy                           0.91     18968\n",
      "   macro avg       0.45      0.50      0.48     18968\n",
      "weighted avg       0.83      0.91      0.87     18968\n",
      "\n",
      "Confusion_matrix\n",
      "[[17257     3]\n",
      " [ 1708     0]]\n",
      "done in 0.690709s\n",
      "0.26448598669059525\n",
      "0.27820099960359335\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2724\n",
      "           1       0.00      0.00      0.00       275\n",
      "\n",
      "    accuracy                           0.91      2999\n",
      "   macro avg       0.45      0.50      0.48      2999\n",
      "weighted avg       0.82      0.91      0.86      2999\n",
      "\n",
      "Confusion_matrix\n",
      "[[2723    1]\n",
      " [ 275    0]]\n",
      "done in 0.644208s\n",
      "0.26448598669059525\n",
      "0.270807273264847\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2674\n",
      "           1       0.00      0.00      0.00       256\n",
      "\n",
      "    accuracy                           0.91      2930\n",
      "   macro avg       0.46      0.50      0.48      2930\n",
      "weighted avg       0.83      0.91      0.87      2930\n",
      "\n",
      "Confusion_matrix\n",
      "[[2674    0]\n",
      " [ 256    0]]\n",
      "done in 0.643081s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19904\n",
      "           1       0.46      0.02      0.03      1994\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.51      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19864    40]\n",
      " [ 1960    34]]\n",
      "done in 36.725209s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19934\n",
      "           1       0.45      0.02      0.05      1964\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19876    58]\n",
      " [ 1917    47]]\n",
      "done in 36.344575s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17180\n",
      "           1       0.48      0.02      0.03      1719\n",
      "\n",
      "    accuracy                           0.91     18899\n",
      "   macro avg       0.69      0.51      0.49     18899\n",
      "weighted avg       0.87      0.91      0.87     18899\n",
      "\n",
      "Confusion_matrix\n",
      "[[17146    34]\n",
      " [ 1688    31]]\n",
      "done in 36.615385s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17260\n",
      "           1       0.44      0.02      0.04      1708\n",
      "\n",
      "    accuracy                           0.91     18968\n",
      "   macro avg       0.68      0.51      0.50     18968\n",
      "weighted avg       0.87      0.91      0.87     18968\n",
      "\n",
      "Confusion_matrix\n",
      "[[17210    50]\n",
      " [ 1668    40]]\n",
      "done in 35.866678s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2724\n",
      "           1       0.38      0.01      0.02       275\n",
      "\n",
      "    accuracy                           0.91      2999\n",
      "   macro avg       0.64      0.50      0.49      2999\n",
      "weighted avg       0.86      0.91      0.87      2999\n",
      "\n",
      "Confusion_matrix\n",
      "[[2719    5]\n",
      " [ 272    3]]\n",
      "done in 36.042764s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2674\n",
      "           1       0.50      0.03      0.05       256\n",
      "\n",
      "    accuracy                           0.91      2930\n",
      "   macro avg       0.71      0.51      0.50      2930\n",
      "weighted avg       0.88      0.91      0.88      2930\n",
      "\n",
      "Confusion_matrix\n",
      "[[2667    7]\n",
      " [ 249    7]]\n",
      "done in 36.082862s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41100000000000003\n",
      "threshold:0.2, J-value:0.26399999999999996\n",
      "threshold:0.30000000000000004, J-value:0.154\n",
      "threshold:0.4, J-value:0.07100000000000001\n",
      "threshold:0.5, J-value:0.030000000000000002\n",
      "threshold:0.6000000000000001, J-value:0.011\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7054833108650711\n",
      "Balanced accuracy score of test is  0.6986732387959697\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.404\n",
      "threshold:0.2, J-value:0.258\n",
      "threshold:0.30000000000000004, J-value:0.153\n",
      "threshold:0.4, J-value:0.069\n",
      "threshold:0.5, J-value:0.029\n",
      "threshold:0.6000000000000001, J-value:0.011\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7022796133875924\n",
      "Balanced accuracy score of test is  0.6992264607151677\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.45100000000000007\n",
      "threshold:0.2, J-value:0.299\n",
      "threshold:0.30000000000000004, J-value:0.155\n",
      "threshold:0.4, J-value:0.077\n",
      "threshold:0.5, J-value:0.034\n",
      "threshold:0.6000000000000001, J-value:0.009999999999999998\n",
      "threshold:0.7000000000000001, J-value:-0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7256114003470832\n",
      "Balanced accuracy score of test is  0.6946785013089005\n",
      "True positive rate of class 1 is  0.663\n",
      "True positive rate of class 2 is  0.633\n",
      "Positive prediction rate of class 1 is  0.3\n",
      "Positive prediction rate of class 2 is  0.277\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.4\n",
      "threshold:0.2, J-value:0.28900000000000003\n",
      "threshold:0.30000000000000004, J-value:0.10600000000000001\n",
      "threshold:0.4, J-value:0.026\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7001874796414969\n",
      "Balanced accuracy score of test is  0.6853257296941414\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.39699999999999996\n",
      "threshold:0.2, J-value:0.275\n",
      "threshold:0.30000000000000004, J-value:0.10700000000000001\n",
      "threshold:0.4, J-value:0.028\n",
      "threshold:0.5, J-value:0.005\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6982421521839388\n",
      "Balanced accuracy score of test is  0.6894750624828698\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.44700000000000006\n",
      "threshold:0.2, J-value:0.313\n",
      "threshold:0.30000000000000004, J-value:0.11000000000000001\n",
      "threshold:0.4, J-value:0.018\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.72375383793886\n",
      "Balanced accuracy score of test is  0.6776248130142108\n",
      "True positive rate of class 1 is  0.726\n",
      "True positive rate of class 2 is  0.719\n",
      "Positive prediction rate of class 1 is  0.381\n",
      "Positive prediction rate of class 2 is  0.395\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.37899999999999995\n",
      "threshold:0.2, J-value:0.21299999999999997\n",
      "threshold:0.30000000000000004, J-value:0.08499999999999999\n",
      "threshold:0.4, J-value:0.028999999999999998\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.689387268517772\n",
      "Balanced accuracy score of test is  0.6746810298833401\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.374\n",
      "threshold:0.2, J-value:0.20599999999999996\n",
      "threshold:0.30000000000000004, J-value:0.088\n",
      "threshold:0.4, J-value:0.032\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6866057878087878\n",
      "Balanced accuracy score of test is  0.6737388093926475\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.4149999999999999\n",
      "threshold:0.2, J-value:0.263\n",
      "threshold:0.30000000000000004, J-value:0.063\n",
      "threshold:0.4, J-value:0.015\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7070377786677347\n",
      "Balanced accuracy score of test is  0.6798861724008975\n",
      "True positive rate of class 1 is  0.703\n",
      "True positive rate of class 2 is  0.641\n",
      "Positive prediction rate of class 1 is  0.386\n",
      "Positive prediction rate of class 2 is  0.312\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.42899999999999994\n",
      "threshold:0.2, J-value:0.27799999999999997\n",
      "threshold:0.30000000000000004, J-value:0.143\n",
      "threshold:0.4, J-value:0.060000000000000005\n",
      "threshold:0.5, J-value:0.015000000000000001\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7141743004334546\n",
      "Balanced accuracy score of test is  0.6986843498003696\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.42299999999999993\n",
      "threshold:0.2, J-value:0.26999999999999996\n",
      "threshold:0.30000000000000004, J-value:0.14\n",
      "threshold:0.4, J-value:0.056\n",
      "threshold:0.5, J-value:0.016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7110900495116892\n",
      "Balanced accuracy score of test is  0.6999248305974746\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.46699999999999997\n",
      "threshold:0.2, J-value:0.32699999999999996\n",
      "threshold:0.30000000000000004, J-value:0.165\n",
      "threshold:0.4, J-value:0.085\n",
      "threshold:0.5, J-value:0.009\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7335142170604725\n",
      "Balanced accuracy score of test is  0.6902536579094989\n",
      "True positive rate of class 1 is  0.674\n",
      "True positive rate of class 2 is  0.645\n",
      "Positive prediction rate of class 1 is  0.311\n",
      "Positive prediction rate of class 2 is  0.297\n",
      "X train 65694\n",
      "Y train 65694\n",
      "21898 18825 3073\n",
      "21898 18825 3073\n",
      "21898 18883 3015\n",
      "21898 18883 3015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26215139120322445\n",
      "0.2559736159575194\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.95     19980\n",
      "           1       0.48      0.04      0.07      1918\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.70      0.52      0.51     21898\n",
      "weighted avg       0.88      0.91      0.88     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19899    81]\n",
      " [ 1842    76]]\n",
      "done in 1.246605s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26215139120322445\n",
      "0.25789795973082535\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19972\n",
      "           1       0.44      0.04      0.07      1926\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.52      0.51     21898\n",
      "weighted avg       0.87      0.91      0.88     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19884    88]\n",
      " [ 1858    68]]\n",
      "done in 1.308818s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26215139120322445\n",
      "0.25548109580288664\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.95     17178\n",
      "           1       0.47      0.04      0.07      1647\n",
      "\n",
      "    accuracy                           0.91     18825\n",
      "   macro avg       0.69      0.52      0.51     18825\n",
      "weighted avg       0.88      0.91      0.88     18825\n",
      "\n",
      "Confusion_matrix\n",
      "[[17109    69]\n",
      " [ 1587    60]]\n",
      "done in 1.148488s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26215139120322445\n",
      "0.26075571606831777\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17196\n",
      "           1       0.44      0.04      0.07      1687\n",
      "\n",
      "    accuracy                           0.91     18883\n",
      "   macro avg       0.68      0.52      0.51     18883\n",
      "weighted avg       0.87      0.91      0.87     18883\n",
      "\n",
      "Confusion_matrix\n",
      "[[17120    76]\n",
      " [ 1627    60]]\n",
      "done in 1.517511s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26215139120322445\n",
      "0.2589907626906667\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.95      2802\n",
      "           1       0.57      0.06      0.11       271\n",
      "\n",
      "    accuracy                           0.91      3073\n",
      "   macro avg       0.74      0.53      0.53      3073\n",
      "weighted avg       0.89      0.91      0.88      3073\n",
      "\n",
      "Confusion_matrix\n",
      "[[2790   12]\n",
      " [ 255   16]]\n",
      "done in 1.377695s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26215139120322445\n",
      "0.23999977965756908\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2776\n",
      "           1       0.40      0.03      0.06       239\n",
      "\n",
      "    accuracy                           0.92      3015\n",
      "   macro avg       0.66      0.51      0.51      3015\n",
      "weighted avg       0.88      0.92      0.89      3015\n",
      "\n",
      "Confusion_matrix\n",
      "[[2764   12]\n",
      " [ 231    8]]\n",
      "done in 1.415235s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19980\n",
      "           1       1.00      0.00      0.00      1918\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.96      0.50      0.48     21898\n",
      "weighted avg       0.92      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19980     0]\n",
      " [ 1915     3]]\n",
      "done in 21.785093s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19972\n",
      "           1       0.67      0.00      0.00      1926\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.79      0.50      0.48     21898\n",
      "weighted avg       0.89      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19970     2]\n",
      " [ 1922     4]]\n",
      "done in 22.157282s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17178\n",
      "           1       0.67      0.00      0.00      1647\n",
      "\n",
      "    accuracy                           0.91     18825\n",
      "   macro avg       0.79      0.50      0.48     18825\n",
      "weighted avg       0.89      0.91      0.87     18825\n",
      "\n",
      "Confusion_matrix\n",
      "[[17177     1]\n",
      " [ 1645     2]]\n",
      "done in 22.134073s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17196\n",
      "           1       0.50      0.00      0.01      1687\n",
      "\n",
      "    accuracy                           0.91     18883\n",
      "   macro avg       0.71      0.50      0.48     18883\n",
      "weighted avg       0.87      0.91      0.87     18883\n",
      "\n",
      "Confusion_matrix\n",
      "[[17190     6]\n",
      " [ 1681     6]]\n",
      "done in 22.056040s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2802\n",
      "           1       1.00      0.00      0.01       271\n",
      "\n",
      "    accuracy                           0.91      3073\n",
      "   macro avg       0.96      0.50      0.48      3073\n",
      "weighted avg       0.92      0.91      0.87      3073\n",
      "\n",
      "Confusion_matrix\n",
      "[[2802    0]\n",
      " [ 270    1]]\n",
      "done in 21.699898s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2776\n",
      "           1       0.00      0.00      0.00       239\n",
      "\n",
      "    accuracy                           0.92      3015\n",
      "   macro avg       0.46      0.50      0.48      3015\n",
      "weighted avg       0.85      0.92      0.88      3015\n",
      "\n",
      "Confusion_matrix\n",
      "[[2775    1]\n",
      " [ 239    0]]\n",
      "done in 21.681359s\n",
      "0.26732574897465733\n",
      "0.2685985620764942\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19980\n",
      "           1       0.40      0.00      0.00      1918\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.66      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19977     3]\n",
      " [ 1916     2]]\n",
      "done in 0.726227s\n",
      "0.26732574897465733\n",
      "0.26671117932484617\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19972\n",
      "           1       0.20      0.00      0.00      1926\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.56      0.50      0.48     21898\n",
      "weighted avg       0.85      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19968     4]\n",
      " [ 1925     1]]\n",
      "done in 0.755981s\n",
      "0.26732574897465733\n",
      "0.2655730048189926\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17178\n",
      "           1       0.67      0.00      0.00      1647\n",
      "\n",
      "    accuracy                           0.91     18825\n",
      "   macro avg       0.79      0.50      0.48     18825\n",
      "weighted avg       0.89      0.91      0.87     18825\n",
      "\n",
      "Confusion_matrix\n",
      "[[17177     1]\n",
      " [ 1645     2]]\n",
      "done in 0.678234s\n",
      "0.26732574897465733\n",
      "0.2708907402588465\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17196\n",
      "           1       0.25      0.00      0.00      1687\n",
      "\n",
      "    accuracy                           0.91     18883\n",
      "   macro avg       0.58      0.50      0.48     18883\n",
      "weighted avg       0.85      0.91      0.87     18883\n",
      "\n",
      "Confusion_matrix\n",
      "[[17193     3]\n",
      " [ 1686     1]]\n",
      "done in 0.694168s\n",
      "0.26732574897465733\n",
      "0.28713293089278685\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2802\n",
      "           1       0.00      0.00      0.00       271\n",
      "\n",
      "    accuracy                           0.91      3073\n",
      "   macro avg       0.46      0.50      0.48      3073\n",
      "weighted avg       0.83      0.91      0.87      3073\n",
      "\n",
      "Confusion_matrix\n",
      "[[2800    2]\n",
      " [ 271    0]]\n",
      "done in 0.678280s\n",
      "0.26732574897465733\n",
      "0.24053451295113856\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2776\n",
      "           1       0.00      0.00      0.00       239\n",
      "\n",
      "    accuracy                           0.92      3015\n",
      "   macro avg       0.46      0.50      0.48      3015\n",
      "weighted avg       0.85      0.92      0.88      3015\n",
      "\n",
      "Confusion_matrix\n",
      "[[2775    1]\n",
      " [ 239    0]]\n",
      "done in 0.690316s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19980\n",
      "           1       0.44      0.02      0.04      1918\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.51      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19935    45]\n",
      " [ 1882    36]]\n",
      "done in 35.892553s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19972\n",
      "           1       0.45      0.02      0.04      1926\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19922    50]\n",
      " [ 1885    41]]\n",
      "done in 35.839452s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17178\n",
      "           1       0.47      0.02      0.04      1647\n",
      "\n",
      "    accuracy                           0.91     18825\n",
      "   macro avg       0.69      0.51      0.50     18825\n",
      "weighted avg       0.87      0.91      0.87     18825\n",
      "\n",
      "Confusion_matrix\n",
      "[[17143    35]\n",
      " [ 1616    31]]\n",
      "done in 35.807273s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17196\n",
      "           1       0.44      0.02      0.04      1687\n",
      "\n",
      "    accuracy                           0.91     18883\n",
      "   macro avg       0.68      0.51      0.50     18883\n",
      "weighted avg       0.87      0.91      0.87     18883\n",
      "\n",
      "Confusion_matrix\n",
      "[[17153    43]\n",
      " [ 1653    34]]\n",
      "done in 36.050992s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2802\n",
      "           1       0.36      0.02      0.04       271\n",
      "\n",
      "    accuracy                           0.91      3073\n",
      "   macro avg       0.64      0.51      0.49      3073\n",
      "weighted avg       0.86      0.91      0.87      3073\n",
      "\n",
      "Confusion_matrix\n",
      "[[2793    9]\n",
      " [ 266    5]]\n",
      "done in 35.984718s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2776\n",
      "           1       0.47      0.03      0.06       239\n",
      "\n",
      "    accuracy                           0.92      3015\n",
      "   macro avg       0.69      0.51      0.51      3015\n",
      "weighted avg       0.89      0.92      0.89      3015\n",
      "\n",
      "Confusion_matrix\n",
      "[[2768    8]\n",
      " [ 232    7]]\n",
      "done in 36.093003s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.2, J-value:0.27599999999999997\n",
      "threshold:0.30000000000000004, J-value:0.155\n",
      "threshold:0.4, J-value:0.07\n",
      "threshold:0.5, J-value:0.036000000000000004\n",
      "threshold:0.6000000000000001, J-value:0.012\n",
      "threshold:0.7000000000000001, J-value:0.004\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7021389481243496\n",
      "Balanced accuracy score of test is  0.6985516223231736\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.406\n",
      "threshold:0.2, J-value:0.27999999999999997\n",
      "threshold:0.30000000000000004, J-value:0.154\n",
      "threshold:0.4, J-value:0.066\n",
      "threshold:0.5, J-value:0.032\n",
      "threshold:0.6000000000000001, J-value:0.011\n",
      "threshold:0.7000000000000001, J-value:0.003\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7031298345980297\n",
      "Balanced accuracy score of test is  0.7005543534269214\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.392\n",
      "threshold:0.2, J-value:0.246\n",
      "threshold:0.30000000000000004, J-value:0.16\n",
      "threshold:0.4, J-value:0.099\n",
      "threshold:0.5, J-value:0.05499999999999999\n",
      "threshold:0.6000000000000001, J-value:0.019999999999999997\n",
      "threshold:0.7000000000000001, J-value:0.006\n",
      "threshold:0.8, J-value:-0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6962370051966045\n",
      "Balanced accuracy score of test is  0.682116135916945\n",
      "True positive rate of class 1 is  0.661\n",
      "True positive rate of class 2 is  0.586\n",
      "Positive prediction rate of class 1 is  0.296\n",
      "Positive prediction rate of class 2 is  0.25\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.389\n",
      "threshold:0.2, J-value:0.308\n",
      "threshold:0.30000000000000004, J-value:0.11500000000000002\n",
      "threshold:0.4, J-value:0.023\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6943534514702399\n",
      "Balanced accuracy score of test is  0.6965857600432922\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.391\n",
      "threshold:0.2, J-value:0.28300000000000003\n",
      "threshold:0.30000000000000004, J-value:0.122\n",
      "threshold:0.4, J-value:0.017\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6953165409816979\n",
      "Balanced accuracy score of test is  0.6930881659662791\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41600000000000004\n",
      "threshold:0.2, J-value:0.318\n",
      "threshold:0.30000000000000004, J-value:0.097\n",
      "threshold:0.4, J-value:0.018\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7076429329603788\n",
      "Balanced accuracy score of test is  0.7037970409848914\n",
      "True positive rate of class 1 is  0.729\n",
      "True positive rate of class 2 is  0.745\n",
      "Positive prediction rate of class 1 is  0.377\n",
      "Positive prediction rate of class 2 is  0.369\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.35300000000000004\n",
      "threshold:0.2, J-value:0.21199999999999997\n",
      "threshold:0.30000000000000004, J-value:0.10800000000000001\n",
      "threshold:0.4, J-value:0.001\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.001\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6761341894553574\n",
      "Balanced accuracy score of test is  0.6841409489380668\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.3430000000000001\n",
      "threshold:0.2, J-value:0.21799999999999997\n",
      "threshold:0.30000000000000004, J-value:0.11599999999999999\n",
      "threshold:0.4, J-value:0.001\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.001\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6716618833637552\n",
      "Balanced accuracy score of test is  0.6788795673936385\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.40700000000000003\n",
      "threshold:0.2, J-value:0.174\n",
      "threshold:0.30000000000000004, J-value:0.06999999999999999\n",
      "threshold:0.4, J-value:-0.001\n",
      "threshold:0.5, J-value:-0.001\n",
      "threshold:0.6000000000000001, J-value:-0.001\n",
      "threshold:0.7000000000000001, J-value:-0.001\n",
      "threshold:0.8, J-value:-0.001\n",
      "threshold:0.9, J-value:-0.001\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7035696695296717\n",
      "Balanced accuracy score of test is  0.716918325636357\n",
      "True positive rate of class 1 is  0.699\n",
      "True positive rate of class 2 is  0.703\n",
      "Positive prediction rate of class 1 is  0.374\n",
      "Positive prediction rate of class 2 is  0.303\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41899999999999993\n",
      "threshold:0.2, J-value:0.27599999999999997\n",
      "threshold:0.30000000000000004, J-value:0.151\n",
      "threshold:0.4, J-value:0.058\n",
      "threshold:0.5, J-value:0.017\n",
      "threshold:0.6000000000000001, J-value:0.006\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7097472081048724\n",
      "Balanced accuracy score of test is  0.7026313994316862\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.417\n",
      "threshold:0.2, J-value:0.28\n",
      "threshold:0.30000000000000004, J-value:0.153\n",
      "threshold:0.4, J-value:0.059000000000000004\n",
      "threshold:0.5, J-value:0.017\n",
      "threshold:0.6000000000000001, J-value:0.007\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7084871126516081\n",
      "Balanced accuracy score of test is  0.7020997701041019\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.43499999999999994\n",
      "threshold:0.2, J-value:0.25\n",
      "threshold:0.30000000000000004, J-value:0.139\n",
      "threshold:0.4, J-value:0.061000000000000006\n",
      "threshold:0.5, J-value:0.015\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.717313147435543\n",
      "Balanced accuracy score of test is  0.7045325744878396\n",
      "True positive rate of class 1 is  0.683\n",
      "True positive rate of class 2 is  0.657\n",
      "Positive prediction rate of class 1 is  0.315\n",
      "Positive prediction rate of class 2 is  0.28\n",
      "X train 65694\n",
      "Y train 65694\n",
      "21898 18936 2962\n",
      "21898 18936 2962\n",
      "21898 18829 3069\n",
      "21898 18829 3069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2595091489403858\n",
      "0.26037470726594736\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19950\n",
      "           1       0.44      0.03      0.06      1948\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.51      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19871    79]\n",
      " [ 1885    63]]\n",
      "done in 1.434885s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2595091489403858\n",
      "0.2625560786274971\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19883\n",
      "           1       0.50      0.03      0.05      2015\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.70      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19824    59]\n",
      " [ 1957    58]]\n",
      "done in 1.372619s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2595091489403858\n",
      "0.26314207108401255\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17239\n",
      "           1       0.41      0.03      0.05      1697\n",
      "\n",
      "    accuracy                           0.91     18936\n",
      "   macro avg       0.66      0.51      0.50     18936\n",
      "weighted avg       0.87      0.91      0.87     18936\n",
      "\n",
      "Confusion_matrix\n",
      "[[17172    67]\n",
      " [ 1650    47]]\n",
      "done in 1.827384s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2595091489403858\n",
      "0.2634339117791125\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17079\n",
      "           1       0.52      0.03      0.05      1750\n",
      "\n",
      "    accuracy                           0.91     18829\n",
      "   macro avg       0.71      0.51      0.50     18829\n",
      "weighted avg       0.87      0.91      0.87     18829\n",
      "\n",
      "Confusion_matrix\n",
      "[[17037    42]\n",
      " [ 1705    45]]\n",
      "done in 1.650912s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2595091489403858\n",
      "0.24268301204012596\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2711\n",
      "           1       0.57      0.06      0.11       251\n",
      "\n",
      "    accuracy                           0.92      2962\n",
      "   macro avg       0.75      0.53      0.54      2962\n",
      "weighted avg       0.89      0.92      0.88      2962\n",
      "\n",
      "Confusion_matrix\n",
      "[[2699   12]\n",
      " [ 235   16]]\n",
      "done in 1.522108s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2595091489403858\n",
      "0.25717037631020556\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95      2804\n",
      "           1       0.43      0.05      0.09       265\n",
      "\n",
      "    accuracy                           0.91      3069\n",
      "   macro avg       0.68      0.52      0.52      3069\n",
      "weighted avg       0.88      0.91      0.88      3069\n",
      "\n",
      "Confusion_matrix\n",
      "[[2787   17]\n",
      " [ 252   13]]\n",
      "done in 1.462186s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19950\n",
      "           1       0.29      0.00      0.00      1948\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.60      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19940    10]\n",
      " [ 1944     4]]\n",
      "done in 20.110685s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19883\n",
      "           1       0.43      0.00      0.00      2015\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.86     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19879     4]\n",
      " [ 2012     3]]\n",
      "done in 20.303249s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17239\n",
      "           1       0.40      0.00      0.01      1697\n",
      "\n",
      "    accuracy                           0.91     18936\n",
      "   macro avg       0.66      0.50      0.48     18936\n",
      "weighted avg       0.86      0.91      0.87     18936\n",
      "\n",
      "Confusion_matrix\n",
      "[[17227    12]\n",
      " [ 1689     8]]\n",
      "done in 19.598401s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17079\n",
      "           1       0.33      0.00      0.00      1750\n",
      "\n",
      "    accuracy                           0.91     18829\n",
      "   macro avg       0.62      0.50      0.48     18829\n",
      "weighted avg       0.85      0.91      0.86     18829\n",
      "\n",
      "Confusion_matrix\n",
      "[[17075     4]\n",
      " [ 1748     2]]\n",
      "done in 19.696314s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2711\n",
      "           1       0.50      0.00      0.01       251\n",
      "\n",
      "    accuracy                           0.92      2962\n",
      "   macro avg       0.71      0.50      0.48      2962\n",
      "weighted avg       0.88      0.92      0.88      2962\n",
      "\n",
      "Confusion_matrix\n",
      "[[2710    1]\n",
      " [ 250    1]]\n",
      "done in 19.530268s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2804\n",
      "           1       0.00      0.00      0.00       265\n",
      "\n",
      "    accuracy                           0.91      3069\n",
      "   macro avg       0.46      0.50      0.48      3069\n",
      "weighted avg       0.83      0.91      0.87      3069\n",
      "\n",
      "Confusion_matrix\n",
      "[[2803    1]\n",
      " [ 265    0]]\n",
      "done in 18.924962s\n",
      "0.264372916262498\n",
      "0.26860351065894233\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19950\n",
      "           1       0.00      0.00      0.00      1948\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.46      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19950     0]\n",
      " [ 1948     0]]\n",
      "done in 0.639099s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.264372916262498\n",
      "0.2794088259193761\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19883\n",
      "           1       0.00      0.00      0.00      2015\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.45      0.50      0.48     21898\n",
      "weighted avg       0.82      0.91      0.86     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19879     4]\n",
      " [ 2015     0]]\n",
      "done in 0.605906s\n",
      "0.264372916262498\n",
      "0.2729337988270996\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17239\n",
      "           1       0.00      0.00      0.00      1697\n",
      "\n",
      "    accuracy                           0.91     18936\n",
      "   macro avg       0.46      0.50      0.48     18936\n",
      "weighted avg       0.83      0.91      0.87     18936\n",
      "\n",
      "Confusion_matrix\n",
      "[[17238     1]\n",
      " [ 1697     0]]\n",
      "done in 0.603317s\n",
      "0.264372916262498\n",
      "0.27474664355551137\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17079\n",
      "           1       0.00      0.00      0.00      1750\n",
      "\n",
      "    accuracy                           0.91     18829\n",
      "   macro avg       0.45      0.50      0.48     18829\n",
      "weighted avg       0.82      0.91      0.86     18829\n",
      "\n",
      "Confusion_matrix\n",
      "[[17079     0]\n",
      " [ 1750     0]]\n",
      "done in 0.623608s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.264372916262498\n",
      "0.2525807016254122\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2711\n",
      "           1       0.00      0.00      0.00       251\n",
      "\n",
      "    accuracy                           0.92      2962\n",
      "   macro avg       0.46      0.50      0.48      2962\n",
      "weighted avg       0.84      0.92      0.87      2962\n",
      "\n",
      "Confusion_matrix\n",
      "[[2711    0]\n",
      " [ 251    0]]\n",
      "done in 0.609747s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.264372916262498\n",
      "0.296758273731138\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2804\n",
      "           1       0.00      0.00      0.00       265\n",
      "\n",
      "    accuracy                           0.91      3069\n",
      "   macro avg       0.46      0.50      0.48      3069\n",
      "weighted avg       0.83      0.91      0.87      3069\n",
      "\n",
      "Confusion_matrix\n",
      "[[2801    3]\n",
      " [ 265    0]]\n",
      "done in 0.599595s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19950\n",
      "           1       0.44      0.02      0.03      1948\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19905    45]\n",
      " [ 1913    35]]\n",
      "done in 33.233627s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19883\n",
      "           1       0.42      0.02      0.03      2015\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.49     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19841    42]\n",
      " [ 1984    31]]\n",
      "done in 33.437274s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17239\n",
      "           1       0.41      0.02      0.03      1697\n",
      "\n",
      "    accuracy                           0.91     18936\n",
      "   macro avg       0.66      0.51      0.49     18936\n",
      "weighted avg       0.87      0.91      0.87     18936\n",
      "\n",
      "Confusion_matrix\n",
      "[[17202    37]\n",
      " [ 1671    26]]\n",
      "done in 33.449011s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17079\n",
      "           1       0.46      0.01      0.03      1750\n",
      "\n",
      "    accuracy                           0.91     18829\n",
      "   macro avg       0.68      0.51      0.49     18829\n",
      "weighted avg       0.87      0.91      0.87     18829\n",
      "\n",
      "Confusion_matrix\n",
      "[[17051    28]\n",
      " [ 1726    24]]\n",
      "done in 33.218872s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2711\n",
      "           1       0.56      0.04      0.07       251\n",
      "\n",
      "    accuracy                           0.92      2962\n",
      "   macro avg       0.74      0.52      0.51      2962\n",
      "weighted avg       0.89      0.92      0.88      2962\n",
      "\n",
      "Confusion_matrix\n",
      "[[2704    7]\n",
      " [ 242    9]]\n",
      "done in 33.286133s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.95      2804\n",
      "           1       0.33      0.03      0.05       265\n",
      "\n",
      "    accuracy                           0.91      3069\n",
      "   macro avg       0.62      0.51      0.50      3069\n",
      "weighted avg       0.87      0.91      0.88      3069\n",
      "\n",
      "Confusion_matrix\n",
      "[[2790   14]\n",
      " [ 258    7]]\n",
      "done in 33.154412s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.397\n",
      "threshold:0.2, J-value:0.254\n",
      "threshold:0.30000000000000004, J-value:0.14100000000000001\n",
      "threshold:0.4, J-value:0.07100000000000001\n",
      "threshold:0.5, J-value:0.028\n",
      "threshold:0.6000000000000001, J-value:0.009000000000000001\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6987633611750115\n",
      "Balanced accuracy score of test is  0.7065258436793205\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.388\n",
      "threshold:0.2, J-value:0.247\n",
      "threshold:0.30000000000000004, J-value:0.138\n",
      "threshold:0.4, J-value:0.066\n",
      "threshold:0.5, J-value:0.024\n",
      "threshold:0.6000000000000001, J-value:0.008\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6938977903051977\n",
      "Balanced accuracy score of test is  0.7105172266693434\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.4610000000000001\n",
      "threshold:0.2, J-value:0.306\n",
      "threshold:0.30000000000000004, J-value:0.16\n",
      "threshold:0.4, J-value:0.1\n",
      "threshold:0.5, J-value:0.06\n",
      "threshold:0.6000000000000001, J-value:0.009000000000000001\n",
      "threshold:0.7000000000000001, J-value:0.004\n",
      "threshold:0.8, J-value:0.004\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7306781725918163\n",
      "Balanced accuracy score of test is  0.6800218017387559\n",
      "True positive rate of class 1 is  0.673\n",
      "True positive rate of class 2 is  0.608\n",
      "Positive prediction rate of class 1 is  0.291\n",
      "Positive prediction rate of class 2 is  0.279\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.391\n",
      "threshold:0.2, J-value:0.279\n",
      "threshold:0.30000000000000004, J-value:0.10700000000000001\n",
      "threshold:0.4, J-value:0.024\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6954572519594675\n",
      "Balanced accuracy score of test is  0.6956838947046176\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.37699999999999995\n",
      "threshold:0.2, J-value:0.276\n",
      "threshold:0.30000000000000004, J-value:0.091\n",
      "threshold:0.4, J-value:0.024\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6885174709207101\n",
      "Balanced accuracy score of test is  0.6974618955609646\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.457\n",
      "threshold:0.2, J-value:0.316\n",
      "threshold:0.30000000000000004, J-value:0.125\n",
      "threshold:0.4, J-value:0.028\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7283584217170418\n",
      "Balanced accuracy score of test is  0.7031551960810702\n",
      "True positive rate of class 1 is  0.737\n",
      "True positive rate of class 2 is  0.781\n",
      "Positive prediction rate of class 1 is  0.378\n",
      "Positive prediction rate of class 2 is  0.41\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.36000000000000004\n",
      "threshold:0.2, J-value:0.226\n",
      "threshold:0.30000000000000004, J-value:0.10600000000000001\n",
      "threshold:0.4, J-value:0.003\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6797208370000978\n",
      "Balanced accuracy score of test is  0.6855804346244389\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.35200000000000004\n",
      "threshold:0.2, J-value:0.222\n",
      "threshold:0.30000000000000004, J-value:0.11100000000000002\n",
      "threshold:0.4, J-value:0.003\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6755665257645271\n",
      "Balanced accuracy score of test is  0.6859463334253427\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41000000000000003\n",
      "threshold:0.2, J-value:0.253\n",
      "threshold:0.30000000000000004, J-value:0.07600000000000001\n",
      "threshold:0.4, J-value:0.0\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7052248402186165\n",
      "Balanced accuracy score of test is  0.680913385190967\n",
      "True positive rate of class 1 is  0.685\n",
      "True positive rate of class 2 is  0.608\n",
      "Positive prediction rate of class 1 is  0.348\n",
      "Positive prediction rate of class 2 is  0.277\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.4149999999999999\n",
      "threshold:0.2, J-value:0.26\n",
      "threshold:0.30000000000000004, J-value:0.138\n",
      "threshold:0.4, J-value:0.053\n",
      "threshold:0.5, J-value:0.016\n",
      "threshold:0.6000000000000001, J-value:0.005\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7072499009330308\n",
      "Balanced accuracy score of test is  0.7106360671466541\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.401\n",
      "threshold:0.2, J-value:0.255\n",
      "threshold:0.30000000000000004, J-value:0.135\n",
      "threshold:0.4, J-value:0.05\n",
      "threshold:0.5, J-value:0.013\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7004537203623789\n",
      "Balanced accuracy score of test is  0.7135740466571312\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.504\n",
      "threshold:0.2, J-value:0.291\n",
      "threshold:0.30000000000000004, J-value:0.159\n",
      "threshold:0.4, J-value:0.07200000000000001\n",
      "threshold:0.5, J-value:0.032999999999999995\n",
      "threshold:0.6000000000000001, J-value:0.02\n",
      "threshold:0.7000000000000001, J-value:0.004\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7522223904088552\n",
      "Balanced accuracy score of test is  0.6913546685328238\n",
      "True positive rate of class 1 is  0.698\n",
      "True positive rate of class 2 is  0.657\n",
      "Positive prediction rate of class 1 is  0.31\n",
      "Positive prediction rate of class 2 is  0.307\n",
      "X train 65694\n",
      "Y train 65694\n",
      "21898 18932 2966\n",
      "21898 18932 2966\n",
      "21898 18882 3016\n",
      "21898 18882 3016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25892930913047413\n",
      "0.26313429063096405\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19908\n",
      "           1       0.46      0.04      0.07      1990\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.69      0.52      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19819    89]\n",
      " [ 1913    77]]\n",
      "done in 0.912884s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25892930913047413\n",
      "0.2609482804053149\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19918\n",
      "           1       0.43      0.03      0.06      1980\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.52      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19825    93]\n",
      " [ 1911    69]]\n",
      "done in 0.917428s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25892930913047413\n",
      "0.26327010097441067\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17204\n",
      "           1       0.48      0.04      0.07      1728\n",
      "\n",
      "    accuracy                           0.91     18932\n",
      "   macro avg       0.70      0.52      0.51     18932\n",
      "weighted avg       0.87      0.91      0.87     18932\n",
      "\n",
      "Confusion_matrix\n",
      "[[17135    69]\n",
      " [ 1664    64]]\n",
      "done in 0.865002s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25892930913047413\n",
      "0.26328324901406003\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17156\n",
      "           1       0.40      0.03      0.06      1726\n",
      "\n",
      "    accuracy                           0.91     18882\n",
      "   macro avg       0.65      0.51      0.50     18882\n",
      "weighted avg       0.86      0.91      0.87     18882\n",
      "\n",
      "Confusion_matrix\n",
      "[[17079    77]\n",
      " [ 1675    51]]\n",
      "done in 1.096779s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25892930913047413\n",
      "0.2622674122013851\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95      2704\n",
      "           1       0.39      0.05      0.09       262\n",
      "\n",
      "    accuracy                           0.91      2966\n",
      "   macro avg       0.65      0.52      0.52      2966\n",
      "weighted avg       0.87      0.91      0.88      2966\n",
      "\n",
      "Confusion_matrix\n",
      "[[2684   20]\n",
      " [ 249   13]]\n",
      "done in 0.956058s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25892930913047413\n",
      "0.24632995239791214\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96      2762\n",
      "           1       0.53      0.07      0.12       254\n",
      "\n",
      "    accuracy                           0.92      3016\n",
      "   macro avg       0.73      0.53      0.54      3016\n",
      "weighted avg       0.89      0.92      0.89      3016\n",
      "\n",
      "Confusion_matrix\n",
      "[[2746   16]\n",
      " [ 236   18]]\n",
      "done in 0.979640s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19908\n",
      "           1       0.45      0.00      0.00      1990\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19902     6]\n",
      " [ 1985     5]]\n",
      "done in 19.987780s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19918\n",
      "           1       0.43      0.00      0.00      1980\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19914     4]\n",
      " [ 1977     3]]\n",
      "done in 19.831301s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17204\n",
      "           1       0.38      0.00      0.00      1728\n",
      "\n",
      "    accuracy                           0.91     18932\n",
      "   macro avg       0.64      0.50      0.48     18932\n",
      "weighted avg       0.86      0.91      0.87     18932\n",
      "\n",
      "Confusion_matrix\n",
      "[[17199     5]\n",
      " [ 1725     3]]\n",
      "done in 19.656294s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17156\n",
      "           1       0.50      0.00      0.00      1726\n",
      "\n",
      "    accuracy                           0.91     18882\n",
      "   macro avg       0.70      0.50      0.48     18882\n",
      "weighted avg       0.87      0.91      0.87     18882\n",
      "\n",
      "Confusion_matrix\n",
      "[[17153     3]\n",
      " [ 1723     3]]\n",
      "done in 19.815636s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2704\n",
      "           1       0.00      0.00      0.00       262\n",
      "\n",
      "    accuracy                           0.91      2966\n",
      "   macro avg       0.46      0.50      0.48      2966\n",
      "weighted avg       0.83      0.91      0.87      2966\n",
      "\n",
      "Confusion_matrix\n",
      "[[2704    0]\n",
      " [ 262    0]]\n",
      "done in 19.629095s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2762\n",
      "           1       0.00      0.00      0.00       254\n",
      "\n",
      "    accuracy                           0.92      3016\n",
      "   macro avg       0.46      0.50      0.48      3016\n",
      "weighted avg       0.84      0.92      0.88      3016\n",
      "\n",
      "Confusion_matrix\n",
      "[[2762    0]\n",
      " [ 254    0]]\n",
      "done in 19.408689s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26428564201629917\n",
      "0.2712285449549372\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19908\n",
      "           1       0.00      0.00      0.00      1990\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.45      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19905     3]\n",
      " [ 1990     0]]\n",
      "done in 0.653973s\n",
      "0.26428564201629917\n",
      "0.27044922960654555\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19918\n",
      "           1       0.00      0.00      0.00      1980\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.45      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19915     3]\n",
      " [ 1980     0]]\n",
      "done in 0.650796s\n",
      "0.26428564201629917\n",
      "0.2718989637650279\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17204\n",
      "           1       0.00      0.00      0.00      1728\n",
      "\n",
      "    accuracy                           0.91     18932\n",
      "   macro avg       0.45      0.50      0.48     18932\n",
      "weighted avg       0.83      0.91      0.87     18932\n",
      "\n",
      "Confusion_matrix\n",
      "[[17201     3]\n",
      " [ 1728     0]]\n",
      "done in 0.633467s\n",
      "0.26428564201629917\n",
      "0.27233511337440713\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17156\n",
      "           1       0.00      0.00      0.00      1726\n",
      "\n",
      "    accuracy                           0.91     18882\n",
      "   macro avg       0.45      0.50      0.48     18882\n",
      "weighted avg       0.83      0.91      0.87     18882\n",
      "\n",
      "Confusion_matrix\n",
      "[[17155     1]\n",
      " [ 1726     0]]\n",
      "done in 0.641370s\n",
      "0.26428564201629917\n",
      "0.2667215164112277\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2704\n",
      "           1       0.00      0.00      0.00       262\n",
      "\n",
      "    accuracy                           0.91      2966\n",
      "   macro avg       0.46      0.50      0.48      2966\n",
      "weighted avg       0.83      0.91      0.87      2966\n",
      "\n",
      "Confusion_matrix\n",
      "[[2704    0]\n",
      " [ 262    0]]\n",
      "done in 0.611777s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26428564201629917\n",
      "0.2588664114511214\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2762\n",
      "           1       0.00      0.00      0.00       254\n",
      "\n",
      "    accuracy                           0.92      3016\n",
      "   macro avg       0.46      0.50      0.48      3016\n",
      "weighted avg       0.84      0.92      0.88      3016\n",
      "\n",
      "Confusion_matrix\n",
      "[[2760    2]\n",
      " [ 254    0]]\n",
      "done in 0.608849s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19908\n",
      "           1       0.44      0.02      0.04      1990\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.51      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19859    49]\n",
      " [ 1951    39]]\n",
      "done in 33.482938s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19918\n",
      "           1       0.37      0.02      0.03      1980\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.64      0.51      0.49     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19861    57]\n",
      " [ 1946    34]]\n",
      "done in 33.360958s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17204\n",
      "           1       0.43      0.02      0.03      1728\n",
      "\n",
      "    accuracy                           0.91     18932\n",
      "   macro avg       0.67      0.51      0.49     18932\n",
      "weighted avg       0.87      0.91      0.87     18932\n",
      "\n",
      "Confusion_matrix\n",
      "[[17166    38]\n",
      " [ 1699    29]]\n",
      "done in 33.403351s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17156\n",
      "           1       0.39      0.02      0.03      1726\n",
      "\n",
      "    accuracy                           0.91     18882\n",
      "   macro avg       0.65      0.51      0.49     18882\n",
      "weighted avg       0.86      0.91      0.87     18882\n",
      "\n",
      "Confusion_matrix\n",
      "[[17110    46]\n",
      " [ 1697    29]]\n",
      "done in 33.099640s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2704\n",
      "           1       0.50      0.04      0.07       262\n",
      "\n",
      "    accuracy                           0.91      2966\n",
      "   macro avg       0.71      0.52      0.51      2966\n",
      "weighted avg       0.88      0.91      0.88      2966\n",
      "\n",
      "Confusion_matrix\n",
      "[[2694   10]\n",
      " [ 252   10]]\n",
      "done in 33.188798s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.95      2762\n",
      "           1       0.27      0.02      0.03       254\n",
      "\n",
      "    accuracy                           0.91      3016\n",
      "   macro avg       0.59      0.51      0.49      3016\n",
      "weighted avg       0.86      0.91      0.88      3016\n",
      "\n",
      "Confusion_matrix\n",
      "[[2751   11]\n",
      " [ 250    4]]\n",
      "done in 33.152433s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.397\n",
      "threshold:0.2, J-value:0.26\n",
      "threshold:0.30000000000000004, J-value:0.157\n",
      "threshold:0.4, J-value:0.077\n",
      "threshold:0.5, J-value:0.035\n",
      "threshold:0.6000000000000001, J-value:0.013999999999999999\n",
      "threshold:0.7000000000000001, J-value:0.004\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6984924118280775\n",
      "Balanced accuracy score of test is  0.7102360841064526\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.398\n",
      "threshold:0.2, J-value:0.258\n",
      "threshold:0.30000000000000004, J-value:0.158\n",
      "threshold:0.4, J-value:0.076\n",
      "threshold:0.5, J-value:0.033\n",
      "threshold:0.6000000000000001, J-value:0.012\n",
      "threshold:0.7000000000000001, J-value:0.003\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6986684701878116\n",
      "Balanced accuracy score of test is  0.7099552278363336\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.394\n",
      "threshold:0.2, J-value:0.273\n",
      "threshold:0.30000000000000004, J-value:0.158\n",
      "threshold:0.4, J-value:0.088\n",
      "threshold:0.5, J-value:0.043000000000000003\n",
      "threshold:0.6000000000000001, J-value:0.022\n",
      "threshold:0.7000000000000001, J-value:0.011\n",
      "threshold:0.8, J-value:0.004\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6972748882063327\n",
      "Balanced accuracy score of test is  0.7108009715657375\n",
      "True positive rate of class 1 is  0.673\n",
      "True positive rate of class 2 is  0.642\n",
      "Positive prediction rate of class 1 is  0.292\n",
      "Positive prediction rate of class 2 is  0.256\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.37999999999999995\n",
      "threshold:0.2, J-value:0.272\n",
      "threshold:0.30000000000000004, J-value:0.11400000000000002\n",
      "threshold:0.4, J-value:0.029\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6897668470946252\n",
      "Balanced accuracy score of test is  0.705549292503304\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.38099999999999995\n",
      "threshold:0.2, J-value:0.27\n",
      "threshold:0.30000000000000004, J-value:0.11500000000000002\n",
      "threshold:0.4, J-value:0.026\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6909800934537188\n",
      "Balanced accuracy score of test is  0.6936972210837662\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.381\n",
      "threshold:0.2, J-value:0.313\n",
      "threshold:0.30000000000000004, J-value:0.10600000000000001\n",
      "threshold:0.4, J-value:0.013\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6907394755860699\n",
      "Balanced accuracy score of test is  0.7104560201155159\n",
      "True positive rate of class 1 is  0.729\n",
      "True positive rate of class 2 is  0.764\n",
      "Positive prediction rate of class 1 is  0.377\n",
      "Positive prediction rate of class 2 is  0.378\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.35500000000000004\n",
      "threshold:0.2, J-value:0.227\n",
      "threshold:0.30000000000000004, J-value:0.101\n",
      "threshold:0.4, J-value:0.003\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6776950353535812\n",
      "Balanced accuracy score of test is  0.6807762330605989\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.35300000000000004\n",
      "threshold:0.2, J-value:0.233\n",
      "threshold:0.30000000000000004, J-value:0.10800000000000001\n",
      "threshold:0.4, J-value:0.003\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6762826205361372\n",
      "Balanced accuracy score of test is  0.6804078151902776\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.374\n",
      "threshold:0.2, J-value:0.18799999999999997\n",
      "threshold:0.30000000000000004, J-value:0.06\n",
      "threshold:0.4, J-value:0.005\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6869198586205338\n",
      "Balanced accuracy score of test is  0.681453015331809\n",
      "True positive rate of class 1 is  0.652\n",
      "True positive rate of class 2 is  0.614\n",
      "Positive prediction rate of class 1 is  0.325\n",
      "Positive prediction rate of class 2 is  0.282\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.397\n",
      "threshold:0.2, J-value:0.27299999999999996\n",
      "threshold:0.30000000000000004, J-value:0.14400000000000002\n",
      "threshold:0.4, J-value:0.059000000000000004\n",
      "threshold:0.5, J-value:0.018000000000000002\n",
      "threshold:0.6000000000000001, J-value:0.005\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6984957437377767\n",
      "Balanced accuracy score of test is  0.70961365842378\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.398\n",
      "threshold:0.2, J-value:0.27399999999999997\n",
      "threshold:0.30000000000000004, J-value:0.14600000000000002\n",
      "threshold:0.4, J-value:0.059000000000000004\n",
      "threshold:0.5, J-value:0.015000000000000001\n",
      "threshold:0.6000000000000001, J-value:0.002\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6988955249425198\n",
      "Balanced accuracy score of test is  0.7075214911518781\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.392\n",
      "threshold:0.2, J-value:0.263\n",
      "threshold:0.30000000000000004, J-value:0.132\n",
      "threshold:0.4, J-value:0.05800000000000001\n",
      "threshold:0.5, J-value:0.034\n",
      "threshold:0.6000000000000001, J-value:0.015\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6961513053886805\n",
      "Balanced accuracy score of test is  0.7224751549430688\n",
      "True positive rate of class 1 is  0.688\n",
      "True positive rate of class 2 is  0.689\n",
      "Positive prediction rate of class 1 is  0.311\n",
      "Positive prediction rate of class 2 is  0.281\n",
      "X train 65694\n",
      "Y train 65694\n",
      "21898 18875 3023\n",
      "21898 18875 3023\n",
      "21898 19009 2889\n",
      "21898 19009 2889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2631517264955017\n",
      "0.25484997974541185\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.95     20006\n",
      "           1       0.39      0.03      0.06      1892\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.65      0.51      0.51     21898\n",
      "weighted avg       0.87      0.91      0.88     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19906   100]\n",
      " [ 1828    64]]\n",
      "done in 0.858252s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2631517264955017\n",
      "0.25647906239900653\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.95     19975\n",
      "           1       0.47      0.04      0.08      1923\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.69      0.52      0.51     21898\n",
      "weighted avg       0.88      0.91      0.88     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19885    90]\n",
      " [ 1844    79]]\n",
      "done in 0.891979s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2631517264955017\n",
      "0.25578922182492775\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.95     17241\n",
      "           1       0.38      0.03      0.05      1634\n",
      "\n",
      "    accuracy                           0.91     18875\n",
      "   macro avg       0.65      0.51      0.50     18875\n",
      "weighted avg       0.87      0.91      0.88     18875\n",
      "\n",
      "Confusion_matrix\n",
      "[[17162    79]\n",
      " [ 1586    48]]\n",
      "done in 0.890070s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2631517264955017\n",
      "0.25996486608496056\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17310\n",
      "           1       0.47      0.04      0.07      1699\n",
      "\n",
      "    accuracy                           0.91     19009\n",
      "   macro avg       0.69      0.52      0.51     19009\n",
      "weighted avg       0.87      0.91      0.87     19009\n",
      "\n",
      "Confusion_matrix\n",
      "[[17243    67]\n",
      " [ 1639    60]]\n",
      "done in 0.992803s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2631517264955017\n",
      "0.24898554234850084\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95      2765\n",
      "           1       0.43      0.06      0.11       258\n",
      "\n",
      "    accuracy                           0.91      3023\n",
      "   macro avg       0.68      0.53      0.53      3023\n",
      "weighted avg       0.88      0.91      0.88      3023\n",
      "\n",
      "Confusion_matrix\n",
      "[[2744   21]\n",
      " [ 242   16]]\n",
      "done in 1.000715s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2631517264955017\n",
      "0.2335432222237556\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      2665\n",
      "           1       0.45      0.08      0.14       224\n",
      "\n",
      "    accuracy                           0.92      2889\n",
      "   macro avg       0.69      0.54      0.55      2889\n",
      "weighted avg       0.89      0.92      0.90      2889\n",
      "\n",
      "Confusion_matrix\n",
      "[[2642   23]\n",
      " [ 205   19]]\n",
      "done in 1.179483s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     20006\n",
      "           1       0.40      0.00      0.00      1892\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.66      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[20000     6]\n",
      " [ 1888     4]]\n",
      "done in 19.435798s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19975\n",
      "           1       0.27      0.00      0.00      1923\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.59      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19964    11]\n",
      " [ 1919     4]]\n",
      "done in 19.874222s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17241\n",
      "           1       0.64      0.00      0.01      1634\n",
      "\n",
      "    accuracy                           0.91     18875\n",
      "   macro avg       0.78      0.50      0.48     18875\n",
      "weighted avg       0.89      0.91      0.87     18875\n",
      "\n",
      "Confusion_matrix\n",
      "[[17237     4]\n",
      " [ 1627     7]]\n",
      "done in 19.568202s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17310\n",
      "           1       0.36      0.00      0.00      1699\n",
      "\n",
      "    accuracy                           0.91     19009\n",
      "   macro avg       0.64      0.50      0.48     19009\n",
      "weighted avg       0.86      0.91      0.87     19009\n",
      "\n",
      "Confusion_matrix\n",
      "[[17303     7]\n",
      " [ 1695     4]]\n",
      "done in 19.474133s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.96      2765\n",
      "           1       0.00      0.00      0.00       258\n",
      "\n",
      "    accuracy                           0.91      3023\n",
      "   macro avg       0.46      0.50      0.48      3023\n",
      "weighted avg       0.84      0.91      0.87      3023\n",
      "\n",
      "Confusion_matrix\n",
      "[[2764    1]\n",
      " [ 258    0]]\n",
      "done in 19.277843s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2665\n",
      "           1       0.67      0.01      0.02       224\n",
      "\n",
      "    accuracy                           0.92      2889\n",
      "   macro avg       0.79      0.50      0.49      2889\n",
      "weighted avg       0.90      0.92      0.89      2889\n",
      "\n",
      "Confusion_matrix\n",
      "[[2664    1]\n",
      " [ 222    2]]\n",
      "done in 19.473706s\n",
      "0.2682128952371694\n",
      "0.2638709963739227\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     20006\n",
      "           1       0.56      0.00      0.01      1892\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.74      0.50      0.48     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19999     7]\n",
      " [ 1883     9]]\n",
      "done in 0.633706s\n",
      "0.2682128952371694\n",
      "0.26619820202997585\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19975\n",
      "           1       0.56      0.00      0.01      1923\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.74      0.50      0.48     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19968     7]\n",
      " [ 1914     9]]\n",
      "done in 0.621883s\n",
      "0.2682128952371694\n",
      "0.26452887711964745\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17241\n",
      "           1       0.50      0.00      0.01      1634\n",
      "\n",
      "    accuracy                           0.91     18875\n",
      "   macro avg       0.71      0.50      0.48     18875\n",
      "weighted avg       0.88      0.91      0.87     18875\n",
      "\n",
      "Confusion_matrix\n",
      "[[17234     7]\n",
      " [ 1627     7]]\n",
      "done in 0.635345s\n",
      "0.2682128952371694\n",
      "0.2686302724769611\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17310\n",
      "           1       0.55      0.00      0.01      1699\n",
      "\n",
      "    accuracy                           0.91     19009\n",
      "   macro avg       0.73      0.50      0.48     19009\n",
      "weighted avg       0.88      0.91      0.87     19009\n",
      "\n",
      "Confusion_matrix\n",
      "[[17305     5]\n",
      " [ 1693     6]]\n",
      "done in 0.632661s\n",
      "0.2682128952371694\n",
      "0.2597633221841926\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2765\n",
      "           1       1.00      0.01      0.02       258\n",
      "\n",
      "    accuracy                           0.92      3023\n",
      "   macro avg       0.96      0.50      0.49      3023\n",
      "weighted avg       0.92      0.92      0.88      3023\n",
      "\n",
      "Confusion_matrix\n",
      "[[2765    0]\n",
      " [ 256    2]]\n",
      "done in 0.607197s\n",
      "0.2682128952371694\n",
      "0.2501957004284727\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2665\n",
      "           1       0.60      0.01      0.03       224\n",
      "\n",
      "    accuracy                           0.92      2889\n",
      "   macro avg       0.76      0.51      0.49      2889\n",
      "weighted avg       0.90      0.92      0.89      2889\n",
      "\n",
      "Confusion_matrix\n",
      "[[2663    2]\n",
      " [ 221    3]]\n",
      "done in 0.666756s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     20006\n",
      "           1       0.36      0.02      0.04      1892\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.64      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19943    63]\n",
      " [ 1856    36]]\n",
      "done in 33.135689s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19975\n",
      "           1       0.47      0.02      0.05      1923\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.69      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19922    53]\n",
      " [ 1876    47]]\n",
      "done in 32.974637s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17241\n",
      "           1       0.36      0.02      0.03      1634\n",
      "\n",
      "    accuracy                           0.91     18875\n",
      "   macro avg       0.64      0.51      0.49     18875\n",
      "weighted avg       0.87      0.91      0.87     18875\n",
      "\n",
      "Confusion_matrix\n",
      "[[17190    51]\n",
      " [ 1605    29]]\n",
      "done in 32.965550s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17310\n",
      "           1       0.50      0.02      0.04      1699\n",
      "\n",
      "    accuracy                           0.91     19009\n",
      "   macro avg       0.71      0.51      0.50     19009\n",
      "weighted avg       0.88      0.91      0.87     19009\n",
      "\n",
      "Confusion_matrix\n",
      "[[17272    38]\n",
      " [ 1661    38]]\n",
      "done in 32.866095s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.95      2765\n",
      "           1       0.39      0.03      0.05       258\n",
      "\n",
      "    accuracy                           0.91      3023\n",
      "   macro avg       0.65      0.51      0.50      3023\n",
      "weighted avg       0.87      0.91      0.88      3023\n",
      "\n",
      "Confusion_matrix\n",
      "[[2754   11]\n",
      " [ 251    7]]\n",
      "done in 33.331760s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96      2665\n",
      "           1       0.39      0.04      0.07       224\n",
      "\n",
      "    accuracy                           0.92      2889\n",
      "   macro avg       0.66      0.52      0.52      2889\n",
      "weighted avg       0.88      0.92      0.89      2889\n",
      "\n",
      "Confusion_matrix\n",
      "[[2651   14]\n",
      " [ 215    9]]\n",
      "done in 33.198834s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.2, J-value:0.262\n",
      "threshold:0.30000000000000004, J-value:0.148\n",
      "threshold:0.4, J-value:0.069\n",
      "threshold:0.5, J-value:0.029\n",
      "threshold:0.6000000000000001, J-value:0.011\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7010668469649379\n",
      "Balanced accuracy score of test is  0.7041008488900258\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.395\n",
      "threshold:0.2, J-value:0.26099999999999995\n",
      "threshold:0.30000000000000004, J-value:0.145\n",
      "threshold:0.4, J-value:0.064\n",
      "threshold:0.5, J-value:0.024\n",
      "threshold:0.6000000000000001, J-value:0.01\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6978414473710832\n",
      "Balanced accuracy score of test is  0.7017047782550581\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.44299999999999995\n",
      "threshold:0.2, J-value:0.274\n",
      "threshold:0.30000000000000004, J-value:0.16799999999999998\n",
      "threshold:0.4, J-value:0.103\n",
      "threshold:0.5, J-value:0.054\n",
      "threshold:0.6000000000000001, J-value:0.016\n",
      "threshold:0.7000000000000001, J-value:0.003\n",
      "threshold:0.8, J-value:-0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7214019372835976\n",
      "Balanced accuracy score of test is  0.7210483114446529\n",
      "True positive rate of class 1 is  0.666\n",
      "True positive rate of class 2 is  0.688\n",
      "Positive prediction rate of class 1 is  0.298\n",
      "Positive prediction rate of class 2 is  0.28\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.399\n",
      "threshold:0.2, J-value:0.29\n",
      "threshold:0.30000000000000004, J-value:0.11699999999999999\n",
      "threshold:0.4, J-value:0.026\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6992129369645765\n",
      "Balanced accuracy score of test is  0.7014149512163215\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.391\n",
      "threshold:0.2, J-value:0.28600000000000003\n",
      "threshold:0.30000000000000004, J-value:0.11000000000000001\n",
      "threshold:0.4, J-value:0.024\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6952772159273918\n",
      "Balanced accuracy score of test is  0.695230534561908\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41900000000000004\n",
      "threshold:0.2, J-value:0.32\n",
      "threshold:0.30000000000000004, J-value:0.12\n",
      "threshold:0.4, J-value:0.034\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7097607132343664\n",
      "Balanced accuracy score of test is  0.7267002814258912\n",
      "True positive rate of class 1 is  0.743\n",
      "True positive rate of class 2 is  0.812\n",
      "Positive prediction rate of class 1 is  0.388\n",
      "Positive prediction rate of class 2 is  0.394\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.35400000000000004\n",
      "threshold:0.2, J-value:0.215\n",
      "threshold:0.30000000000000004, J-value:0.053000000000000005\n",
      "threshold:0.4, J-value:0.049999999999999996\n",
      "threshold:0.5, J-value:0.005\n",
      "threshold:0.6000000000000001, J-value:0.005\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.001\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6772188480876455\n",
      "Balanced accuracy score of test is  0.6904182620371148\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.3549999999999999\n",
      "threshold:0.2, J-value:0.213\n",
      "threshold:0.30000000000000004, J-value:0.051000000000000004\n",
      "threshold:0.4, J-value:0.049999999999999996\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.004\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6775605238345843\n",
      "Balanced accuracy score of test is  0.6888223235267015\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.349\n",
      "threshold:0.2, J-value:0.222\n",
      "threshold:0.30000000000000004, J-value:0.064\n",
      "threshold:0.4, J-value:0.05\n",
      "threshold:0.5, J-value:0.007\n",
      "threshold:0.6000000000000001, J-value:0.008\n",
      "threshold:0.7000000000000001, J-value:0.004\n",
      "threshold:0.8, J-value:0.004\n",
      "threshold:0.9, J-value:0.004\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6745559807673438\n",
      "Balanced accuracy score of test is  0.697860828196194\n",
      "True positive rate of class 1 is  0.716\n",
      "True positive rate of class 2 is  0.67\n",
      "Positive prediction rate of class 1 is  0.372\n",
      "Positive prediction rate of class 2 is  0.305\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.4119999999999999\n",
      "threshold:0.2, J-value:0.265\n",
      "threshold:0.30000000000000004, J-value:0.15\n",
      "threshold:0.4, J-value:0.06199999999999999\n",
      "threshold:0.5, J-value:0.016\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.705811168911483\n",
      "Balanced accuracy score of test is  0.7053091455322793\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.407\n",
      "threshold:0.2, J-value:0.268\n",
      "threshold:0.30000000000000004, J-value:0.148\n",
      "threshold:0.4, J-value:0.060000000000000005\n",
      "threshold:0.5, J-value:0.015\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7036681441018631\n",
      "Balanced accuracy score of test is  0.7041339776107807\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.43800000000000006\n",
      "threshold:0.2, J-value:0.251\n",
      "threshold:0.30000000000000004, J-value:0.154\n",
      "threshold:0.4, J-value:0.075\n",
      "threshold:0.5, J-value:0.023\n",
      "threshold:0.6000000000000001, J-value:0.011\n",
      "threshold:0.7000000000000001, J-value:0.004\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7191534547289625\n",
      "Balanced accuracy score of test is  0.7124371817207182\n",
      "True positive rate of class 1 is  0.691\n",
      "True positive rate of class 2 is  0.683\n",
      "Positive prediction rate of class 1 is  0.319\n",
      "Positive prediction rate of class 2 is  0.291\n",
      "X train 65694\n",
      "Y train 65694\n",
      "21898 18970 2928\n",
      "21898 18970 2928\n",
      "21898 18892 3006\n",
      "21898 18892 3006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2586404020735353\n",
      "0.2639917869176803\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19911\n",
      "           1       0.43      0.03      0.06      1987\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19820    91]\n",
      " [ 1919    68]]\n",
      "done in 0.895167s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2586404020735353\n",
      "0.2609678507142087\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19927\n",
      "           1       0.45      0.03      0.06      1971\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.51      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19851    76]\n",
      " [ 1910    61]]\n",
      "done in 1.044744s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2586404020735353\n",
      "0.265962196209266\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17229\n",
      "           1       0.41      0.03      0.06      1741\n",
      "\n",
      "    accuracy                           0.91     18970\n",
      "   macro avg       0.66      0.51      0.50     18970\n",
      "weighted avg       0.86      0.91      0.87     18970\n",
      "\n",
      "Confusion_matrix\n",
      "[[17150    79]\n",
      " [ 1686    55]]\n",
      "done in 1.041442s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2586404020735353\n",
      "0.2606548438568971\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17198\n",
      "           1       0.44      0.03      0.05      1694\n",
      "\n",
      "    accuracy                           0.91     18892\n",
      "   macro avg       0.68      0.51      0.50     18892\n",
      "weighted avg       0.87      0.91      0.87     18892\n",
      "\n",
      "Confusion_matrix\n",
      "[[17142    56]\n",
      " [ 1650    44]]\n",
      "done in 1.071952s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2586404020735353\n",
      "0.2512258496699414\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2682\n",
      "           1       0.52      0.05      0.10       246\n",
      "\n",
      "    accuracy                           0.92      2928\n",
      "   macro avg       0.72      0.52      0.53      2928\n",
      "weighted avg       0.89      0.92      0.88      2928\n",
      "\n",
      "Confusion_matrix\n",
      "[[2670   12]\n",
      " [ 233   13]]\n",
      "done in 1.065897s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2586404020735353\n",
      "0.26293502488198356\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95      2729\n",
      "           1       0.46      0.06      0.11       277\n",
      "\n",
      "    accuracy                           0.91      3006\n",
      "   macro avg       0.69      0.53      0.53      3006\n",
      "weighted avg       0.87      0.91      0.87      3006\n",
      "\n",
      "Confusion_matrix\n",
      "[[2709   20]\n",
      " [ 260   17]]\n",
      "done in 1.150670s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19911\n",
      "           1       0.22      0.00      0.00      1987\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.57      0.50      0.48     21898\n",
      "weighted avg       0.85      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19904     7]\n",
      " [ 1985     2]]\n",
      "done in 19.663683s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19927\n",
      "           1       0.70      0.00      0.01      1971\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.81      0.50      0.48     21898\n",
      "weighted avg       0.89      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19924     3]\n",
      " [ 1964     7]]\n",
      "done in 19.995740s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17229\n",
      "           1       0.57      0.00      0.00      1741\n",
      "\n",
      "    accuracy                           0.91     18970\n",
      "   macro avg       0.74      0.50      0.48     18970\n",
      "weighted avg       0.88      0.91      0.86     18970\n",
      "\n",
      "Confusion_matrix\n",
      "[[17226     3]\n",
      " [ 1737     4]]\n",
      "done in 20.014424s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17198\n",
      "           1       0.44      0.00      0.00      1694\n",
      "\n",
      "    accuracy                           0.91     18892\n",
      "   macro avg       0.68      0.50      0.48     18892\n",
      "weighted avg       0.87      0.91      0.87     18892\n",
      "\n",
      "Confusion_matrix\n",
      "[[17193     5]\n",
      " [ 1690     4]]\n",
      "done in 19.962844s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2682\n",
      "           1       0.50      0.00      0.01       246\n",
      "\n",
      "    accuracy                           0.92      2928\n",
      "   macro avg       0.71      0.50      0.48      2928\n",
      "weighted avg       0.88      0.92      0.88      2928\n",
      "\n",
      "Confusion_matrix\n",
      "[[2681    1]\n",
      " [ 245    1]]\n",
      "done in 19.368199s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2729\n",
      "           1       0.00      0.00      0.00       277\n",
      "\n",
      "    accuracy                           0.91      3006\n",
      "   macro avg       0.45      0.50      0.48      3006\n",
      "weighted avg       0.82      0.91      0.86      3006\n",
      "\n",
      "Confusion_matrix\n",
      "[[2729    0]\n",
      " [ 277    0]]\n",
      "done in 19.232789s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26445464621705217\n",
      "0.2702963274846509\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19911\n",
      "           1       0.32      0.00      0.01      1987\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.61      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19898    13]\n",
      " [ 1981     6]]\n",
      "done in 0.664255s\n",
      "0.26445464621705217\n",
      "0.26900537003743663\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19927\n",
      "           1       0.30      0.00      0.01      1971\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.61      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19913    14]\n",
      " [ 1965     6]]\n",
      "done in 0.639602s\n",
      "0.26445464621705217\n",
      "0.2725960626011161\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17229\n",
      "           1       0.31      0.00      0.00      1741\n",
      "\n",
      "    accuracy                           0.91     18970\n",
      "   macro avg       0.61      0.50      0.48     18970\n",
      "weighted avg       0.85      0.91      0.86     18970\n",
      "\n",
      "Confusion_matrix\n",
      "[[17220     9]\n",
      " [ 1737     4]]\n",
      "done in 0.632004s\n",
      "0.26445464621705217\n",
      "0.2687477613627732\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17198\n",
      "           1       0.25      0.00      0.00      1694\n",
      "\n",
      "    accuracy                           0.91     18892\n",
      "   macro avg       0.58      0.50      0.48     18892\n",
      "weighted avg       0.85      0.91      0.87     18892\n",
      "\n",
      "Confusion_matrix\n",
      "[[17189     9]\n",
      " [ 1691     3]]\n",
      "done in 0.618273s\n",
      "0.26445464621705217\n",
      "0.2553967458045464\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2682\n",
      "           1       0.33      0.01      0.02       246\n",
      "\n",
      "    accuracy                           0.92      2928\n",
      "   macro avg       0.62      0.50      0.49      2928\n",
      "weighted avg       0.87      0.92      0.88      2928\n",
      "\n",
      "Confusion_matrix\n",
      "[[2678    4]\n",
      " [ 244    2]]\n",
      "done in 0.584624s\n",
      "0.26445464621705217\n",
      "0.2706243797120013\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2729\n",
      "           1       0.38      0.01      0.02       277\n",
      "\n",
      "    accuracy                           0.91      3006\n",
      "   macro avg       0.64      0.50      0.49      3006\n",
      "weighted avg       0.86      0.91      0.87      3006\n",
      "\n",
      "Confusion_matrix\n",
      "[[2724    5]\n",
      " [ 274    3]]\n",
      "done in 0.609446s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19911\n",
      "           1       0.42      0.02      0.04      1987\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19856    55]\n",
      " [ 1947    40]]\n",
      "done in 33.222476s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19927\n",
      "           1       0.43      0.02      0.04      1971\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19879    48]\n",
      " [ 1935    36]]\n",
      "done in 33.047523s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17229\n",
      "           1       0.40      0.02      0.03      1741\n",
      "\n",
      "    accuracy                           0.91     18970\n",
      "   macro avg       0.65      0.51      0.49     18970\n",
      "weighted avg       0.86      0.91      0.87     18970\n",
      "\n",
      "Confusion_matrix\n",
      "[[17184    45]\n",
      " [ 1711    30]]\n",
      "done in 32.999640s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17198\n",
      "           1       0.41      0.02      0.03      1694\n",
      "\n",
      "    accuracy                           0.91     18892\n",
      "   macro avg       0.66      0.51      0.49     18892\n",
      "weighted avg       0.87      0.91      0.87     18892\n",
      "\n",
      "Confusion_matrix\n",
      "[[17161    37]\n",
      " [ 1668    26]]\n",
      "done in 33.035392s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2682\n",
      "           1       0.50      0.04      0.08       246\n",
      "\n",
      "    accuracy                           0.92      2928\n",
      "   macro avg       0.71      0.52      0.52      2928\n",
      "weighted avg       0.88      0.92      0.88      2928\n",
      "\n",
      "Confusion_matrix\n",
      "[[2672   10]\n",
      " [ 236   10]]\n",
      "done in 33.182143s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2729\n",
      "           1       0.48      0.04      0.07       277\n",
      "\n",
      "    accuracy                           0.91      3006\n",
      "   macro avg       0.69      0.52      0.51      3006\n",
      "weighted avg       0.87      0.91      0.87      3006\n",
      "\n",
      "Confusion_matrix\n",
      "[[2718   11]\n",
      " [ 267   10]]\n",
      "done in 32.976488s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.39\n",
      "threshold:0.2, J-value:0.248\n",
      "threshold:0.30000000000000004, J-value:0.145\n",
      "threshold:0.4, J-value:0.07\n",
      "threshold:0.5, J-value:0.029\n",
      "threshold:0.6000000000000001, J-value:0.013000000000000001\n",
      "threshold:0.7000000000000001, J-value:0.005\n",
      "threshold:0.8, J-value:0.002\n",
      "threshold:0.9, J-value:0.001\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6950035736531339\n",
      "Balanced accuracy score of test is  0.7058600268453218\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.39\n",
      "threshold:0.2, J-value:0.246\n",
      "threshold:0.30000000000000004, J-value:0.141\n",
      "threshold:0.4, J-value:0.065\n",
      "threshold:0.5, J-value:0.027\n",
      "threshold:0.6000000000000001, J-value:0.009999999999999998\n",
      "threshold:0.7000000000000001, J-value:0.005\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6950732320234417\n",
      "Balanced accuracy score of test is  0.7062750150926367\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.387\n",
      "threshold:0.2, J-value:0.259\n",
      "threshold:0.30000000000000004, J-value:0.164\n",
      "threshold:0.4, J-value:0.101\n",
      "threshold:0.5, J-value:0.049\n",
      "threshold:0.6000000000000001, J-value:0.026000000000000002\n",
      "threshold:0.7000000000000001, J-value:0.015\n",
      "threshold:0.8, J-value:0.007\n",
      "threshold:0.9, J-value:0.004\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6936941852640003\n",
      "Balanced accuracy score of test is  0.7034637990403911\n",
      "True positive rate of class 1 is  0.663\n",
      "True positive rate of class 2 is  0.646\n",
      "Positive prediction rate of class 1 is  0.287\n",
      "Positive prediction rate of class 2 is  0.277\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.397\n",
      "threshold:0.2, J-value:0.281\n",
      "threshold:0.30000000000000004, J-value:0.11300000000000002\n",
      "threshold:0.4, J-value:0.024\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6982697311036123\n",
      "Balanced accuracy score of test is  0.6993127528365393\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.381\n",
      "threshold:0.2, J-value:0.28600000000000003\n",
      "threshold:0.30000000000000004, J-value:0.11500000000000002\n",
      "threshold:0.4, J-value:0.02\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6903436857209715\n",
      "Balanced accuracy score of test is  0.6975162401163311\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.394\n",
      "threshold:0.2, J-value:0.323\n",
      "threshold:0.30000000000000004, J-value:0.12\n",
      "threshold:0.4, J-value:0.022\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6970635310379949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy score of test is  0.7040617356300095\n",
      "True positive rate of class 1 is  0.736\n",
      "True positive rate of class 2 is  0.762\n",
      "Positive prediction rate of class 1 is  0.376\n",
      "Positive prediction rate of class 2 is  0.391\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.348\n",
      "threshold:0.2, J-value:0.21099999999999997\n",
      "threshold:0.30000000000000004, J-value:0.11000000000000001\n",
      "threshold:0.4, J-value:0.007\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.002\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6740769195946623\n",
      "Balanced accuracy score of test is  0.6700628399696437\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.347\n",
      "threshold:0.2, J-value:0.21699999999999997\n",
      "threshold:0.30000000000000004, J-value:0.11100000000000002\n",
      "threshold:0.4, J-value:0.007\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6735025656520175\n",
      "Balanced accuracy score of test is  0.6690458364437368\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.353\n",
      "threshold:0.2, J-value:0.169\n",
      "threshold:0.30000000000000004, J-value:0.096\n",
      "threshold:0.4, J-value:0.005\n",
      "threshold:0.5, J-value:0.007\n",
      "threshold:0.6000000000000001, J-value:0.007\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6765382586711772\n",
      "Balanced accuracy score of test is  0.6765169664507305\n",
      "True positive rate of class 1 is  0.603\n",
      "True positive rate of class 2 is  0.599\n",
      "Positive prediction rate of class 1 is  0.295\n",
      "Positive prediction rate of class 2 is  0.279\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.405\n",
      "threshold:0.2, J-value:0.26399999999999996\n",
      "threshold:0.30000000000000004, J-value:0.137\n",
      "threshold:0.4, J-value:0.052\n",
      "threshold:0.5, J-value:0.017\n",
      "threshold:0.6000000000000001, J-value:0.008\n",
      "threshold:0.7000000000000001, J-value:0.003\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7026204834968048\n",
      "Balanced accuracy score of test is  0.7129174454796536\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.40700000000000003\n",
      "threshold:0.2, J-value:0.26399999999999996\n",
      "threshold:0.30000000000000004, J-value:0.138\n",
      "threshold:0.4, J-value:0.049999999999999996\n",
      "threshold:0.5, J-value:0.014000000000000002\n",
      "threshold:0.6000000000000001, J-value:0.007\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7034533529134803\n",
      "Balanced accuracy score of test is  0.7109446020260174\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.391\n",
      "threshold:0.2, J-value:0.267\n",
      "threshold:0.30000000000000004, J-value:0.139\n",
      "threshold:0.4, J-value:0.065\n",
      "threshold:0.5, J-value:0.037000000000000005\n",
      "threshold:0.6000000000000001, J-value:0.019\n",
      "threshold:0.7000000000000001, J-value:0.008\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6958585693239483\n",
      "Balanced accuracy score of test is  0.725199190933588\n",
      "True positive rate of class 1 is  0.692\n",
      "True positive rate of class 2 is  0.704\n",
      "Positive prediction rate of class 1 is  0.308\n",
      "Positive prediction rate of class 2 is  0.295\n",
      "X train 65694\n",
      "Y train 65694\n",
      "21898 18842 3056\n",
      "21898 18842 3056\n",
      "21898 18914 2984\n",
      "21898 18914 2984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2615249031494391\n",
      "0.2575706140794245\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19944\n",
      "           1       0.43      0.03      0.06      1954\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19861    83]\n",
      " [ 1891    63]]\n",
      "done in 1.009826s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2615249031494391\n",
      "0.25832616083809007\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19955\n",
      "           1       0.47      0.04      0.07      1943\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.69      0.52      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19876    79]\n",
      " [ 1873    70]]\n",
      "done in 0.961090s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2615249031494391\n",
      "0.25826521100481026\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17147\n",
      "           1       0.44      0.03      0.06      1695\n",
      "\n",
      "    accuracy                           0.91     18842\n",
      "   macro avg       0.67      0.51      0.51     18842\n",
      "weighted avg       0.87      0.91      0.87     18842\n",
      "\n",
      "Confusion_matrix\n",
      "[[17077    70]\n",
      " [ 1641    54]]\n",
      "done in 0.944324s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2615249031494391\n",
      "0.25989764454343484\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17231\n",
      "           1       0.43      0.03      0.06      1683\n",
      "\n",
      "    accuracy                           0.91     18914\n",
      "   macro avg       0.67      0.51      0.50     18914\n",
      "weighted avg       0.87      0.91      0.87     18914\n",
      "\n",
      "Confusion_matrix\n",
      "[[17163    68]\n",
      " [ 1632    51]]\n",
      "done in 1.125843s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2615249031494391\n",
      "0.25328802400477807\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.95      2797\n",
      "           1       0.41      0.03      0.06       259\n",
      "\n",
      "    accuracy                           0.91      3056\n",
      "   macro avg       0.66      0.52      0.51      3056\n",
      "weighted avg       0.87      0.91      0.88      3056\n",
      "\n",
      "Confusion_matrix\n",
      "[[2784   13]\n",
      " [ 250    9]]\n",
      "done in 1.316333s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2615249031494391\n",
      "0.24836535560923897\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2724\n",
      "           1       0.63      0.07      0.13       260\n",
      "\n",
      "    accuracy                           0.92      2984\n",
      "   macro avg       0.78      0.53      0.54      2984\n",
      "weighted avg       0.89      0.92      0.88      2984\n",
      "\n",
      "Confusion_matrix\n",
      "[[2713   11]\n",
      " [ 241   19]]\n",
      "done in 1.103375s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19944\n",
      "           1       0.50      0.00      0.01      1954\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.71      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19939     5]\n",
      " [ 1949     5]]\n",
      "done in 19.507105s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19955\n",
      "           1       0.50      0.00      0.01      1943\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.71      0.50      0.48     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19948     7]\n",
      " [ 1936     7]]\n",
      "done in 19.640311s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17147\n",
      "           1       0.73      0.00      0.01      1695\n",
      "\n",
      "    accuracy                           0.91     18842\n",
      "   macro avg       0.82      0.50      0.48     18842\n",
      "weighted avg       0.89      0.91      0.87     18842\n",
      "\n",
      "Confusion_matrix\n",
      "[[17144     3]\n",
      " [ 1687     8]]\n",
      "done in 19.575930s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17231\n",
      "           1       0.33      0.00      0.00      1683\n",
      "\n",
      "    accuracy                           0.91     18914\n",
      "   macro avg       0.62      0.50      0.48     18914\n",
      "weighted avg       0.86      0.91      0.87     18914\n",
      "\n",
      "Confusion_matrix\n",
      "[[17225     6]\n",
      " [ 1680     3]]\n",
      "done in 19.524584s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2797\n",
      "           1       0.00      0.00      0.00       259\n",
      "\n",
      "    accuracy                           0.91      3056\n",
      "   macro avg       0.46      0.50      0.48      3056\n",
      "weighted avg       0.84      0.91      0.87      3056\n",
      "\n",
      "Confusion_matrix\n",
      "[[2796    1]\n",
      " [ 259    0]]\n",
      "done in 19.385265s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2724\n",
      "           1       0.00      0.00      0.00       260\n",
      "\n",
      "    accuracy                           0.91      2984\n",
      "   macro avg       0.46      0.50      0.48      2984\n",
      "weighted avg       0.83      0.91      0.87      2984\n",
      "\n",
      "Confusion_matrix\n",
      "[[2724    0]\n",
      " [ 260    0]]\n",
      "done in 19.390334s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26691180010608717\n",
      "0.26804236350549815\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19944\n",
      "           1       0.34      0.01      0.03      1954\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.63      0.51      0.49     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19890    54]\n",
      " [ 1926    28]]\n",
      "done in 0.642173s\n",
      "0.26691180010608717\n",
      "0.2720697371491411\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19955\n",
      "           1       0.38      0.01      0.03      1943\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.65      0.51      0.49     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19909    46]\n",
      " [ 1915    28]]\n",
      "done in 0.617115s\n",
      "0.26691180010608717\n",
      "0.26965226840168327\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17147\n",
      "           1       0.35      0.01      0.03      1695\n",
      "\n",
      "    accuracy                           0.91     18842\n",
      "   macro avg       0.63      0.51      0.49     18842\n",
      "weighted avg       0.86      0.91      0.87     18842\n",
      "\n",
      "Confusion_matrix\n",
      "[[17102    45]\n",
      " [ 1671    24]]\n",
      "done in 0.632281s\n",
      "0.26691180010608717\n",
      "0.2733018765049085\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17231\n",
      "           1       0.39      0.01      0.03      1683\n",
      "\n",
      "    accuracy                           0.91     18914\n",
      "   macro avg       0.65      0.51      0.49     18914\n",
      "weighted avg       0.87      0.91      0.87     18914\n",
      "\n",
      "Confusion_matrix\n",
      "[[17193    38]\n",
      " [ 1659    24]]\n",
      "done in 0.675786s\n",
      "0.26691180010608717\n",
      "0.25811637265015813\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.95      2797\n",
      "           1       0.31      0.02      0.03       259\n",
      "\n",
      "    accuracy                           0.91      3056\n",
      "   macro avg       0.61      0.51      0.49      3056\n",
      "weighted avg       0.86      0.91      0.88      3056\n",
      "\n",
      "Confusion_matrix\n",
      "[[2788    9]\n",
      " [ 255    4]]\n",
      "done in 0.615955s\n",
      "0.26691180010608717\n",
      "0.264259856527497\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2724\n",
      "           1       0.33      0.02      0.03       260\n",
      "\n",
      "    accuracy                           0.91      2984\n",
      "   macro avg       0.62      0.51      0.49      2984\n",
      "weighted avg       0.86      0.91      0.87      2984\n",
      "\n",
      "Confusion_matrix\n",
      "[[2716    8]\n",
      " [ 256    4]]\n",
      "done in 0.589736s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19944\n",
      "           1       0.45      0.01      0.03      1954\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.51      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19911    33]\n",
      " [ 1927    27]]\n",
      "done in 33.281389s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19955\n",
      "           1       0.54      0.02      0.03      1943\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.73      0.51      0.49     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19925    30]\n",
      " [ 1908    35]]\n",
      "done in 33.285132s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17147\n",
      "           1       0.46      0.01      0.03      1695\n",
      "\n",
      "    accuracy                           0.91     18842\n",
      "   macro avg       0.69      0.51      0.49     18842\n",
      "weighted avg       0.87      0.91      0.87     18842\n",
      "\n",
      "Confusion_matrix\n",
      "[[17118    29]\n",
      " [ 1670    25]]\n",
      "done in 33.347484s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17231\n",
      "           1       0.50      0.01      0.03      1683\n",
      "\n",
      "    accuracy                           0.91     18914\n",
      "   macro avg       0.71      0.51      0.49     18914\n",
      "weighted avg       0.88      0.91      0.87     18914\n",
      "\n",
      "Confusion_matrix\n",
      "[[17207    24]\n",
      " [ 1659    24]]\n",
      "done in 33.269342s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2797\n",
      "           1       0.33      0.01      0.02       259\n",
      "\n",
      "    accuracy                           0.91      3056\n",
      "   macro avg       0.62      0.50      0.49      3056\n",
      "weighted avg       0.87      0.91      0.88      3056\n",
      "\n",
      "Confusion_matrix\n",
      "[[2791    6]\n",
      " [ 256    3]]\n",
      "done in 32.947070s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2724\n",
      "           1       0.69      0.04      0.08       260\n",
      "\n",
      "    accuracy                           0.91      2984\n",
      "   macro avg       0.80      0.52      0.52      2984\n",
      "weighted avg       0.90      0.91      0.88      2984\n",
      "\n",
      "Confusion_matrix\n",
      "[[2719    5]\n",
      " [ 249   11]]\n",
      "done in 33.132834s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41400000000000003\n",
      "threshold:0.2, J-value:0.26599999999999996\n",
      "threshold:0.30000000000000004, J-value:0.143\n",
      "threshold:0.4, J-value:0.07\n",
      "threshold:0.5, J-value:0.028\n",
      "threshold:0.6000000000000001, J-value:0.011\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.707055317837745\n",
      "Balanced accuracy score of test is  0.7037223485214352\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41700000000000004\n",
      "threshold:0.2, J-value:0.26699999999999996\n",
      "threshold:0.30000000000000004, J-value:0.146\n",
      "threshold:0.4, J-value:0.07300000000000001\n",
      "threshold:0.5, J-value:0.028\n",
      "threshold:0.6000000000000001, J-value:0.012\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7087885029554435\n",
      "Balanced accuracy score of test is  0.7002840504992919\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.39\n",
      "threshold:0.2, J-value:0.261\n",
      "threshold:0.30000000000000004, J-value:0.123\n",
      "threshold:0.4, J-value:0.05600000000000001\n",
      "threshold:0.5, J-value:0.030000000000000002\n",
      "threshold:0.6000000000000001, J-value:0.006\n",
      "threshold:0.7000000000000001, J-value:-0.001\n",
      "threshold:0.8, J-value:-0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6948295401995795\n",
      "Balanced accuracy score of test is  0.7256636168530441\n",
      "True positive rate of class 1 is  0.661\n",
      "True positive rate of class 2 is  0.681\n",
      "Positive prediction rate of class 1 is  0.296\n",
      "Positive prediction rate of class 2 is  0.269\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.393\n",
      "threshold:0.2, J-value:0.28500000000000003\n",
      "threshold:0.30000000000000004, J-value:0.10800000000000001\n",
      "threshold:0.4, J-value:0.021\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6963247605064908\n",
      "Balanced accuracy score of test is  0.6951480641015109\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.4\n",
      "threshold:0.2, J-value:0.276\n",
      "threshold:0.30000000000000004, J-value:0.10900000000000001\n",
      "threshold:0.4, J-value:0.022\n",
      "threshold:0.5, J-value:0.005\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7000065200565714\n",
      "Balanced accuracy score of test is  0.6952784768349738\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.387\n",
      "threshold:0.2, J-value:0.29700000000000004\n",
      "threshold:0.30000000000000004, J-value:0.10500000000000001\n",
      "threshold:0.4, J-value:0.008\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6938956935381676\n",
      "Balanced accuracy score of test is  0.7137100417937423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positive rate of class 1 is  0.737\n",
      "True positive rate of class 2 is  0.785\n",
      "Positive prediction rate of class 1 is  0.382\n",
      "Positive prediction rate of class 2 is  0.394\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.364\n",
      "threshold:0.2, J-value:0.23500000000000001\n",
      "threshold:0.30000000000000004, J-value:0.143\n",
      "threshold:0.4, J-value:0.011\n",
      "threshold:0.5, J-value:0.011\n",
      "threshold:0.6000000000000001, J-value:0.002\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6823207591286309\n",
      "Balanced accuracy score of test is  0.6769141788788026\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.366\n",
      "threshold:0.2, J-value:0.24000000000000002\n",
      "threshold:0.30000000000000004, J-value:0.149\n",
      "threshold:0.4, J-value:0.011\n",
      "threshold:0.5, J-value:0.011\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6831660913017801\n",
      "Balanced accuracy score of test is  0.675193371341217\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.35\n",
      "threshold:0.2, J-value:0.20399999999999996\n",
      "threshold:0.30000000000000004, J-value:0.10500000000000001\n",
      "threshold:0.4, J-value:0.012\n",
      "threshold:0.5, J-value:0.012\n",
      "threshold:0.6000000000000001, J-value:0.011\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6750600132795341\n",
      "Balanced accuracy score of test is  0.687481644640235\n",
      "True positive rate of class 1 is  0.632\n",
      "True positive rate of class 2 is  0.6\n",
      "Positive prediction rate of class 1 is  0.313\n",
      "Positive prediction rate of class 2 is  0.258\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.42799999999999994\n",
      "threshold:0.2, J-value:0.27199999999999996\n",
      "threshold:0.30000000000000004, J-value:0.138\n",
      "threshold:0.4, J-value:0.043\n",
      "threshold:0.5, J-value:0.012\n",
      "threshold:0.6000000000000001, J-value:0.004\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.713955446796578\n",
      "Balanced accuracy score of test is  0.7088256219313838\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.42599999999999993\n",
      "threshold:0.2, J-value:0.27499999999999997\n",
      "threshold:0.30000000000000004, J-value:0.14200000000000002\n",
      "threshold:0.4, J-value:0.048\n",
      "threshold:0.5, J-value:0.013\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7131793223717248\n",
      "Balanced accuracy score of test is  0.7075193485135212\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.43600000000000005\n",
      "threshold:0.2, J-value:0.263\n",
      "threshold:0.30000000000000004, J-value:0.119\n",
      "threshold:0.4, J-value:0.024000000000000004\n",
      "threshold:0.5, J-value:0.01\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7176732378734524\n",
      "Balanced accuracy score of test is  0.717028126058963\n",
      "True positive rate of class 1 is  0.695\n",
      "True positive rate of class 2 is  0.688\n",
      "Positive prediction rate of class 1 is  0.316\n",
      "Positive prediction rate of class 2 is  0.292\n",
      "X train 65694\n",
      "Y train 65694\n",
      "21898 18920 2978\n",
      "21898 18920 2978\n",
      "21898 18865 3033\n",
      "21898 18865 3033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25825949338863036\n",
      "0.2633059221721374\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19893\n",
      "           1       0.41      0.03      0.06      2005\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.66      0.51      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19795    98]\n",
      " [ 1936    69]]\n",
      "done in 0.896884s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25825949338863036\n",
      "0.2622847363281984\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19907\n",
      "           1       0.48      0.03      0.06      1991\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.70      0.52      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19833    74]\n",
      " [ 1922    69]]\n",
      "done in 0.880424s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25825949338863036\n",
      "0.26182896927128774\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17191\n",
      "           1       0.41      0.03      0.06      1729\n",
      "\n",
      "    accuracy                           0.91     18920\n",
      "   macro avg       0.66      0.51      0.51     18920\n",
      "weighted avg       0.87      0.91      0.87     18920\n",
      "\n",
      "Confusion_matrix\n",
      "[[17108    83]\n",
      " [ 1671    58]]\n",
      "done in 0.939585s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25825949338863036\n",
      "0.2643884932567561\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17135\n",
      "           1       0.46      0.03      0.06      1730\n",
      "\n",
      "    accuracy                           0.91     18865\n",
      "   macro avg       0.68      0.51      0.50     18865\n",
      "weighted avg       0.87      0.91      0.87     18865\n",
      "\n",
      "Confusion_matrix\n",
      "[[17075    60]\n",
      " [ 1679    51]]\n",
      "done in 1.153805s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25825949338863036\n",
      "0.2726893838524846\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95      2702\n",
      "           1       0.42      0.04      0.07       276\n",
      "\n",
      "    accuracy                           0.91      2978\n",
      "   macro avg       0.67      0.52      0.51      2978\n",
      "weighted avg       0.87      0.91      0.87      2978\n",
      "\n",
      "Confusion_matrix\n",
      "[[2687   15]\n",
      " [ 265   11]]\n",
      "done in 1.083728s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25825949338863036\n",
      "0.24919954857440885\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96      2772\n",
      "           1       0.56      0.07      0.12       261\n",
      "\n",
      "    accuracy                           0.92      3033\n",
      "   macro avg       0.74      0.53      0.54      3033\n",
      "weighted avg       0.89      0.92      0.88      3033\n",
      "\n",
      "Confusion_matrix\n",
      "[[2758   14]\n",
      " [ 243   18]]\n",
      "done in 0.992812s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19893\n",
      "           1       0.54      0.00      0.01      2005\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.72      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19887     6]\n",
      " [ 1998     7]]\n",
      "done in 19.163097s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19907\n",
      "           1       0.22      0.00      0.00      1991\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.57      0.50      0.48     21898\n",
      "weighted avg       0.85      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19900     7]\n",
      " [ 1989     2]]\n",
      "done in 19.700458s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17191\n",
      "           1       0.42      0.00      0.01      1729\n",
      "\n",
      "    accuracy                           0.91     18920\n",
      "   macro avg       0.66      0.50      0.48     18920\n",
      "weighted avg       0.86      0.91      0.87     18920\n",
      "\n",
      "Confusion_matrix\n",
      "[[17184     7]\n",
      " [ 1724     5]]\n",
      "done in 19.959832s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17135\n",
      "           1       0.25      0.00      0.00      1730\n",
      "\n",
      "    accuracy                           0.91     18865\n",
      "   macro avg       0.58      0.50      0.48     18865\n",
      "weighted avg       0.85      0.91      0.86     18865\n",
      "\n",
      "Confusion_matrix\n",
      "[[17132     3]\n",
      " [ 1729     1]]\n",
      "done in 20.479710s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2702\n",
      "           1       0.00      0.00      0.00       276\n",
      "\n",
      "    accuracy                           0.91      2978\n",
      "   macro avg       0.45      0.50      0.48      2978\n",
      "weighted avg       0.82      0.91      0.86      2978\n",
      "\n",
      "Confusion_matrix\n",
      "[[2701    1]\n",
      " [ 276    0]]\n",
      "done in 19.355945s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.96      2772\n",
      "           1       0.00      0.00      0.00       261\n",
      "\n",
      "    accuracy                           0.91      3033\n",
      "   macro avg       0.46      0.50      0.48      3033\n",
      "weighted avg       0.84      0.91      0.87      3033\n",
      "\n",
      "Confusion_matrix\n",
      "[[2772    0]\n",
      " [ 261    0]]\n",
      "done in 19.468184s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2638844630577774\n",
      "0.27072063991639456\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19893\n",
      "           1       0.08      0.00      0.00      2005\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.50      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.86     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19882    11]\n",
      " [ 2004     1]]\n",
      "done in 0.636178s\n",
      "0.2638844630577774\n",
      "0.27224900833516935\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19907\n",
      "           1       0.33      0.00      0.00      1991\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.62      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19903     4]\n",
      " [ 1989     2]]\n",
      "done in 0.636339s\n",
      "0.2638844630577774\n",
      "0.26930585598613827\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17191\n",
      "           1       0.10      0.00      0.00      1729\n",
      "\n",
      "    accuracy                           0.91     18920\n",
      "   macro avg       0.50      0.50      0.48     18920\n",
      "weighted avg       0.83      0.91      0.87     18920\n",
      "\n",
      "Confusion_matrix\n",
      "[[17182     9]\n",
      " [ 1728     1]]\n",
      "done in 0.651817s\n",
      "0.2638844630577774\n",
      "0.2728144665236338\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17135\n",
      "           1       0.33      0.00      0.00      1730\n",
      "\n",
      "    accuracy                           0.91     18865\n",
      "   macro avg       0.62      0.50      0.48     18865\n",
      "weighted avg       0.86      0.91      0.86     18865\n",
      "\n",
      "Confusion_matrix\n",
      "[[17133     2]\n",
      " [ 1729     1]]\n",
      "done in 0.727781s\n",
      "0.2638844630577774\n",
      "0.2797091261354845\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2702\n",
      "           1       0.00      0.00      0.00       276\n",
      "\n",
      "    accuracy                           0.91      2978\n",
      "   macro avg       0.45      0.50      0.48      2978\n",
      "weighted avg       0.82      0.91      0.86      2978\n",
      "\n",
      "Confusion_matrix\n",
      "[[2700    2]\n",
      " [ 276    0]]\n",
      "done in 0.598266s\n",
      "0.2638844630577774\n",
      "0.26873190687609205\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2772\n",
      "           1       0.33      0.00      0.01       261\n",
      "\n",
      "    accuracy                           0.91      3033\n",
      "   macro avg       0.62      0.50      0.48      3033\n",
      "weighted avg       0.86      0.91      0.87      3033\n",
      "\n",
      "Confusion_matrix\n",
      "[[2770    2]\n",
      " [ 260    1]]\n",
      "done in 0.601425s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19893\n",
      "           1       0.46      0.02      0.04      2005\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.51      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19846    47]\n",
      " [ 1965    40]]\n",
      "done in 33.327086s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19907\n",
      "           1       0.51      0.02      0.03      1991\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.71      0.51      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19874    33]\n",
      " [ 1957    34]]\n",
      "done in 33.227243s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17191\n",
      "           1       0.45      0.02      0.04      1729\n",
      "\n",
      "    accuracy                           0.91     18920\n",
      "   macro avg       0.68      0.51      0.49     18920\n",
      "weighted avg       0.87      0.91      0.87     18920\n",
      "\n",
      "Confusion_matrix\n",
      "[[17150    41]\n",
      " [ 1695    34]]\n",
      "done in 33.064963s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17135\n",
      "           1       0.44      0.01      0.03      1730\n",
      "\n",
      "    accuracy                           0.91     18865\n",
      "   macro avg       0.67      0.51      0.49     18865\n",
      "weighted avg       0.87      0.91      0.87     18865\n",
      "\n",
      "Confusion_matrix\n",
      "[[17104    31]\n",
      " [ 1706    24]]\n",
      "done in 33.197385s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2702\n",
      "           1       0.46      0.02      0.04       276\n",
      "\n",
      "    accuracy                           0.91      2978\n",
      "   macro avg       0.69      0.51      0.50      2978\n",
      "weighted avg       0.87      0.91      0.87      2978\n",
      "\n",
      "Confusion_matrix\n",
      "[[2695    7]\n",
      " [ 270    6]]\n",
      "done in 33.187618s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2772\n",
      "           1       0.83      0.04      0.07       261\n",
      "\n",
      "    accuracy                           0.92      3033\n",
      "   macro avg       0.88      0.52      0.51      3033\n",
      "weighted avg       0.91      0.92      0.88      3033\n",
      "\n",
      "Confusion_matrix\n",
      "[[2770    2]\n",
      " [ 251   10]]\n",
      "done in 33.156744s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41000000000000003\n",
      "threshold:0.2, J-value:0.26899999999999996\n",
      "threshold:0.30000000000000004, J-value:0.147\n",
      "threshold:0.4, J-value:0.07100000000000001\n",
      "threshold:0.5, J-value:0.029\n",
      "threshold:0.6000000000000001, J-value:0.008\n",
      "threshold:0.7000000000000001, J-value:0.005\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7048403221574576\n",
      "Balanced accuracy score of test is  0.6978716980720774\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41400000000000003\n",
      "threshold:0.2, J-value:0.27399999999999997\n",
      "threshold:0.30000000000000004, J-value:0.15\n",
      "threshold:0.4, J-value:0.07200000000000001\n",
      "threshold:0.5, J-value:0.029\n",
      "threshold:0.6000000000000001, J-value:0.01\n",
      "threshold:0.7000000000000001, J-value:0.006\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7068077943995269\n",
      "Balanced accuracy score of test is  0.6982196801665117\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.385\n",
      "threshold:0.2, J-value:0.23299999999999998\n",
      "threshold:0.30000000000000004, J-value:0.134\n",
      "threshold:0.4, J-value:0.073\n",
      "threshold:0.5, J-value:0.034\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:-0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6927249273216833\n",
      "Balanced accuracy score of test is  0.6950166691546003\n",
      "True positive rate of class 1 is  0.649\n",
      "True positive rate of class 2 is  0.625\n",
      "Positive prediction rate of class 1 is  0.288\n",
      "Positive prediction rate of class 2 is  0.268\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.39699999999999996\n",
      "threshold:0.2, J-value:0.29700000000000004\n",
      "threshold:0.30000000000000004, J-value:0.11499999999999999\n",
      "threshold:0.4, J-value:0.027\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6985902007159751\n",
      "Balanced accuracy score of test is  0.6970110284545891\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.408\n",
      "threshold:0.2, J-value:0.29600000000000004\n",
      "threshold:0.30000000000000004, J-value:0.11500000000000002\n",
      "threshold:0.4, J-value:0.025\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7042304171493557\n",
      "Balanced accuracy score of test is  0.6991292372202385\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.406\n",
      "threshold:0.2, J-value:0.253\n",
      "threshold:0.30000000000000004, J-value:0.11599999999999999\n",
      "threshold:0.4, J-value:0.029\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7027885945998134\n",
      "Balanced accuracy score of test is  0.6997250833457731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positive rate of class 1 is  0.732\n",
      "True positive rate of class 2 is  0.755\n",
      "Positive prediction rate of class 1 is  0.371\n",
      "Positive prediction rate of class 2 is  0.39\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.37400000000000005\n",
      "threshold:0.2, J-value:0.21000000000000002\n",
      "threshold:0.30000000000000004, J-value:0.093\n",
      "threshold:0.4, J-value:0.008\n",
      "threshold:0.5, J-value:-0.001\n",
      "threshold:0.6000000000000001, J-value:-0.001\n",
      "threshold:0.7000000000000001, J-value:-0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.687285719246347\n",
      "Balanced accuracy score of test is  0.6872702163503284\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.38099999999999995\n",
      "threshold:0.2, J-value:0.21500000000000002\n",
      "threshold:0.30000000000000004, J-value:0.10099999999999999\n",
      "threshold:0.4, J-value:0.008\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6902225729840546\n",
      "Balanced accuracy score of test is  0.6843686906595194\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.33799999999999997\n",
      "threshold:0.2, J-value:0.182\n",
      "threshold:0.30000000000000004, J-value:0.043\n",
      "threshold:0.4, J-value:0.005\n",
      "threshold:0.5, J-value:-0.001\n",
      "threshold:0.6000000000000001, J-value:-0.001\n",
      "threshold:0.7000000000000001, J-value:-0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6693498642980509\n",
      "Balanced accuracy score of test is  0.7046822908891874\n",
      "True positive rate of class 1 is  0.677\n",
      "True positive rate of class 2 is  0.659\n",
      "Positive prediction rate of class 1 is  0.342\n",
      "Positive prediction rate of class 2 is  0.285\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.42399999999999993\n",
      "threshold:0.2, J-value:0.285\n",
      "threshold:0.30000000000000004, J-value:0.14100000000000001\n",
      "threshold:0.4, J-value:0.060000000000000005\n",
      "threshold:0.5, J-value:0.018000000000000002\n",
      "threshold:0.6000000000000001, J-value:0.006\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7122527341727118\n",
      "Balanced accuracy score of test is  0.7062079755746189\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.42999999999999994\n",
      "threshold:0.2, J-value:0.289\n",
      "threshold:0.30000000000000004, J-value:0.14200000000000002\n",
      "threshold:0.4, J-value:0.061000000000000006\n",
      "threshold:0.5, J-value:0.018000000000000002\n",
      "threshold:0.6000000000000001, J-value:0.008\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7147984948746668\n",
      "Balanced accuracy score of test is  0.7041347105862827\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.393\n",
      "threshold:0.2, J-value:0.26199999999999996\n",
      "threshold:0.30000000000000004, J-value:0.127\n",
      "threshold:0.4, J-value:0.05800000000000001\n",
      "threshold:0.5, J-value:0.019\n",
      "threshold:0.6000000000000001, J-value:-0.001\n",
      "threshold:0.7000000000000001, J-value:-0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.696484890419335\n",
      "Balanced accuracy score of test is  0.7199146638801811\n",
      "True positive rate of class 1 is  0.675\n",
      "True positive rate of class 2 is  0.705\n",
      "Positive prediction rate of class 1 is  0.304\n",
      "Positive prediction rate of class 2 is  0.303\n",
      "X train 65694\n",
      "Y train 65694\n",
      "21898 18905 2993\n",
      "21898 18905 2993\n",
      "21898 18918 2980\n",
      "21898 18918 2980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.259703992793075\n",
      "0.2622894173060706\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19931\n",
      "           1       0.50      0.04      0.08      1967\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.71      0.52      0.51     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19851    80]\n",
      " [ 1886    81]]\n",
      "done in 0.906977s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.259703992793075\n",
      "0.25915565572607974\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19956\n",
      "           1       0.47      0.04      0.07      1942\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.69      0.52      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19877    79]\n",
      " [ 1873    69]]\n",
      "done in 0.853088s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.259703992793075\n",
      "0.2606057245497353\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17217\n",
      "           1       0.52      0.04      0.08      1688\n",
      "\n",
      "    accuracy                           0.91     18905\n",
      "   macro avg       0.72      0.52      0.52     18905\n",
      "weighted avg       0.88      0.91      0.87     18905\n",
      "\n",
      "Confusion_matrix\n",
      "[[17152    65]\n",
      " [ 1618    70]]\n",
      "done in 1.085203s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.259703992793075\n",
      "0.26030672244598035\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17231\n",
      "           1       0.44      0.03      0.06      1687\n",
      "\n",
      "    accuracy                           0.91     18918\n",
      "   macro avg       0.68      0.51      0.51     18918\n",
      "weighted avg       0.87      0.91      0.87     18918\n",
      "\n",
      "Confusion_matrix\n",
      "[[17166    65]\n",
      " [ 1635    52]]\n",
      "done in 0.983221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.259703992793075\n",
      "0.272924302557831\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95      2714\n",
      "           1       0.42      0.04      0.07       279\n",
      "\n",
      "    accuracy                           0.91      2993\n",
      "   macro avg       0.67      0.52      0.51      2993\n",
      "weighted avg       0.86      0.91      0.87      2993\n",
      "\n",
      "Confusion_matrix\n",
      "[[2699   15]\n",
      " [ 268   11]]\n",
      "done in 1.029004s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.259703992793075\n",
      "0.251848313374711\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96      2725\n",
      "           1       0.55      0.07      0.12       255\n",
      "\n",
      "    accuracy                           0.92      2980\n",
      "   macro avg       0.73      0.53      0.54      2980\n",
      "weighted avg       0.89      0.92      0.88      2980\n",
      "\n",
      "Confusion_matrix\n",
      "[[2711   14]\n",
      " [ 238   17]]\n",
      "done in 0.960931s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19931\n",
      "           1       0.28      0.00      0.01      1967\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.59      0.50      0.48     21898\n",
      "weighted avg       0.85      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19918    13]\n",
      " [ 1962     5]]\n",
      "done in 19.871417s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19956\n",
      "           1       0.56      0.00      0.01      1942\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.73      0.50      0.48     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19952     4]\n",
      " [ 1937     5]]\n",
      "done in 20.118606s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17217\n",
      "           1       0.60      0.01      0.01      1688\n",
      "\n",
      "    accuracy                           0.91     18905\n",
      "   macro avg       0.76      0.50      0.48     18905\n",
      "weighted avg       0.88      0.91      0.87     18905\n",
      "\n",
      "Confusion_matrix\n",
      "[[17211     6]\n",
      " [ 1679     9]]\n",
      "done in 19.986542s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17231\n",
      "           1       0.44      0.00      0.00      1687\n",
      "\n",
      "    accuracy                           0.91     18918\n",
      "   macro avg       0.68      0.50      0.48     18918\n",
      "weighted avg       0.87      0.91      0.87     18918\n",
      "\n",
      "Confusion_matrix\n",
      "[[17226     5]\n",
      " [ 1683     4]]\n",
      "done in 19.874004s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2714\n",
      "           1       1.00      0.00      0.01       279\n",
      "\n",
      "    accuracy                           0.91      2993\n",
      "   macro avg       0.95      0.50      0.48      2993\n",
      "weighted avg       0.92      0.91      0.86      2993\n",
      "\n",
      "Confusion_matrix\n",
      "[[2714    0]\n",
      " [ 278    1]]\n",
      "done in 19.668024s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.96      2725\n",
      "           1       0.50      0.00      0.01       255\n",
      "\n",
      "    accuracy                           0.91      2980\n",
      "   macro avg       0.71      0.50      0.48      2980\n",
      "weighted avg       0.88      0.91      0.87      2980\n",
      "\n",
      "Confusion_matrix\n",
      "[[2724    1]\n",
      " [ 254    1]]\n",
      "done in 19.623776s\n",
      "0.2649943867570085\n",
      "0.2698423370473158\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19931\n",
      "           1       0.33      0.00      0.01      1967\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.62      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19921    10]\n",
      " [ 1962     5]]\n",
      "done in 0.653006s\n",
      "0.2649943867570085\n",
      "0.2675627714271921\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19956\n",
      "           1       0.35      0.00      0.01      1942\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.63      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19943    13]\n",
      " [ 1935     7]]\n",
      "done in 0.612687s\n",
      "0.2649943867570085\n",
      "0.26939186254002206\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17217\n",
      "           1       0.29      0.00      0.00      1688\n",
      "\n",
      "    accuracy                           0.91     18905\n",
      "   macro avg       0.60      0.50      0.48     18905\n",
      "weighted avg       0.85      0.91      0.87     18905\n",
      "\n",
      "Confusion_matrix\n",
      "[[17212     5]\n",
      " [ 1686     2]]\n",
      "done in 0.662908s\n",
      "0.2649943867570085\n",
      "0.26901786238039543\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17231\n",
      "           1       0.44      0.00      0.00      1687\n",
      "\n",
      "    accuracy                           0.91     18918\n",
      "   macro avg       0.68      0.50      0.48     18918\n",
      "weighted avg       0.87      0.91      0.87     18918\n",
      "\n",
      "Confusion_matrix\n",
      "[[17226     5]\n",
      " [ 1683     4]]\n",
      "done in 0.625536s\n",
      "0.2649943867570085\n",
      "0.2726877164527246\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2714\n",
      "           1       0.38      0.01      0.02       279\n",
      "\n",
      "    accuracy                           0.91      2993\n",
      "   macro avg       0.64      0.50      0.49      2993\n",
      "weighted avg       0.86      0.91      0.86      2993\n",
      "\n",
      "Confusion_matrix\n",
      "[[2709    5]\n",
      " [ 276    3]]\n",
      "done in 0.600332s\n",
      "0.2649943867570085\n",
      "0.2583253853021249\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.95      2725\n",
      "           1       0.27      0.01      0.02       255\n",
      "\n",
      "    accuracy                           0.91      2980\n",
      "   macro avg       0.59      0.50      0.49      2980\n",
      "weighted avg       0.86      0.91      0.87      2980\n",
      "\n",
      "Confusion_matrix\n",
      "[[2717    8]\n",
      " [ 252    3]]\n",
      "done in 0.616702s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19931\n",
      "           1       0.46      0.02      0.04      1967\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19881    50]\n",
      " [ 1925    42]]\n",
      "done in 32.934683s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19956\n",
      "           1       0.43      0.02      0.04      1942\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19900    56]\n",
      " [ 1900    42]]\n",
      "done in 33.024736s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17217\n",
      "           1       0.44      0.02      0.04      1688\n",
      "\n",
      "    accuracy                           0.91     18905\n",
      "   macro avg       0.68      0.51      0.49     18905\n",
      "weighted avg       0.87      0.91      0.87     18905\n",
      "\n",
      "Confusion_matrix\n",
      "[[17176    41]\n",
      " [ 1656    32]]\n",
      "done in 33.037970s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17231\n",
      "           1       0.41      0.02      0.04      1687\n",
      "\n",
      "    accuracy                           0.91     18918\n",
      "   macro avg       0.66      0.51      0.50     18918\n",
      "weighted avg       0.87      0.91      0.87     18918\n",
      "\n",
      "Confusion_matrix\n",
      "[[17184    47]\n",
      " [ 1654    33]]\n",
      "done in 33.182446s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2714\n",
      "           1       0.53      0.04      0.07       279\n",
      "\n",
      "    accuracy                           0.91      2993\n",
      "   macro avg       0.72      0.52      0.51      2993\n",
      "weighted avg       0.87      0.91      0.87      2993\n",
      "\n",
      "Confusion_matrix\n",
      "[[2705    9]\n",
      " [ 269   10]]\n",
      "done in 32.992053s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2725\n",
      "           1       0.50      0.04      0.07       255\n",
      "\n",
      "    accuracy                           0.91      2980\n",
      "   macro avg       0.71      0.52      0.51      2980\n",
      "weighted avg       0.88      0.91      0.88      2980\n",
      "\n",
      "Confusion_matrix\n",
      "[[2716    9]\n",
      " [ 246    9]]\n",
      "done in 32.976156s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.393\n",
      "threshold:0.2, J-value:0.255\n",
      "threshold:0.30000000000000004, J-value:0.149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.4, J-value:0.07\n",
      "threshold:0.5, J-value:0.037000000000000005\n",
      "threshold:0.6000000000000001, J-value:0.009999999999999998\n",
      "threshold:0.7000000000000001, J-value:0.003\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6964505938982116\n",
      "Balanced accuracy score of test is  0.7007504821627146\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.391\n",
      "threshold:0.2, J-value:0.24900000000000003\n",
      "threshold:0.30000000000000004, J-value:0.152\n",
      "threshold:0.4, J-value:0.07100000000000001\n",
      "threshold:0.5, J-value:0.037000000000000005\n",
      "threshold:0.6000000000000001, J-value:0.009999999999999998\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.695777701114874\n",
      "Balanced accuracy score of test is  0.7004161727648129\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.403\n",
      "threshold:0.2, J-value:0.288\n",
      "threshold:0.30000000000000004, J-value:0.131\n",
      "threshold:0.4, J-value:0.06899999999999999\n",
      "threshold:0.5, J-value:0.033\n",
      "threshold:0.6000000000000001, J-value:0.012\n",
      "threshold:0.7000000000000001, J-value:0.006\n",
      "threshold:0.8, J-value:0.003\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7012900056259459\n",
      "Balanced accuracy score of test is  0.7024177010253643\n",
      "True positive rate of class 1 is  0.659\n",
      "True positive rate of class 2 is  0.635\n",
      "Positive prediction rate of class 1 is  0.293\n",
      "Positive prediction rate of class 2 is  0.265\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.387\n",
      "threshold:0.2, J-value:0.28300000000000003\n",
      "threshold:0.30000000000000004, J-value:0.11499999999999999\n",
      "threshold:0.4, J-value:0.024\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6931398326769296\n",
      "Balanced accuracy score of test is  0.7000729101448522\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.375\n",
      "threshold:0.2, J-value:0.276\n",
      "threshold:0.30000000000000004, J-value:0.12\n",
      "threshold:0.4, J-value:0.027\n",
      "threshold:0.5, J-value:0.005\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6872325400580876\n",
      "Balanced accuracy score of test is  0.6953204335233878\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41800000000000004\n",
      "threshold:0.2, J-value:0.352\n",
      "threshold:0.30000000000000004, J-value:0.123\n",
      "threshold:0.4, J-value:0.016999999999999998\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7092812259807767\n",
      "Balanced accuracy score of test is  0.7099442345745638\n",
      "True positive rate of class 1 is  0.734\n",
      "True positive rate of class 2 is  0.773\n",
      "Positive prediction rate of class 1 is  0.379\n",
      "Positive prediction rate of class 2 is  0.389\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.36099999999999993\n",
      "threshold:0.2, J-value:0.20099999999999996\n",
      "threshold:0.30000000000000004, J-value:0.093\n",
      "threshold:0.4, J-value:0.012\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6805777976724325\n",
      "Balanced accuracy score of test is  0.683010862827159\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.3559999999999999\n",
      "threshold:0.2, J-value:0.20299999999999996\n",
      "threshold:0.30000000000000004, J-value:0.095\n",
      "threshold:0.4, J-value:0.012\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6780735252300782\n",
      "Balanced accuracy score of test is  0.68148376241288\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.394\n",
      "threshold:0.2, J-value:0.184\n",
      "threshold:0.30000000000000004, J-value:0.07899999999999999\n",
      "threshold:0.4, J-value:0.018000000000000002\n",
      "threshold:0.5, J-value:0.012\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.696953008824547\n",
      "Balanced accuracy score of test is  0.6920489296636085\n",
      "True positive rate of class 1 is  0.699\n",
      "True positive rate of class 2 is  0.667\n",
      "Positive prediction rate of class 1 is  0.368\n",
      "Positive prediction rate of class 2 is  0.315\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.4\n",
      "threshold:0.2, J-value:0.266\n",
      "threshold:0.30000000000000004, J-value:0.14\n",
      "threshold:0.4, J-value:0.060000000000000005\n",
      "threshold:0.5, J-value:0.018000000000000002\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7001140462302111\n",
      "Balanced accuracy score of test is  0.705527598409601\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.395\n",
      "threshold:0.2, J-value:0.266\n",
      "threshold:0.30000000000000004, J-value:0.14200000000000002\n",
      "threshold:0.4, J-value:0.059000000000000004\n",
      "threshold:0.5, J-value:0.017\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6974152351899519\n",
      "Balanced accuracy score of test is  0.7052201720634399\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.43400000000000005\n",
      "threshold:0.2, J-value:0.266\n",
      "threshold:0.30000000000000004, J-value:0.127\n",
      "threshold:0.4, J-value:0.068\n",
      "threshold:0.5, J-value:0.032999999999999995\n",
      "threshold:0.6000000000000001, J-value:0.009999999999999998\n",
      "threshold:0.7000000000000001, J-value:-0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7170677464256754\n",
      "Balanced accuracy score of test is  0.7071631588415183\n",
      "True positive rate of class 1 is  0.691\n",
      "True positive rate of class 2 is  0.675\n",
      "Positive prediction rate of class 1 is  0.317\n",
      "Positive prediction rate of class 2 is  0.296\n",
      "X train 65694\n",
      "Y train 65694\n",
      "21898 18847 3051\n",
      "21898 18847 3051\n",
      "21898 18817 3081\n",
      "21898 18817 3081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2599848723690683\n",
      "0.25514036585612926\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19973\n",
      "           1       0.52      0.04      0.07      1925\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.72      0.52      0.51     21898\n",
      "weighted avg       0.88      0.91      0.88     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19905    68]\n",
      " [ 1851    74]]\n",
      "done in 0.903564s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2599848723690683\n",
      "0.26502750161480243\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19866\n",
      "           1       0.45      0.03      0.06      2032\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.51      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19782    84]\n",
      " [ 1963    69]]\n",
      "done in 0.922397s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2599848723690683\n",
      "0.25503552980805894\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17189\n",
      "           1       0.50      0.04      0.07      1658\n",
      "\n",
      "    accuracy                           0.91     18847\n",
      "   macro avg       0.71      0.52      0.51     18847\n",
      "weighted avg       0.88      0.91      0.88     18847\n",
      "\n",
      "Confusion_matrix\n",
      "[[17130    59]\n",
      " [ 1598    60]]\n",
      "done in 0.900432s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2599848723690683\n",
      "0.26591197547752504\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17067\n",
      "           1       0.43      0.03      0.05      1750\n",
      "\n",
      "    accuracy                           0.91     18817\n",
      "   macro avg       0.67      0.51      0.50     18817\n",
      "weighted avg       0.86      0.91      0.87     18817\n",
      "\n",
      "Confusion_matrix\n",
      "[[17000    67]\n",
      " [ 1699    51]]\n",
      "done in 1.007260s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2599848723690683\n",
      "0.25578797155851585\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.95      2784\n",
      "           1       0.61      0.05      0.10       267\n",
      "\n",
      "    accuracy                           0.91      3051\n",
      "   macro avg       0.76      0.52      0.53      3051\n",
      "weighted avg       0.89      0.91      0.88      3051\n",
      "\n",
      "Confusion_matrix\n",
      "[[2775    9]\n",
      " [ 253   14]]\n",
      "done in 1.040701s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2599848723690683\n",
      "0.25962563706600295\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95      2799\n",
      "           1       0.51      0.06      0.11       282\n",
      "\n",
      "    accuracy                           0.91      3081\n",
      "   macro avg       0.71      0.53      0.53      3081\n",
      "weighted avg       0.88      0.91      0.88      3081\n",
      "\n",
      "Confusion_matrix\n",
      "[[2782   17]\n",
      " [ 264   18]]\n",
      "done in 1.270504s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19973\n",
      "           1       0.55      0.00      0.01      1925\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.73      0.50      0.48     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19968     5]\n",
      " [ 1919     6]]\n",
      "done in 19.445024s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19866\n",
      "           1       0.67      0.00      0.01      2032\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.79      0.50      0.48     21898\n",
      "weighted avg       0.89      0.91      0.86     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19863     3]\n",
      " [ 2026     6]]\n",
      "done in 19.863064s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17189\n",
      "           1       0.64      0.00      0.01      1658\n",
      "\n",
      "    accuracy                           0.91     18847\n",
      "   macro avg       0.77      0.50      0.48     18847\n",
      "weighted avg       0.89      0.91      0.87     18847\n",
      "\n",
      "Confusion_matrix\n",
      "[[17185     4]\n",
      " [ 1651     7]]\n",
      "done in 19.619401s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17067\n",
      "           1       0.42      0.00      0.01      1750\n",
      "\n",
      "    accuracy                           0.91     18817\n",
      "   macro avg       0.66      0.50      0.48     18817\n",
      "weighted avg       0.86      0.91      0.86     18817\n",
      "\n",
      "Confusion_matrix\n",
      "[[17060     7]\n",
      " [ 1745     5]]\n",
      "done in 19.416858s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2784\n",
      "           1       0.00      0.00      0.00       267\n",
      "\n",
      "    accuracy                           0.91      3051\n",
      "   macro avg       0.46      0.50      0.48      3051\n",
      "weighted avg       0.83      0.91      0.87      3051\n",
      "\n",
      "Confusion_matrix\n",
      "[[2784    0]\n",
      " [ 267    0]]\n",
      "done in 19.198140s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2799\n",
      "           1       0.00      0.00      0.00       282\n",
      "\n",
      "    accuracy                           0.91      3081\n",
      "   macro avg       0.45      0.50      0.48      3081\n",
      "weighted avg       0.83      0.91      0.86      3081\n",
      "\n",
      "Confusion_matrix\n",
      "[[2799    0]\n",
      " [ 282    0]]\n",
      "done in 19.175401s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26553645312445306\n",
      "0.27413100329676604\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19973\n",
      "           1       0.10      0.00      0.00      1925\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.51      0.50      0.48     21898\n",
      "weighted avg       0.84      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19955    18]\n",
      " [ 1923     2]]\n",
      "done in 0.616123s\n",
      "0.26553645312445306\n",
      "0.2781555748145189\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19866\n",
      "           1       0.11      0.00      0.00      2032\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.51      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.86     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19850    16]\n",
      " [ 2030     2]]\n",
      "done in 0.603733s\n",
      "0.26553645312445306\n",
      "0.26935524529999305\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17189\n",
      "           1       0.13      0.00      0.00      1658\n",
      "\n",
      "    accuracy                           0.91     18847\n",
      "   macro avg       0.52      0.50      0.48     18847\n",
      "weighted avg       0.84      0.91      0.87     18847\n",
      "\n",
      "Confusion_matrix\n",
      "[[17176    13]\n",
      " [ 1656     2]]\n",
      "done in 0.585295s\n",
      "0.26553645312445306\n",
      "0.28017006368715347\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17067\n",
      "           1       0.07      0.00      0.00      1750\n",
      "\n",
      "    accuracy                           0.91     18817\n",
      "   macro avg       0.49      0.50      0.48     18817\n",
      "weighted avg       0.83      0.91      0.86     18817\n",
      "\n",
      "Confusion_matrix\n",
      "[[17054    13]\n",
      " [ 1749     1]]\n",
      "done in 0.612739s\n",
      "0.26553645312445306\n",
      "0.2697583531593985\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2784\n",
      "           1       0.00      0.00      0.00       267\n",
      "\n",
      "    accuracy                           0.91      3051\n",
      "   macro avg       0.46      0.50      0.48      3051\n",
      "weighted avg       0.83      0.91      0.87      3051\n",
      "\n",
      "Confusion_matrix\n",
      "[[2782    2]\n",
      " [ 267    0]]\n",
      "done in 0.580134s\n",
      "0.26553645312445306\n",
      "0.2666521216051041\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2799\n",
      "           1       0.00      0.00      0.00       282\n",
      "\n",
      "    accuracy                           0.91      3081\n",
      "   macro avg       0.45      0.50      0.48      3081\n",
      "weighted avg       0.83      0.91      0.86      3081\n",
      "\n",
      "Confusion_matrix\n",
      "[[2796    3]\n",
      " [ 282    0]]\n",
      "done in 0.606931s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19973\n",
      "           1       0.50      0.02      0.04      1925\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.71      0.51      0.49     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19938    35]\n",
      " [ 1890    35]]\n",
      "done in 32.965042s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19866\n",
      "           1       0.49      0.02      0.04      2032\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.70      0.51      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19825    41]\n",
      " [ 1992    40]]\n",
      "done in 33.463663s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17189\n",
      "           1       0.46      0.02      0.03      1658\n",
      "\n",
      "    accuracy                           0.91     18847\n",
      "   macro avg       0.69      0.51      0.49     18847\n",
      "weighted avg       0.87      0.91      0.87     18847\n",
      "\n",
      "Confusion_matrix\n",
      "[[17159    30]\n",
      " [ 1632    26]]\n",
      "done in 33.278041s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17067\n",
      "           1       0.50      0.02      0.04      1750\n",
      "\n",
      "    accuracy                           0.91     18817\n",
      "   macro avg       0.70      0.51      0.49     18817\n",
      "weighted avg       0.87      0.91      0.87     18817\n",
      "\n",
      "Confusion_matrix\n",
      "[[17032    35]\n",
      " [ 1715    35]]\n",
      "done in 33.419895s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.95      2784\n",
      "           1       0.64      0.03      0.06       267\n",
      "\n",
      "    accuracy                           0.91      3051\n",
      "   macro avg       0.78      0.52      0.51      3051\n",
      "weighted avg       0.89      0.91      0.88      3051\n",
      "\n",
      "Confusion_matrix\n",
      "[[2779    5]\n",
      " [ 258    9]]\n",
      "done in 33.266913s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2799\n",
      "           1       0.45      0.02      0.03       282\n",
      "\n",
      "    accuracy                           0.91      3081\n",
      "   macro avg       0.68      0.51      0.49      3081\n",
      "weighted avg       0.87      0.91      0.87      3081\n",
      "\n",
      "Confusion_matrix\n",
      "[[2793    6]\n",
      " [ 277    5]]\n",
      "done in 33.106867s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.40900000000000003\n",
      "threshold:0.2, J-value:0.26399999999999996\n",
      "threshold:0.30000000000000004, J-value:0.156\n",
      "threshold:0.4, J-value:0.08\n",
      "threshold:0.5, J-value:0.034999999999999996\n",
      "threshold:0.6000000000000001, J-value:0.012\n",
      "threshold:0.7000000000000001, J-value:0.003\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7044758475890505\n",
      "Balanced accuracy score of test is  0.7055447928284864\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.406\n",
      "threshold:0.2, J-value:0.26499999999999996\n",
      "threshold:0.30000000000000004, J-value:0.154\n",
      "threshold:0.4, J-value:0.078\n",
      "threshold:0.5, J-value:0.032999999999999995\n",
      "threshold:0.6000000000000001, J-value:0.013000000000000001\n",
      "threshold:0.7000000000000001, J-value:0.004\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7028266808218373\n",
      "Balanced accuracy score of test is  0.7057262888280642\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.429\n",
      "threshold:0.2, J-value:0.26\n",
      "threshold:0.30000000000000004, J-value:0.175\n",
      "threshold:0.4, J-value:0.094\n",
      "threshold:0.5, J-value:0.048999999999999995\n",
      "threshold:0.6000000000000001, J-value:0.006\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7145708220328038\n",
      "Balanced accuracy score of test is  0.7042598800483455\n",
      "True positive rate of class 1 is  0.669\n",
      "True positive rate of class 2 is  0.645\n",
      "Positive prediction rate of class 1 is  0.296\n",
      "Positive prediction rate of class 2 is  0.274\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.388\n",
      "threshold:0.2, J-value:0.275\n",
      "threshold:0.30000000000000004, J-value:0.10200000000000001\n",
      "threshold:0.4, J-value:0.02\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6941109068671277\n",
      "Balanced accuracy score of test is  0.7041020556230683\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.401\n",
      "threshold:0.2, J-value:0.277\n",
      "threshold:0.30000000000000004, J-value:0.101\n",
      "threshold:0.4, J-value:0.019\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7005089622708045\n",
      "Balanced accuracy score of test is  0.700696967414141\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.39799999999999996\n",
      "threshold:0.2, J-value:0.276\n",
      "threshold:0.30000000000000004, J-value:0.11599999999999999\n",
      "threshold:0.4, J-value:0.027\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6989639835980885\n",
      "Balanced accuracy score of test is  0.715187034883279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positive rate of class 1 is  0.742\n",
      "True positive rate of class 2 is  0.78\n",
      "Positive prediction rate of class 1 is  0.378\n",
      "Positive prediction rate of class 2 is  0.389\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.33799999999999997\n",
      "threshold:0.2, J-value:0.193\n",
      "threshold:0.30000000000000004, J-value:0.067\n",
      "threshold:0.4, J-value:0.054\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6691380116403898\n",
      "Balanced accuracy score of test is  0.674852813060101\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.33599999999999997\n",
      "threshold:0.2, J-value:0.195\n",
      "threshold:0.30000000000000004, J-value:0.07\n",
      "threshold:0.4, J-value:0.059000000000000004\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.668126202263756\n",
      "Balanced accuracy score of test is  0.6728513338188149\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.35200000000000004\n",
      "threshold:0.2, J-value:0.181\n",
      "threshold:0.30000000000000004, J-value:0.05199999999999999\n",
      "threshold:0.4, J-value:0.025\n",
      "threshold:0.5, J-value:-0.001\n",
      "threshold:0.6000000000000001, J-value:-0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6758362391837789\n",
      "Balanced accuracy score of test is  0.6852466306355613\n",
      "True positive rate of class 1 is  0.579\n",
      "True positive rate of class 2 is  0.571\n",
      "Positive prediction rate of class 1 is  0.266\n",
      "Positive prediction rate of class 2 is  0.234\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41899999999999993\n",
      "threshold:0.2, J-value:0.26299999999999996\n",
      "threshold:0.30000000000000004, J-value:0.14300000000000002\n",
      "threshold:0.4, J-value:0.053\n",
      "threshold:0.5, J-value:0.016\n",
      "threshold:0.6000000000000001, J-value:0.005\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7093144186209825\n",
      "Balanced accuracy score of test is  0.7089494940907228\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.4169999999999999\n",
      "threshold:0.2, J-value:0.26499999999999996\n",
      "threshold:0.30000000000000004, J-value:0.14400000000000002\n",
      "threshold:0.4, J-value:0.049\n",
      "threshold:0.5, J-value:0.014\n",
      "threshold:0.6000000000000001, J-value:0.004\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7086122489338533\n",
      "Balanced accuracy score of test is  0.7089518954707916\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.42700000000000005\n",
      "threshold:0.2, J-value:0.255\n",
      "threshold:0.30000000000000004, J-value:0.137\n",
      "threshold:0.4, J-value:0.07100000000000001\n",
      "threshold:0.5, J-value:0.032\n",
      "threshold:0.6000000000000001, J-value:0.011\n",
      "threshold:0.7000000000000001, J-value:0.004\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7135679000387447\n",
      "Balanced accuracy score of test is  0.7091552454143957\n",
      "True positive rate of class 1 is  0.692\n",
      "True positive rate of class 2 is  0.674\n",
      "Positive prediction rate of class 1 is  0.313\n",
      "Positive prediction rate of class 2 is  0.294\n"
     ]
    }
   ],
   "source": [
    "records_lr = []\n",
    "records_rf = []\n",
    "records_dt = []\n",
    "records_gbt = []\n",
    "for random_state in range(10):\n",
    "    fairness_metrics (X, y, \"Race_W\", random_state)\n",
    "\n",
    "result_lr = pd.DataFrame(records_lr)\n",
    "result_rf = pd.DataFrame(records_rf)\n",
    "result_dt = pd.DataFrame(records_dt)\n",
    "result_gbt = pd.DataFrame(records_gbt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def add_mean_sd(records, result_table, overall_records, type):\n",
    "    records.append({\n",
    "        'auroc': result_table[\"auroc\"].mean(),\n",
    "        'overall threshold': result_table[\"overall threshold\"].mean(),\n",
    "        'white threshold': result_table[\"white threshold\"].mean(),\n",
    "        'black threshold': result_table[\"black threshold\"].mean(),\n",
    "        'overall ba validation': result_table[\"overall ba validation\"].mean(),\n",
    "        'overall ba test': result_table[\"overall ba test\"].mean(),\n",
    "        'white ba validation': result_table[\"white ba validation\"].mean(),\n",
    "        'white ba test': result_table[\"white ba test\"].mean(),\n",
    "        'black ba validation': result_table[\"black ba validation\"].mean(),\n",
    "        'black ba test': result_table[\"black ba test\"].mean(),\n",
    "        'overall precision':result_table[\"overall precision\"].mean(),\n",
    "        'overall recall':result_table[\"overall recall\"].mean(),\n",
    "        'overall tpr':result_table[\"overall tpr\"].mean(),\n",
    "        'overall tnr':result_table[\"overall tnr\"].mean(),\n",
    "        'overall pd':result_table[\"overall pd\"].mean(),\n",
    "        'white precision':result_table[\"white precision\"].mean(),\n",
    "        'white recall':result_table[\"white recall\"].mean(),\n",
    "        'white tpr':result_table[\"white tpr\"].mean(),\n",
    "        'white tnr':result_table[\"white tnr\"].mean(),\n",
    "        'white pd':result_table[\"white pd\"].mean(),\n",
    "        'black precision':result_table[\"black precision\"].mean(),\n",
    "        'black recall':result_table[\"black recall\"].mean(),\n",
    "        'black tpr':result_table[\"black tpr\"].mean(),\n",
    "        'black tnr':result_table[\"black tnr\"].mean(),\n",
    "        'black pd':result_table[\"black pd\"].mean(),\n",
    "        'eod': result_table[\"eod\"].mean(),\n",
    "        'di': result_table[\"di\"].mean(),\n",
    "        })\n",
    "    records.append({\n",
    "        'auroc': result_table[\"auroc\"].std(),\n",
    "        'overall threshold': result_table[\"overall threshold\"].std(),\n",
    "        'white threshold': result_table[\"white threshold\"].std(),\n",
    "        'black threshold': result_table[\"black threshold\"].std(),\n",
    "        'overall ba validation': result_table[\"overall ba validation\"].std(),\n",
    "        'overall ba test': result_table[\"overall ba test\"].std(),\n",
    "        'white ba validation': result_table[\"white ba validation\"].std(),\n",
    "        'white ba test': result_table[\"white ba test\"].std(),\n",
    "        'black ba validation': result_table[\"black ba validation\"].std(),\n",
    "        'black ba test': result_table[\"black ba test\"].std(),\n",
    "        'overall precision':result_table[\"overall precision\"].std(),\n",
    "        'overall recall':result_table[\"overall recall\"].std(),\n",
    "        'overall tpr':result_table[\"overall tpr\"].std(),\n",
    "        'overall tnr':result_table[\"overall tnr\"].std(),\n",
    "        'overall pd':result_table[\"overall pd\"].std(),\n",
    "        'white precision':result_table[\"white precision\"].std(),\n",
    "        'white recall':result_table[\"white recall\"].std(),\n",
    "        'white tpr':result_table[\"white tpr\"].std(),\n",
    "        'white tnr':result_table[\"white tnr\"].std(),\n",
    "        'white pd':result_table[\"white pd\"].std(),\n",
    "        'black precision':result_table[\"black precision\"].std(),\n",
    "        'black recall':result_table[\"black recall\"].std(),\n",
    "        'black tpr':result_table[\"black tpr\"].std(),\n",
    "        'black tnr':result_table[\"black tnr\"].std(),\n",
    "        'black pd':result_table[\"black pd\"].std(),\n",
    "        'eod': result_table[\"eod\"].std(),\n",
    "        'di': result_table[\"di\"].std(),\n",
    "        })\n",
    "    overall_records.append({\n",
    "        'type': type,\n",
    "        'auroc': result_table[\"auroc\"].mean(),\n",
    "        'overall threshold': result_table[\"overall threshold\"].mean(),\n",
    "        'white threshold': result_table[\"white threshold\"].mean(),\n",
    "        'black threshold': result_table[\"black threshold\"].mean(),\n",
    "        'overall ba test': result_table[\"overall ba test\"].mean(),\n",
    "        'white ba test': result_table[\"white ba test\"].mean(),\n",
    "        'black ba test': result_table[\"black ba test\"].mean(),\n",
    "        'overall tpr':result_table[\"overall tpr\"].mean(),\n",
    "        'overall pd':result_table[\"overall pd\"].mean(),\n",
    "        'white tpr':result_table[\"white tpr\"].mean(),\n",
    "        'white pd':result_table[\"white pd\"].mean(),\n",
    "        'black tpr':result_table[\"black tpr\"].mean(),\n",
    "        'black pd':result_table[\"black pd\"].mean(),\n",
    "        'eod': result_table[\"eod\"].mean(),\n",
    "        'di': result_table[\"di\"].mean(),\n",
    "        })\n",
    "    pd_result = pd.DataFrame(records)\n",
    "    return pd_result, overall_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "overall_table = []\n",
    "result_lr, overall_records = add_mean_sd (records_lr, result_lr, overall_table, 'lr')\n",
    "result_rf, overall_records = add_mean_sd (records_rf, result_rf, overall_records, 'rf')\n",
    "result_dt, overall_records = add_mean_sd (records_dt, result_dt, overall_records, 'dt')\n",
    "result_gbt, overall_records = add_mean_sd (records_gbt, result_gbt, overall_records, 'gbt')\n",
    "\n",
    "result_path='/Users/lifuchen/Desktop/research/resample_data/'\n",
    "result_lr.to_csv(path.join(result_path,'race-lr-result_no_protected.csv'), index=False)\n",
    "result_rf.to_csv(path.join(result_path,'race-rf-result_no_protected.csv'), index=False)\n",
    "result_dt.to_csv(path.join(result_path,'race-dt-result_no_protected.csv'), index=False)\n",
    "result_gbt.to_csv(path.join(result_path,'race-gbt-result_no_protected.csv'), index=False)\n",
    "\n",
    "overall_result = pd.DataFrame(overall_table)\n",
    "result_path='/Users/lifuchen/Desktop/research/resample_result/'\n",
    "overall_result.to_csv(path.join(result_path,'race_no_protected.csv'), index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
