{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import imblearn\n",
    "from os import path\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score\n",
    "import sklearn.preprocessing\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import src.lib.utility_classfier as uclf\n",
    "import src.lib.optimal_threhold_related as thres\n",
    "import src.lib.fairness_tests as fair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109490, 89)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path='/Users/lifuchen/Desktop/research/data.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109490, 87)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df.Class.values\n",
    "X = df.drop(['GRID','Class'], axis=1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def save_prediction(classifier, characteristic, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_male_scaled, y_val_male, X_test_male_scaled, y_test_male, X_val_female_scaled, y_val_female, X_test_female_scaled, y_test_female):\n",
    "    method_to_call = getattr(uclf, classifier)\n",
    "    y_val_score = method_to_call(X_train_scaled, y_train,X_val_scaled, y_val)\n",
    "    y_test_score = method_to_call(X_train_scaled, y_train,X_test_scaled, y_test)\n",
    "\n",
    "    y_val_score_male = method_to_call(X_train_scaled, y_train, X_val_male_scaled, y_val_male)\n",
    "    y_test_score_male = method_to_call(X_train_scaled, y_train,X_test_male_scaled, y_test_male)\n",
    "\n",
    "    y_val_score_female = method_to_call(X_train_scaled, y_train, X_val_female_scaled, y_val_female)\n",
    "    y_test_score_female = method_to_call(X_train_scaled, y_train,X_test_female_scaled, y_test_female)\n",
    "\n",
    "    my_dict = dict(val_score = y_val_score, test_score = y_test_score, val_1_score = y_val_score_male, test_1_score = y_test_score_male, val_2_score = y_val_score_female, test_2_score = y_test_score_female)\n",
    "    overall_prediction = pd.DataFrame.from_dict(my_dict, orient='index')\n",
    "    overall_prediction = overall_prediction.transpose()\n",
    "\n",
    "    result_path='/Users/lifuchen/Desktop/research/predictions/'\n",
    "    filename = str(classifier) + str(characteristic) + \"prediction.csv\"\n",
    "    overall_prediction.to_csv(path.join(result_path, filename), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_result (classifier, characteristic, records, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_male_scaled, y_val_male, X_test_male_scaled, y_test_male, X_val_female_scaled, y_val_female, X_test_female_scaled, y_test_female):\n",
    "    result_path='/Users/lifuchen/Desktop/research/predictions/'\n",
    "    filename = str(classifier) + characteristic + \"prediction.csv\"\n",
    "    prediction = pd.read_csv(path.join(result_path, filename))\n",
    "\n",
    "    y_val_score = prediction['val_score'][prediction['val_score'].notna()]\n",
    "    y_test_score = prediction['test_score'][prediction['test_score'].notna()]\n",
    "\n",
    "    y_val_score_male = prediction['val_1_score'][prediction['val_1_score'].notna()]\n",
    "    y_test_score_male = prediction['test_1_score'][prediction['test_1_score'].notna()]\n",
    "\n",
    "    y_val_score_female = prediction['val_2_score'][prediction['val_2_score'].notna()]\n",
    "    y_test_score_female = prediction['test_2_score'][prediction['test_2_score'].notna()]\n",
    "\n",
    "    threshold, ba_val, ba_test = balance_accuracy (y_val, y_val_score,y_test, y_test_score)\n",
    "    auroc = roc_auc_score(y_test, y_test_score)\n",
    "    precision, recall, tpr, tnr, pd_overall = thres.calculate_precision_metrics(y_test, y_test_score,threshold)\n",
    "\n",
    "    threshold_male, ba_val_male, ba_test_male = balance_accuracy (y_val_male, y_val_score_male,y_test_male, y_test_score_male)\n",
    "    precision_male, recall_male, tpr_male, tnr_male, pd_male = thres.calculate_precision_metrics(y_test_male, y_test_score_male,threshold_male)\n",
    "\n",
    "    threshold_female, ba_val_female, ba_test_female = balance_accuracy (y_val_female, y_val_score_female, y_test_female, y_test_score_female)\n",
    "    precision_female, recall_female, tpr_female, tnr_female, pd_female = thres.calculate_precision_metrics(y_test_female, y_test_score_female,threshold_female)\n",
    "\n",
    "    eod = fair.get_EOD(y_test_male, y_test_score_male,threshold_male, y_test_female, y_test_score_female, threshold_female)\n",
    "    sp = fair.get_SP(y_test_male, y_test_score_male,threshold_male, y_test_female, y_test_score_female, threshold_female)\n",
    "\n",
    "    records.append({\n",
    "        'auroc': auroc,\n",
    "        'overall threshold': threshold,\n",
    "        'male threshold': threshold_male,\n",
    "        'female threshold': threshold_female,\n",
    "        'overall ba validation': ba_val,\n",
    "        'overall ba test': ba_test,\n",
    "        'male ba validation': ba_val_male,\n",
    "        'male ba test': ba_test_male,\n",
    "        'female ba validation': ba_val_female,\n",
    "        'female ba test': ba_test_female,\n",
    "        'overall precision':precision,\n",
    "        'overall recall':recall,\n",
    "        'overall tpr':tpr,\n",
    "        'overall tnr':tnr,\n",
    "        'overall pd':pd_overall,\n",
    "        'male precision':precision_male,\n",
    "        'male recall':recall_male,\n",
    "        'male tpr':tpr_male,\n",
    "        'male tnr':tnr_male,\n",
    "        'male pd':pd_male,\n",
    "        'female precision':precision_female,\n",
    "        'female recall':recall_female,\n",
    "        'female tpr':tpr_female,\n",
    "        'female tnr':tnr_female,\n",
    "        'female pd':pd_female,\n",
    "        'eod': eod,\n",
    "        'di': sp,\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def balance_accuracy (y_val, y_val_score,y_test, y_test_score):\n",
    "    \n",
    "    threshold, _ = thres.get_optimal_threshold_Jvalue (y_val, y_val_score)\n",
    "    print (\"Optimal threshold by J value is \",threshold)\n",
    "\n",
    "    ba_val = thres.calculate_balanced_accuracy(y_val, y_val_score, threshold)\n",
    "    print (\"Balanced accuracy score of val is \", ba_val)\n",
    "\n",
    "    ba_test = thres.calculate_balanced_accuracy(y_test, y_test_score, threshold)\n",
    "    print (\"Balanced accuracy score of test is \",ba_test)\n",
    "\n",
    "    return threshold, ba_val, ba_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def fairness_metrics (X, y, attribute, random_state):\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, X_val_female, X_val_male, y_val_female, y_val_male, X_test_female, X_test_male, y_test_female, y_test_male \\\n",
    "        = fair.split_by_trait_balance_proportion_no_protected_trait(X, y, attribute, random_state)\n",
    "    print(\"X train\", X_train.shape[0])\n",
    "    print(\"Y train\", y_train.shape[0])\n",
    "    print(X_val.shape[0], X_val_male.shape[0], X_val_female.shape[0])\n",
    "    print(y_val.shape[0], y_val_male.shape[0], y_val_female.shape[0])\n",
    "    print(X_test.shape[0], X_test_male.shape[0], X_test_female.shape[0])\n",
    "    print(y_test.shape[0], y_test_male.shape[0], y_test_female.shape[0])\n",
    "\n",
    "    max_abs_scaler = preprocessing.MaxAbsScaler()\n",
    "    X_train_scaled = max_abs_scaler.fit_transform(X_train)\n",
    "    X_test_scaled = max_abs_scaler.transform(X_test)\n",
    "    X_test_male_scaled = max_abs_scaler.transform(X_test_male)\n",
    "    X_test_female_scaled = max_abs_scaler.transform(X_test_female)\n",
    "    X_val_scaled = max_abs_scaler.transform(X_val)\n",
    "    X_val_male_scaled = max_abs_scaler.transform(X_val_male)\n",
    "    X_val_female_scaled = max_abs_scaler.transform(X_val_female)\n",
    "\n",
    "    characteristic = attribute + \"resample-by-proportion\" + str(random_state)\n",
    "    save_prediction (\"logic_regression\", characteristic, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_male_scaled, y_val_male, X_test_male_scaled, y_test_male, X_val_female_scaled, y_val_female, X_test_female_scaled, y_test_female)\n",
    "    save_prediction (\"random_forest\", characteristic, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_male_scaled, y_val_male, X_test_male_scaled, y_test_male, X_val_female_scaled, y_val_female, X_test_female_scaled, y_test_female)\n",
    "    save_prediction (\"decision_tree\", characteristic, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_male_scaled, y_val_male, X_test_male_scaled, y_test_male, X_val_female_scaled, y_val_female, X_test_female_scaled, y_test_female)\n",
    "    save_prediction (\"gradiant_boosting\", characteristic, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_male_scaled, y_val_male, X_test_male_scaled, y_test_male, X_val_female_scaled, y_val_female, X_test_female_scaled, y_test_female)\n",
    "\n",
    "    get_result (\"logic_regression\", characteristic, records_lr, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_male_scaled, y_val_male, X_test_male_scaled, y_test_male, X_val_female_scaled, y_val_female, X_test_female_scaled, y_test_female)\n",
    "    get_result (\"random_forest\", characteristic, records_rf, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_male_scaled, y_val_male, X_test_male_scaled, y_test_male, X_val_female_scaled, y_val_female, X_test_female_scaled, y_test_female)\n",
    "    get_result (\"decision_tree\", characteristic, records_dt, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_male_scaled, y_val_male, X_test_male_scaled, y_test_male, X_val_female_scaled, y_val_female, X_test_female_scaled, y_test_female)\n",
    "    get_result (\"gradiant_boosting\", characteristic, records_gbt, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_male_scaled, y_val_male, X_test_male_scaled, y_test_male, X_val_female_scaled, y_val_female, X_test_female_scaled, y_test_female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lifuchen/Desktop/research/CVDPrediction-master/src/lib/fairness_tests.py:272: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train ['Class'] = y_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23364, 88)\n",
      "(42330, 88)\n",
      "0.12175917034760898 0.08538461538461538\n",
      "0.12174358974358974\n",
      "(67112, 87)\n",
      "X train 67112\n",
      "Y train 67112\n",
      "21898 7782 14116\n",
      "21898 7782 14116\n",
      "21898 7707 14191\n",
      "21898 7707 14191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2900474063766968\n",
      "0.26632413896430224\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19904\n",
      "           1       0.44      0.04      0.07      1994\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.52      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19816    88]\n",
      " [ 1924    70]]\n",
      "done in 0.660612s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2900474063766968\n",
      "0.26813915239089947\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19934\n",
      "           1       0.39      0.03      0.06      1964\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.65      0.51      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19836    98]\n",
      " [ 1902    62]]\n",
      "done in 0.644881s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2900474063766968\n",
      "0.30757232922912725\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6915\n",
      "           1       0.50      0.03      0.05       867\n",
      "\n",
      "    accuracy                           0.89      7782\n",
      "   macro avg       0.70      0.51      0.50      7782\n",
      "weighted avg       0.85      0.89      0.84      7782\n",
      "\n",
      "Confusion_matrix\n",
      "[[6892   23]\n",
      " [ 844   23]]\n",
      "done in 0.670199s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2900474063766968\n",
      "0.30475578647059626\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6860\n",
      "           1       0.51      0.02      0.05       847\n",
      "\n",
      "    accuracy                           0.89      7707\n",
      "   macro avg       0.70      0.51      0.49      7707\n",
      "weighted avg       0.85      0.89      0.84      7707\n",
      "\n",
      "Confusion_matrix\n",
      "[[6840   20]\n",
      " [ 826   21]]\n",
      "done in 0.544270s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2900474063766968\n",
      "0.2435844523221325\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96     12989\n",
      "           1       0.42      0.04      0.08      1127\n",
      "\n",
      "    accuracy                           0.92     14116\n",
      "   macro avg       0.67      0.52      0.52     14116\n",
      "weighted avg       0.88      0.92      0.89     14116\n",
      "\n",
      "Confusion_matrix\n",
      "[[12924    65]\n",
      " [ 1080    47]]\n",
      "done in 0.583437s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2900474063766968\n",
      "0.24825299927609265\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96     13074\n",
      "           1       0.34      0.04      0.07      1117\n",
      "\n",
      "    accuracy                           0.92     14191\n",
      "   macro avg       0.63      0.52      0.51     14191\n",
      "weighted avg       0.88      0.92      0.89     14191\n",
      "\n",
      "Confusion_matrix\n",
      "[[12996    78]\n",
      " [ 1076    41]]\n",
      "done in 0.577790s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19904\n",
      "           1       0.38      0.00      0.01      1994\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.65      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19891    13]\n",
      " [ 1986     8]]\n",
      "done in 17.403412s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19934\n",
      "           1       0.42      0.00      0.01      1964\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.66      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19927     7]\n",
      " [ 1959     5]]\n",
      "done in 17.897760s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6915\n",
      "           1       0.50      0.00      0.01       867\n",
      "\n",
      "    accuracy                           0.89      7782\n",
      "   macro avg       0.69      0.50      0.47      7782\n",
      "weighted avg       0.85      0.89      0.84      7782\n",
      "\n",
      "Confusion_matrix\n",
      "[[6912    3]\n",
      " [ 864    3]]\n",
      "done in 18.041955s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6860\n",
      "           1       0.50      0.00      0.01       847\n",
      "\n",
      "    accuracy                           0.89      7707\n",
      "   macro avg       0.70      0.50      0.47      7707\n",
      "weighted avg       0.85      0.89      0.84      7707\n",
      "\n",
      "Confusion_matrix\n",
      "[[6857    3]\n",
      " [ 844    3]]\n",
      "done in 20.556563s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12989\n",
      "           1       0.50      0.01      0.01      1127\n",
      "\n",
      "    accuracy                           0.92     14116\n",
      "   macro avg       0.71      0.50      0.48     14116\n",
      "weighted avg       0.89      0.92      0.88     14116\n",
      "\n",
      "Confusion_matrix\n",
      "[[12983     6]\n",
      " [ 1121     6]]\n",
      "done in 18.741002s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13074\n",
      "           1       0.50      0.00      0.01      1117\n",
      "\n",
      "    accuracy                           0.92     14191\n",
      "   macro avg       0.71      0.50      0.48     14191\n",
      "weighted avg       0.89      0.92      0.88     14191\n",
      "\n",
      "Confusion_matrix\n",
      "[[13069     5]\n",
      " [ 1112     5]]\n",
      "done in 18.182141s\n",
      "0.30186566200281223\n",
      "0.27780502565594656\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19904\n",
      "           1       0.25      0.00      0.00      1994\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.58      0.50      0.48     21898\n",
      "weighted avg       0.85      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19901     3]\n",
      " [ 1993     1]]\n",
      "done in 0.610439s\n",
      "0.30186566200281223\n",
      "0.2783221451636195\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19934\n",
      "           1       0.00      0.00      0.00      1964\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.46      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19927     7]\n",
      " [ 1964     0]]\n",
      "done in 0.607015s\n",
      "0.30186566200281223\n",
      "0.3252841378167604\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6915\n",
      "           1       0.25      0.00      0.00       867\n",
      "\n",
      "    accuracy                           0.89      7782\n",
      "   macro avg       0.57      0.50      0.47      7782\n",
      "weighted avg       0.82      0.89      0.84      7782\n",
      "\n",
      "Confusion_matrix\n",
      "[[6912    3]\n",
      " [ 866    1]]\n",
      "done in 0.598304s\n",
      "0.30186566200281223\n",
      "0.31952781941864367\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6860\n",
      "           1       0.00      0.00      0.00       847\n",
      "\n",
      "    accuracy                           0.89      7707\n",
      "   macro avg       0.45      0.50      0.47      7707\n",
      "weighted avg       0.79      0.89      0.84      7707\n",
      "\n",
      "Confusion_matrix\n",
      "[[6857    3]\n",
      " [ 847    0]]\n",
      "done in 0.625808s\n",
      "0.30186566200281223\n",
      "0.25405605949354126\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12989\n",
      "           1       0.00      0.00      0.00      1127\n",
      "\n",
      "    accuracy                           0.92     14116\n",
      "   macro avg       0.46      0.50      0.48     14116\n",
      "weighted avg       0.85      0.92      0.88     14116\n",
      "\n",
      "Confusion_matrix\n",
      "[[12988     1]\n",
      " [ 1127     0]]\n",
      "done in 0.585577s\n",
      "0.30186566200281223\n",
      "0.25594372704766777\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13074\n",
      "           1       0.00      0.00      0.00      1117\n",
      "\n",
      "    accuracy                           0.92     14191\n",
      "   macro avg       0.46      0.50      0.48     14191\n",
      "weighted avg       0.85      0.92      0.88     14191\n",
      "\n",
      "Confusion_matrix\n",
      "[[13070     4]\n",
      " [ 1117     0]]\n",
      "done in 0.583804s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19904\n",
      "           1       0.49      0.01      0.02      1994\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.70      0.51      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19878    26]\n",
      " [ 1969    25]]\n",
      "done in 33.603081s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19934\n",
      "           1       0.40      0.01      0.02      1964\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.65      0.50      0.49     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19905    29]\n",
      " [ 1945    19]]\n",
      "done in 33.367338s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6915\n",
      "           1       0.48      0.01      0.02       867\n",
      "\n",
      "    accuracy                           0.89      7782\n",
      "   macro avg       0.68      0.51      0.48      7782\n",
      "weighted avg       0.84      0.89      0.84      7782\n",
      "\n",
      "Confusion_matrix\n",
      "[[6903   12]\n",
      " [ 856   11]]\n",
      "done in 33.135066s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6860\n",
      "           1       0.58      0.01      0.03       847\n",
      "\n",
      "    accuracy                           0.89      7707\n",
      "   macro avg       0.74      0.51      0.48      7707\n",
      "weighted avg       0.86      0.89      0.84      7707\n",
      "\n",
      "Confusion_matrix\n",
      "[[6852    8]\n",
      " [ 836   11]]\n",
      "done in 32.322391s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12989\n",
      "           1       0.50      0.01      0.02      1127\n",
      "\n",
      "    accuracy                           0.92     14116\n",
      "   macro avg       0.71      0.51      0.49     14116\n",
      "weighted avg       0.89      0.92      0.88     14116\n",
      "\n",
      "Confusion_matrix\n",
      "[[12975    14]\n",
      " [ 1113    14]]\n",
      "done in 32.258155s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13074\n",
      "           1       0.28      0.01      0.01      1117\n",
      "\n",
      "    accuracy                           0.92     14191\n",
      "   macro avg       0.60      0.50      0.49     14191\n",
      "weighted avg       0.87      0.92      0.88     14191\n",
      "\n",
      "Confusion_matrix\n",
      "[[13053    21]\n",
      " [ 1109     8]]\n",
      "done in 32.733227s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.40599999999999997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.2, J-value:0.28\n",
      "threshold:0.30000000000000004, J-value:0.15\n",
      "threshold:0.4, J-value:0.079\n",
      "threshold:0.5, J-value:0.031000000000000003\n",
      "threshold:0.6000000000000001, J-value:0.011\n",
      "threshold:0.7000000000000001, J-value:0.003\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7029095727697562\n",
      "Balanced accuracy score of test is  0.6906734688831596\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.381\n",
      "threshold:0.2, J-value:0.241\n",
      "threshold:0.30000000000000004, J-value:0.10699999999999998\n",
      "threshold:0.4, J-value:0.049999999999999996\n",
      "threshold:0.5, J-value:0.024\n",
      "threshold:0.6000000000000001, J-value:0.006\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6907807859650177\n",
      "Balanced accuracy score of test is  0.6872436932269956\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.418\n",
      "threshold:0.2, J-value:0.311\n",
      "threshold:0.30000000000000004, J-value:0.183\n",
      "threshold:0.4, J-value:0.101\n",
      "threshold:0.5, J-value:0.037000000000000005\n",
      "threshold:0.6000000000000001, J-value:0.015\n",
      "threshold:0.7000000000000001, J-value:0.004\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7093710035035448\n",
      "Balanced accuracy score of test is  0.6900212261886713\n",
      "True positive rate of class 1 is  0.738\n",
      "True positive rate of class 2 is  0.701\n",
      "Positive prediction rate of class 1 is  0.405\n",
      "Positive prediction rate of class 2 is  0.351\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.392\n",
      "threshold:0.2, J-value:0.291\n",
      "threshold:0.30000000000000004, J-value:0.128\n",
      "threshold:0.4, J-value:0.029000000000000005\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6961144940045216\n",
      "Balanced accuracy score of test is  0.6840383857360655\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.36800000000000005\n",
      "threshold:0.2, J-value:0.29400000000000004\n",
      "threshold:0.30000000000000004, J-value:0.113\n",
      "threshold:0.4, J-value:0.033\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6838753824867959\n",
      "Balanced accuracy score of test is  0.6724736766016914\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.381\n",
      "threshold:0.2, J-value:0.311\n",
      "threshold:0.30000000000000004, J-value:0.134\n",
      "threshold:0.4, J-value:0.032\n",
      "threshold:0.5, J-value:0.005\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6905936652561724\n",
      "Balanced accuracy score of test is  0.6908669731926069\n",
      "True positive rate of class 1 is  0.802\n",
      "True positive rate of class 2 is  0.743\n",
      "Positive prediction rate of class 1 is  0.495\n",
      "Positive prediction rate of class 2 is  0.391\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.34800000000000003\n",
      "threshold:0.2, J-value:0.172\n",
      "threshold:0.30000000000000004, J-value:0.111\n",
      "threshold:0.4, J-value:0.043\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6738286352223875\n",
      "Balanced accuracy score of test is  0.6597202540277007\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.32599999999999996\n",
      "threshold:0.2, J-value:0.17500000000000002\n",
      "threshold:0.30000000000000004, J-value:0.09199999999999998\n",
      "threshold:0.4, J-value:0.055999999999999994\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6626685381310875\n",
      "Balanced accuracy score of test is  0.6453599739777848\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.35700000000000004\n",
      "threshold:0.2, J-value:0.16699999999999998\n",
      "threshold:0.30000000000000004, J-value:0.126\n",
      "threshold:0.4, J-value:0.031\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6783965655739144\n",
      "Balanced accuracy score of test is  0.66568256391652\n",
      "True positive rate of class 1 is  0.802\n",
      "True positive rate of class 2 is  0.778\n",
      "Positive prediction rate of class 1 is  0.543\n",
      "Positive prediction rate of class 2 is  0.473\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41500000000000004\n",
      "threshold:0.2, J-value:0.301\n",
      "threshold:0.30000000000000004, J-value:0.136\n",
      "threshold:0.4, J-value:0.047\n",
      "threshold:0.5, J-value:0.012\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7072601445816549\n",
      "Balanced accuracy score of test is  0.6956306881956894\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.388\n",
      "threshold:0.2, J-value:0.285\n",
      "threshold:0.30000000000000004, J-value:0.11099999999999999\n",
      "threshold:0.4, J-value:0.041\n",
      "threshold:0.5, J-value:0.011\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.694183198352711\n",
      "Balanced accuracy score of test is  0.6889104402091415\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.424\n",
      "threshold:0.2, J-value:0.31\n",
      "threshold:0.30000000000000004, J-value:0.154\n",
      "threshold:0.4, J-value:0.052\n",
      "threshold:0.5, J-value:0.011\n",
      "threshold:0.6000000000000001, J-value:0.002\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7115710085176843\n",
      "Balanced accuracy score of test is  0.6943601733209583\n",
      "True positive rate of class 1 is  0.784\n",
      "True positive rate of class 2 is  0.712\n",
      "Positive prediction rate of class 1 is  0.448\n",
      "Positive prediction rate of class 2 is  0.354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lifuchen/Desktop/research/CVDPrediction-master/src/lib/fairness_tests.py:272: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train ['Class'] = y_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23381, 88)\n",
      "(42313, 88)\n",
      "0.12489776280971855 0.0869274833671556\n",
      "0.12489403786380333\n",
      "(67172, 87)\n",
      "X train 67172\n",
      "Y train 67172\n",
      "21898 7665 14233\n",
      "21898 7665 14233\n",
      "21898 7807 14091\n",
      "21898 7807 14091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29384293083333485\n",
      "0.2613568837094544\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19980\n",
      "           1       0.42      0.03      0.06      1918\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.51     21898\n",
      "weighted avg       0.87      0.91      0.88     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19893    87]\n",
      " [ 1854    64]]\n",
      "done in 0.595534s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29384293083333485\n",
      "0.2618675763395544\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19972\n",
      "           1       0.43      0.03      0.06      1926\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19886    86]\n",
      " [ 1862    64]]\n",
      "done in 0.606153s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29384293083333485\n",
      "0.29908473402159264\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6836\n",
      "           1       0.44      0.02      0.04       829\n",
      "\n",
      "    accuracy                           0.89      7665\n",
      "   macro avg       0.67      0.51      0.49      7665\n",
      "weighted avg       0.84      0.89      0.84      7665\n",
      "\n",
      "Confusion_matrix\n",
      "[[6813   23]\n",
      " [ 811   18]]\n",
      "done in 0.594872s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29384293083333485\n",
      "0.2983175136242497\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.94      6982\n",
      "           1       0.36      0.02      0.04       825\n",
      "\n",
      "    accuracy                           0.89      7807\n",
      "   macro avg       0.63      0.51      0.49      7807\n",
      "weighted avg       0.84      0.89      0.85      7807\n",
      "\n",
      "Confusion_matrix\n",
      "[[6953   29]\n",
      " [ 809   16]]\n",
      "done in 0.613644s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29384293083333485\n",
      "0.24103903275445265\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96     13144\n",
      "           1       0.42      0.04      0.08      1089\n",
      "\n",
      "    accuracy                           0.92     14233\n",
      "   macro avg       0.67      0.52      0.52     14233\n",
      "weighted avg       0.89      0.92      0.89     14233\n",
      "\n",
      "Confusion_matrix\n",
      "[[13080    64]\n",
      " [ 1043    46]]\n",
      "done in 0.677310s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29384293083333485\n",
      "0.24167279524654345\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12990\n",
      "           1       0.46      0.04      0.08      1101\n",
      "\n",
      "    accuracy                           0.92     14091\n",
      "   macro avg       0.69      0.52      0.52     14091\n",
      "weighted avg       0.89      0.92      0.89     14091\n",
      "\n",
      "Confusion_matrix\n",
      "[[12933    57]\n",
      " [ 1053    48]]\n",
      "done in 0.597819s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19980\n",
      "           1       0.58      0.00      0.01      1918\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.75      0.50      0.48     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19975     5]\n",
      " [ 1911     7]]\n",
      "done in 18.085458s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19972\n",
      "           1       0.40      0.00      0.00      1926\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.66      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19966     6]\n",
      " [ 1922     4]]\n",
      "done in 17.969884s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6836\n",
      "           1       1.00      0.00      0.00       829\n",
      "\n",
      "    accuracy                           0.89      7665\n",
      "   macro avg       0.95      0.50      0.47      7665\n",
      "weighted avg       0.90      0.89      0.84      7665\n",
      "\n",
      "Confusion_matrix\n",
      "[[6836    0]\n",
      " [ 827    2]]\n",
      "done in 17.516250s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6982\n",
      "           1       0.25      0.00      0.00       825\n",
      "\n",
      "    accuracy                           0.89      7807\n",
      "   macro avg       0.57      0.50      0.47      7807\n",
      "weighted avg       0.83      0.89      0.84      7807\n",
      "\n",
      "Confusion_matrix\n",
      "[[6976    6]\n",
      " [ 823    2]]\n",
      "done in 17.707187s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13144\n",
      "           1       0.33      0.00      0.00      1089\n",
      "\n",
      "    accuracy                           0.92     14233\n",
      "   macro avg       0.63      0.50      0.48     14233\n",
      "weighted avg       0.88      0.92      0.89     14233\n",
      "\n",
      "Confusion_matrix\n",
      "[[13140     4]\n",
      " [ 1087     2]]\n",
      "done in 17.766756s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12990\n",
      "           1       0.40      0.00      0.00      1101\n",
      "\n",
      "    accuracy                           0.92     14091\n",
      "   macro avg       0.66      0.50      0.48     14091\n",
      "weighted avg       0.88      0.92      0.88     14091\n",
      "\n",
      "Confusion_matrix\n",
      "[[12987     3]\n",
      " [ 1099     2]]\n",
      "done in 17.540246s\n",
      "0.30658506233917926\n",
      "0.2690028749548924\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19980\n",
      "           1       0.00      0.00      0.00      1918\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.46      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19980     0]\n",
      " [ 1918     0]]\n",
      "done in 0.596583s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30658506233917926\n",
      "0.2696422537016649\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19972\n",
      "           1       0.00      0.00      0.00      1926\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.46      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19972     0]\n",
      " [ 1926     0]]\n",
      "done in 0.636676s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30658506233917926\n",
      "0.3067476162817166\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6836\n",
      "           1       0.00      0.00      0.00       829\n",
      "\n",
      "    accuracy                           0.89      7665\n",
      "   macro avg       0.45      0.50      0.47      7665\n",
      "weighted avg       0.80      0.89      0.84      7665\n",
      "\n",
      "Confusion_matrix\n",
      "[[6836    0]\n",
      " [ 829    0]]\n",
      "done in 0.571423s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30658506233917926\n",
      "0.30759040710100444\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6982\n",
      "           1       0.00      0.00      0.00       825\n",
      "\n",
      "    accuracy                           0.89      7807\n",
      "   macro avg       0.45      0.50      0.47      7807\n",
      "weighted avg       0.80      0.89      0.84      7807\n",
      "\n",
      "Confusion_matrix\n",
      "[[6982    0]\n",
      " [ 825    0]]\n",
      "done in 0.558284s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30658506233917926\n",
      "0.24867592756009804\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13144\n",
      "           1       0.00      0.00      0.00      1089\n",
      "\n",
      "    accuracy                           0.92     14233\n",
      "   macro avg       0.46      0.50      0.48     14233\n",
      "weighted avg       0.85      0.92      0.89     14233\n",
      "\n",
      "Confusion_matrix\n",
      "[[13144     0]\n",
      " [ 1089     0]]\n",
      "done in 0.567335s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30658506233917926\n",
      "0.24861739857508453\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12990\n",
      "           1       0.00      0.00      0.00      1101\n",
      "\n",
      "    accuracy                           0.92     14091\n",
      "   macro avg       0.46      0.50      0.48     14091\n",
      "weighted avg       0.85      0.92      0.88     14091\n",
      "\n",
      "Confusion_matrix\n",
      "[[12990     0]\n",
      " [ 1101     0]]\n",
      "done in 0.586580s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19980\n",
      "           1       0.43      0.01      0.02      1918\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.50      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19959    21]\n",
      " [ 1902    16]]\n",
      "done in 32.332005s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19972\n",
      "           1       0.42      0.01      0.02      1926\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.50      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19942    30]\n",
      " [ 1904    22]]\n",
      "done in 31.979195s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6836\n",
      "           1       0.33      0.00      0.01       829\n",
      "\n",
      "    accuracy                           0.89      7665\n",
      "   macro avg       0.61      0.50      0.48      7665\n",
      "weighted avg       0.83      0.89      0.84      7665\n",
      "\n",
      "Confusion_matrix\n",
      "[[6828    8]\n",
      " [ 825    4]]\n",
      "done in 31.634166s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6982\n",
      "           1       0.31      0.01      0.01       825\n",
      "\n",
      "    accuracy                           0.89      7807\n",
      "   macro avg       0.60      0.50      0.48      7807\n",
      "weighted avg       0.83      0.89      0.85      7807\n",
      "\n",
      "Confusion_matrix\n",
      "[[6971   11]\n",
      " [ 820    5]]\n",
      "done in 32.538042s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13144\n",
      "           1       0.48      0.01      0.02      1089\n",
      "\n",
      "    accuracy                           0.92     14233\n",
      "   macro avg       0.70      0.50      0.49     14233\n",
      "weighted avg       0.89      0.92      0.89     14233\n",
      "\n",
      "Confusion_matrix\n",
      "[[13132    12]\n",
      " [ 1078    11]]\n",
      "done in 32.966362s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12990\n",
      "           1       0.46      0.01      0.03      1101\n",
      "\n",
      "    accuracy                           0.92     14091\n",
      "   macro avg       0.69      0.51      0.49     14091\n",
      "weighted avg       0.89      0.92      0.89     14091\n",
      "\n",
      "Confusion_matrix\n",
      "[[12971    19]\n",
      " [ 1085    16]]\n",
      "done in 33.920332s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.38399999999999995\n",
      "threshold:0.2, J-value:0.295\n",
      "threshold:0.30000000000000004, J-value:0.176\n",
      "threshold:0.4, J-value:0.076\n",
      "threshold:0.5, J-value:0.029\n",
      "threshold:0.6000000000000001, J-value:0.011\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6919133158184254\n",
      "Balanced accuracy score of test is  0.6934356073580894\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.376\n",
      "threshold:0.2, J-value:0.292\n",
      "threshold:0.30000000000000004, J-value:0.175\n",
      "threshold:0.4, J-value:0.05800000000000001\n",
      "threshold:0.5, J-value:0.019\n",
      "threshold:0.6000000000000001, J-value:0.005\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6884199240379993\n",
      "Balanced accuracy score of test is  0.6792442037099728\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.38299999999999995\n",
      "threshold:0.2, J-value:0.296\n",
      "threshold:0.30000000000000004, J-value:0.178\n",
      "threshold:0.4, J-value:0.09\n",
      "threshold:0.5, J-value:0.037000000000000005\n",
      "threshold:0.6000000000000001, J-value:0.016\n",
      "threshold:0.7000000000000001, J-value:0.003\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6915408511608645\n",
      "Balanced accuracy score of test is  0.7010969452502764\n",
      "True positive rate of class 1 is  0.722\n",
      "True positive rate of class 2 is  0.723\n",
      "Positive prediction rate of class 1 is  0.402\n",
      "Positive prediction rate of class 2 is  0.352\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.39\n",
      "threshold:0.2, J-value:0.316\n",
      "threshold:0.30000000000000004, J-value:0.135\n",
      "threshold:0.4, J-value:0.024999999999999998\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6948694523512042\n",
      "Balanced accuracy score of test is  0.6923332592940605\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.37499999999999994\n",
      "threshold:0.2, J-value:0.31899999999999995\n",
      "threshold:0.30000000000000004, J-value:0.147\n",
      "threshold:0.4, J-value:0.03\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6873392901131525\n",
      "Balanced accuracy score of test is  0.67211773998941\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.377\n",
      "threshold:0.2, J-value:0.295\n",
      "threshold:0.30000000000000004, J-value:0.124\n",
      "threshold:0.4, J-value:0.024\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6882897614444674\n",
      "Balanced accuracy score of test is  0.6983240094560268\n",
      "True positive rate of class 1 is  0.805\n",
      "True positive rate of class 2 is  0.746\n",
      "Positive prediction rate of class 1 is  0.497\n",
      "Positive prediction rate of class 2 is  0.38\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.3360000000000001\n",
      "threshold:0.2, J-value:0.27599999999999997\n",
      "threshold:0.30000000000000004, J-value:0.126\n",
      "threshold:0.4, J-value:0.0\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6680391288055522\n",
      "Balanced accuracy score of test is  0.6676902440155574\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.31099999999999994\n",
      "threshold:0.2, J-value:0.26999999999999996\n",
      "threshold:0.30000000000000004, J-value:0.136\n",
      "threshold:0.4, J-value:0.0\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6555787285223125\n",
      "Balanced accuracy score of test is  0.6503594524448149\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.34600000000000003\n",
      "threshold:0.2, J-value:0.28099999999999997\n",
      "threshold:0.30000000000000004, J-value:0.118\n",
      "threshold:0.4, J-value:0.0\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6731232957025576\n",
      "Balanced accuracy score of test is  0.6761723018964494\n",
      "True positive rate of class 1 is  0.816\n",
      "True positive rate of class 2 is  0.802\n",
      "Positive prediction rate of class 1 is  0.547\n",
      "Positive prediction rate of class 2 is  0.477\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.401\n",
      "threshold:0.2, J-value:0.297\n",
      "threshold:0.30000000000000004, J-value:0.146\n",
      "threshold:0.4, J-value:0.04\n",
      "threshold:0.5, J-value:0.007\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7003536904996759\n",
      "Balanced accuracy score of test is  0.7017359869757431\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.38500000000000006\n",
      "threshold:0.2, J-value:0.31\n",
      "threshold:0.30000000000000004, J-value:0.156\n",
      "threshold:0.4, J-value:0.036\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.002\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6923401335863988\n",
      "Balanced accuracy score of test is  0.6917488259854344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.40199999999999997\n",
      "threshold:0.2, J-value:0.28400000000000003\n",
      "threshold:0.30000000000000004, J-value:0.139\n",
      "threshold:0.4, J-value:0.045\n",
      "threshold:0.5, J-value:0.009000000000000001\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7006200862160028\n",
      "Balanced accuracy score of test is  0.7034520370941386\n",
      "True positive rate of class 1 is  0.784\n",
      "True positive rate of class 2 is  0.731\n",
      "Positive prediction rate of class 1 is  0.441\n",
      "Positive prediction rate of class 2 is  0.356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lifuchen/Desktop/research/CVDPrediction-master/src/lib/fairness_tests.py:272: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train ['Class'] = y_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23370, 88)\n",
      "(42324, 88)\n",
      "0.12097083653108212 0.0856483262793382\n",
      "0.12096960369372836\n",
      "(67071, 87)\n",
      "X train 67071\n",
      "Y train 67071\n",
      "21898 7743 14155\n",
      "21898 7743 14155\n",
      "21898 7740 14158\n",
      "21898 7740 14158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2893187733670113\n",
      "0.26466851013847176\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19950\n",
      "           1       0.41      0.03      0.06      1948\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.66      0.51      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19860    90]\n",
      " [ 1886    62]]\n",
      "done in 0.701703s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2893187733670113\n",
      "0.2673361408383091\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19883\n",
      "           1       0.44      0.03      0.05      2015\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19809    74]\n",
      " [ 1957    58]]\n",
      "done in 0.644388s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2893187733670113\n",
      "0.30377746124965377\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6895\n",
      "           1       0.43      0.02      0.04       848\n",
      "\n",
      "    accuracy                           0.89      7743\n",
      "   macro avg       0.66      0.51      0.49      7743\n",
      "weighted avg       0.84      0.89      0.84      7743\n",
      "\n",
      "Confusion_matrix\n",
      "[[6868   27]\n",
      " [ 828   20]]\n",
      "done in 0.605811s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2893187733670113\n",
      "0.3080505385005307\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6860\n",
      "           1       0.45      0.02      0.04       880\n",
      "\n",
      "    accuracy                           0.89      7740\n",
      "   macro avg       0.67      0.51      0.49      7740\n",
      "weighted avg       0.84      0.89      0.84      7740\n",
      "\n",
      "Confusion_matrix\n",
      "[[6839   21]\n",
      " [ 863   17]]\n",
      "done in 0.582326s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2893187733670113\n",
      "0.24327531985561188\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13055\n",
      "           1       0.40      0.04      0.07      1100\n",
      "\n",
      "    accuracy                           0.92     14155\n",
      "   macro avg       0.66      0.52      0.51     14155\n",
      "weighted avg       0.88      0.92      0.89     14155\n",
      "\n",
      "Confusion_matrix\n",
      "[[12992    63]\n",
      " [ 1058    42]]\n",
      "done in 0.594825s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2893187733670113\n",
      "0.24507809323938298\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13023\n",
      "           1       0.44      0.04      0.07      1135\n",
      "\n",
      "    accuracy                           0.92     14158\n",
      "   macro avg       0.68      0.52      0.51     14158\n",
      "weighted avg       0.88      0.92      0.89     14158\n",
      "\n",
      "Confusion_matrix\n",
      "[[12970    53]\n",
      " [ 1094    41]]\n",
      "done in 0.600231s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19950\n",
      "           1       0.45      0.00      0.01      1948\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19944     6]\n",
      " [ 1943     5]]\n",
      "done in 18.697857s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19883\n",
      "           1       0.56      0.00      0.00      2015\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.73      0.50      0.48     21898\n",
      "weighted avg       0.88      0.91      0.86     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19879     4]\n",
      " [ 2010     5]]\n",
      "done in 18.162819s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6895\n",
      "           1       0.25      0.00      0.00       848\n",
      "\n",
      "    accuracy                           0.89      7743\n",
      "   macro avg       0.57      0.50      0.47      7743\n",
      "weighted avg       0.82      0.89      0.84      7743\n",
      "\n",
      "Confusion_matrix\n",
      "[[6889    6]\n",
      " [ 846    2]]\n",
      "done in 17.879911s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6860\n",
      "           1       0.50      0.00      0.00       880\n",
      "\n",
      "    accuracy                           0.89      7740\n",
      "   macro avg       0.69      0.50      0.47      7740\n",
      "weighted avg       0.84      0.89      0.83      7740\n",
      "\n",
      "Confusion_matrix\n",
      "[[6858    2]\n",
      " [ 878    2]]\n",
      "done in 17.977118s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13055\n",
      "           1       0.67      0.01      0.01      1100\n",
      "\n",
      "    accuracy                           0.92     14155\n",
      "   macro avg       0.79      0.50      0.49     14155\n",
      "weighted avg       0.90      0.92      0.89     14155\n",
      "\n",
      "Confusion_matrix\n",
      "[[13052     3]\n",
      " [ 1094     6]]\n",
      "done in 18.036836s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13023\n",
      "           1       0.17      0.00      0.00      1135\n",
      "\n",
      "    accuracy                           0.92     14158\n",
      "   macro avg       0.54      0.50      0.48     14158\n",
      "weighted avg       0.86      0.92      0.88     14158\n",
      "\n",
      "Confusion_matrix\n",
      "[[13018     5]\n",
      " [ 1134     1]]\n",
      "done in 17.746619s\n",
      "0.3000629835927724\n",
      "0.2713812783789082\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19950\n",
      "           1       0.00      0.00      0.00      1948\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.46      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19950     0]\n",
      " [ 1948     0]]\n",
      "done in 0.586741s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3000629835927724\n",
      "0.2759129739704951\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19883\n",
      "           1       0.00      0.00      0.00      2015\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.45      0.50      0.48     21898\n",
      "weighted avg       0.82      0.91      0.86     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19883     0]\n",
      " [ 2015     0]]\n",
      "done in 0.622639s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3000629835927724\n",
      "0.3112362245271311\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6895\n",
      "           1       0.00      0.00      0.00       848\n",
      "\n",
      "    accuracy                           0.89      7743\n",
      "   macro avg       0.45      0.50      0.47      7743\n",
      "weighted avg       0.79      0.89      0.84      7743\n",
      "\n",
      "Confusion_matrix\n",
      "[[6895    0]\n",
      " [ 848    0]]\n",
      "done in 0.556140s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3000629835927724\n",
      "0.31776697127669407\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6860\n",
      "           1       0.00      0.00      0.00       880\n",
      "\n",
      "    accuracy                           0.89      7740\n",
      "   macro avg       0.44      0.50      0.47      7740\n",
      "weighted avg       0.79      0.89      0.83      7740\n",
      "\n",
      "Confusion_matrix\n",
      "[[6860    0]\n",
      " [ 880    0]]\n",
      "done in 0.554997s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3000629835927724\n",
      "0.24958001747988381\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13055\n",
      "           1       0.00      0.00      0.00      1100\n",
      "\n",
      "    accuracy                           0.92     14155\n",
      "   macro avg       0.46      0.50      0.48     14155\n",
      "weighted avg       0.85      0.92      0.89     14155\n",
      "\n",
      "Confusion_matrix\n",
      "[[13055     0]\n",
      " [ 1100     0]]\n",
      "done in 0.699804s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3000629835927724\n",
      "0.2530319216220009\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13023\n",
      "           1       0.00      0.00      0.00      1135\n",
      "\n",
      "    accuracy                           0.92     14158\n",
      "   macro avg       0.46      0.50      0.48     14158\n",
      "weighted avg       0.85      0.92      0.88     14158\n",
      "\n",
      "Confusion_matrix\n",
      "[[13023     0]\n",
      " [ 1135     0]]\n",
      "done in 0.582101s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19950\n",
      "           1       0.48      0.01      0.02      1948\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.69      0.50      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19928    22]\n",
      " [ 1928    20]]\n",
      "done in 32.462374s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19883\n",
      "           1       0.42      0.01      0.02      2015\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19857    26]\n",
      " [ 1996    19]]\n",
      "done in 32.584423s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6895\n",
      "           1       0.62      0.01      0.02       848\n",
      "\n",
      "    accuracy                           0.89      7743\n",
      "   macro avg       0.76      0.51      0.48      7743\n",
      "weighted avg       0.86      0.89      0.84      7743\n",
      "\n",
      "Confusion_matrix\n",
      "[[6889    6]\n",
      " [ 838   10]]\n",
      "done in 32.379976s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6860\n",
      "           1       0.26      0.01      0.01       880\n",
      "\n",
      "    accuracy                           0.89      7740\n",
      "   macro avg       0.57      0.50      0.48      7740\n",
      "weighted avg       0.82      0.89      0.83      7740\n",
      "\n",
      "Confusion_matrix\n",
      "[[6846   14]\n",
      " [ 875    5]]\n",
      "done in 32.768223s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13055\n",
      "           1       0.38      0.01      0.02      1100\n",
      "\n",
      "    accuracy                           0.92     14155\n",
      "   macro avg       0.65      0.50      0.49     14155\n",
      "weighted avg       0.88      0.92      0.89     14155\n",
      "\n",
      "Confusion_matrix\n",
      "[[13039    16]\n",
      " [ 1090    10]]\n",
      "done in 32.862089s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13023\n",
      "           1       0.62      0.01      0.02      1135\n",
      "\n",
      "    accuracy                           0.92     14158\n",
      "   macro avg       0.77      0.51      0.49     14158\n",
      "weighted avg       0.90      0.92      0.88     14158\n",
      "\n",
      "Confusion_matrix\n",
      "[[13015     8]\n",
      " [ 1122    13]]\n",
      "done in 32.713542s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.38099999999999995\n",
      "threshold:0.2, J-value:0.278\n",
      "threshold:0.30000000000000004, J-value:0.15\n",
      "threshold:0.4, J-value:0.068\n",
      "threshold:0.5, J-value:0.027\n",
      "threshold:0.6000000000000001, J-value:0.009999999999999998\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6906877048885046\n",
      "Balanced accuracy score of test is  0.7002097506142946\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.378\n",
      "threshold:0.2, J-value:0.269\n",
      "threshold:0.30000000000000004, J-value:0.122\n",
      "threshold:0.4, J-value:0.047\n",
      "threshold:0.5, J-value:0.02\n",
      "threshold:0.6000000000000001, J-value:0.006\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.002\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.689032847838877\n",
      "Balanced accuracy score of test is  0.6978167240922343\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.37799999999999995\n",
      "threshold:0.2, J-value:0.28600000000000003\n",
      "threshold:0.30000000000000004, J-value:0.172\n",
      "threshold:0.4, J-value:0.084\n",
      "threshold:0.5, J-value:0.033\n",
      "threshold:0.6000000000000001, J-value:0.013000000000000001\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6893588315170085\n",
      "Balanced accuracy score of test is  0.6997215363803992\n",
      "True positive rate of class 1 is  0.739\n",
      "True positive rate of class 2 is  0.714\n",
      "Positive prediction rate of class 1 is  0.388\n",
      "Positive prediction rate of class 2 is  0.346\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.385\n",
      "threshold:0.2, J-value:0.29\n",
      "threshold:0.30000000000000004, J-value:0.119\n",
      "threshold:0.4, J-value:0.026\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6926362363815082\n",
      "Balanced accuracy score of test is  0.6913362026415324\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.34\n",
      "threshold:0.2, J-value:0.30200000000000005\n",
      "threshold:0.30000000000000004, J-value:0.121\n",
      "threshold:0.4, J-value:0.025\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.669865023875655\n",
      "Balanced accuracy score of test is  0.683322289954943\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.385\n",
      "threshold:0.2, J-value:0.307\n",
      "threshold:0.30000000000000004, J-value:0.124\n",
      "threshold:0.4, J-value:0.022\n",
      "threshold:0.5, J-value:0.005\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6926934995299606\n",
      "Balanced accuracy score of test is  0.6938133853998061\n",
      "True positive rate of class 1 is  0.805\n",
      "True positive rate of class 2 is  0.744\n",
      "Positive prediction rate of class 1 is  0.48\n",
      "Positive prediction rate of class 2 is  0.387\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.355\n",
      "threshold:0.2, J-value:0.276\n",
      "threshold:0.30000000000000004, J-value:0.101\n",
      "threshold:0.4, J-value:0.0\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6777318295739349\n",
      "Balanced accuracy score of test is  0.6797745720654413\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.331\n",
      "threshold:0.2, J-value:0.257\n",
      "threshold:0.30000000000000004, J-value:0.10200000000000001\n",
      "threshold:0.4, J-value:0.0\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6654001395597029\n",
      "Balanced accuracy score of test is  0.6654187649085608\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.363\n",
      "threshold:0.2, J-value:0.28900000000000003\n",
      "threshold:0.30000000000000004, J-value:0.101\n",
      "threshold:0.4, J-value:0.0\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6813820897601058\n",
      "Balanced accuracy score of test is  0.6855647463433892\n",
      "True positive rate of class 1 is  0.764\n",
      "True positive rate of class 2 is  0.738\n",
      "Positive prediction rate of class 1 is  0.47\n",
      "Positive prediction rate of class 2 is  0.397\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.4\n",
      "threshold:0.2, J-value:0.29600000000000004\n",
      "threshold:0.30000000000000004, J-value:0.147\n",
      "threshold:0.4, J-value:0.045\n",
      "threshold:0.5, J-value:0.009000000000000001\n",
      "threshold:0.6000000000000001, J-value:0.002\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6997498108721496\n",
      "Balanced accuracy score of test is  0.7095593714545226\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.388\n",
      "threshold:0.2, J-value:0.27\n",
      "threshold:0.30000000000000004, J-value:0.144\n",
      "threshold:0.4, J-value:0.039\n",
      "threshold:0.5, J-value:0.011\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6938143924364114\n",
      "Balanced accuracy score of test is  0.700556586270872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.39599999999999996\n",
      "threshold:0.2, J-value:0.313\n",
      "threshold:0.30000000000000004, J-value:0.148\n",
      "threshold:0.4, J-value:0.049\n",
      "threshold:0.5, J-value:0.008\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6978933532954981\n",
      "Balanced accuracy score of test is  0.7108439456995941\n",
      "True positive rate of class 1 is  0.791\n",
      "True positive rate of class 2 is  0.741\n",
      "Positive prediction rate of class 1 is  0.435\n",
      "Positive prediction rate of class 2 is  0.353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lifuchen/Desktop/research/CVDPrediction-master/src/lib/fairness_tests.py:272: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train ['Class'] = y_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23345, 88)\n",
      "(42349, 88)\n",
      "0.12230181241286477 0.08478700786393094\n",
      "0.1222879684418146\n",
      "(67158, 87)\n",
      "X train 67158\n",
      "Y train 67158\n",
      "21898 7751 14147\n",
      "21898 7751 14147\n",
      "21898 7757 14141\n",
      "21898 7757 14141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2911272230137969\n",
      "0.26575357908367847\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19908\n",
      "           1       0.46      0.04      0.07      1990\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.52      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19820    88]\n",
      " [ 1916    74]]\n",
      "done in 1.486704s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2911272230137969\n",
      "0.2648087868792824\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19918\n",
      "           1       0.43      0.03      0.06      1980\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19840    78]\n",
      " [ 1921    59]]\n",
      "done in 0.865046s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2911272230137969\n",
      "0.3027345783222792\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6908\n",
      "           1       0.46      0.03      0.05       843\n",
      "\n",
      "    accuracy                           0.89      7751\n",
      "   macro avg       0.68      0.51      0.50      7751\n",
      "weighted avg       0.85      0.89      0.85      7751\n",
      "\n",
      "Confusion_matrix\n",
      "[[6880   28]\n",
      " [ 819   24]]\n",
      "done in 0.751957s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2911272230137969\n",
      "0.30498106185217216\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6894\n",
      "           1       0.45      0.02      0.04       863\n",
      "\n",
      "    accuracy                           0.89      7757\n",
      "   macro avg       0.67      0.51      0.49      7757\n",
      "weighted avg       0.84      0.89      0.84      7757\n",
      "\n",
      "Confusion_matrix\n",
      "[[6870   24]\n",
      " [ 843   20]]\n",
      "done in 1.200068s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2911272230137969\n",
      "0.2454920589664526\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13000\n",
      "           1       0.45      0.04      0.08      1147\n",
      "\n",
      "    accuracy                           0.92     14147\n",
      "   macro avg       0.69      0.52      0.52     14147\n",
      "weighted avg       0.88      0.92      0.89     14147\n",
      "\n",
      "Confusion_matrix\n",
      "[[12940    60]\n",
      " [ 1097    50]]\n",
      "done in 0.894958s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2911272230137969\n",
      "0.24277241484302564\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13024\n",
      "           1       0.42      0.03      0.06      1117\n",
      "\n",
      "    accuracy                           0.92     14141\n",
      "   macro avg       0.67      0.52      0.51     14141\n",
      "weighted avg       0.88      0.92      0.89     14141\n",
      "\n",
      "Confusion_matrix\n",
      "[[12970    54]\n",
      " [ 1078    39]]\n",
      "done in 0.627408s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19908\n",
      "           1       0.69      0.01      0.01      1990\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.80      0.50      0.48     21898\n",
      "weighted avg       0.89      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19903     5]\n",
      " [ 1979    11]]\n",
      "done in 18.107810s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19918\n",
      "           1       0.43      0.00      0.00      1980\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19914     4]\n",
      " [ 1977     3]]\n",
      "done in 17.951046s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6908\n",
      "           1       0.50      0.00      0.01       843\n",
      "\n",
      "    accuracy                           0.89      7751\n",
      "   macro avg       0.70      0.50      0.47      7751\n",
      "weighted avg       0.85      0.89      0.84      7751\n",
      "\n",
      "Confusion_matrix\n",
      "[[6905    3]\n",
      " [ 840    3]]\n",
      "done in 17.776077s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6894\n",
      "           1       0.67      0.00      0.00       863\n",
      "\n",
      "    accuracy                           0.89      7757\n",
      "   macro avg       0.78      0.50      0.47      7757\n",
      "weighted avg       0.86      0.89      0.84      7757\n",
      "\n",
      "Confusion_matrix\n",
      "[[6893    1]\n",
      " [ 861    2]]\n",
      "done in 17.703175s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13000\n",
      "           1       0.71      0.00      0.01      1147\n",
      "\n",
      "    accuracy                           0.92     14147\n",
      "   macro avg       0.82      0.50      0.48     14147\n",
      "weighted avg       0.90      0.92      0.88     14147\n",
      "\n",
      "Confusion_matrix\n",
      "[[12998     2]\n",
      " [ 1142     5]]\n",
      "done in 17.939330s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13024\n",
      "           1       0.50      0.00      0.00      1117\n",
      "\n",
      "    accuracy                           0.92     14141\n",
      "   macro avg       0.71      0.50      0.48     14141\n",
      "weighted avg       0.89      0.92      0.88     14141\n",
      "\n",
      "Confusion_matrix\n",
      "[[13022     2]\n",
      " [ 1115     2]]\n",
      "done in 17.479195s\n",
      "0.302941220949911\n",
      "0.2729956394208239\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19908\n",
      "           1       0.00      0.00      0.00      1990\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.45      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19908     0]\n",
      " [ 1990     0]]\n",
      "done in 0.619816s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.302941220949911\n",
      "0.2728952533315954\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19918\n",
      "           1       0.33      0.00      0.00      1980\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.62      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19916     2]\n",
      " [ 1979     1]]\n",
      "done in 0.595148s\n",
      "0.302941220949911\n",
      "0.30958774797380123\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6908\n",
      "           1       0.00      0.00      0.00       843\n",
      "\n",
      "    accuracy                           0.89      7751\n",
      "   macro avg       0.45      0.50      0.47      7751\n",
      "weighted avg       0.79      0.89      0.84      7751\n",
      "\n",
      "Confusion_matrix\n",
      "[[6908    0]\n",
      " [ 843    0]]\n",
      "done in 0.564240s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.302941220949911\n",
      "0.31146757757447097\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6894\n",
      "           1       0.00      0.00      0.00       863\n",
      "\n",
      "    accuracy                           0.89      7757\n",
      "   macro avg       0.44      0.50      0.47      7757\n",
      "weighted avg       0.79      0.89      0.84      7757\n",
      "\n",
      "Confusion_matrix\n",
      "[[6894    0]\n",
      " [ 863    0]]\n",
      "done in 0.575934s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.302941220949911\n",
      "0.25294718862601745\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13000\n",
      "           1       0.00      0.00      0.00      1147\n",
      "\n",
      "    accuracy                           0.92     14147\n",
      "   macro avg       0.46      0.50      0.48     14147\n",
      "weighted avg       0.84      0.92      0.88     14147\n",
      "\n",
      "Confusion_matrix\n",
      "[[13000     0]\n",
      " [ 1147     0]]\n",
      "done in 0.573356s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.302941220949911\n",
      "0.2517365291146387\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13024\n",
      "           1       0.33      0.00      0.00      1117\n",
      "\n",
      "    accuracy                           0.92     14141\n",
      "   macro avg       0.63      0.50      0.48     14141\n",
      "weighted avg       0.87      0.92      0.88     14141\n",
      "\n",
      "Confusion_matrix\n",
      "[[13022     2]\n",
      " [ 1116     1]]\n",
      "done in 0.578001s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19908\n",
      "           1       0.54      0.02      0.03      1990\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.73      0.51      0.49     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19881    27]\n",
      " [ 1958    32]]\n",
      "done in 32.363167s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19918\n",
      "           1       0.29      0.01      0.01      1980\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.60      0.50      0.48     21898\n",
      "weighted avg       0.85      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19889    29]\n",
      " [ 1968    12]]\n",
      "done in 32.239625s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6908\n",
      "           1       0.58      0.02      0.03       843\n",
      "\n",
      "    accuracy                           0.89      7751\n",
      "   macro avg       0.73      0.51      0.49      7751\n",
      "weighted avg       0.86      0.89      0.84      7751\n",
      "\n",
      "Confusion_matrix\n",
      "[[6897   11]\n",
      " [ 828   15]]\n",
      "done in 32.111368s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6894\n",
      "           1       0.19      0.00      0.01       863\n",
      "\n",
      "    accuracy                           0.89      7757\n",
      "   macro avg       0.54      0.50      0.47      7757\n",
      "weighted avg       0.81      0.89      0.84      7757\n",
      "\n",
      "Confusion_matrix\n",
      "[[6877   17]\n",
      " [ 859    4]]\n",
      "done in 32.210211s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13000\n",
      "           1       0.53      0.01      0.03      1147\n",
      "\n",
      "    accuracy                           0.92     14147\n",
      "   macro avg       0.73      0.51      0.49     14147\n",
      "weighted avg       0.89      0.92      0.88     14147\n",
      "\n",
      "Confusion_matrix\n",
      "[[12985    15]\n",
      " [ 1130    17]]\n",
      "done in 32.506814s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13024\n",
      "           1       0.40      0.01      0.01      1117\n",
      "\n",
      "    accuracy                           0.92     14141\n",
      "   macro avg       0.66      0.50      0.49     14141\n",
      "weighted avg       0.88      0.92      0.88     14141\n",
      "\n",
      "Confusion_matrix\n",
      "[[13012    12]\n",
      " [ 1109     8]]\n",
      "done in 33.398043s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.39799999999999996\n",
      "threshold:0.2, J-value:0.28700000000000003\n",
      "threshold:0.30000000000000004, J-value:0.16899999999999998\n",
      "threshold:0.4, J-value:0.077\n",
      "threshold:0.5, J-value:0.033\n",
      "threshold:0.6000000000000001, J-value:0.012\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6992616286172675\n",
      "Balanced accuracy score of test is  0.6978877539325375\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.385\n",
      "threshold:0.2, J-value:0.275\n",
      "threshold:0.30000000000000004, J-value:0.141\n",
      "threshold:0.4, J-value:0.05700000000000001\n",
      "threshold:0.5, J-value:0.024\n",
      "threshold:0.6000000000000001, J-value:0.008\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.692627421161773\n",
      "Balanced accuracy score of test is  0.6910004702898821\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.39999999999999997\n",
      "threshold:0.2, J-value:0.29500000000000004\n",
      "threshold:0.30000000000000004, J-value:0.188\n",
      "threshold:0.4, J-value:0.092\n",
      "threshold:0.5, J-value:0.039\n",
      "threshold:0.6000000000000001, J-value:0.015\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7000437261082423\n",
      "Balanced accuracy score of test is  0.6991908334231521\n",
      "True positive rate of class 1 is  0.749\n",
      "True positive rate of class 2 is  0.714\n",
      "Positive prediction rate of class 1 is  0.409\n",
      "Positive prediction rate of class 2 is  0.348\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.365\n",
      "threshold:0.2, J-value:0.295\n",
      "threshold:0.30000000000000004, J-value:0.127\n",
      "threshold:0.4, J-value:0.029\n",
      "threshold:0.5, J-value:0.006\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.682213332081343\n",
      "Balanced accuracy score of test is  0.6866620822138445\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.337\n",
      "threshold:0.2, J-value:0.264\n",
      "threshold:0.30000000000000004, J-value:0.13199999999999998\n",
      "threshold:0.4, J-value:0.031\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.668625730753142\n",
      "Balanced accuracy score of test is  0.6766673020118255\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.388\n",
      "threshold:0.2, J-value:0.308\n",
      "threshold:0.30000000000000004, J-value:0.126\n",
      "threshold:0.4, J-value:0.027\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6941470055663604\n",
      "Balanced accuracy score of test is  0.6873004166675831\n",
      "True positive rate of class 1 is  0.811\n",
      "True positive rate of class 2 is  0.722\n",
      "Positive prediction rate of class 1 is  0.497\n",
      "Positive prediction rate of class 2 is  0.377\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.354\n",
      "threshold:0.2, J-value:0.30899999999999994\n",
      "threshold:0.30000000000000004, J-value:0.11299999999999999\n",
      "threshold:0.4, J-value:0.016\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6767387520281738\n",
      "Balanced accuracy score of test is  0.6777475528454542\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.304\n",
      "threshold:0.2, J-value:0.289\n",
      "threshold:0.30000000000000004, J-value:0.11599999999999999\n",
      "threshold:0.4, J-value:0.023\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6523360574944999\n",
      "Balanced accuracy score of test is  0.6718897753466581\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.377\n",
      "threshold:0.2, J-value:0.32199999999999995\n",
      "threshold:0.30000000000000004, J-value:0.11000000000000001\n",
      "threshold:0.4, J-value:0.01\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6884293474616056\n",
      "Balanced accuracy score of test is  0.6762538040095113\n",
      "True positive rate of class 1 is  0.798\n",
      "True positive rate of class 2 is  0.731\n",
      "Positive prediction rate of class 1 is  0.493\n",
      "Positive prediction rate of class 2 is  0.407\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.40099999999999997\n",
      "threshold:0.2, J-value:0.311\n",
      "threshold:0.30000000000000004, J-value:0.157\n",
      "threshold:0.4, J-value:0.048\n",
      "threshold:0.5, J-value:0.015\n",
      "threshold:0.6000000000000001, J-value:0.004\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7005463574654466\n",
      "Balanced accuracy score of test is  0.7104746125782375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.377\n",
      "threshold:0.2, J-value:0.289\n",
      "threshold:0.30000000000000004, J-value:0.153\n",
      "threshold:0.4, J-value:0.048\n",
      "threshold:0.5, J-value:0.016\n",
      "threshold:0.6000000000000001, J-value:0.002\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6885803315014277\n",
      "Balanced accuracy score of test is  0.7051011829185605\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.407\n",
      "threshold:0.2, J-value:0.32299999999999995\n",
      "threshold:0.30000000000000004, J-value:0.158\n",
      "threshold:0.4, J-value:0.049\n",
      "threshold:0.5, J-value:0.013999999999999999\n",
      "threshold:0.6000000000000001, J-value:0.005\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7035697471665214\n",
      "Balanced accuracy score of test is  0.7084750499869121\n",
      "True positive rate of class 1 is  0.806\n",
      "True positive rate of class 2 is  0.736\n",
      "Positive prediction rate of class 1 is  0.442\n",
      "Positive prediction rate of class 2 is  0.352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lifuchen/Desktop/research/CVDPrediction-master/src/lib/fairness_tests.py:272: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train ['Class'] = y_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23252, 88)\n",
      "(42442, 88)\n",
      "0.12775244931613153 0.08639004786648578\n",
      "0.12772928558630045\n",
      "(67309, 87)\n",
      "X train 67309\n",
      "Y train 67309\n",
      "21898 7842 14056\n",
      "21898 7842 14056\n",
      "21898 7759 14139\n",
      "21898 7759 14139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29752136737961843\n",
      "0.2592216992631809\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.95     20006\n",
      "           1       0.42      0.03      0.06      1892\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.52      0.51     21898\n",
      "weighted avg       0.87      0.91      0.88     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19916    90]\n",
      " [ 1826    66]]\n",
      "done in 0.570570s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29752136737961843\n",
      "0.26239128801752915\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19975\n",
      "           1       0.43      0.04      0.07      1923\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.52      0.51     21898\n",
      "weighted avg       0.87      0.91      0.88     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19879    96]\n",
      " [ 1852    71]]\n",
      "done in 0.577667s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29752136737961843\n",
      "0.2928411058415271\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      7042\n",
      "           1       0.38      0.03      0.05       800\n",
      "\n",
      "    accuracy                           0.90      7842\n",
      "   macro avg       0.64      0.51      0.50      7842\n",
      "weighted avg       0.85      0.90      0.85      7842\n",
      "\n",
      "Confusion_matrix\n",
      "[[7008   34]\n",
      " [ 779   21]]\n",
      "done in 0.598521s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29752136737961843\n",
      "0.29441151762554985\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.94      6943\n",
      "           1       0.52      0.03      0.06       816\n",
      "\n",
      "    accuracy                           0.90      7759\n",
      "   macro avg       0.71      0.52      0.50      7759\n",
      "weighted avg       0.86      0.90      0.85      7759\n",
      "\n",
      "Confusion_matrix\n",
      "[[6917   26]\n",
      " [ 788   28]]\n",
      "done in 0.625347s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29752136737961843\n",
      "0.24046505538246157\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12964\n",
      "           1       0.45      0.04      0.08      1092\n",
      "\n",
      "    accuracy                           0.92     14056\n",
      "   macro avg       0.69      0.52      0.52     14056\n",
      "weighted avg       0.89      0.92      0.89     14056\n",
      "\n",
      "Confusion_matrix\n",
      "[[12908    56]\n",
      " [ 1047    45]]\n",
      "done in 1.069592s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29752136737961843\n",
      "0.24481968029925819\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96     13032\n",
      "           1       0.38      0.04      0.07      1107\n",
      "\n",
      "    accuracy                           0.92     14139\n",
      "   macro avg       0.65      0.52      0.51     14139\n",
      "weighted avg       0.88      0.92      0.89     14139\n",
      "\n",
      "Confusion_matrix\n",
      "[[12962    70]\n",
      " [ 1064    43]]\n",
      "done in 0.782944s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     20006\n",
      "           1       0.38      0.00      0.00      1892\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.64      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[20001     5]\n",
      " [ 1889     3]]\n",
      "done in 42.321842s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19975\n",
      "           1       0.55      0.01      0.01      1923\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.73      0.50      0.48     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19965    10]\n",
      " [ 1911    12]]\n",
      "done in 21.702299s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      7042\n",
      "           1       0.20      0.00      0.00       800\n",
      "\n",
      "    accuracy                           0.90      7842\n",
      "   macro avg       0.55      0.50      0.47      7842\n",
      "weighted avg       0.83      0.90      0.85      7842\n",
      "\n",
      "Confusion_matrix\n",
      "[[7038    4]\n",
      " [ 799    1]]\n",
      "done in 18.322666s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.94      6943\n",
      "           1       0.50      0.00      0.01       816\n",
      "\n",
      "    accuracy                           0.89      7759\n",
      "   macro avg       0.70      0.50      0.48      7759\n",
      "weighted avg       0.85      0.89      0.85      7759\n",
      "\n",
      "Confusion_matrix\n",
      "[[6940    3]\n",
      " [ 813    3]]\n",
      "done in 17.580008s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12964\n",
      "           1       0.57      0.00      0.01      1092\n",
      "\n",
      "    accuracy                           0.92     14056\n",
      "   macro avg       0.75      0.50      0.48     14056\n",
      "weighted avg       0.90      0.92      0.89     14056\n",
      "\n",
      "Confusion_matrix\n",
      "[[12961     3]\n",
      " [ 1088     4]]\n",
      "done in 37.705776s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13032\n",
      "           1       0.50      0.00      0.01      1107\n",
      "\n",
      "    accuracy                           0.92     14139\n",
      "   macro avg       0.71      0.50      0.48     14139\n",
      "weighted avg       0.89      0.92      0.88     14139\n",
      "\n",
      "Confusion_matrix\n",
      "[[13029     3]\n",
      " [ 1104     3]]\n",
      "done in 24.243725s\n",
      "0.31014310153376173\n",
      "0.2701805793544173\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     20006\n",
      "           1       0.50      0.00      0.01      1892\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.71      0.50      0.48     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19998     8]\n",
      " [ 1884     8]]\n",
      "done in 0.618089s\n",
      "0.31014310153376173\n",
      "0.27480016413684355\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19975\n",
      "           1       0.44      0.00      0.01      1923\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19966     9]\n",
      " [ 1916     7]]\n",
      "done in 0.651414s\n",
      "0.31014310153376173\n",
      "0.3023657418550856\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      7042\n",
      "           1       0.60      0.00      0.01       800\n",
      "\n",
      "    accuracy                           0.90      7842\n",
      "   macro avg       0.75      0.50      0.48      7842\n",
      "weighted avg       0.87      0.90      0.85      7842\n",
      "\n",
      "Confusion_matrix\n",
      "[[7040    2]\n",
      " [ 797    3]]\n",
      "done in 0.581333s\n",
      "0.31014310153376173\n",
      "0.3087101850105547\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.94      6943\n",
      "           1       0.40      0.00      0.00       816\n",
      "\n",
      "    accuracy                           0.89      7759\n",
      "   macro avg       0.65      0.50      0.47      7759\n",
      "weighted avg       0.84      0.89      0.85      7759\n",
      "\n",
      "Confusion_matrix\n",
      "[[6940    3]\n",
      " [ 814    2]]\n",
      "done in 0.570743s\n",
      "0.31014310153376173\n",
      "0.2522241163258003\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12964\n",
      "           1       0.45      0.00      0.01      1092\n",
      "\n",
      "    accuracy                           0.92     14056\n",
      "   macro avg       0.69      0.50      0.48     14056\n",
      "weighted avg       0.89      0.92      0.89     14056\n",
      "\n",
      "Confusion_matrix\n",
      "[[12958     6]\n",
      " [ 1087     5]]\n",
      "done in 0.567019s\n",
      "0.31014310153376173\n",
      "0.25374870163213775\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13032\n",
      "           1       0.50      0.00      0.01      1107\n",
      "\n",
      "    accuracy                           0.92     14139\n",
      "   macro avg       0.71      0.50      0.48     14139\n",
      "weighted avg       0.89      0.92      0.88     14139\n",
      "\n",
      "Confusion_matrix\n",
      "[[13027     5]\n",
      " [ 1102     5]]\n",
      "done in 0.583223s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     20006\n",
      "           1       0.40      0.01      0.03      1892\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.66      0.51      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19969    37]\n",
      " [ 1867    25]]\n",
      "done in 32.707497s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19975\n",
      "           1       0.45      0.02      0.03      1923\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.51      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19933    42]\n",
      " [ 1889    34]]\n",
      "done in 45.601403s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      7042\n",
      "           1       0.39      0.01      0.03       800\n",
      "\n",
      "    accuracy                           0.90      7842\n",
      "   macro avg       0.65      0.51      0.49      7842\n",
      "weighted avg       0.85      0.90      0.85      7842\n",
      "\n",
      "Confusion_matrix\n",
      "[[7025   17]\n",
      " [ 789   11]]\n",
      "done in 42.049878s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.94      6943\n",
      "           1       0.39      0.01      0.03       816\n",
      "\n",
      "    accuracy                           0.89      7759\n",
      "   macro avg       0.64      0.51      0.49      7759\n",
      "weighted avg       0.84      0.89      0.85      7759\n",
      "\n",
      "Confusion_matrix\n",
      "[[6924   19]\n",
      " [ 804   12]]\n",
      "done in 32.827926s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12964\n",
      "           1       0.41      0.01      0.02      1092\n",
      "\n",
      "    accuracy                           0.92     14056\n",
      "   macro avg       0.67      0.51      0.49     14056\n",
      "weighted avg       0.88      0.92      0.89     14056\n",
      "\n",
      "Confusion_matrix\n",
      "[[12944    20]\n",
      " [ 1078    14]]\n",
      "done in 34.455899s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13032\n",
      "           1       0.49      0.02      0.04      1107\n",
      "\n",
      "    accuracy                           0.92     14139\n",
      "   macro avg       0.71      0.51      0.50     14139\n",
      "weighted avg       0.89      0.92      0.89     14139\n",
      "\n",
      "Confusion_matrix\n",
      "[[13009    23]\n",
      " [ 1085    22]]\n",
      "done in 33.566321s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.2, J-value:0.295\n",
      "threshold:0.30000000000000004, J-value:0.16\n",
      "threshold:0.4, J-value:0.075\n",
      "threshold:0.5, J-value:0.031000000000000003\n",
      "threshold:0.6000000000000001, J-value:0.009999999999999998\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.699130562099869\n",
      "Balanced accuracy score of test is  0.6961581331839006\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.369\n",
      "threshold:0.2, J-value:0.272\n",
      "threshold:0.30000000000000004, J-value:0.15\n",
      "threshold:0.4, J-value:0.059\n",
      "threshold:0.5, J-value:0.020999999999999998\n",
      "threshold:0.6000000000000001, J-value:0.008\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.684486119000284\n",
      "Balanced accuracy score of test is  0.6839039284877138\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.413\n",
      "threshold:0.2, J-value:0.313\n",
      "threshold:0.30000000000000004, J-value:0.16699999999999998\n",
      "threshold:0.4, J-value:0.08600000000000001\n",
      "threshold:0.5, J-value:0.037000000000000005\n",
      "threshold:0.6000000000000001, J-value:0.011\n",
      "threshold:0.7000000000000001, J-value:0.004\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7063663478350304\n",
      "Balanced accuracy score of test is  0.7024341583194837\n",
      "True positive rate of class 1 is  0.741\n",
      "True positive rate of class 2 is  0.737\n",
      "Positive prediction rate of class 1 is  0.412\n",
      "Positive prediction rate of class 2 is  0.364\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.38\n",
      "threshold:0.2, J-value:0.30700000000000005\n",
      "threshold:0.30000000000000004, J-value:0.141\n",
      "threshold:0.4, J-value:0.032\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6897189299869658\n",
      "Balanced accuracy score of test is  0.6891313830275363\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.35699999999999993\n",
      "threshold:0.2, J-value:0.3\n",
      "threshold:0.30000000000000004, J-value:0.139\n",
      "threshold:0.4, J-value:0.046\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6783326824765692\n",
      "Balanced accuracy score of test is  0.677602441307792\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.392\n",
      "threshold:0.2, J-value:0.293\n",
      "threshold:0.30000000000000004, J-value:0.13\n",
      "threshold:0.4, J-value:0.022\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.69561468049589\n",
      "Balanced accuracy score of test is  0.6890596380641523\n",
      "True positive rate of class 1 is  0.812\n",
      "True positive rate of class 2 is  0.743\n",
      "Positive prediction rate of class 1 is  0.495\n",
      "Positive prediction rate of class 2 is  0.395\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.333\n",
      "threshold:0.2, J-value:0.264\n",
      "threshold:0.30000000000000004, J-value:0.088\n",
      "threshold:0.4, J-value:0.065\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.004\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6663936337069281\n",
      "Balanced accuracy score of test is  0.67058452550868\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.31\n",
      "threshold:0.2, J-value:0.269\n",
      "threshold:0.30000000000000004, J-value:0.086\n",
      "threshold:0.4, J-value:0.059\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.004\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6554022294802613\n",
      "Balanced accuracy score of test is  0.6602147070119997\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.345\n",
      "threshold:0.2, J-value:0.249\n",
      "threshold:0.30000000000000004, J-value:0.091\n",
      "threshold:0.4, J-value:0.069\n",
      "threshold:0.5, J-value:0.005\n",
      "threshold:0.6000000000000001, J-value:0.005\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6722234748692633\n",
      "Balanced accuracy score of test is  0.6771096912166175\n",
      "True positive rate of class 1 is  0.749\n",
      "True positive rate of class 2 is  0.765\n",
      "Positive prediction rate of class 1 is  0.462\n",
      "Positive prediction rate of class 2 is  0.439\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.406\n",
      "threshold:0.2, J-value:0.29\n",
      "threshold:0.30000000000000004, J-value:0.15\n",
      "threshold:0.4, J-value:0.058\n",
      "threshold:0.5, J-value:0.011\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7030168433613679\n",
      "Balanced accuracy score of test is  0.6955704771369828\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.38200000000000006\n",
      "threshold:0.2, J-value:0.27899999999999997\n",
      "threshold:0.30000000000000004, J-value:0.152\n",
      "threshold:0.4, J-value:0.06\n",
      "threshold:0.5, J-value:0.012\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6906835771087758\n",
      "Balanced accuracy score of test is  0.6853981510507127\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.413\n",
      "threshold:0.2, J-value:0.296\n",
      "threshold:0.30000000000000004, J-value:0.149\n",
      "threshold:0.4, J-value:0.056\n",
      "threshold:0.5, J-value:0.011\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7063238237644285\n",
      "Balanced accuracy score of test is  0.6982749155300025\n",
      "True positive rate of class 1 is  0.777\n",
      "True positive rate of class 2 is  0.731\n",
      "Positive prediction rate of class 1 is  0.445\n",
      "Positive prediction rate of class 2 is  0.365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lifuchen/Desktop/research/CVDPrediction-master/src/lib/fairness_tests.py:272: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train ['Class'] = y_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23261, 88)\n",
      "(42433, 88)\n",
      "0.12388268831231579 0.08438322557563058\n",
      "0.12386598860238686\n",
      "(67239, 87)\n",
      "X train 67239\n",
      "Y train 67239\n",
      "21898 7814 14084\n",
      "21898 7814 14084\n",
      "21898 7778 14120\n",
      "21898 7778 14120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29281746550269033\n",
      "0.2684413978458392\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19911\n",
      "           1       0.39      0.03      0.05      1987\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.65      0.51      0.50     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19822    89]\n",
      " [ 1930    57]]\n",
      "done in 0.757685s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29281746550269033\n",
      "0.2655069707345037\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19927\n",
      "           1       0.38      0.03      0.05      1971\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.65      0.51      0.50     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19847    80]\n",
      " [ 1921    50]]\n",
      "done in 0.656072s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29281746550269033\n",
      "0.29880350828427577\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6979\n",
      "           1       0.35      0.02      0.04       835\n",
      "\n",
      "    accuracy                           0.89      7814\n",
      "   macro avg       0.62      0.51      0.49      7814\n",
      "weighted avg       0.84      0.89      0.85      7814\n",
      "\n",
      "Confusion_matrix\n",
      "[[6947   32]\n",
      " [ 818   17]]\n",
      "done in 0.662179s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29281746550269033\n",
      "0.30433381114839797\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6927\n",
      "           1       0.52      0.02      0.04       851\n",
      "\n",
      "    accuracy                           0.89      7778\n",
      "   macro avg       0.70      0.51      0.49      7778\n",
      "weighted avg       0.85      0.89      0.84      7778\n",
      "\n",
      "Confusion_matrix\n",
      "[[6911   16]\n",
      " [ 834   17]]\n",
      "done in 0.702791s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29281746550269033\n",
      "0.2515960747156245\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12932\n",
      "           1       0.41      0.03      0.06      1152\n",
      "\n",
      "    accuracy                           0.92     14084\n",
      "   macro avg       0.67      0.52      0.51     14084\n",
      "weighted avg       0.88      0.92      0.88     14084\n",
      "\n",
      "Confusion_matrix\n",
      "[[12875    57]\n",
      " [ 1112    40]]\n",
      "done in 0.677231s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29281746550269033\n",
      "0.2441192111920625\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13000\n",
      "           1       0.34      0.03      0.05      1120\n",
      "\n",
      "    accuracy                           0.92     14120\n",
      "   macro avg       0.63      0.51      0.51     14120\n",
      "weighted avg       0.88      0.92      0.89     14120\n",
      "\n",
      "Confusion_matrix\n",
      "[[12936    64]\n",
      " [ 1087    33]]\n",
      "done in 0.624617s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19911\n",
      "           1       0.33      0.00      0.00      1987\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.62      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19907     4]\n",
      " [ 1985     2]]\n",
      "done in 19.632073s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19927\n",
      "           1       0.44      0.00      0.00      1971\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19922     5]\n",
      " [ 1967     4]]\n",
      "done in 21.459398s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6979\n",
      "           1       0.00      0.00      0.00       835\n",
      "\n",
      "    accuracy                           0.89      7814\n",
      "   macro avg       0.45      0.50      0.47      7814\n",
      "weighted avg       0.80      0.89      0.84      7814\n",
      "\n",
      "Confusion_matrix\n",
      "[[6978    1]\n",
      " [ 835    0]]\n",
      "done in 18.136544s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6927\n",
      "           1       0.00      0.00      0.00       851\n",
      "\n",
      "    accuracy                           0.89      7778\n",
      "   macro avg       0.45      0.50      0.47      7778\n",
      "weighted avg       0.79      0.89      0.84      7778\n",
      "\n",
      "Confusion_matrix\n",
      "[[6924    3]\n",
      " [ 851    0]]\n",
      "done in 18.020971s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12932\n",
      "           1       0.50      0.00      0.00      1152\n",
      "\n",
      "    accuracy                           0.92     14084\n",
      "   macro avg       0.71      0.50      0.48     14084\n",
      "weighted avg       0.88      0.92      0.88     14084\n",
      "\n",
      "Confusion_matrix\n",
      "[[12930     2]\n",
      " [ 1150     2]]\n",
      "done in 18.875069s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13000\n",
      "           1       0.57      0.00      0.01      1120\n",
      "\n",
      "    accuracy                           0.92     14120\n",
      "   macro avg       0.75      0.50      0.48     14120\n",
      "weighted avg       0.89      0.92      0.88     14120\n",
      "\n",
      "Confusion_matrix\n",
      "[[12997     3]\n",
      " [ 1116     4]]\n",
      "done in 18.338273s\n",
      "0.3054786536678037\n",
      "0.27623812244649887\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19911\n",
      "           1       0.00      0.00      0.00      1987\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.45      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19911     0]\n",
      " [ 1987     0]]\n",
      "done in 0.965198s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3054786536678037\n",
      "0.2731869826446992\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19927\n",
      "           1       1.00      0.00      0.00      1971\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.96      0.50      0.48     21898\n",
      "weighted avg       0.92      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19927     0]\n",
      " [ 1970     1]]\n",
      "done in 0.601841s\n",
      "0.3054786536678037\n",
      "0.307866868236583\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6979\n",
      "           1       0.00      0.00      0.00       835\n",
      "\n",
      "    accuracy                           0.89      7814\n",
      "   macro avg       0.45      0.50      0.47      7814\n",
      "weighted avg       0.80      0.89      0.84      7814\n",
      "\n",
      "Confusion_matrix\n",
      "[[6979    0]\n",
      " [ 835    0]]\n",
      "done in 0.569481s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3054786536678037\n",
      "0.3117481834809884\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6927\n",
      "           1       0.00      0.00      0.00       851\n",
      "\n",
      "    accuracy                           0.89      7778\n",
      "   macro avg       0.45      0.50      0.47      7778\n",
      "weighted avg       0.79      0.89      0.84      7778\n",
      "\n",
      "Confusion_matrix\n",
      "[[6927    0]\n",
      " [ 851    0]]\n",
      "done in 0.575021s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3054786536678037\n",
      "0.2586900523241105\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12932\n",
      "           1       0.00      0.00      0.00      1152\n",
      "\n",
      "    accuracy                           0.92     14084\n",
      "   macro avg       0.46      0.50      0.48     14084\n",
      "weighted avg       0.84      0.92      0.88     14084\n",
      "\n",
      "Confusion_matrix\n",
      "[[12932     0]\n",
      " [ 1152     0]]\n",
      "done in 0.640487s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3054786536678037\n",
      "0.2519455506259558\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13000\n",
      "           1       1.00      0.00      0.00      1120\n",
      "\n",
      "    accuracy                           0.92     14120\n",
      "   macro avg       0.96      0.50      0.48     14120\n",
      "weighted avg       0.93      0.92      0.88     14120\n",
      "\n",
      "Confusion_matrix\n",
      "[[13000     0]\n",
      " [ 1119     1]]\n",
      "done in 0.621642s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19911\n",
      "           1       0.53      0.01      0.02      1987\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.72      0.51      0.49     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19889    22]\n",
      " [ 1962    25]]\n",
      "done in 32.873380s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19927\n",
      "           1       0.49      0.01      0.02      1971\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.70      0.50      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19908    19]\n",
      " [ 1953    18]]\n",
      "done in 33.629311s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6979\n",
      "           1       0.65      0.01      0.03       835\n",
      "\n",
      "    accuracy                           0.89      7814\n",
      "   macro avg       0.77      0.51      0.48      7814\n",
      "weighted avg       0.87      0.89      0.85      7814\n",
      "\n",
      "Confusion_matrix\n",
      "[[6973    6]\n",
      " [ 824   11]]\n",
      "done in 32.527160s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6927\n",
      "           1       0.57      0.01      0.02       851\n",
      "\n",
      "    accuracy                           0.89      7778\n",
      "   macro avg       0.73      0.50      0.48      7778\n",
      "weighted avg       0.86      0.89      0.84      7778\n",
      "\n",
      "Confusion_matrix\n",
      "[[6921    6]\n",
      " [ 843    8]]\n",
      "done in 33.577431s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12932\n",
      "           1       0.48      0.01      0.02      1152\n",
      "\n",
      "    accuracy                           0.92     14084\n",
      "   macro avg       0.70      0.51      0.49     14084\n",
      "weighted avg       0.88      0.92      0.88     14084\n",
      "\n",
      "Confusion_matrix\n",
      "[[12917    15]\n",
      " [ 1138    14]]\n",
      "done in 33.129190s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13000\n",
      "           1       0.43      0.01      0.02      1120\n",
      "\n",
      "    accuracy                           0.92     14120\n",
      "   macro avg       0.68      0.50      0.49     14120\n",
      "weighted avg       0.88      0.92      0.88     14120\n",
      "\n",
      "Confusion_matrix\n",
      "[[12987    13]\n",
      " [ 1110    10]]\n",
      "done in 32.729365s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.38899999999999996\n",
      "threshold:0.2, J-value:0.274\n",
      "threshold:0.30000000000000004, J-value:0.143\n",
      "threshold:0.4, J-value:0.064\n",
      "threshold:0.5, J-value:0.025\n",
      "threshold:0.6000000000000001, J-value:0.012\n",
      "threshold:0.7000000000000001, J-value:0.006\n",
      "threshold:0.8, J-value:0.002\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6945627594885817\n",
      "Balanced accuracy score of test is  0.6972027555575313\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.385\n",
      "threshold:0.2, J-value:0.26\n",
      "threshold:0.30000000000000004, J-value:0.121\n",
      "threshold:0.4, J-value:0.043000000000000003\n",
      "threshold:0.5, J-value:0.015\n",
      "threshold:0.6000000000000001, J-value:0.009\n",
      "threshold:0.7000000000000001, J-value:0.005\n",
      "threshold:0.8, J-value:0.004\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.692609565222614\n",
      "Balanced accuracy score of test is  0.6851116656038794\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.38799999999999996\n",
      "threshold:0.2, J-value:0.28400000000000003\n",
      "threshold:0.30000000000000004, J-value:0.159\n",
      "threshold:0.4, J-value:0.078\n",
      "threshold:0.5, J-value:0.031000000000000003\n",
      "threshold:0.6000000000000001, J-value:0.015\n",
      "threshold:0.7000000000000001, J-value:0.006\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6938977815582362\n",
      "Balanced accuracy score of test is  0.7029615384615384\n",
      "True positive rate of class 1 is  0.736\n",
      "True positive rate of class 2 is  0.725\n",
      "Positive prediction rate of class 1 is  0.406\n",
      "Positive prediction rate of class 2 is  0.351\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.367\n",
      "threshold:0.2, J-value:0.294\n",
      "threshold:0.30000000000000004, J-value:0.125\n",
      "threshold:0.4, J-value:0.029\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6835237137420556\n",
      "Balanced accuracy score of test is  0.6974483882915411\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.34900000000000003\n",
      "threshold:0.2, J-value:0.30899999999999994\n",
      "threshold:0.30000000000000004, J-value:0.131\n",
      "threshold:0.4, J-value:0.03\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6742416299368593\n",
      "Balanced accuracy score of test is  0.6803122440044127\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.373\n",
      "threshold:0.2, J-value:0.287\n",
      "threshold:0.30000000000000004, J-value:0.134\n",
      "threshold:0.4, J-value:0.019\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6863520347888099\n",
      "Balanced accuracy score of test is  0.6994917582417582\n",
      "True positive rate of class 1 is  0.816\n",
      "True positive rate of class 2 is  0.748\n",
      "Positive prediction rate of class 1 is  0.494\n",
      "Positive prediction rate of class 2 is  0.381\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.349\n",
      "threshold:0.2, J-value:0.22500000000000003\n",
      "threshold:0.30000000000000004, J-value:0.124\n",
      "threshold:0.4, J-value:0.002\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6748526286716705\n",
      "Balanced accuracy score of test is  0.6795907675903909\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.318\n",
      "threshold:0.2, J-value:0.22399999999999998\n",
      "threshold:0.30000000000000004, J-value:0.138\n",
      "threshold:0.4, J-value:0.002\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6587628582925852\n",
      "Balanced accuracy score of test is  0.6653914916290874\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.365\n",
      "threshold:0.2, J-value:0.223\n",
      "threshold:0.30000000000000004, J-value:0.11299999999999999\n",
      "threshold:0.4, J-value:0.002\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6824931747688765\n",
      "Balanced accuracy score of test is  0.6848997252747253\n",
      "True positive rate of class 1 is  0.759\n",
      "True positive rate of class 2 is  0.724\n",
      "Positive prediction rate of class 1 is  0.465\n",
      "Positive prediction rate of class 2 is  0.384\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.398\n",
      "threshold:0.2, J-value:0.298\n",
      "threshold:0.30000000000000004, J-value:0.143\n",
      "threshold:0.4, J-value:0.044\n",
      "threshold:0.5, J-value:0.012\n",
      "threshold:0.6000000000000001, J-value:0.004\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy score of val is  0.699258934265534\n",
      "Balanced accuracy score of test is  0.7030921488496431\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.39\n",
      "threshold:0.2, J-value:0.296\n",
      "threshold:0.30000000000000004, J-value:0.149\n",
      "threshold:0.4, J-value:0.044\n",
      "threshold:0.5, J-value:0.012\n",
      "threshold:0.6000000000000001, J-value:0.004\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6951402539526192\n",
      "Balanced accuracy score of test is  0.6928243795417615\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.39499999999999996\n",
      "threshold:0.2, J-value:0.29700000000000004\n",
      "threshold:0.30000000000000004, J-value:0.138\n",
      "threshold:0.4, J-value:0.043\n",
      "threshold:0.5, J-value:0.011\n",
      "threshold:0.6000000000000001, J-value:0.004\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6976107126593807\n",
      "Balanced accuracy score of test is  0.7048571428571428\n",
      "True positive rate of class 1 is  0.793\n",
      "True positive rate of class 2 is  0.736\n",
      "Positive prediction rate of class 1 is  0.45\n",
      "Positive prediction rate of class 2 is  0.358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lifuchen/Desktop/research/CVDPrediction-master/src/lib/fairness_tests.py:272: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train ['Class'] = y_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23328, 88)\n",
      "(42366, 88)\n",
      "0.12332065295902152 0.08630769230769231\n",
      "0.12330769230769231\n",
      "(67137, 87)\n",
      "X train 67137\n",
      "Y train 67137\n",
      "21898 7644 14254\n",
      "21898 7644 14254\n",
      "21898 7881 14017\n",
      "21898 7881 14017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2931188218278894\n",
      "0.26198865113994235\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19944\n",
      "           1       0.44      0.03      0.06      1954\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.51      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19868    76]\n",
      " [ 1894    60]]\n",
      "done in 0.709687s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2931188218278894\n",
      "0.2634831313226838\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19955\n",
      "           1       0.45      0.03      0.06      1943\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.51      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19877    78]\n",
      " [ 1880    63]]\n",
      "done in 0.761163s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2931188218278894\n",
      "0.3026873797485269\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6814\n",
      "           1       0.37      0.02      0.03       830\n",
      "\n",
      "    accuracy                           0.89      7644\n",
      "   macro avg       0.63      0.51      0.49      7644\n",
      "weighted avg       0.84      0.89      0.84      7644\n",
      "\n",
      "Confusion_matrix\n",
      "[[6792   22]\n",
      " [ 817   13]]\n",
      "done in 0.622228s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2931188218278894\n",
      "0.29873830964435155\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      7022\n",
      "           1       0.42      0.02      0.04       859\n",
      "\n",
      "    accuracy                           0.89      7881\n",
      "   macro avg       0.66      0.51      0.49      7881\n",
      "weighted avg       0.84      0.89      0.84      7881\n",
      "\n",
      "Confusion_matrix\n",
      "[[6996   26]\n",
      " [ 840   19]]\n",
      "done in 0.725680s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2931188218278894\n",
      "0.24016312276306423\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13130\n",
      "           1       0.47      0.04      0.08      1124\n",
      "\n",
      "    accuracy                           0.92     14254\n",
      "   macro avg       0.69      0.52      0.52     14254\n",
      "weighted avg       0.89      0.92      0.89     14254\n",
      "\n",
      "Confusion_matrix\n",
      "[[13076    54]\n",
      " [ 1077    47]]\n",
      "done in 0.841808s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2931188218278894\n",
      "0.24366105382014666\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96     12933\n",
      "           1       0.46      0.04      0.07      1084\n",
      "\n",
      "    accuracy                           0.92     14017\n",
      "   macro avg       0.69      0.52      0.52     14017\n",
      "weighted avg       0.89      0.92      0.89     14017\n",
      "\n",
      "Confusion_matrix\n",
      "[[12881    52]\n",
      " [ 1040    44]]\n",
      "done in 0.815245s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19944\n",
      "           1       0.45      0.00      0.01      1954\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19938     6]\n",
      " [ 1949     5]]\n",
      "done in 18.953298s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19955\n",
      "           1       0.36      0.00      0.00      1943\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.64      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19948     7]\n",
      " [ 1939     4]]\n",
      "done in 18.237389s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6814\n",
      "           1       0.60      0.00      0.01       830\n",
      "\n",
      "    accuracy                           0.89      7644\n",
      "   macro avg       0.75      0.50      0.47      7644\n",
      "weighted avg       0.86      0.89      0.84      7644\n",
      "\n",
      "Confusion_matrix\n",
      "[[6812    2]\n",
      " [ 827    3]]\n",
      "done in 17.866646s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      7022\n",
      "           1       0.50      0.00      0.00       859\n",
      "\n",
      "    accuracy                           0.89      7881\n",
      "   macro avg       0.70      0.50      0.47      7881\n",
      "weighted avg       0.85      0.89      0.84      7881\n",
      "\n",
      "Confusion_matrix\n",
      "[[7020    2]\n",
      " [ 857    2]]\n",
      "done in 17.690518s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13130\n",
      "           1       0.50      0.00      0.00      1124\n",
      "\n",
      "    accuracy                           0.92     14254\n",
      "   macro avg       0.71      0.50      0.48     14254\n",
      "weighted avg       0.89      0.92      0.88     14254\n",
      "\n",
      "Confusion_matrix\n",
      "[[13128     2]\n",
      " [ 1122     2]]\n",
      "done in 18.389037s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12933\n",
      "           1       0.56      0.00      0.01      1084\n",
      "\n",
      "    accuracy                           0.92     14017\n",
      "   macro avg       0.74      0.50      0.48     14017\n",
      "weighted avg       0.89      0.92      0.89     14017\n",
      "\n",
      "Confusion_matrix\n",
      "[[12929     4]\n",
      " [ 1079     5]]\n",
      "done in 18.723412s\n",
      "0.3048709001612465\n",
      "0.2756297670478613\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19944\n",
      "           1       0.19      0.00      0.01      1954\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.55      0.50      0.48     21898\n",
      "weighted avg       0.85      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19915    29]\n",
      " [ 1947     7]]\n",
      "done in 0.623248s\n",
      "0.3048709001612465\n",
      "0.27363814776069484\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19955\n",
      "           1       0.24      0.01      0.01      1943\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.58      0.50      0.48     21898\n",
      "weighted avg       0.85      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19921    34]\n",
      " [ 1932    11]]\n",
      "done in 0.655719s\n",
      "0.3048709001612465\n",
      "0.3217423123781037\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6814\n",
      "           1       0.23      0.00      0.01       830\n",
      "\n",
      "    accuracy                           0.89      7644\n",
      "   macro avg       0.56      0.50      0.47      7644\n",
      "weighted avg       0.82      0.89      0.84      7644\n",
      "\n",
      "Confusion_matrix\n",
      "[[6804   10]\n",
      " [ 827    3]]\n",
      "done in 0.653327s\n",
      "0.3048709001612465\n",
      "0.31192275229408967\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      7022\n",
      "           1       0.21      0.00      0.01       859\n",
      "\n",
      "    accuracy                           0.89      7881\n",
      "   macro avg       0.55      0.50      0.47      7881\n",
      "weighted avg       0.82      0.89      0.84      7881\n",
      "\n",
      "Confusion_matrix\n",
      "[[7011   11]\n",
      " [ 856    3]]\n",
      "done in 0.600636s\n",
      "0.3048709001612465\n",
      "0.25331967811018236\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13130\n",
      "           1       0.17      0.00      0.01      1124\n",
      "\n",
      "    accuracy                           0.92     14254\n",
      "   macro avg       0.54      0.50      0.48     14254\n",
      "weighted avg       0.86      0.92      0.88     14254\n",
      "\n",
      "Confusion_matrix\n",
      "[[13110    20]\n",
      " [ 1120     4]]\n",
      "done in 0.622907s\n",
      "0.3048709001612465\n",
      "0.252112787959904\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12933\n",
      "           1       0.26      0.01      0.01      1084\n",
      "\n",
      "    accuracy                           0.92     14017\n",
      "   macro avg       0.59      0.50      0.49     14017\n",
      "weighted avg       0.87      0.92      0.89     14017\n",
      "\n",
      "Confusion_matrix\n",
      "[[12910    23]\n",
      " [ 1076     8]]\n",
      "done in 0.606230s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19944\n",
      "           1       0.44      0.01      0.02      1954\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.51      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19915    29]\n",
      " [ 1931    23]]\n",
      "done in 33.302232s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19955\n",
      "           1       0.46      0.01      0.02      1943\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.69      0.51      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19927    28]\n",
      " [ 1919    24]]\n",
      "done in 33.312798s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6814\n",
      "           1       0.39      0.01      0.02       830\n",
      "\n",
      "    accuracy                           0.89      7644\n",
      "   macro avg       0.64      0.50      0.48      7644\n",
      "weighted avg       0.84      0.89      0.84      7644\n",
      "\n",
      "Confusion_matrix\n",
      "[[6803   11]\n",
      " [ 823    7]]\n",
      "done in 34.666749s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      7022\n",
      "           1       0.46      0.02      0.03       859\n",
      "\n",
      "    accuracy                           0.89      7881\n",
      "   macro avg       0.68      0.51      0.49      7881\n",
      "weighted avg       0.85      0.89      0.84      7881\n",
      "\n",
      "Confusion_matrix\n",
      "[[7007   15]\n",
      " [ 846   13]]\n",
      "done in 33.952319s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13130\n",
      "           1       0.47      0.01      0.03      1124\n",
      "\n",
      "    accuracy                           0.92     14254\n",
      "   macro avg       0.70      0.51      0.49     14254\n",
      "weighted avg       0.89      0.92      0.89     14254\n",
      "\n",
      "Confusion_matrix\n",
      "[[13112    18]\n",
      " [ 1108    16]]\n",
      "done in 34.183159s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12933\n",
      "           1       0.46      0.01      0.02      1084\n",
      "\n",
      "    accuracy                           0.92     14017\n",
      "   macro avg       0.69      0.50      0.49     14017\n",
      "weighted avg       0.89      0.92      0.89     14017\n",
      "\n",
      "Confusion_matrix\n",
      "[[12920    13]\n",
      " [ 1073    11]]\n",
      "done in 33.039065s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.40399999999999997\n",
      "threshold:0.2, J-value:0.29500000000000004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.30000000000000004, J-value:0.154\n",
      "threshold:0.4, J-value:0.065\n",
      "threshold:0.5, J-value:0.027\n",
      "threshold:0.6000000000000001, J-value:0.009999999999999998\n",
      "threshold:0.7000000000000001, J-value:0.003\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7017226791823656\n",
      "Balanced accuracy score of test is  0.6920526537256434\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.365\n",
      "threshold:0.2, J-value:0.253\n",
      "threshold:0.30000000000000004, J-value:0.118\n",
      "threshold:0.4, J-value:0.048999999999999995\n",
      "threshold:0.5, J-value:0.013000000000000001\n",
      "threshold:0.6000000000000001, J-value:0.005\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6822286504397396\n",
      "Balanced accuracy score of test is  0.696607436001073\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.426\n",
      "threshold:0.2, J-value:0.324\n",
      "threshold:0.30000000000000004, J-value:0.181\n",
      "threshold:0.4, J-value:0.078\n",
      "threshold:0.5, J-value:0.038000000000000006\n",
      "threshold:0.6000000000000001, J-value:0.013000000000000001\n",
      "threshold:0.7000000000000001, J-value:0.004\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7128731166300315\n",
      "Balanced accuracy score of test is  0.6854879804887124\n",
      "True positive rate of class 1 is  0.754\n",
      "True positive rate of class 2 is  0.696\n",
      "Positive prediction rate of class 1 is  0.404\n",
      "Positive prediction rate of class 2 is  0.353\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.388\n",
      "threshold:0.2, J-value:0.29600000000000004\n",
      "threshold:0.30000000000000004, J-value:0.131\n",
      "threshold:0.4, J-value:0.024\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6937284683705984\n",
      "Balanced accuracy score of test is  0.6963980329905952\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.34900000000000003\n",
      "threshold:0.2, J-value:0.29400000000000004\n",
      "threshold:0.30000000000000004, J-value:0.142\n",
      "threshold:0.4, J-value:0.028\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6741911585290383\n",
      "Balanced accuracy score of test is  0.6901527512567354\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.389\n",
      "threshold:0.2, J-value:0.328\n",
      "threshold:0.30000000000000004, J-value:0.124\n",
      "threshold:0.4, J-value:0.022\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6946375283572704\n",
      "Balanced accuracy score of test is  0.6861235653066343\n",
      "True positive rate of class 1 is  0.83\n",
      "True positive rate of class 2 is  0.73\n",
      "Positive prediction rate of class 1 is  0.491\n",
      "Positive prediction rate of class 2 is  0.386\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.36100000000000004\n",
      "threshold:0.2, J-value:0.29000000000000004\n",
      "threshold:0.30000000000000004, J-value:0.10200000000000001\n",
      "threshold:0.4, J-value:0.003\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6805821653752309\n",
      "Balanced accuracy score of test is  0.6771561283087668\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.32700000000000007\n",
      "threshold:0.2, J-value:0.24300000000000002\n",
      "threshold:0.30000000000000004, J-value:0.10800000000000001\n",
      "threshold:0.4, J-value:0.003\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:-0.001\n",
      "threshold:0.7000000000000001, J-value:-0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6637371322684338\n",
      "Balanced accuracy score of test is  0.6755150700492614\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.374\n",
      "threshold:0.2, J-value:0.32200000000000006\n",
      "threshold:0.30000000000000004, J-value:0.099\n",
      "threshold:0.4, J-value:0.002\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6866716085788704\n",
      "Balanced accuracy score of test is  0.6721149848937599\n",
      "True positive rate of class 1 is  0.82\n",
      "True positive rate of class 2 is  0.734\n",
      "Positive prediction rate of class 1 is  0.507\n",
      "Positive prediction rate of class 2 is  0.417\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41400000000000003\n",
      "threshold:0.2, J-value:0.305\n",
      "threshold:0.30000000000000004, J-value:0.14100000000000001\n",
      "threshold:0.4, J-value:0.034\n",
      "threshold:0.5, J-value:0.011\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7070191623546955\n",
      "Balanced accuracy score of test is  0.7028077843186284\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.38800000000000007\n",
      "threshold:0.2, J-value:0.277\n",
      "threshold:0.30000000000000004, J-value:0.135\n",
      "threshold:0.4, J-value:0.04\n",
      "threshold:0.5, J-value:0.006\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6941157644962002\n",
      "Balanced accuracy score of test is  0.7012629358122435\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.421\n",
      "threshold:0.2, J-value:0.323\n",
      "threshold:0.30000000000000004, J-value:0.145\n",
      "threshold:0.4, J-value:0.03\n",
      "threshold:0.5, J-value:0.013000000000000001\n",
      "threshold:0.6000000000000001, J-value:0.004\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7104272088856847\n",
      "Balanced accuracy score of test is  0.6980670746164663\n",
      "True positive rate of class 1 is  0.81\n",
      "True positive rate of class 2 is  0.731\n",
      "Positive prediction rate of class 1 is  0.452\n",
      "Positive prediction rate of class 2 is  0.365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lifuchen/Desktop/research/CVDPrediction-master/src/lib/fairness_tests.py:272: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train ['Class'] = y_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23296, 88)\n",
      "(42398, 88)\n",
      "0.12005384874272802 0.085263777612819\n",
      "0.1200501702203906\n",
      "(67053, 87)\n",
      "X train 67053\n",
      "Y train 67053\n",
      "21898 7795 14103\n",
      "21898 7795 14103\n",
      "21898 7762 14136\n",
      "21898 7762 14136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2896755097159808\n",
      "0.2675567031128867\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19893\n",
      "           1       0.42      0.03      0.06      2005\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.66      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19806    87]\n",
      " [ 1943    62]]\n",
      "done in 0.873394s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2896755097159808\n",
      "0.26570775704499433\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19907\n",
      "           1       0.47      0.03      0.06      1991\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.69      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19839    68]\n",
      " [ 1931    60]]\n",
      "done in 0.824732s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2896755097159808\n",
      "0.30772431727222116\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6922\n",
      "           1       0.34      0.02      0.03       873\n",
      "\n",
      "    accuracy                           0.89      7795\n",
      "   macro avg       0.62      0.51      0.49      7795\n",
      "weighted avg       0.83      0.89      0.84      7795\n",
      "\n",
      "Confusion_matrix\n",
      "[[6893   29]\n",
      " [ 858   15]]\n",
      "done in 0.688888s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2896755097159808\n",
      "0.3074825621617685\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6882\n",
      "           1       0.58      0.03      0.05       880\n",
      "\n",
      "    accuracy                           0.89      7762\n",
      "   macro avg       0.74      0.51      0.50      7762\n",
      "weighted avg       0.85      0.89      0.84      7762\n",
      "\n",
      "Confusion_matrix\n",
      "[[6864   18]\n",
      " [ 855   25]]\n",
      "done in 0.990580s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2896755097159808\n",
      "0.2453552883520548\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12971\n",
      "           1       0.45      0.04      0.08      1132\n",
      "\n",
      "    accuracy                           0.92     14103\n",
      "   macro avg       0.69      0.52      0.52     14103\n",
      "weighted avg       0.88      0.92      0.89     14103\n",
      "\n",
      "Confusion_matrix\n",
      "[[12913    58]\n",
      " [ 1085    47]]\n",
      "done in 0.674091s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2896755097159808\n",
      "0.24276944087943103\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13025\n",
      "           1       0.41      0.03      0.06      1111\n",
      "\n",
      "    accuracy                           0.92     14136\n",
      "   macro avg       0.67      0.51      0.51     14136\n",
      "weighted avg       0.88      0.92      0.89     14136\n",
      "\n",
      "Confusion_matrix\n",
      "[[12975    50]\n",
      " [ 1076    35]]\n",
      "done in 0.652389s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19893\n",
      "           1       0.50      0.00      0.01      2005\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.70      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19885     8]\n",
      " [ 1997     8]]\n",
      "done in 19.102137s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19907\n",
      "           1       0.33      0.00      0.00      1991\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.62      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19901     6]\n",
      " [ 1988     3]]\n",
      "done in 18.466347s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6922\n",
      "           1       0.60      0.00      0.01       873\n",
      "\n",
      "    accuracy                           0.89      7795\n",
      "   macro avg       0.74      0.50      0.47      7795\n",
      "weighted avg       0.86      0.89      0.84      7795\n",
      "\n",
      "Confusion_matrix\n",
      "[[6920    2]\n",
      " [ 870    3]]\n",
      "done in 18.035376s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6882\n",
      "           1       0.50      0.00      0.00       880\n",
      "\n",
      "    accuracy                           0.89      7762\n",
      "   macro avg       0.69      0.50      0.47      7762\n",
      "weighted avg       0.84      0.89      0.83      7762\n",
      "\n",
      "Confusion_matrix\n",
      "[[6880    2]\n",
      " [ 878    2]]\n",
      "done in 18.131786s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12971\n",
      "           1       0.47      0.01      0.01      1132\n",
      "\n",
      "    accuracy                           0.92     14103\n",
      "   macro avg       0.69      0.50      0.49     14103\n",
      "weighted avg       0.88      0.92      0.88     14103\n",
      "\n",
      "Confusion_matrix\n",
      "[[12963     8]\n",
      " [ 1125     7]]\n",
      "done in 17.856801s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13025\n",
      "           1       0.25      0.00      0.00      1111\n",
      "\n",
      "    accuracy                           0.92     14136\n",
      "   macro avg       0.59      0.50      0.48     14136\n",
      "weighted avg       0.87      0.92      0.88     14136\n",
      "\n",
      "Confusion_matrix\n",
      "[[13019     6]\n",
      " [ 1109     2]]\n",
      "done in 18.926063s\n",
      "0.30044194784970474\n",
      "0.27784967300328933\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19893\n",
      "           1       0.03      0.00      0.00      2005\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.47      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.86     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19865    28]\n",
      " [ 2004     1]]\n",
      "done in 0.593736s\n",
      "0.30044194784970474\n",
      "0.2768518073925276\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19907\n",
      "           1       0.32      0.00      0.01      1991\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.61      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19890    17]\n",
      " [ 1983     8]]\n",
      "done in 0.612154s\n",
      "0.30044194784970474\n",
      "0.3160006438662092\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6922\n",
      "           1       0.07      0.00      0.00       873\n",
      "\n",
      "    accuracy                           0.89      7795\n",
      "   macro avg       0.48      0.50      0.47      7795\n",
      "weighted avg       0.80      0.89      0.83      7795\n",
      "\n",
      "Confusion_matrix\n",
      "[[6908   14]\n",
      " [ 872    1]]\n",
      "done in 0.584698s\n",
      "0.30044194784970474\n",
      "0.317656025971264\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6882\n",
      "           1       0.27      0.00      0.01       880\n",
      "\n",
      "    accuracy                           0.89      7762\n",
      "   macro avg       0.58      0.50      0.47      7762\n",
      "weighted avg       0.82      0.89      0.83      7762\n",
      "\n",
      "Confusion_matrix\n",
      "[[6874    8]\n",
      " [ 877    3]]\n",
      "done in 0.568362s\n",
      "0.30044194784970474\n",
      "0.25676289587243345\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12971\n",
      "           1       0.00      0.00      0.00      1132\n",
      "\n",
      "    accuracy                           0.92     14103\n",
      "   macro avg       0.46      0.50      0.48     14103\n",
      "weighted avg       0.85      0.92      0.88     14103\n",
      "\n",
      "Confusion_matrix\n",
      "[[12957    14]\n",
      " [ 1132     0]]\n",
      "done in 0.576200s\n",
      "0.30044194784970474\n",
      "0.25444643496693675\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13025\n",
      "           1       0.36      0.00      0.01      1111\n",
      "\n",
      "    accuracy                           0.92     14136\n",
      "   macro avg       0.64      0.50      0.48     14136\n",
      "weighted avg       0.88      0.92      0.88     14136\n",
      "\n",
      "Confusion_matrix\n",
      "[[13016     9]\n",
      " [ 1106     5]]\n",
      "done in 0.569987s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19893\n",
      "           1       0.50      0.02      0.03      2005\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.70      0.51      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19858    35]\n",
      " [ 1970    35]]\n",
      "done in 32.663299s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19907\n",
      "           1       0.34      0.01      0.01      1991\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.63      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19880    27]\n",
      " [ 1977    14]]\n",
      "done in 32.793784s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6922\n",
      "           1       0.45      0.01      0.02       873\n",
      "\n",
      "    accuracy                           0.89      7795\n",
      "   macro avg       0.67      0.50      0.48      7795\n",
      "weighted avg       0.84      0.89      0.84      7795\n",
      "\n",
      "Confusion_matrix\n",
      "[[6910   12]\n",
      " [ 863   10]]\n",
      "done in 32.225715s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6882\n",
      "           1       0.45      0.01      0.02       880\n",
      "\n",
      "    accuracy                           0.89      7762\n",
      "   macro avg       0.67      0.50      0.48      7762\n",
      "weighted avg       0.84      0.89      0.84      7762\n",
      "\n",
      "Confusion_matrix\n",
      "[[6871   11]\n",
      " [ 871    9]]\n",
      "done in 32.730912s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12971\n",
      "           1       0.50      0.02      0.04      1132\n",
      "\n",
      "    accuracy                           0.92     14103\n",
      "   macro avg       0.71      0.51      0.50     14103\n",
      "weighted avg       0.89      0.92      0.88     14103\n",
      "\n",
      "Confusion_matrix\n",
      "[[12947    24]\n",
      " [ 1108    24]]\n",
      "done in 32.830422s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13025\n",
      "           1       0.24      0.00      0.01      1111\n",
      "\n",
      "    accuracy                           0.92     14136\n",
      "   macro avg       0.58      0.50      0.48     14136\n",
      "weighted avg       0.87      0.92      0.88     14136\n",
      "\n",
      "Confusion_matrix\n",
      "[[13009    16]\n",
      " [ 1106     5]]\n",
      "done in 32.317982s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.40399999999999997\n",
      "threshold:0.2, J-value:0.29400000000000004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.30000000000000004, J-value:0.165\n",
      "threshold:0.4, J-value:0.07300000000000001\n",
      "threshold:0.5, J-value:0.027\n",
      "threshold:0.6000000000000001, J-value:0.005\n",
      "threshold:0.7000000000000001, J-value:0.003\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7018502604896295\n",
      "Balanced accuracy score of test is  0.6977655162300781\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.388\n",
      "threshold:0.2, J-value:0.266\n",
      "threshold:0.30000000000000004, J-value:0.131\n",
      "threshold:0.4, J-value:0.051000000000000004\n",
      "threshold:0.5, J-value:0.013000000000000001\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6938525934376607\n",
      "Balanced accuracy score of test is  0.6958221050962987\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.409\n",
      "threshold:0.2, J-value:0.314\n",
      "threshold:0.30000000000000004, J-value:0.193\n",
      "threshold:0.4, J-value:0.089\n",
      "threshold:0.5, J-value:0.038000000000000006\n",
      "threshold:0.6000000000000001, J-value:0.009\n",
      "threshold:0.7000000000000001, J-value:0.004\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.704552292924172\n",
      "Balanced accuracy score of test is  0.6964992890843786\n",
      "True positive rate of class 1 is  0.739\n",
      "True positive rate of class 2 is  0.707\n",
      "Positive prediction rate of class 1 is  0.391\n",
      "Positive prediction rate of class 2 is  0.345\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.385\n",
      "threshold:0.2, J-value:0.302\n",
      "threshold:0.30000000000000004, J-value:0.128\n",
      "threshold:0.4, J-value:0.026000000000000002\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6922383128791403\n",
      "Balanced accuracy score of test is  0.6926883665498611\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.36100000000000004\n",
      "threshold:0.2, J-value:0.29500000000000004\n",
      "threshold:0.30000000000000004, J-value:0.11499999999999999\n",
      "threshold:0.4, J-value:0.028000000000000004\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6805632918996258\n",
      "Balanced accuracy score of test is  0.6836850413463317\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41700000000000004\n",
      "threshold:0.2, J-value:0.309\n",
      "threshold:0.30000000000000004, J-value:0.13\n",
      "threshold:0.4, J-value:0.030000000000000002\n",
      "threshold:0.5, J-value:0.005\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7081551588444241\n",
      "Balanced accuracy score of test is  0.6951324652618813\n",
      "True positive rate of class 1 is  0.802\n",
      "True positive rate of class 2 is  0.745\n",
      "Positive prediction rate of class 1 is  0.477\n",
      "Positive prediction rate of class 2 is  0.386\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.34700000000000003\n",
      "threshold:0.2, J-value:0.275\n",
      "threshold:0.30000000000000004, J-value:0.10300000000000001\n",
      "threshold:0.4, J-value:0.042\n",
      "threshold:0.5, J-value:-0.001\n",
      "threshold:0.6000000000000001, J-value:-0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6732178752334967\n",
      "Balanced accuracy score of test is  0.6752576527563365\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.327\n",
      "threshold:0.2, J-value:0.255\n",
      "threshold:0.30000000000000004, J-value:0.093\n",
      "threshold:0.4, J-value:0.052\n",
      "threshold:0.5, J-value:-0.001\n",
      "threshold:0.6000000000000001, J-value:-0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.663758132262855\n",
      "Balanced accuracy score of test is  0.6642755475416766\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.351\n",
      "threshold:0.2, J-value:0.28500000000000003\n",
      "threshold:0.30000000000000004, J-value:0.11100000000000002\n",
      "threshold:0.4, J-value:0.034\n",
      "threshold:0.5, J-value:-0.001\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6755759586552552\n",
      "Balanced accuracy score of test is  0.6800511375513751\n",
      "True positive rate of class 1 is  0.772\n",
      "True positive rate of class 2 is  0.758\n",
      "Positive prediction rate of class 1 is  0.48\n",
      "Positive prediction rate of class 2 is  0.426\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.406\n",
      "threshold:0.2, J-value:0.308\n",
      "threshold:0.30000000000000004, J-value:0.152\n",
      "threshold:0.4, J-value:0.058\n",
      "threshold:0.5, J-value:0.015000000000000001\n",
      "threshold:0.6000000000000001, J-value:0.002\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7030898849994602\n",
      "Balanced accuracy score of test is  0.702837026931636\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.385\n",
      "threshold:0.2, J-value:0.284\n",
      "threshold:0.30000000000000004, J-value:0.13599999999999998\n",
      "threshold:0.4, J-value:0.055\n",
      "threshold:0.5, J-value:0.009\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6925844122016791\n",
      "Balanced accuracy score of test is  0.6973737483818129\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41\n",
      "threshold:0.2, J-value:0.324\n",
      "threshold:0.30000000000000004, J-value:0.162\n",
      "threshold:0.4, J-value:0.059000000000000004\n",
      "threshold:0.5, J-value:0.019000000000000003\n",
      "threshold:0.6000000000000001, J-value:0.004\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.704977984321099\n",
      "Balanced accuracy score of test is  0.7015290818909146\n",
      "True positive rate of class 1 is  0.781\n",
      "True positive rate of class 2 is  0.724\n",
      "Positive prediction rate of class 1 is  0.431\n",
      "Positive prediction rate of class 2 is  0.352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lifuchen/Desktop/research/CVDPrediction-master/src/lib/fairness_tests.py:272: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train ['Class'] = y_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23200, 88)\n",
      "(42494, 88)\n",
      "0.12305160228482913 0.08621967741110913\n",
      "0.12302855243986606\n",
      "(67134, 87)\n",
      "X train 67134\n",
      "Y train 67134\n",
      "21898 7804 14094\n",
      "21898 7804 14094\n",
      "21898 7849 14049\n",
      "21898 7849 14049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29196351864161635\n",
      "0.26569594508936734\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19931\n",
      "           1       0.51      0.03      0.06      1967\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.71      0.52      0.51     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19866    65]\n",
      " [ 1899    68]]\n",
      "done in 0.762245s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29196351864161635\n",
      "0.2626298436035843\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19956\n",
      "           1       0.42      0.03      0.06      1942\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19876    80]\n",
      " [ 1883    59]]\n",
      "done in 0.646569s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29196351864161635\n",
      "0.3068925974834796\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6937\n",
      "           1       0.53      0.03      0.06       867\n",
      "\n",
      "    accuracy                           0.89      7804\n",
      "   macro avg       0.71      0.51      0.50      7804\n",
      "weighted avg       0.85      0.89      0.84      7804\n",
      "\n",
      "Confusion_matrix\n",
      "[[6913   24]\n",
      " [ 840   27]]\n",
      "done in 0.610850s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29196351864161635\n",
      "0.2976828937985205\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.94      7008\n",
      "           1       0.54      0.03      0.06       841\n",
      "\n",
      "    accuracy                           0.89      7849\n",
      "   macro avg       0.72      0.51      0.50      7849\n",
      "weighted avg       0.86      0.89      0.85      7849\n",
      "\n",
      "Confusion_matrix\n",
      "[[6985   23]\n",
      " [ 814   27]]\n",
      "done in 0.581048s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29196351864161635\n",
      "0.242884913779331\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12994\n",
      "           1       0.50      0.04      0.07      1100\n",
      "\n",
      "    accuracy                           0.92     14094\n",
      "   macro avg       0.71      0.52      0.51     14094\n",
      "weighted avg       0.89      0.92      0.89     14094\n",
      "\n",
      "Confusion_matrix\n",
      "[[12953    41]\n",
      " [ 1059    41]]\n",
      "done in 0.587410s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29196351864161635\n",
      "0.24304614433815233\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12948\n",
      "           1       0.36      0.03      0.05      1101\n",
      "\n",
      "    accuracy                           0.92     14049\n",
      "   macro avg       0.64      0.51      0.51     14049\n",
      "weighted avg       0.88      0.92      0.89     14049\n",
      "\n",
      "Confusion_matrix\n",
      "[[12891    57]\n",
      " [ 1069    32]]\n",
      "done in 0.675523s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19931\n",
      "           1       0.37      0.00      0.01      1967\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.64      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19919    12]\n",
      " [ 1960     7]]\n",
      "done in 18.039911s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19956\n",
      "           1       0.60      0.00      0.01      1942\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.76      0.50      0.48     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19952     4]\n",
      " [ 1936     6]]\n",
      "done in 17.952261s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6937\n",
      "           1       0.00      0.00      0.00       867\n",
      "\n",
      "    accuracy                           0.89      7804\n",
      "   macro avg       0.44      0.50      0.47      7804\n",
      "weighted avg       0.79      0.89      0.84      7804\n",
      "\n",
      "Confusion_matrix\n",
      "[[6927   10]\n",
      " [ 867    0]]\n",
      "done in 17.828014s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      7008\n",
      "           1       0.25      0.00      0.00       841\n",
      "\n",
      "    accuracy                           0.89      7849\n",
      "   macro avg       0.57      0.50      0.47      7849\n",
      "weighted avg       0.82      0.89      0.84      7849\n",
      "\n",
      "Confusion_matrix\n",
      "[[7005    3]\n",
      " [ 840    1]]\n",
      "done in 17.797814s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12994\n",
      "           1       0.80      0.00      0.01      1100\n",
      "\n",
      "    accuracy                           0.92     14094\n",
      "   macro avg       0.86      0.50      0.48     14094\n",
      "weighted avg       0.91      0.92      0.89     14094\n",
      "\n",
      "Confusion_matrix\n",
      "[[12993     1]\n",
      " [ 1096     4]]\n",
      "done in 18.349092s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12948\n",
      "           1       0.60      0.00      0.01      1101\n",
      "\n",
      "    accuracy                           0.92     14049\n",
      "   macro avg       0.76      0.50      0.48     14049\n",
      "weighted avg       0.90      0.92      0.88     14049\n",
      "\n",
      "Confusion_matrix\n",
      "[[12946     2]\n",
      " [ 1098     3]]\n",
      "done in 17.871036s\n",
      "0.30440458513738927\n",
      "0.2729159448448805\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19931\n",
      "           1       0.21      0.00      0.00      1967\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.56      0.50      0.48     21898\n",
      "weighted avg       0.85      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19920    11]\n",
      " [ 1964     3]]\n",
      "done in 0.629464s\n",
      "0.30440458513738927\n",
      "0.2709830770066746\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19956\n",
      "           1       0.32      0.00      0.01      1942\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.62      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19937    19]\n",
      " [ 1933     9]]\n",
      "done in 0.654722s\n",
      "0.30440458513738927\n",
      "0.31497659756678364\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6937\n",
      "           1       0.12      0.00      0.00       867\n",
      "\n",
      "    accuracy                           0.89      7804\n",
      "   macro avg       0.51      0.50      0.47      7804\n",
      "weighted avg       0.80      0.89      0.84      7804\n",
      "\n",
      "Confusion_matrix\n",
      "[[6930    7]\n",
      " [ 866    1]]\n",
      "done in 0.567850s\n",
      "0.3044045851373892\n",
      "0.3066691400690733\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      7008\n",
      "           1       0.36      0.00      0.01       841\n",
      "\n",
      "    accuracy                           0.89      7849\n",
      "   macro avg       0.63      0.50      0.48      7849\n",
      "weighted avg       0.84      0.89      0.84      7849\n",
      "\n",
      "Confusion_matrix\n",
      "[[7001    7]\n",
      " [ 837    4]]\n",
      "done in 0.563680s\n",
      "0.30440458513738927\n",
      "0.2496265072230747\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12994\n",
      "           1       0.33      0.00      0.00      1100\n",
      "\n",
      "    accuracy                           0.92     14094\n",
      "   macro avg       0.63      0.50      0.48     14094\n",
      "weighted avg       0.88      0.92      0.88     14094\n",
      "\n",
      "Confusion_matrix\n",
      "[[12990     4]\n",
      " [ 1098     2]]\n",
      "done in 0.571360s\n",
      "0.3044045851373892\n",
      "0.25104572139582926\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12948\n",
      "           1       0.29      0.00      0.01      1101\n",
      "\n",
      "    accuracy                           0.92     14049\n",
      "   macro avg       0.61      0.50      0.48     14049\n",
      "weighted avg       0.87      0.92      0.88     14049\n",
      "\n",
      "Confusion_matrix\n",
      "[[12936    12]\n",
      " [ 1096     5]]\n",
      "done in 0.565602s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19931\n",
      "           1       0.45      0.01      0.02      1967\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.51      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19901    30]\n",
      " [ 1942    25]]\n",
      "done in 32.397502s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19956\n",
      "           1       0.42      0.01      0.02      1942\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.50      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19926    30]\n",
      " [ 1920    22]]\n",
      "done in 32.158865s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6937\n",
      "           1       0.54      0.01      0.03       867\n",
      "\n",
      "    accuracy                           0.89      7804\n",
      "   macro avg       0.72      0.51      0.49      7804\n",
      "weighted avg       0.85      0.89      0.84      7804\n",
      "\n",
      "Confusion_matrix\n",
      "[[6926   11]\n",
      " [ 854   13]]\n",
      "done in 32.234025s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      7008\n",
      "           1       0.36      0.01      0.02       841\n",
      "\n",
      "    accuracy                           0.89      7849\n",
      "   macro avg       0.63      0.50      0.48      7849\n",
      "weighted avg       0.84      0.89      0.84      7849\n",
      "\n",
      "Confusion_matrix\n",
      "[[6992   16]\n",
      " [ 832    9]]\n",
      "done in 32.412187s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12994\n",
      "           1       0.39      0.01      0.02      1100\n",
      "\n",
      "    accuracy                           0.92     14094\n",
      "   macro avg       0.65      0.50      0.49     14094\n",
      "weighted avg       0.88      0.92      0.89     14094\n",
      "\n",
      "Confusion_matrix\n",
      "[[12975    19]\n",
      " [ 1088    12]]\n",
      "done in 32.471793s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12948\n",
      "           1       0.48      0.01      0.02      1101\n",
      "\n",
      "    accuracy                           0.92     14049\n",
      "   macro avg       0.70      0.51      0.49     14049\n",
      "weighted avg       0.89      0.92      0.89     14049\n",
      "\n",
      "Confusion_matrix\n",
      "[[12934    14]\n",
      " [ 1088    13]]\n",
      "done in 33.049497s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.38799999999999996\n",
      "threshold:0.2, J-value:0.278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.30000000000000004, J-value:0.151\n",
      "threshold:0.4, J-value:0.069\n",
      "threshold:0.5, J-value:0.032\n",
      "threshold:0.6000000000000001, J-value:0.009000000000000001\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6938424983580236\n",
      "Balanced accuracy score of test is  0.6981046768389942\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.367\n",
      "threshold:0.2, J-value:0.271\n",
      "threshold:0.30000000000000004, J-value:0.14600000000000002\n",
      "threshold:0.4, J-value:0.061\n",
      "threshold:0.5, J-value:0.028\n",
      "threshold:0.6000000000000001, J-value:0.009000000000000001\n",
      "threshold:0.7000000000000001, J-value:0.003\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6830570537706386\n",
      "Balanced accuracy score of test is  0.6898843143083631\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.39599999999999996\n",
      "threshold:0.2, J-value:0.28300000000000003\n",
      "threshold:0.30000000000000004, J-value:0.153\n",
      "threshold:0.4, J-value:0.076\n",
      "threshold:0.5, J-value:0.033999999999999996\n",
      "threshold:0.6000000000000001, J-value:0.009000000000000001\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6983772930163572\n",
      "Balanced accuracy score of test is  0.7012625012731707\n",
      "True positive rate of class 1 is  0.744\n",
      "True positive rate of class 2 is  0.724\n",
      "Positive prediction rate of class 1 is  0.405\n",
      "Positive prediction rate of class 2 is  0.353\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.375\n",
      "threshold:0.2, J-value:0.299\n",
      "threshold:0.30000000000000004, J-value:0.133\n",
      "threshold:0.4, J-value:0.034\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6872867978154527\n",
      "Balanced accuracy score of test is  0.6902756610371861\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.34600000000000003\n",
      "threshold:0.2, J-value:0.29000000000000004\n",
      "threshold:0.30000000000000004, J-value:0.15100000000000002\n",
      "threshold:0.4, J-value:0.032\n",
      "threshold:0.5, J-value:-0.001\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6728990640596477\n",
      "Balanced accuracy score of test is  0.6809879078233675\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.386\n",
      "threshold:0.2, J-value:0.277\n",
      "threshold:0.30000000000000004, J-value:0.13\n",
      "threshold:0.4, J-value:0.027\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6930120894958511\n",
      "Balanced accuracy score of test is  0.7012179929106491\n",
      "True positive rate of class 1 is  0.82\n",
      "True positive rate of class 2 is  0.755\n",
      "Positive prediction rate of class 1 is  0.497\n",
      "Positive prediction rate of class 2 is  0.384\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.36100000000000004\n",
      "threshold:0.2, J-value:0.271\n",
      "threshold:0.30000000000000004, J-value:0.131\n",
      "threshold:0.4, J-value:0.021\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6802029788739632\n",
      "Balanced accuracy score of test is  0.6832863917508323\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.33199999999999996\n",
      "threshold:0.2, J-value:0.267\n",
      "threshold:0.30000000000000004, J-value:0.13399999999999998\n",
      "threshold:0.4, J-value:0.018000000000000002\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:-0.001\n",
      "threshold:0.7000000000000001, J-value:-0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6660536357951503\n",
      "Balanced accuracy score of test is  0.6656005333127013\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.36900000000000005\n",
      "threshold:0.2, J-value:0.27\n",
      "threshold:0.30000000000000004, J-value:0.127\n",
      "threshold:0.4, J-value:0.022000000000000002\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6843979039276868\n",
      "Balanced accuracy score of test is  0.6905958564924128\n",
      "True positive rate of class 1 is  0.829\n",
      "True positive rate of class 2 is  0.793\n",
      "Positive prediction rate of class 1 is  0.533\n",
      "Positive prediction rate of class 2 is  0.442\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.391\n",
      "threshold:0.2, J-value:0.299\n",
      "threshold:0.30000000000000004, J-value:0.147\n",
      "threshold:0.4, J-value:0.058\n",
      "threshold:0.5, J-value:0.011\n",
      "threshold:0.6000000000000001, J-value:0.002\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6954941548851927\n",
      "Balanced accuracy score of test is  0.7072146260392844\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.36800000000000005\n",
      "threshold:0.2, J-value:0.285\n",
      "threshold:0.30000000000000004, J-value:0.145\n",
      "threshold:0.4, J-value:0.061\n",
      "threshold:0.5, J-value:0.013\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6842134491358127\n",
      "Balanced accuracy score of test is  0.6987300737326188\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.39499999999999996\n",
      "threshold:0.2, J-value:0.307\n",
      "threshold:0.30000000000000004, J-value:0.147\n",
      "threshold:0.4, J-value:0.054\n",
      "threshold:0.5, J-value:0.009999999999999998\n",
      "threshold:0.6000000000000001, J-value:0.002\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6975644703149706\n",
      "Balanced accuracy score of test is  0.708174976156986\n",
      "True positive rate of class 1 is  0.798\n",
      "True positive rate of class 2 is  0.747\n",
      "Positive prediction rate of class 1 is  0.443\n",
      "Positive prediction rate of class 2 is  0.363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lifuchen/Desktop/research/CVDPrediction-master/src/lib/fairness_tests.py:272: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train ['Class'] = y_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23317, 88)\n",
      "(42377, 88)\n",
      "0.12501206214416674 0.08378302345208563\n",
      "0.12500959054755634\n",
      "(67306, 87)\n",
      "X train 67306\n",
      "Y train 67306\n",
      "21898 7696 14202\n",
      "21898 7696 14202\n",
      "21898 7840 14058\n",
      "21898 7840 14058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29494459237783427\n",
      "0.2605526667929227\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19973\n",
      "           1       0.43      0.03      0.06      1925\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.51     21898\n",
      "weighted avg       0.87      0.91      0.88     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19884    89]\n",
      " [ 1859    66]]\n",
      "done in 0.609032s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29494459237783427\n",
      "0.2689075301841586\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19866\n",
      "           1       0.48      0.04      0.07      2032\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.70      0.52      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19787    79]\n",
      " [ 1959    73]]\n",
      "done in 0.605621s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29494459237783427\n",
      "0.2882783214318874\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      6911\n",
      "           1       0.48      0.03      0.05       785\n",
      "\n",
      "    accuracy                           0.90      7696\n",
      "   macro avg       0.69      0.51      0.50      7696\n",
      "weighted avg       0.86      0.90      0.85      7696\n",
      "\n",
      "Confusion_matrix\n",
      "[[6888   23]\n",
      " [ 764   21]]\n",
      "done in 0.583947s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29494459237783427\n",
      "0.30604269132342016\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6966\n",
      "           1       0.40      0.02      0.04       874\n",
      "\n",
      "    accuracy                           0.89      7840\n",
      "   macro avg       0.64      0.51      0.49      7840\n",
      "weighted avg       0.84      0.89      0.84      7840\n",
      "\n",
      "Confusion_matrix\n",
      "[[6937   29]\n",
      " [ 855   19]]\n",
      "done in 0.605736s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29494459237783427\n",
      "0.2455282590967199\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96     13062\n",
      "           1       0.41      0.04      0.07      1140\n",
      "\n",
      "    accuracy                           0.92     14202\n",
      "   macro avg       0.66      0.52      0.51     14202\n",
      "weighted avg       0.88      0.92      0.89     14202\n",
      "\n",
      "Confusion_matrix\n",
      "[[12996    66]\n",
      " [ 1095    45]]\n",
      "done in 0.629856s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29494459237783427\n",
      "0.24819763807064243\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12900\n",
      "           1       0.52      0.05      0.09      1158\n",
      "\n",
      "    accuracy                           0.92     14058\n",
      "   macro avg       0.72      0.52      0.52     14058\n",
      "weighted avg       0.89      0.92      0.89     14058\n",
      "\n",
      "Confusion_matrix\n",
      "[[12850    50]\n",
      " [ 1104    54]]\n",
      "done in 1.153846s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19973\n",
      "           1       0.39      0.00      0.01      1925\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.65      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19962    11]\n",
      " [ 1918     7]]\n",
      "done in 19.752912s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19866\n",
      "           1       0.47      0.00      0.01      2032\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.69      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.86     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19858     8]\n",
      " [ 2025     7]]\n",
      "done in 17.757835s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      6911\n",
      "           1       0.43      0.00      0.01       785\n",
      "\n",
      "    accuracy                           0.90      7696\n",
      "   macro avg       0.66      0.50      0.48      7696\n",
      "weighted avg       0.85      0.90      0.85      7696\n",
      "\n",
      "Confusion_matrix\n",
      "[[6907    4]\n",
      " [ 782    3]]\n",
      "done in 18.913094s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6966\n",
      "           1       0.43      0.00      0.01       874\n",
      "\n",
      "    accuracy                           0.89      7840\n",
      "   macro avg       0.66      0.50      0.47      7840\n",
      "weighted avg       0.84      0.89      0.84      7840\n",
      "\n",
      "Confusion_matrix\n",
      "[[6962    4]\n",
      " [ 871    3]]\n",
      "done in 20.029987s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13062\n",
      "           1       0.60      0.00      0.01      1140\n",
      "\n",
      "    accuracy                           0.92     14202\n",
      "   macro avg       0.76      0.50      0.48     14202\n",
      "weighted avg       0.89      0.92      0.88     14202\n",
      "\n",
      "Confusion_matrix\n",
      "[[13060     2]\n",
      " [ 1137     3]]\n",
      "done in 18.317669s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12900\n",
      "           1       0.83      0.00      0.01      1158\n",
      "\n",
      "    accuracy                           0.92     14058\n",
      "   macro avg       0.88      0.50      0.48     14058\n",
      "weighted avg       0.91      0.92      0.88     14058\n",
      "\n",
      "Confusion_matrix\n",
      "[[12899     1]\n",
      " [ 1153     5]]\n",
      "done in 18.699755s\n",
      "0.3070631224486327\n",
      "0.2698724943443314\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19973\n",
      "           1       0.12      0.00      0.00      1925\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.52      0.50      0.48     21898\n",
      "weighted avg       0.84      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19966     7]\n",
      " [ 1924     1]]\n",
      "done in 0.678719s\n",
      "0.3070631224486327\n",
      "0.278308185732581\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19866\n",
      "           1       0.14      0.00      0.00      2032\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.53      0.50      0.48     21898\n",
      "weighted avg       0.84      0.91      0.86     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19854    12]\n",
      " [ 2030     2]]\n",
      "done in 0.658840s\n",
      "0.3070631224486327\n",
      "0.29733307270023385\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      6911\n",
      "           1       0.00      0.00      0.00       785\n",
      "\n",
      "    accuracy                           0.90      7696\n",
      "   macro avg       0.45      0.50      0.47      7696\n",
      "weighted avg       0.81      0.90      0.85      7696\n",
      "\n",
      "Confusion_matrix\n",
      "[[6908    3]\n",
      " [ 785    0]]\n",
      "done in 0.678108s\n",
      "0.3070631224486327\n",
      "0.31409227002961543\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6966\n",
      "           1       0.10      0.00      0.00       874\n",
      "\n",
      "    accuracy                           0.89      7840\n",
      "   macro avg       0.49      0.50      0.47      7840\n",
      "weighted avg       0.80      0.89      0.84      7840\n",
      "\n",
      "Confusion_matrix\n",
      "[[6957    9]\n",
      " [ 873    1]]\n",
      "done in 0.652006s\n",
      "0.3070631224486327\n",
      "0.2549917302951112\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13062\n",
      "           1       0.20      0.00      0.00      1140\n",
      "\n",
      "    accuracy                           0.92     14202\n",
      "   macro avg       0.56      0.50      0.48     14202\n",
      "weighted avg       0.86      0.92      0.88     14202\n",
      "\n",
      "Confusion_matrix\n",
      "[[13058     4]\n",
      " [ 1139     1]]\n",
      "done in 0.666966s\n",
      "0.3070631224486327\n",
      "0.2583517750846403\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12900\n",
      "           1       0.25      0.00      0.00      1158\n",
      "\n",
      "    accuracy                           0.92     14058\n",
      "   macro avg       0.58      0.50      0.48     14058\n",
      "weighted avg       0.86      0.92      0.88     14058\n",
      "\n",
      "Confusion_matrix\n",
      "[[12897     3]\n",
      " [ 1157     1]]\n",
      "done in 0.661979s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19973\n",
      "           1       0.57      0.01      0.02      1925\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.74      0.50      0.49     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19961    12]\n",
      " [ 1909    16]]\n",
      "done in 34.247449s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19866\n",
      "           1       0.54      0.01      0.02      2032\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.72      0.50      0.49     21898\n",
      "weighted avg       0.87      0.91      0.86     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19849    17]\n",
      " [ 2012    20]]\n",
      "done in 32.922843s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      6911\n",
      "           1       0.62      0.01      0.01       785\n",
      "\n",
      "    accuracy                           0.90      7696\n",
      "   macro avg       0.76      0.50      0.48      7696\n",
      "weighted avg       0.87      0.90      0.85      7696\n",
      "\n",
      "Confusion_matrix\n",
      "[[6908    3]\n",
      " [ 780    5]]\n",
      "done in 32.719051s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6966\n",
      "           1       0.61      0.01      0.02       874\n",
      "\n",
      "    accuracy                           0.89      7840\n",
      "   macro avg       0.75      0.51      0.48      7840\n",
      "weighted avg       0.86      0.89      0.84      7840\n",
      "\n",
      "Confusion_matrix\n",
      "[[6959    7]\n",
      " [ 863   11]]\n",
      "done in 32.217248s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13062\n",
      "           1       0.55      0.01      0.02      1140\n",
      "\n",
      "    accuracy                           0.92     14202\n",
      "   macro avg       0.74      0.50      0.49     14202\n",
      "weighted avg       0.89      0.92      0.88     14202\n",
      "\n",
      "Confusion_matrix\n",
      "[[13053     9]\n",
      " [ 1129    11]]\n",
      "done in 32.537622s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12900\n",
      "           1       0.47      0.01      0.02      1158\n",
      "\n",
      "    accuracy                           0.92     14058\n",
      "   macro avg       0.70      0.50      0.49     14058\n",
      "weighted avg       0.88      0.92      0.88     14058\n",
      "\n",
      "Confusion_matrix\n",
      "[[12890    10]\n",
      " [ 1149     9]]\n",
      "done in 33.339966s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.39899999999999997\n",
      "threshold:0.2, J-value:0.29200000000000004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.30000000000000004, J-value:0.173\n",
      "threshold:0.4, J-value:0.079\n",
      "threshold:0.5, J-value:0.030000000000000002\n",
      "threshold:0.6000000000000001, J-value:0.009999999999999998\n",
      "threshold:0.7000000000000001, J-value:0.003\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6994431053350594\n",
      "Balanced accuracy score of test is  0.7041274967478959\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.394\n",
      "threshold:0.2, J-value:0.276\n",
      "threshold:0.30000000000000004, J-value:0.158\n",
      "threshold:0.4, J-value:0.069\n",
      "threshold:0.5, J-value:0.024\n",
      "threshold:0.6000000000000001, J-value:0.009000000000000001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6968231205306412\n",
      "Balanced accuracy score of test is  0.6965309108445007\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.39699999999999996\n",
      "threshold:0.2, J-value:0.301\n",
      "threshold:0.30000000000000004, J-value:0.182\n",
      "threshold:0.4, J-value:0.085\n",
      "threshold:0.5, J-value:0.034\n",
      "threshold:0.6000000000000001, J-value:0.011\n",
      "threshold:0.7000000000000001, J-value:0.005\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6987625816953961\n",
      "Balanced accuracy score of test is  0.7062368960115677\n",
      "True positive rate of class 1 is  0.767\n",
      "True positive rate of class 2 is  0.734\n",
      "Positive prediction rate of class 1 is  0.417\n",
      "Positive prediction rate of class 2 is  0.356\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.373\n",
      "threshold:0.2, J-value:0.30600000000000005\n",
      "threshold:0.30000000000000004, J-value:0.121\n",
      "threshold:0.4, J-value:0.024999999999999998\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.68637628330714\n",
      "Balanced accuracy score of test is  0.6961664064587064\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.3539999999999999\n",
      "threshold:0.2, J-value:0.29\n",
      "threshold:0.30000000000000004, J-value:0.15200000000000002\n",
      "threshold:0.4, J-value:0.023\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6770120927866312\n",
      "Balanced accuracy score of test is  0.670031489989626\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.379\n",
      "threshold:0.2, J-value:0.291\n",
      "threshold:0.30000000000000004, J-value:0.123\n",
      "threshold:0.4, J-value:0.021\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6893169418723657\n",
      "Balanced accuracy score of test is  0.7022585050407679\n",
      "True positive rate of class 1 is  0.812\n",
      "True positive rate of class 2 is  0.755\n",
      "Positive prediction rate of class 1 is  0.51\n",
      "Positive prediction rate of class 2 is  0.384\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.368\n",
      "threshold:0.2, J-value:0.18499999999999997\n",
      "threshold:0.30000000000000004, J-value:0.10600000000000001\n",
      "threshold:0.4, J-value:0.001\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.001\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.683862799194497\n",
      "Balanced accuracy score of test is  0.6751624417058861\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.342\n",
      "threshold:0.2, J-value:0.162\n",
      "threshold:0.30000000000000004, J-value:0.133\n",
      "threshold:0.4, J-value:0.0\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6711619157864275\n",
      "Balanced accuracy score of test is  0.6594575745809492\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.37199999999999994\n",
      "threshold:0.2, J-value:0.20500000000000002\n",
      "threshold:0.30000000000000004, J-value:0.08399999999999999\n",
      "threshold:0.4, J-value:0.001\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.001\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6858597458275915\n",
      "Balanced accuracy score of test is  0.6773952685062457\n",
      "True positive rate of class 1 is  0.786\n",
      "True positive rate of class 2 is  0.684\n",
      "Positive prediction rate of class 1 is  0.503\n",
      "Positive prediction rate of class 2 is  0.358\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41100000000000003\n",
      "threshold:0.2, J-value:0.29500000000000004\n",
      "threshold:0.30000000000000004, J-value:0.148\n",
      "threshold:0.4, J-value:0.04\n",
      "threshold:0.5, J-value:0.007\n",
      "threshold:0.6000000000000001, J-value:0.002\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7051768979030782\n",
      "Balanced accuracy score of test is  0.7025212377654696\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.39099999999999996\n",
      "threshold:0.2, J-value:0.289\n",
      "threshold:0.30000000000000004, J-value:0.159\n",
      "threshold:0.4, J-value:0.041\n",
      "threshold:0.5, J-value:0.006\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6956921809319031\n",
      "Balanced accuracy score of test is  0.6897176610026734\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.413\n",
      "threshold:0.2, J-value:0.29600000000000004\n",
      "threshold:0.30000000000000004, J-value:0.14\n",
      "threshold:0.4, J-value:0.039\n",
      "threshold:0.5, J-value:0.009000000000000001\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7066412010734231\n",
      "Balanced accuracy score of test is  0.7054833915732819\n",
      "True positive rate of class 1 is  0.802\n",
      "True positive rate of class 2 is  0.737\n",
      "Positive prediction rate of class 1 is  0.465\n",
      "Positive prediction rate of class 2 is  0.36\n"
     ]
    }
   ],
   "source": [
    "records_lr = []\n",
    "records_rf = []\n",
    "records_dt = []\n",
    "records_gbt = []\n",
    "for random_state in range(10):\n",
    "    fairness_metrics (X, y, \"GENDER\", random_state)\n",
    "\n",
    "result_lr = pd.DataFrame(records_lr)\n",
    "result_rf = pd.DataFrame(records_rf)\n",
    "result_dt = pd.DataFrame(records_dt)\n",
    "result_gbt = pd.DataFrame(records_gbt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_mean_sd(records, result_table, overall_records, type):\n",
    "    records.append({\n",
    "        'auroc': result_table[\"auroc\"].mean(),\n",
    "        'overall threshold': result_table[\"overall threshold\"].mean(),\n",
    "        'male threshold': result_table[\"male threshold\"].mean(),\n",
    "        'female threshold': result_table[\"female threshold\"].mean(),\n",
    "        'overall ba validation': result_table[\"overall ba validation\"].mean(),\n",
    "        'overall ba test': result_table[\"overall ba test\"].mean(),\n",
    "        'male ba validation': result_table[\"male ba validation\"].mean(),\n",
    "        'male ba test': result_table[\"male ba test\"].mean(),\n",
    "        'female ba validation': result_table[\"female ba validation\"].mean(),\n",
    "        'female ba test': result_table[\"female ba test\"].mean(),\n",
    "        'overall precision':result_table[\"overall precision\"].mean(),\n",
    "        'overall recall':result_table[\"overall recall\"].mean(),\n",
    "        'overall tpr':result_table[\"overall tpr\"].mean(),\n",
    "        'overall tnr':result_table[\"overall tnr\"].mean(),\n",
    "        'overall pd':result_table[\"overall pd\"].mean(),\n",
    "        'male precision':result_table[\"male precision\"].mean(),\n",
    "        'male recall':result_table[\"male recall\"].mean(),\n",
    "        'male tpr':result_table[\"male tpr\"].mean(),\n",
    "        'male tnr':result_table[\"male tnr\"].mean(),\n",
    "        'male pd':result_table[\"male pd\"].mean(),\n",
    "        'female precision':result_table[\"female precision\"].mean(),\n",
    "        'female recall':result_table[\"female recall\"].mean(),\n",
    "        'female tpr':result_table[\"female tpr\"].mean(),\n",
    "        'female tnr':result_table[\"female tnr\"].mean(),\n",
    "        'female pd':result_table[\"female pd\"].mean(),\n",
    "        'eod': result_table[\"eod\"].mean(),\n",
    "        'di': result_table[\"di\"].mean(),\n",
    "        })\n",
    "    records.append({\n",
    "        'auroc': result_table[\"auroc\"].std(),\n",
    "        'overall threshold': result_table[\"overall threshold\"].std(),\n",
    "        'male threshold': result_table[\"male threshold\"].std(),\n",
    "        'female threshold': result_table[\"female threshold\"].std(),\n",
    "        'overall ba validation': result_table[\"overall ba validation\"].std(),\n",
    "        'overall ba test': result_table[\"overall ba test\"].std(),\n",
    "        'male ba validation': result_table[\"male ba validation\"].std(),\n",
    "        'male ba test': result_table[\"male ba test\"].std(),\n",
    "        'female ba validation': result_table[\"female ba validation\"].std(),\n",
    "        'female ba test': result_table[\"female ba test\"].std(),\n",
    "        'overall precision':result_table[\"overall precision\"].std(),\n",
    "        'overall recall':result_table[\"overall recall\"].std(),\n",
    "        'overall tpr':result_table[\"overall tpr\"].std(),\n",
    "        'overall tnr':result_table[\"overall tnr\"].std(),\n",
    "        'overall pd':result_table[\"overall pd\"].std(),\n",
    "        'male precision':result_table[\"male precision\"].std(),\n",
    "        'male recall':result_table[\"male recall\"].std(),\n",
    "        'male tpr':result_table[\"male tpr\"].std(),\n",
    "        'male tnr':result_table[\"male tnr\"].std(),\n",
    "        'male pd':result_table[\"male pd\"].std(),\n",
    "        'female precision':result_table[\"female precision\"].std(),\n",
    "        'female recall':result_table[\"female recall\"].std(),\n",
    "        'female tpr':result_table[\"female tpr\"].std(),\n",
    "        'female tnr':result_table[\"female tnr\"].std(),\n",
    "        'female pd':result_table[\"female pd\"].std(),\n",
    "        'eod': result_table[\"eod\"].std(),\n",
    "        'di': result_table[\"di\"].std(),\n",
    "        })\n",
    "    overall_records.append({\n",
    "        'type': type,\n",
    "        'auroc': result_table[\"auroc\"].mean(),\n",
    "        'overall threshold': result_table[\"overall threshold\"].mean(),\n",
    "        'male threshold': result_table[\"male threshold\"].mean(),\n",
    "        'female threshold': result_table[\"female threshold\"].mean(),\n",
    "        'overall ba test': result_table[\"overall ba test\"].mean(),\n",
    "        'male ba test': result_table[\"male ba test\"].mean(),\n",
    "        'female ba test': result_table[\"female ba test\"].mean(),\n",
    "        'overall tpr':result_table[\"overall tpr\"].mean(),\n",
    "        'overall pd':result_table[\"overall pd\"].mean(),\n",
    "        'male tpr':result_table[\"male tpr\"].mean(),\n",
    "        'male pd':result_table[\"male pd\"].mean(),\n",
    "        'female tpr':result_table[\"female tpr\"].mean(),\n",
    "        'female pd':result_table[\"female pd\"].mean(),\n",
    "        'eod': result_table[\"eod\"].mean(),\n",
    "        'di': result_table[\"di\"].mean(),\n",
    "        })\n",
    "    pd_result = pd.DataFrame(records)\n",
    "    return pd_result, overall_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_table = []\n",
    "result_lr, overall_records = add_mean_sd (records_lr, result_lr, overall_table, 'lr')\n",
    "result_rf, overall_records = add_mean_sd (records_rf, result_rf, overall_records, 'rf')\n",
    "result_dt, overall_records = add_mean_sd (records_dt, result_dt, overall_records, 'dt')\n",
    "result_gbt, overall_records = add_mean_sd (records_gbt, result_gbt, overall_records, 'gbt')\n",
    "\n",
    "result_path='/Users/lifuchen/Desktop/research/resample_data/'\n",
    "result_lr.to_csv(path.join(result_path,'gender-lr-resample-proportion-result.csv'), index=False)\n",
    "result_rf.to_csv(path.join(result_path,'gender-rf-resample-proportion-result.csv'), index=False)\n",
    "result_dt.to_csv(path.join(result_path,'gender-dt-resample-proportion-result.csv'), index=False)\n",
    "result_gbt.to_csv(path.join(result_path,'gender-gbt-resample-proportion-result.csv'), index=False)\n",
    "\n",
    "overall_result = pd.DataFrame(overall_table)\n",
    "result_path='/Users/lifuchen/Desktop/research/resample_result/'\n",
    "overall_result.to_csv(path.join(result_path,'gender-resample-proportion.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
