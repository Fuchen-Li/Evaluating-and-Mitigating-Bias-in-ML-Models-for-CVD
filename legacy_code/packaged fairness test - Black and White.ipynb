{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from os import path\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score\n",
    "import sklearn.preprocessing\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import src.lib.utility_classfier as uclf\n",
    "import src.lib.optimal_threhold_related as thres\n",
    "import src.lib.fairness_tests as fair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_path='/Users/lifuchen/Desktop/research/data.csv'\n",
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109490, 87)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df.Class.values\n",
    "X = df.drop(['GRID','Class'], axis=1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_result (classifier, records, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_white_scaled, y_val_white, X_test_white_scaled, y_test_white, X_val_black_scaled, y_val_black, X_test_black_scaled, y_test_black):\n",
    "        method_to_call = getattr(uclf, classifier)\n",
    "        y_val_score = method_to_call(X_train_scaled, y_train,X_val_scaled, y_val)\n",
    "        y_test_score = method_to_call(X_train_scaled, y_train,X_test_scaled, y_test)\n",
    "        \n",
    "        threshold, ba_val, ba_test = balance_accuracy (y_val, y_val_score,y_test, y_test_score)\n",
    "        auroc = roc_auc_score(y_val, y_val_score)\n",
    "        \n",
    "        y_val_score_white = method_to_call(X_train_scaled, y_train, X_val_white_scaled, y_val_white)\n",
    "        y_test_score_white = method_to_call(X_train_scaled, y_train,X_test_white_scaled, y_test_white)\n",
    "        threshold_white, ba_val_white, ba_test_white = balance_accuracy (y_val_white, y_val_score_white,y_test_white, y_test_score_white)\n",
    "\n",
    "        y_val_score_black = method_to_call(X_train_scaled, y_train, X_val_black_scaled, y_val_black)\n",
    "        y_test_score_black = method_to_call(X_train_scaled, y_train,X_test_black_scaled, y_test_black)\n",
    "        threshold_black, ba_val_black, ba_test_black = balance_accuracy (y_val_black, y_val_score_black, y_test_black, y_test_score_black)\n",
    "\n",
    "        eod = fair.get_EOD(y_test_white, y_test_score_white,threshold_white, y_test_black, y_test_score_black, threshold_black)\n",
    "        sp = fair.get_SP(y_test_white, y_test_score_white,threshold_white, y_test_black, y_test_score_black, threshold_black)\n",
    "\n",
    "        records.append({\n",
    "            'auroc': auroc,\n",
    "            'overall threshold': threshold,\n",
    "            'overall ba validation': ba_val,\n",
    "            'overall ba test': ba_test,\n",
    "            'white threshold': threshold_white,\n",
    "            'white ba validation': ba_val_white,\n",
    "            'white ba test': ba_test_white,\n",
    "            'black threshold': threshold_black,\n",
    "            'black ba validation': ba_val_black,\n",
    "            'black ba test': ba_test_black,\n",
    "            'eod': eod,\n",
    "            'di': sp,\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def balance_accuracy (y_val, y_val_score,y_test, y_test_score):\n",
    "    \n",
    "    threshold, _ = thres.get_optimal_threshold_Jvalue (y_val, y_val_score)\n",
    "    print (\"Optimal threshold by J value is \",threshold)\n",
    "\n",
    "    ba_val = thres.calculate_balanced_accuracy(y_val, y_val_score, threshold)\n",
    "    print (\"Balanced accuracy score of val is \", ba_val)\n",
    "\n",
    "    ba_test = thres.calculate_balanced_accuracy(y_test, y_test_score, threshold)\n",
    "    print (\"Balanced accuracy score of test is \",ba_test)\n",
    "\n",
    "    return threshold, ba_val, ba_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def fairness_metrics (X, y, attribute, random_state):\n",
    "    global threshold\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, X_val_white, X_val_black, y_val_white, y_val_black, X_test_white, X_test_black, y_test_white, y_test_black \\\n",
    "        = fair.split_by_trait(X, y, attribute, random_state)\n",
    "    print(\"X train\", X_train.shape[0])\n",
    "    print(\"Y train\", y_train.shape[0])\n",
    "    print(X_val.shape[0], X_val_white.shape[0], X_val_black.shape[0])\n",
    "    print(y_val.shape[0], y_val_white.shape[0], y_val_black.shape[0])\n",
    "    print(X_test.shape[0], X_test_white.shape[0], X_test_black.shape[0])\n",
    "    print(y_test.shape[0], y_test_white.shape[0], y_test_black.shape[0])\n",
    "\n",
    "    max_abs_scaler = preprocessing.MaxAbsScaler()\n",
    "    X_train_scaled = max_abs_scaler.fit_transform(X_train)\n",
    "    X_test_scaled = max_abs_scaler.transform(X_test)\n",
    "    X_test_white_scaled = max_abs_scaler.transform(X_test_white)\n",
    "    X_test_black_scaled = max_abs_scaler.transform(X_test_black)\n",
    "    X_val_scaled = max_abs_scaler.transform(X_val)\n",
    "    X_val_white_scaled = max_abs_scaler.transform(X_val_white)\n",
    "    X_val_black_scaled = max_abs_scaler.transform(X_val_black)\n",
    "\n",
    "    get_result (\"logic_regression\", records_lr, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_white_scaled, y_val_white, X_test_white_scaled, y_test_white, X_val_black_scaled, y_val_black, X_test_black_scaled, y_test_black)\n",
    "    get_result (\"random_forest\", records_rf, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_white_scaled, y_val_white, X_test_white_scaled, y_test_white, X_val_black_scaled, y_val_black, X_test_black_scaled, y_test_black)\n",
    "    get_result (\"decision_tree\", records_dt, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_white_scaled, y_val_white, X_test_white_scaled, y_test_white, X_val_black_scaled, y_val_black, X_test_black_scaled, y_test_black)\n",
    "    get_result (\"gradiant_boosting\", records_gbt, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_white_scaled, y_val_white, X_test_white_scaled, y_test_white, X_val_black_scaled, y_val_black, X_test_black_scaled, y_test_black)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train 65694\n",
      "Y train 65694\n",
      "21898 18899 2999\n",
      "21898 18899 2999\n",
      "21898 18968 2930\n",
      "21898 18968 2930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25882185696726207\n",
      "0.2619870551548744\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19904\n",
      "           1       0.43      0.03      0.06      1994\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19822    82]\n",
      " [ 1931    63]]\n",
      "done in 2.171373s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25882185696726207\n",
      "0.2623041485961046\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19934\n",
      "           1       0.43      0.03      0.06      1964\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19847    87]\n",
      " [ 1899    65]]\n",
      "done in 2.584278s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41300000000000003\n",
      "threshold:0.2, J-value:0.26499999999999996\n",
      "threshold:0.30000000000000004, J-value:0.152\n",
      "threshold:0.4, J-value:0.07100000000000001\n",
      "threshold:0.5, J-value:0.028\n",
      "threshold:0.6000000000000001, J-value:0.012\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7064876804851854\n",
      "Balanced accuracy score of test is  0.6998057183409937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25882185696726207\n",
      "0.26282254893490486\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17180\n",
      "           1       0.45      0.03      0.06      1719\n",
      "\n",
      "    accuracy                           0.91     18899\n",
      "   macro avg       0.68      0.51      0.51     18899\n",
      "weighted avg       0.87      0.91      0.87     18899\n",
      "\n",
      "Confusion_matrix\n",
      "[[17114    66]\n",
      " [ 1665    54]]\n",
      "done in 2.364846s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25882185696726207\n",
      "0.26278189359925863\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17260\n",
      "           1       0.42      0.03      0.06      1708\n",
      "\n",
      "    accuracy                           0.91     18968\n",
      "   macro avg       0.67      0.51      0.51     18968\n",
      "weighted avg       0.87      0.91      0.87     18968\n",
      "\n",
      "Confusion_matrix\n",
      "[[17186    74]\n",
      " [ 1654    54]]\n",
      "done in 2.242202s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.40700000000000003\n",
      "threshold:0.2, J-value:0.259\n",
      "threshold:0.30000000000000004, J-value:0.152\n",
      "threshold:0.4, J-value:0.069\n",
      "threshold:0.5, J-value:0.027\n",
      "threshold:0.6000000000000001, J-value:0.011\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7032689667829457\n",
      "Balanced accuracy score of test is  0.7000665534150518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25882185696726207\n",
      "0.25672196780949413\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95      2724\n",
      "           1       0.36      0.03      0.06       275\n",
      "\n",
      "    accuracy                           0.91      2999\n",
      "   macro avg       0.64      0.51      0.51      2999\n",
      "weighted avg       0.86      0.91      0.87      2999\n",
      "\n",
      "Confusion_matrix\n",
      "[[2708   16]\n",
      " [ 266    9]]\n",
      "done in 2.646432s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25882185696726207\n",
      "0.259211361149066\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.95      2674\n",
      "           1       0.46      0.04      0.08       256\n",
      "\n",
      "    accuracy                           0.91      2930\n",
      "   macro avg       0.69      0.52      0.52      2930\n",
      "weighted avg       0.88      0.91      0.88      2930\n",
      "\n",
      "Confusion_matrix\n",
      "[[2661   13]\n",
      " [ 245   11]]\n",
      "done in 2.591161s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.45300000000000007\n",
      "threshold:0.2, J-value:0.303\n",
      "threshold:0.30000000000000004, J-value:0.156\n",
      "threshold:0.4, J-value:0.082\n",
      "threshold:0.5, J-value:0.027000000000000003\n",
      "threshold:0.6000000000000001, J-value:0.013999999999999999\n",
      "threshold:0.7000000000000001, J-value:-0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7267127219329863\n",
      "Balanced accuracy score of test is  0.6977535410433807\n",
      "True positive rate of class 1 is  0.663\n",
      "True positive rate of class 2 is  0.637\n",
      "Positive prediction rate of class 1 is  0.299\n",
      "Positive prediction rate of class 2 is  0.276\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19904\n",
      "           1       0.41      0.00      0.01      1994\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.66      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19894    10]\n",
      " [ 1987     7]]\n",
      "done in 25.074297s\n"
     ]
    }
   ],
   "source": [
    "records_lr = []\n",
    "records_rf = []\n",
    "records_dt = []\n",
    "records_gbt = []\n",
    "for random_state in range(0,16):\n",
    "    fairness_metrics (X, y, \"Race_W\", random_state)\n",
    "\n",
    "result_lr = pd.DataFrame(records_lr)\n",
    "result_rf = pd.DataFrame(records_rf)\n",
    "result_dt = pd.DataFrame(records_dt)\n",
    "result_gbt = pd.DataFrame(records_gbt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def add_mean_sd(records, result_table):\n",
    "    records.append({\n",
    "        'auroc': result_table[\"auroc\"].mean(),\n",
    "        'overall threshold': result_table[\"threshold\"].mean(),\n",
    "        'male threshold': result_table[\"threshold_male\"].mean(),\n",
    "        'female threshold': result_table[\"threshold_female\"].mean(),\n",
    "        'overall ba validation': result_table[\"ba_val\"].mean(),\n",
    "        'overall ba test': result_table[\"ba_test\"].mean(),\n",
    "        'male ba validation': result_table[\"ba_val_male\"].mean(),\n",
    "        'male ba test': result_table[\"ba_test_male\"].mean(),\n",
    "        'female ba validation': result_table[\"ba_val_female\"].mean(),\n",
    "        'female ba test': result_table[\"ba_test_female\"].mean(),\n",
    "        'overall precision':result_table[\"precision\"].mean(),\n",
    "        'overall recall':result_table[\"recall\"].mean(),\n",
    "        'overall tpr':result_table[\"tpr\"].mean(),\n",
    "        'overall tnr':result_table[\"tnr\"].mean(),\n",
    "        'overall pd':result_table[\"pd\"].mean(),\n",
    "        'male precision':result_table[\"precision_male\"].mean(),\n",
    "        'male recall':result_table[\"recall_male\"].mean(),\n",
    "        'male tpr':result_table[\"tpr_male\"].mean(),\n",
    "        'male tnr':result_table[\"tnr_male\"].mean(),\n",
    "        'male pd':result_table[\"pd_male\"].mean(),\n",
    "        'female precision':result_table[\"precision_female\"].mean(),\n",
    "        'female recall':result_table[\"recall_female\"].mean(),\n",
    "        'female tpr':result_table[\"tpr_female\"].mean(),\n",
    "        'female tnr':result_table[\"tnr_female\"].mean(),\n",
    "        'female pd':result_table[\"pd_female\"].mean(),\n",
    "        'eod': result_table[\"eod\"].mean(),\n",
    "        'di': result_table[\"sp\"].mean(),\n",
    "        })\n",
    "    records.append({\n",
    "        'auroc': result_table[\"auroc\"].std(),\n",
    "        'overall threshold': result_table[\"threshold\"].std(),\n",
    "        'male threshold': result_table[\"threshold_male\"].std(),\n",
    "        'female threshold': result_table[\"threshold_female\"].std(),\n",
    "        'male ba validation': result_table[\"ba_val_male\"].std(),\n",
    "        'male ba test': result_table[\"ba_test_male\"].std(),\n",
    "        'female ba validation': result_table[\"ba_val_female\"].std(),\n",
    "        'female ba test': result_table[\"ba_test_female\"].std(),\n",
    "        'overall ba validation': result_table[\"ba_val\"].std(),\n",
    "        'overall ba test': result_table[\"ba_test\"].std(),\n",
    "        'overall precision':result_table[\"precision\"].std(),\n",
    "        'overall recall':result_table[\"recall\"].std(),\n",
    "        'overall tpr':result_table[\"tpr\"].std(),\n",
    "        'overall tnr':result_table[\"tnr\"].std(),\n",
    "        'overall pd':result_table[\"pd\"].std(),\n",
    "        'male precision':result_table[\"precision_male\"].std(),\n",
    "        'male recall':result_table[\"recall_male\"].std(),\n",
    "        'male tpr':result_table[\"tpr_male\"].std(),\n",
    "        'male tnr':result_table[\"tnr_male\"].std(),\n",
    "        'male pd':result_table[\"pd_male\"].std(),\n",
    "        'female precision':result_table[\"precision_female\"].std(),\n",
    "        'female recall':result_table[\"recall_female\"].std(),\n",
    "        'female tpr':result_table[\"tpr_female\"].std(),\n",
    "        'female tnr':result_table[\"tnr_female\"].std(),\n",
    "        'female pd':result_table[\"pd_female\"].std(),\n",
    "        'eod': result_table[\"eod\"].std(),\n",
    "        'di': result_table[\"sp\"].std(),\n",
    "        })\n",
    "    records.append({\n",
    "        'auroc': result_table[\"auroc\"].mean(),\n",
    "        'overall threshold': result_table[\"threshold\"].mean(),\n",
    "        'male threshold': result_table[\"threshold_male\"].mean(),\n",
    "        'female threshold': result_table[\"threshold_female\"].mean(),\n",
    "        'overall ba test': result_table[\"ba_test\"].mean(),\n",
    "        'male ba test': result_table[\"ba_test_male\"].mean(),\n",
    "        'female ba test': result_table[\"ba_test_female\"].mean(),\n",
    "        'overall tpr':result_table[\"tpr\"].mean(),\n",
    "        'overall pd':result_table[\"pd\"].mean(),\n",
    "        'male tpr':result_table[\"tpr_male\"].mean(),\n",
    "        'male pd':result_table[\"pd_male\"].mean(),\n",
    "        'female tpr':result_table[\"tpr_female\"].mean(),\n",
    "        'female pd':result_table[\"pd_female\"].mean(),\n",
    "        'eod': result_table[\"eod\"].mean(),\n",
    "        'di': result_table[\"sp\"].mean(),\n",
    "        })\n",
    "    pd_result = pd.DataFrame(records)\n",
    "    return pd_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "result_lr = add_mean_sd (records_lr, result_lr)\n",
    "result_rf = add_mean_sd (records_rf, result_rf)\n",
    "result_dt = add_mean_sd (records_dt, result_dt)\n",
    "result_gbt = add_mean_sd (records_gbt, result_gbt)\n",
    "\n",
    "result_path='/Users/lifuchen/Desktop/research/results/'\n",
    "result_lr.to_csv(path.join(result_path,'race-lr-result.csv'), index=False)\n",
    "result_rf.to_csv(path.join(result_path,'race-rf-result.csv'), index=False)\n",
    "result_dt.to_csv(path.join(result_path,'race-dt-result.csv'), index=False)\n",
    "result_gbt.to_csv(path.join(result_path,'race-gbt-result.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def print_result(result_table):\n",
    "    print ('overall ba validation: %.4f (+/- %.4f)' % (result_table[\"overall ba validation\"].mean(), result_table[\"overall ba validation\"].std()))\n",
    "    print ('overall ba test: %.4f (+/- %.4f)' % (result_table[\"overall ba test\"].mean(), result_table[\"overall ba test\"].std()))\n",
    "    print ('white ba validation: %.4f (+/- %.4f)' % (result_table[\"white ba validation\"].mean(), result_table[\"white ba validation\"].std()))\n",
    "    print ('white ba test: %.4f (+/- %.4f)' % (result_table[\"white ba test\"].mean(), result_table[\"white ba test\"].std()))\n",
    "    print ('black ba validation: %.4f (+/- %.4f)' % (result_table[\"black ba validation\"].mean(), result_table[\"black ba validation\"].std()))\n",
    "    print ('black ba test: %.4f (+/- %.4f)' % (result_table[\"black ba test\"].mean(), result_table[\"black ba test\"].std()))\n",
    "    print ('eod: %.4f (+/- %.4f)' % (result_table[\"eod\"].mean(), result_table[\"eod\"].std()))\n",
    "    print ('di: %.4f (+/- %.4f)' % (result_table[\"di\"].mean(), result_table[\"di\"].std()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
