{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from os import path\n",
    "import imblearn\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score\n",
    "import sklearn.preprocessing\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import src.lib.utility_classfier as uclf\n",
    "import src.lib.optimal_threhold_related as thres\n",
    "import src.lib.fairness_tests as fair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_path='/Users/lifuchen/Desktop/research/data.csv'\n",
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109490, 87)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df.Class.values\n",
    "X = df.drop(['GRID','Class'], axis=1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def save_prediction(classifier, characteristic, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_white_scaled, y_val_white, X_test_white_scaled, y_test_white, X_val_black_scaled, y_val_black, X_test_black_scaled, y_test_black):\n",
    "    method_to_call = getattr(uclf, classifier)\n",
    "    y_val_score = method_to_call(X_train_scaled, y_train,X_val_scaled, y_val)\n",
    "    y_test_score = method_to_call(X_train_scaled, y_train,X_test_scaled, y_test)\n",
    "\n",
    "    y_val_score_white = method_to_call(X_train_scaled, y_train, X_val_white_scaled, y_val_white)\n",
    "    y_test_score_white = method_to_call(X_train_scaled, y_train,X_test_white_scaled, y_test_white)\n",
    "\n",
    "    y_val_score_black = method_to_call(X_train_scaled, y_train, X_val_black_scaled, y_val_black)\n",
    "    y_test_score_black = method_to_call(X_train_scaled, y_train,X_test_black_scaled, y_test_black)\n",
    "\n",
    "    my_dict = dict(val_score = y_val_score, test_score = y_test_score, val_1_score = y_val_score_white, test_1_score = y_test_score_white, val_2_score = y_val_score_black, test_2_score = y_test_score_black)\n",
    "    overall_prediction = pd.DataFrame.from_dict(my_dict, orient='index')\n",
    "    overall_prediction = overall_prediction.transpose()\n",
    "\n",
    "    result_path='/Users/lifuchen/Desktop/research/predictions/'\n",
    "    filename = str(classifier) + str(characteristic) + \"prediction.csv\"\n",
    "    overall_prediction.to_csv(path.join(result_path, filename), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_result (classifier, characteristic, records, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_white_scaled, y_val_white, X_test_white_scaled, y_test_white, X_val_black_scaled, y_val_black, X_test_black_scaled, y_test_black):        \n",
    "    result_path='/Users/lifuchen/Desktop/research/predictions/'\n",
    "    filename = str(classifier) + characteristic + \"prediction.csv\"\n",
    "    prediction = pd.read_csv(path.join(result_path, filename))\n",
    "    \n",
    "    y_val_score = prediction['val_score'][prediction['val_score'].notna()]\n",
    "    y_test_score = prediction['test_score'][prediction['test_score'].notna()]\n",
    "    \n",
    "    y_val_score_white = prediction['val_1_score'][prediction['val_1_score'].notna()]\n",
    "    y_test_score_white = prediction['test_1_score'][prediction['test_1_score'].notna()]\n",
    "    \n",
    "    y_val_score_black = prediction['val_2_score'][prediction['val_2_score'].notna()]\n",
    "    y_test_score_black = prediction['test_2_score'][prediction['test_2_score'].notna()]\n",
    "    \n",
    "    threshold, ba_val, ba_test = balance_accuracy (y_val, y_val_score,y_test, y_test_score)\n",
    "    auroc = roc_auc_score(y_test, y_test_score)\n",
    "    precision, recall, tpr, tnr, pd_overall = thres.calculate_precision_metrics(y_test, y_test_score,threshold)\n",
    "    \n",
    "    threshold_white, ba_val_white, ba_test_white = balance_accuracy (y_val_white, y_val_score_white,y_test_white, y_test_score_white)\n",
    "    precision_white, recall_white, tpr_white, tnr_white, pd_white = thres.calculate_precision_metrics(y_test_white, y_test_score_white,threshold_white)\n",
    "    \n",
    "    threshold_black, ba_val_black, ba_test_black = balance_accuracy (y_val_black, y_val_score_black, y_test_black, y_test_score_black)\n",
    "    precision_black, recall_black, tpr_black, tnr_black, pd_black = thres.calculate_precision_metrics(y_test_black, y_test_score_black,threshold_black)\n",
    "\n",
    "    eod = fair.get_EOD(y_test_white, y_test_score_white,threshold_white, y_test_black, y_test_score_black, threshold_black)\n",
    "    sp = fair.get_SP(y_test_white, y_test_score_white,threshold_white, y_test_black, y_test_score_black, threshold_black)\n",
    "\n",
    "    records.append({\n",
    "        'auroc': auroc,\n",
    "        'overall threshold': threshold,\n",
    "        'white threshold': threshold_white,\n",
    "        'black threshold': threshold_black,\n",
    "        'overall ba validation': ba_val,\n",
    "        'overall ba test': ba_test,\n",
    "        'white ba validation': ba_val_white,\n",
    "        'white ba test': ba_test_white,\n",
    "        'black ba validation': ba_val_black,\n",
    "        'black ba test': ba_test_black,\n",
    "        'overall precision':precision,\n",
    "        'overall recall':recall,\n",
    "        'overall tpr':tpr,\n",
    "        'overall tnr':tnr,\n",
    "        'overall pd':pd_overall,\n",
    "        'white precision':precision_white,\n",
    "        'white recall':recall_white,\n",
    "        'white tpr':tpr_white,\n",
    "        'white tnr':tnr_white,\n",
    "        'white pd':pd_white,\n",
    "        'black precision':precision_black,\n",
    "        'black recall':recall_black,\n",
    "        'black tpr':tpr_black,\n",
    "        'black tnr':tnr_black,\n",
    "        'black pd':pd_black,\n",
    "        'eod': eod,\n",
    "        'di': sp,\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def balance_accuracy (y_val, y_val_score,y_test, y_test_score):\n",
    "    \n",
    "    threshold, _ = thres.get_optimal_threshold_Jvalue (y_val, y_val_score)\n",
    "    print (\"Optimal threshold by J value is \",threshold)\n",
    "\n",
    "    ba_val = thres.calculate_balanced_accuracy(y_val, y_val_score, threshold)\n",
    "    print (\"Balanced accuracy score of val is \", ba_val)\n",
    "\n",
    "    ba_test = thres.calculate_balanced_accuracy(y_test, y_test_score, threshold)\n",
    "    print (\"Balanced accuracy score of test is \",ba_test)\n",
    "\n",
    "    return threshold, ba_val, ba_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def fairness_metrics (X, y, attribute, random_state):\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, X_val_white, X_val_black, y_val_white, y_val_black, X_test_white, X_test_black, y_test_white, y_test_black \\\n",
    "        = fair.split_by_trait_balance_size(X, y, attribute, random_state)\n",
    "    \n",
    "    print(\"X train\", X_train.shape[0])\n",
    "    print(\"Y train\", y_train.shape[0])\n",
    "    print(X_val.shape[0], X_val_white.shape[0], X_val_black.shape[0])\n",
    "    print(y_val.shape[0], y_val_white.shape[0], y_val_black.shape[0])\n",
    "    print(X_test.shape[0], X_test_white.shape[0], X_test_black.shape[0])\n",
    "    print(y_test.shape[0], y_test_white.shape[0], y_test_black.shape[0])\n",
    "\n",
    "    max_abs_scaler = preprocessing.MaxAbsScaler()\n",
    "    X_train_scaled = max_abs_scaler.fit_transform(X_train)\n",
    "    X_test_scaled = max_abs_scaler.transform(X_test)\n",
    "    X_test_white_scaled = max_abs_scaler.transform(X_test_white)\n",
    "    X_test_black_scaled = max_abs_scaler.transform(X_test_black)\n",
    "    X_val_scaled = max_abs_scaler.transform(X_val)\n",
    "    X_val_white_scaled = max_abs_scaler.transform(X_val_white)\n",
    "    X_val_black_scaled = max_abs_scaler.transform(X_val_black)\n",
    "\n",
    "    characteristic = attribute + \"resample-by-size\" + str(random_state)\n",
    "    save_prediction (\"logic_regression\", characteristic, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_white_scaled, y_val_white, X_test_white_scaled, y_test_white, X_val_black_scaled, y_val_black, X_test_black_scaled, y_test_black)\n",
    "    save_prediction (\"random_forest\", characteristic, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_white_scaled, y_val_white, X_test_white_scaled, y_test_white, X_val_black_scaled, y_val_black, X_test_black_scaled, y_test_black)\n",
    "    save_prediction (\"decision_tree\", characteristic, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_white_scaled, y_val_white, X_test_white_scaled, y_test_white, X_val_black_scaled, y_val_black, X_test_black_scaled, y_test_black)\n",
    "    save_prediction (\"gradiant_boosting\", characteristic, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_white_scaled, y_val_white, X_test_white_scaled, y_test_white, X_val_black_scaled, y_val_black, X_test_black_scaled, y_test_black)\n",
    "\n",
    "    get_result (\"logic_regression\", characteristic, records_lr, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_white_scaled, y_val_white, X_test_white_scaled, y_test_white, X_val_black_scaled, y_val_black, X_test_black_scaled, y_test_black)\n",
    "    get_result (\"random_forest\", characteristic, records_rf, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_white_scaled, y_val_white, X_test_white_scaled, y_test_white, X_val_black_scaled, y_val_black, X_test_black_scaled, y_test_black)\n",
    "    get_result (\"decision_tree\", characteristic, records_dt, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_white_scaled, y_val_white, X_test_white_scaled, y_test_white, X_val_black_scaled, y_val_black, X_test_black_scaled, y_test_black)\n",
    "    get_result (\"gradiant_boosting\", characteristic, records_gbt, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_white_scaled, y_val_white, X_test_white_scaled, y_test_white, X_val_black_scaled, y_val_black, X_test_black_scaled, y_test_black)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lifuchen/Desktop/research/CVDPrediction-master/src/lib/fairness_tests.py:112: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train ['Class'] = y_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56639,)\n",
      "(56639,)\n",
      "(113278, 87)\n",
      "X train 113278\n",
      "Y train 113278\n",
      "21898 18899 2999\n",
      "21898 18899 2999\n",
      "21898 18968 2930\n",
      "21898 18968 2930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1724412648007032\n",
      "0.2667097658936393\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95     19904\n",
      "           1       0.43      0.04      0.08      1994\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.52      0.52     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19788   116]\n",
      " [ 1906    88]]\n",
      "done in 0.784989s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1724412648007032\n",
      "0.2656993027243624\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95     19934\n",
      "           1       0.40      0.04      0.08      1964\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.66      0.52      0.52     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19803   131]\n",
      " [ 1877    87]]\n",
      "done in 0.776438s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1724412648007032\n",
      "0.26363803689543175\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95     17180\n",
      "           1       0.43      0.05      0.09      1719\n",
      "\n",
      "    accuracy                           0.91     18899\n",
      "   macro avg       0.67      0.52      0.52     18899\n",
      "weighted avg       0.87      0.91      0.87     18899\n",
      "\n",
      "Confusion_matrix\n",
      "[[17066   114]\n",
      " [ 1633    86]]\n",
      "done in 0.780972s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1724412648007032\n",
      "0.26332500967201733\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95     17260\n",
      "           1       0.39      0.05      0.09      1708\n",
      "\n",
      "    accuracy                           0.91     18968\n",
      "   macro avg       0.65      0.52      0.52     18968\n",
      "weighted avg       0.87      0.91      0.87     18968\n",
      "\n",
      "Confusion_matrix\n",
      "[[17130   130]\n",
      " [ 1624    84]]\n",
      "done in 0.780329s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1724412648007032\n",
      "0.2860670871130874\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2724\n",
      "           1       0.50      0.01      0.01       275\n",
      "\n",
      "    accuracy                           0.91      2999\n",
      "   macro avg       0.70      0.50      0.48      2999\n",
      "weighted avg       0.87      0.91      0.87      2999\n",
      "\n",
      "Confusion_matrix\n",
      "[[2722    2]\n",
      " [ 273    2]]\n",
      "done in 0.753528s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1724412648007032\n",
      "0.28106981146732546\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2674\n",
      "           1       0.75      0.01      0.02       256\n",
      "\n",
      "    accuracy                           0.91      2930\n",
      "   macro avg       0.83      0.51      0.49      2930\n",
      "weighted avg       0.90      0.91      0.87      2930\n",
      "\n",
      "Confusion_matrix\n",
      "[[2673    1]\n",
      " [ 253    3]]\n",
      "done in 0.754666s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19904\n",
      "           1       0.44      0.00      0.01      1994\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19895     9]\n",
      " [ 1987     7]]\n",
      "done in 36.471092s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19934\n",
      "           1       0.62      0.00      0.01      1964\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.77      0.50      0.48     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19931     3]\n",
      " [ 1959     5]]\n",
      "done in 35.977986s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17180\n",
      "           1       0.40      0.00      0.01      1719\n",
      "\n",
      "    accuracy                           0.91     18899\n",
      "   macro avg       0.65      0.50      0.48     18899\n",
      "weighted avg       0.86      0.91      0.87     18899\n",
      "\n",
      "Confusion_matrix\n",
      "[[17171     9]\n",
      " [ 1713     6]]\n",
      "done in 37.035142s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17260\n",
      "           1       0.30      0.00      0.00      1708\n",
      "\n",
      "    accuracy                           0.91     18968\n",
      "   macro avg       0.61      0.50      0.48     18968\n",
      "weighted avg       0.86      0.91      0.87     18968\n",
      "\n",
      "Confusion_matrix\n",
      "[[17253     7]\n",
      " [ 1705     3]]\n",
      "done in 36.067073s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2724\n",
      "           1       0.00      0.00      0.00       275\n",
      "\n",
      "    accuracy                           0.91      2999\n",
      "   macro avg       0.45      0.50      0.48      2999\n",
      "weighted avg       0.83      0.91      0.86      2999\n",
      "\n",
      "Confusion_matrix\n",
      "[[2724    0]\n",
      " [ 275    0]]\n",
      "done in 36.171156s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2674\n",
      "           1       0.00      0.00      0.00       256\n",
      "\n",
      "    accuracy                           0.91      2930\n",
      "   macro avg       0.46      0.50      0.48      2930\n",
      "weighted avg       0.83      0.91      0.87      2930\n",
      "\n",
      "Confusion_matrix\n",
      "[[2674    0]\n",
      " [ 256    0]]\n",
      "done in 35.921536s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1771912989679764\n",
      "0.27792524189794077\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19904\n",
      "           1       0.26      0.00      0.01      1994\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.58      0.50      0.48     21898\n",
      "weighted avg       0.85      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19884    20]\n",
      " [ 1987     7]]\n",
      "done in 1.321928s\n",
      "0.1771912989679764\n",
      "0.2771017993194354\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19934\n",
      "           1       0.06      0.00      0.00      1964\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.49      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19919    15]\n",
      " [ 1963     1]]\n",
      "done in 1.314397s\n",
      "0.1771912989679764\n",
      "0.2743897100138779\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17180\n",
      "           1       0.26      0.00      0.01      1719\n",
      "\n",
      "    accuracy                           0.91     18899\n",
      "   macro avg       0.59      0.50      0.48     18899\n",
      "weighted avg       0.85      0.91      0.87     18899\n",
      "\n",
      "Confusion_matrix\n",
      "[[17166    14]\n",
      " [ 1714     5]]\n",
      "done in 1.313775s\n",
      "0.1771912989679764\n",
      "0.27250143625318973\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17260\n",
      "           1       0.07      0.00      0.00      1708\n",
      "\n",
      "    accuracy                           0.91     18968\n",
      "   macro avg       0.49      0.50      0.48     18968\n",
      "weighted avg       0.83      0.91      0.87     18968\n",
      "\n",
      "Confusion_matrix\n",
      "[[17247    13]\n",
      " [ 1707     1]]\n",
      "done in 1.316503s\n",
      "0.1771912989679764\n",
      "0.30020534095659457\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2724\n",
      "           1       0.25      0.01      0.01       275\n",
      "\n",
      "    accuracy                           0.91      2999\n",
      "   macro avg       0.58      0.50      0.48      2999\n",
      "weighted avg       0.85      0.91      0.87      2999\n",
      "\n",
      "Confusion_matrix\n",
      "[[2718    6]\n",
      " [ 273    2]]\n",
      "done in 1.291635s\n",
      "0.1771912989679764\n",
      "0.30688326233668733\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2674\n",
      "           1       0.00      0.00      0.00       256\n",
      "\n",
      "    accuracy                           0.91      2930\n",
      "   macro avg       0.46      0.50      0.48      2930\n",
      "weighted avg       0.83      0.91      0.87      2930\n",
      "\n",
      "Confusion_matrix\n",
      "[[2672    2]\n",
      " [ 256    0]]\n",
      "done in 1.289810s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19904\n",
      "           1       0.47      0.03      0.06      1994\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.69      0.51      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19835    69]\n",
      " [ 1932    62]]\n",
      "done in 73.746492s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19934\n",
      "           1       0.46      0.04      0.07      1964\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.69      0.52      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19849    85]\n",
      " [ 1892    72]]\n",
      "done in 73.769360s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17180\n",
      "           1       0.49      0.03      0.06      1719\n",
      "\n",
      "    accuracy                           0.91     18899\n",
      "   macro avg       0.70      0.52      0.51     18899\n",
      "weighted avg       0.87      0.91      0.87     18899\n",
      "\n",
      "Confusion_matrix\n",
      "[[17119    61]\n",
      " [ 1661    58]]\n",
      "done in 73.767157s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17260\n",
      "           1       0.45      0.04      0.07      1708\n",
      "\n",
      "    accuracy                           0.91     18968\n",
      "   macro avg       0.68      0.52      0.51     18968\n",
      "weighted avg       0.87      0.91      0.87     18968\n",
      "\n",
      "Confusion_matrix\n",
      "[[17180    80]\n",
      " [ 1643    65]]\n",
      "done in 73.814819s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2724\n",
      "           1       0.27      0.01      0.02       275\n",
      "\n",
      "    accuracy                           0.91      2999\n",
      "   macro avg       0.59      0.50      0.49      2999\n",
      "weighted avg       0.85      0.91      0.87      2999\n",
      "\n",
      "Confusion_matrix\n",
      "[[2716    8]\n",
      " [ 272    3]]\n",
      "done in 73.466807s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2674\n",
      "           1       0.58      0.03      0.05       256\n",
      "\n",
      "    accuracy                           0.91      2930\n",
      "   macro avg       0.75      0.51      0.50      2930\n",
      "weighted avg       0.89      0.91      0.88      2930\n",
      "\n",
      "Confusion_matrix\n",
      "[[2669    5]\n",
      " [ 249    7]]\n",
      "done in 73.518824s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.384\n",
      "threshold:0.2, J-value:0.251\n",
      "threshold:0.30000000000000004, J-value:0.153\n",
      "threshold:0.4, J-value:0.085\n",
      "threshold:0.5, J-value:0.038\n",
      "threshold:0.6000000000000001, J-value:0.016\n",
      "threshold:0.7000000000000001, J-value:0.006\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6923238566180858\n",
      "Balanced accuracy score of test is  0.6884402336263642\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.403\n",
      "threshold:0.2, J-value:0.271\n",
      "threshold:0.30000000000000004, J-value:0.16999999999999998\n",
      "threshold:0.4, J-value:0.096\n",
      "threshold:0.5, J-value:0.043000000000000003\n",
      "threshold:0.6000000000000001, J-value:0.019000000000000003\n",
      "threshold:0.7000000000000001, J-value:0.006\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7014107377587072\n",
      "Balanced accuracy score of test is  0.694484614695754\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.27199999999999996\n",
      "threshold:0.2, J-value:0.12499999999999999\n",
      "threshold:0.30000000000000004, J-value:0.044\n",
      "threshold:0.4, J-value:0.015\n",
      "threshold:0.5, J-value:0.006\n",
      "threshold:0.6000000000000001, J-value:-0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6362001067948204\n",
      "Balanced accuracy score of test is  0.645698450355273\n",
      "True positive rate of class 1 is  0.642\n",
      "True positive rate of class 2 is  0.379\n",
      "Positive prediction rate of class 1 is  0.288\n",
      "Positive prediction rate of class 2 is  0.113\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.40499999999999997\n",
      "threshold:0.2, J-value:0.263\n",
      "threshold:0.30000000000000004, J-value:0.093\n",
      "threshold:0.4, J-value:0.025\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7024915935507487\n",
      "Balanced accuracy score of test is  0.6904842242128146\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.408\n",
      "threshold:0.2, J-value:0.259\n",
      "threshold:0.30000000000000004, J-value:0.097\n",
      "threshold:0.4, J-value:0.022000000000000002\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7037131227308835\n",
      "Balanced accuracy score of test is  0.6903471768054903\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.45000000000000007\n",
      "threshold:0.2, J-value:0.22499999999999998\n",
      "threshold:0.30000000000000004, J-value:0.055\n",
      "threshold:0.4, J-value:0.003\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7252442931517822\n",
      "Balanced accuracy score of test is  0.695343177356021\n",
      "True positive rate of class 1 is  0.727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positive rate of class 2 is  0.629\n",
      "Positive prediction rate of class 1 is  0.38\n",
      "Positive prediction rate of class 2 is  0.272\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.344\n",
      "threshold:0.2, J-value:0.18800000000000003\n",
      "threshold:0.30000000000000004, J-value:0.064\n",
      "threshold:0.4, J-value:0.004\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6723430188072256\n",
      "Balanced accuracy score of test is  0.6664952081175415\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.36100000000000004\n",
      "threshold:0.2, J-value:0.20099999999999998\n",
      "threshold:0.30000000000000004, J-value:0.064\n",
      "threshold:0.4, J-value:0.002\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6801343066365709\n",
      "Balanced accuracy score of test is  0.6729105891164475\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.24800000000000003\n",
      "threshold:0.2, J-value:0.10700000000000001\n",
      "threshold:0.30000000000000004, J-value:0.067\n",
      "threshold:0.4, J-value:0.012\n",
      "threshold:0.5, J-value:0.012\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6242444266453077\n",
      "Balanced accuracy score of test is  0.6213698462041886\n",
      "True positive rate of class 1 is  0.649\n",
      "True positive rate of class 2 is  0.387\n",
      "Positive prediction rate of class 1 is  0.335\n",
      "Positive prediction rate of class 2 is  0.165\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.399\n",
      "threshold:0.2, J-value:0.256\n",
      "threshold:0.30000000000000004, J-value:0.137\n",
      "threshold:0.4, J-value:0.076\n",
      "threshold:0.5, J-value:0.028\n",
      "threshold:0.6000000000000001, J-value:0.007\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6995021690876488\n",
      "Balanced accuracy score of test is  0.6943192065383995\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41500000000000004\n",
      "threshold:0.2, J-value:0.271\n",
      "threshold:0.30000000000000004, J-value:0.146\n",
      "threshold:0.4, J-value:0.081\n",
      "threshold:0.5, J-value:0.030000000000000002\n",
      "threshold:0.6000000000000001, J-value:0.007\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7070478646856573\n",
      "Balanced accuracy score of test is  0.7007176371298857\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.30600000000000005\n",
      "threshold:0.2, J-value:0.16\n",
      "threshold:0.30000000000000004, J-value:0.082\n",
      "threshold:0.4, J-value:0.045\n",
      "threshold:0.5, J-value:0.008\n",
      "threshold:0.6000000000000001, J-value:0.007\n",
      "threshold:0.7000000000000001, J-value:0.004\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6528093712454945\n",
      "Balanced accuracy score of test is  0.6492730927449514\n",
      "True positive rate of class 1 is  0.671\n",
      "True positive rate of class 2 is  0.406\n",
      "Positive prediction rate of class 1 is  0.306\n",
      "Positive prediction rate of class 2 is  0.134\n"
     ]
    }
   ],
   "source": [
    "records_lr = []\n",
    "records_rf = []\n",
    "records_dt = []\n",
    "records_gbt = []\n",
    "for random_state in range(1):\n",
    "    fairness_metrics (X, y, \"Race_W\", random_state)\n",
    "\n",
    "result_lr = pd.DataFrame(records_lr)\n",
    "result_rf = pd.DataFrame(records_rf)\n",
    "result_dt = pd.DataFrame(records_dt)\n",
    "result_gbt = pd.DataFrame(records_gbt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def add_mean_sd(records, result_table, overall_records, type):\n",
    "    records.append({\n",
    "        'auroc': result_table[\"auroc\"].mean(),\n",
    "        'overall threshold': result_table[\"overall threshold\"].mean(),\n",
    "        'white threshold': result_table[\"white threshold\"].mean(),\n",
    "        'black threshold': result_table[\"black threshold\"].mean(),\n",
    "        'overall ba validation': result_table[\"overall ba validation\"].mean(),\n",
    "        'overall ba test': result_table[\"overall ba test\"].mean(),\n",
    "        'white ba validation': result_table[\"white ba validation\"].mean(),\n",
    "        'white ba test': result_table[\"white ba test\"].mean(),\n",
    "        'black ba validation': result_table[\"black ba validation\"].mean(),\n",
    "        'black ba test': result_table[\"black ba test\"].mean(),\n",
    "        'overall precision':result_table[\"overall precision\"].mean(),\n",
    "        'overall recall':result_table[\"overall recall\"].mean(),\n",
    "        'overall tpr':result_table[\"overall tpr\"].mean(),\n",
    "        'overall tnr':result_table[\"overall tnr\"].mean(),\n",
    "        'overall pd':result_table[\"overall pd\"].mean(),\n",
    "        'white precision':result_table[\"white precision\"].mean(),\n",
    "        'white recall':result_table[\"white recall\"].mean(),\n",
    "        'white tpr':result_table[\"white tpr\"].mean(),\n",
    "        'white tnr':result_table[\"white tnr\"].mean(),\n",
    "        'white pd':result_table[\"white pd\"].mean(),\n",
    "        'black precision':result_table[\"black precision\"].mean(),\n",
    "        'black recall':result_table[\"black recall\"].mean(),\n",
    "        'black tpr':result_table[\"black tpr\"].mean(),\n",
    "        'black tnr':result_table[\"black tnr\"].mean(),\n",
    "        'black pd':result_table[\"black pd\"].mean(),\n",
    "        'eod': result_table[\"eod\"].mean(),\n",
    "        'di': result_table[\"di\"].mean(),\n",
    "        })\n",
    "    records.append({\n",
    "        'auroc': result_table[\"auroc\"].std(),\n",
    "        'overall threshold': result_table[\"overall threshold\"].std(),\n",
    "        'white threshold': result_table[\"white threshold\"].std(),\n",
    "        'black threshold': result_table[\"black threshold\"].std(),\n",
    "        'overall ba validation': result_table[\"overall ba validation\"].std(),\n",
    "        'overall ba test': result_table[\"overall ba test\"].std(),\n",
    "        'white ba validation': result_table[\"white ba validation\"].std(),\n",
    "        'white ba test': result_table[\"white ba test\"].std(),\n",
    "        'black ba validation': result_table[\"black ba validation\"].std(),\n",
    "        'black ba test': result_table[\"black ba test\"].std(),\n",
    "        'overall precision':result_table[\"overall precision\"].std(),\n",
    "        'overall recall':result_table[\"overall recall\"].std(),\n",
    "        'overall tpr':result_table[\"overall tpr\"].std(),\n",
    "        'overall tnr':result_table[\"overall tnr\"].std(),\n",
    "        'overall pd':result_table[\"overall pd\"].std(),\n",
    "        'white precision':result_table[\"white precision\"].std(),\n",
    "        'white recall':result_table[\"white recall\"].std(),\n",
    "        'white tpr':result_table[\"white tpr\"].std(),\n",
    "        'white tnr':result_table[\"white tnr\"].std(),\n",
    "        'white pd':result_table[\"white pd\"].std(),\n",
    "        'black precision':result_table[\"black precision\"].std(),\n",
    "        'black recall':result_table[\"black recall\"].std(),\n",
    "        'black tpr':result_table[\"black tpr\"].std(),\n",
    "        'black tnr':result_table[\"black tnr\"].std(),\n",
    "        'black pd':result_table[\"black pd\"].std(),\n",
    "        'eod': result_table[\"eod\"].std(),\n",
    "        'di': result_table[\"di\"].std(),\n",
    "        })\n",
    "    overall_records.append({\n",
    "        'type': type,\n",
    "        'auroc': result_table[\"auroc\"].mean(),\n",
    "        'overall threshold': result_table[\"overall threshold\"].mean(),\n",
    "        'white threshold': result_table[\"white threshold\"].mean(),\n",
    "        'black threshold': result_table[\"black threshold\"].mean(),\n",
    "        'overall ba test': result_table[\"overall ba test\"].mean(),\n",
    "        'white ba test': result_table[\"white ba test\"].mean(),\n",
    "        'black ba test': result_table[\"black ba test\"].mean(),\n",
    "        'overall tpr':result_table[\"overall tpr\"].mean(),\n",
    "        'overall pd':result_table[\"overall pd\"].mean(),\n",
    "        'white tpr':result_table[\"white tpr\"].mean(),\n",
    "        'white pd':result_table[\"white pd\"].mean(),\n",
    "        'black tpr':result_table[\"black tpr\"].mean(),\n",
    "        'black pd':result_table[\"black pd\"].mean(),\n",
    "        'eod': result_table[\"eod\"].mean(),\n",
    "        'di': result_table[\"di\"].mean(),\n",
    "        })\n",
    "    pd_result = pd.DataFrame(records)\n",
    "    return pd_result, overall_records\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "overall_table = []\n",
    "result_lr, overall_records = add_mean_sd (records_lr, result_lr, overall_table, 'lr')\n",
    "result_rf, overall_records = add_mean_sd (records_rf, result_rf, overall_records, 'rf')\n",
    "result_dt, overall_records = add_mean_sd (records_dt, result_dt, overall_records, 'dt')\n",
    "result_gbt, overall_records = add_mean_sd (records_gbt, result_gbt, overall_records, 'gbt')\n",
    "\n",
    "result_path='/Users/lifuchen/Desktop/research/resample_data/'\n",
    "result_lr.to_csv(path.join(result_path,'race-lr-resample-size-result.csv'), index=False)\n",
    "result_rf.to_csv(path.join(result_path,'race-rf-resample-size-result.csv'), index=False)\n",
    "result_dt.to_csv(path.join(result_path,'race-dt-resample-size-result.csv'), index=False)\n",
    "result_gbt.to_csv(path.join(result_path,'race-gbt-resample-size-result.csv'), index=False)\n",
    "\n",
    "overall_result = pd.DataFrame(overall_table)\n",
    "result_path='/Users/lifuchen/Desktop/research/resample_result/'\n",
    "overall_result.to_csv(path.join(result_path,'race-resample-size.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
