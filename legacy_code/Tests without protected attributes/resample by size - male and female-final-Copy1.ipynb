{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import imblearn\n",
    "from os import path\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score\n",
    "import sklearn.preprocessing\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import src.lib.utility_classfier as uclf\n",
    "import src.lib.optimal_threhold_related as thres\n",
    "import src.lib.fairness_tests as fair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109490, 89)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path='/Users/lifuchen/Desktop/research/data.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109490, 87)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df.Class.values\n",
    "X = df.drop(['GRID','Class'], axis=1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def save_prediction(classifier, characteristic, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_male_scaled, y_val_male, X_test_male_scaled, y_test_male, X_val_female_scaled, y_val_female, X_test_female_scaled, y_test_female):\n",
    "    method_to_call = getattr(uclf, classifier)\n",
    "    y_val_score = method_to_call(X_train_scaled, y_train,X_val_scaled, y_val)\n",
    "    y_test_score = method_to_call(X_train_scaled, y_train,X_test_scaled, y_test)\n",
    "\n",
    "    y_val_score_male = method_to_call(X_train_scaled, y_train, X_val_male_scaled, y_val_male)\n",
    "    y_test_score_male = method_to_call(X_train_scaled, y_train,X_test_male_scaled, y_test_male)\n",
    "\n",
    "    y_val_score_female = method_to_call(X_train_scaled, y_train, X_val_female_scaled, y_val_female)\n",
    "    y_test_score_female = method_to_call(X_train_scaled, y_train,X_test_female_scaled, y_test_female)\n",
    "\n",
    "    my_dict = dict(val_score = y_val_score, test_score = y_test_score, val_1_score = y_val_score_male, test_1_score = y_test_score_male, val_2_score = y_val_score_female, test_2_score = y_test_score_female)\n",
    "    overall_prediction = pd.DataFrame.from_dict(my_dict, orient='index')\n",
    "    overall_prediction = overall_prediction.transpose()\n",
    "\n",
    "    result_path='/Users/lifuchen/Desktop/research/predictions/'\n",
    "    filename = str(classifier) + str(characteristic) + \"prediction.csv\"\n",
    "    overall_prediction.to_csv(path.join(result_path, filename), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_result (classifier,characteristic, records, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_male_scaled, y_val_male, X_test_male_scaled, y_test_male, X_val_female_scaled, y_val_female, X_test_female_scaled, y_test_female):\n",
    "    result_path='/Users/lifuchen/Desktop/research/predictions/'\n",
    "    filename = str(classifier) + characteristic + \"prediction.csv\"\n",
    "    prediction = pd.read_csv(path.join(result_path, filename))\n",
    "    \n",
    "    y_val_score = prediction['val_score'][prediction['val_score'].notna()]\n",
    "    y_test_score = prediction['test_score'][prediction['test_score'].notna()]\n",
    "    \n",
    "    y_val_score_male = prediction['val_1_score'][prediction['val_1_score'].notna()]\n",
    "    y_test_score_male = prediction['test_1_score'][prediction['test_1_score'].notna()]\n",
    "    \n",
    "    y_val_score_female = prediction['val_2_score'][prediction['val_2_score'].notna()]\n",
    "    y_test_score_female = prediction['test_2_score'][prediction['test_2_score'].notna()]\n",
    "    \n",
    "    threshold, ba_val, ba_test = balance_accuracy (y_val, y_val_score,y_test, y_test_score)\n",
    "    auroc = roc_auc_score(y_test, y_test_score)\n",
    "    precision, recall, tpr, tnr, pd_overall = thres.calculate_precision_metrics(y_test, y_test_score,threshold)\n",
    "    \n",
    "    threshold_male, ba_val_male, ba_test_male = balance_accuracy (y_val_male, y_val_score_male,y_test_male, y_test_score_male)\n",
    "    precision_male, recall_male, tpr_male, tnr_male, pd_male = thres.calculate_precision_metrics(y_test_male, y_test_score_male,threshold_male)\n",
    "    \n",
    "    threshold_female, ba_val_female, ba_test_female = balance_accuracy (y_val_female, y_val_score_female, y_test_female, y_test_score_female)\n",
    "    precision_female, recall_female, tpr_female, tnr_female, pd_female = thres.calculate_precision_metrics(y_test_female, y_test_score_female,threshold_female)\n",
    "\n",
    "    eod = fair.get_EOD(y_test_male, y_test_score_male,threshold_male, y_test_female, y_test_score_female, threshold_female)\n",
    "    sp = fair.get_SP(y_test_male, y_test_score_male,threshold_male, y_test_female, y_test_score_female, threshold_female)\n",
    "\n",
    "    records.append({\n",
    "        'auroc': auroc,\n",
    "        'overall threshold': threshold,\n",
    "        'male threshold': threshold_male,\n",
    "        'female threshold': threshold_female,\n",
    "        'overall ba validation': ba_val,\n",
    "        'overall ba test': ba_test,\n",
    "        'male ba validation': ba_val_male,\n",
    "        'male ba test': ba_test_male,\n",
    "        'female ba validation': ba_val_female,\n",
    "        'female ba test': ba_test_female,\n",
    "        'overall precision':precision,\n",
    "        'overall recall':recall,\n",
    "        'overall tpr':tpr,\n",
    "        'overall tnr':tnr,\n",
    "        'overall pd':pd_overall,\n",
    "        'male precision':precision_male,\n",
    "        'male recall':recall_male,\n",
    "        'male tpr':tpr_male,\n",
    "        'male tnr':tnr_male,\n",
    "        'male pd':pd_male,\n",
    "        'female precision':precision_female,\n",
    "        'female recall':recall_female,\n",
    "        'female tpr':tpr_female,\n",
    "        'female tnr':tnr_female,\n",
    "        'female pd':pd_female,\n",
    "        'eod': eod,\n",
    "        'di': sp,\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def balance_accuracy (y_val, y_val_score,y_test, y_test_score):\n",
    "    \n",
    "    threshold, _ = thres.get_optimal_threshold_Jvalue (y_val, y_val_score)\n",
    "    print (\"Optimal threshold by J value is \",threshold)\n",
    "\n",
    "    ba_val = thres.calculate_balanced_accuracy(y_val, y_val_score, threshold)\n",
    "    print (\"Balanced accuracy score of val is \", ba_val)\n",
    "\n",
    "    ba_test = thres.calculate_balanced_accuracy(y_test, y_test_score, threshold)\n",
    "    print (\"Balanced accuracy score of test is \",ba_test)\n",
    "\n",
    "    return threshold, ba_val, ba_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def fairness_metrics (X, y, attribute, random_state):\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, X_val_female, X_val_male, y_val_female, y_val_male, X_test_female, X_test_male, y_test_female, y_test_male \\\n",
    "        = fair.split_by_trait_balance_size(X, y, attribute, random_state)\n",
    "    \n",
    "    print(\"X train\", X_train.shape[0])\n",
    "    print(\"Y train\", y_train.shape[0])\n",
    "    print(X_val.shape[0], X_val_male.shape[0], X_val_female.shape[0])\n",
    "    print(y_val.shape[0], y_val_male.shape[0], y_val_female.shape[0])\n",
    "    print(X_test.shape[0], X_test_male.shape[0], X_test_female.shape[0])\n",
    "    print(y_test.shape[0], y_test_male.shape[0], y_test_female.shape[0])\n",
    "\n",
    "    max_abs_scaler = preprocessing.MaxAbsScaler()\n",
    "    X_train_scaled = max_abs_scaler.fit_transform(X_train)\n",
    "    X_test_scaled = max_abs_scaler.transform(X_test)\n",
    "    X_test_male_scaled = max_abs_scaler.transform(X_test_male)\n",
    "    X_test_female_scaled = max_abs_scaler.transform(X_test_female)\n",
    "    X_val_scaled = max_abs_scaler.transform(X_val)\n",
    "    X_val_male_scaled = max_abs_scaler.transform(X_val_male)\n",
    "    X_val_female_scaled = max_abs_scaler.transform(X_val_female)\n",
    "\n",
    "    characteristic = attribute + \"resample-by-size\" + str(random_state)\n",
    "    save_prediction (\"logic_regression\", characteristic, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_male_scaled, y_val_male, X_test_male_scaled, y_test_male, X_val_female_scaled, y_val_female, X_test_female_scaled, y_test_female)\n",
    "    save_prediction (\"random_forest\", characteristic, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_male_scaled, y_val_male, X_test_male_scaled, y_test_male, X_val_female_scaled, y_val_female, X_test_female_scaled, y_test_female)\n",
    "    save_prediction (\"decision_tree\", characteristic, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_male_scaled, y_val_male, X_test_male_scaled, y_test_male, X_val_female_scaled, y_val_female, X_test_female_scaled, y_test_female)\n",
    "    save_prediction (\"gradiant_boosting\", characteristic, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_male_scaled, y_val_male, X_test_male_scaled, y_test_male, X_val_female_scaled, y_val_female, X_test_female_scaled, y_test_female)\n",
    "\n",
    "    get_result (\"logic_regression\", characteristic, records_lr, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_male_scaled, y_val_male, X_test_male_scaled, y_test_male, X_val_female_scaled, y_val_female, X_test_female_scaled, y_test_female)\n",
    "    get_result (\"random_forest\", characteristic, records_rf, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_male_scaled, y_val_male, X_test_male_scaled, y_test_male, X_val_female_scaled, y_val_female, X_test_female_scaled, y_test_female)\n",
    "    get_result (\"decision_tree\", characteristic, records_dt, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_male_scaled, y_val_male, X_test_male_scaled, y_test_male, X_val_female_scaled, y_val_female, X_test_female_scaled, y_test_female)\n",
    "    get_result (\"gradiant_boosting\", characteristic, records_gbt, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_male_scaled, y_val_male, X_test_male_scaled, y_test_male, X_val_female_scaled, y_val_female, X_test_female_scaled, y_test_female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lifuchen/Desktop/research/CVDPrediction-master/src/lib/fairness_tests.py:80: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train ['Class'] = y_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42330,)\n",
      "(42330,)\n",
      "(84660, 87)\n",
      "X train 84660\n",
      "Y train 84660\n",
      "21898 7782 14116\n",
      "21898 7782 14116\n",
      "21898 7707 14191\n",
      "21898 7707 14191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22184378337711239\n",
      "0.26379589257469205\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95     19904\n",
      "           1       0.43      0.04      0.08      1994\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.52      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19794   110]\n",
      " [ 1910    84]]\n",
      "done in 2.891152s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22184378337711239\n",
      "0.2633859471686394\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95     19934\n",
      "           1       0.42      0.04      0.08      1964\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.52      0.52     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19815   119]\n",
      " [ 1879    85]]\n",
      "done in 2.867661s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22184378337711239\n",
      "0.3097088538401907\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94      6915\n",
      "           1       0.41      0.03      0.06       867\n",
      "\n",
      "    accuracy                           0.89      7782\n",
      "   macro avg       0.65      0.51      0.50      7782\n",
      "weighted avg       0.84      0.89      0.84      7782\n",
      "\n",
      "Confusion_matrix\n",
      "[[6872   43]\n",
      " [ 837   30]]\n",
      "done in 2.522097s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22184378337711239\n",
      "0.3044070941223497\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6860\n",
      "           1       0.48      0.04      0.07       847\n",
      "\n",
      "    accuracy                           0.89      7707\n",
      "   macro avg       0.69      0.52      0.50      7707\n",
      "weighted avg       0.85      0.89      0.85      7707\n",
      "\n",
      "Confusion_matrix\n",
      "[[6828   32]\n",
      " [ 817   30]]\n",
      "done in 2.366919s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22184378337711239\n",
      "0.2384845675131936\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96     12989\n",
      "           1       0.45      0.05      0.09      1127\n",
      "\n",
      "    accuracy                           0.92     14116\n",
      "   macro avg       0.68      0.52      0.52     14116\n",
      "weighted avg       0.89      0.92      0.89     14116\n",
      "\n",
      "Confusion_matrix\n",
      "[[12922    67]\n",
      " [ 1073    54]]\n",
      "done in 2.517064s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22184378337711239\n",
      "0.24110774411231886\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96     13074\n",
      "           1       0.39      0.05      0.09      1117\n",
      "\n",
      "    accuracy                           0.92     14191\n",
      "   macro avg       0.66      0.52      0.52     14191\n",
      "weighted avg       0.88      0.92      0.89     14191\n",
      "\n",
      "Confusion_matrix\n",
      "[[12987    87]\n",
      " [ 1062    55]]\n",
      "done in 3.000894s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19904\n",
      "           1       0.14      0.00      0.00      1994\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.53      0.50      0.48     21898\n",
      "weighted avg       0.84      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19898     6]\n",
      " [ 1993     1]]\n",
      "done in 37.964923s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19934\n",
      "           1       0.36      0.00      0.00      1964\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.64      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19927     7]\n",
      " [ 1960     4]]\n",
      "done in 39.399293s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6915\n",
      "           1       0.25      0.00      0.00       867\n",
      "\n",
      "    accuracy                           0.89      7782\n",
      "   macro avg       0.57      0.50      0.47      7782\n",
      "weighted avg       0.82      0.89      0.84      7782\n",
      "\n",
      "Confusion_matrix\n",
      "[[6912    3]\n",
      " [ 866    1]]\n",
      "done in 36.523397s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6860\n",
      "           1       0.40      0.00      0.00       847\n",
      "\n",
      "    accuracy                           0.89      7707\n",
      "   macro avg       0.65      0.50      0.47      7707\n",
      "weighted avg       0.84      0.89      0.84      7707\n",
      "\n",
      "Confusion_matrix\n",
      "[[6857    3]\n",
      " [ 845    2]]\n",
      "done in 32.554856s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12989\n",
      "           1       0.33      0.00      0.00      1127\n",
      "\n",
      "    accuracy                           0.92     14116\n",
      "   macro avg       0.63      0.50      0.48     14116\n",
      "weighted avg       0.87      0.92      0.88     14116\n",
      "\n",
      "Confusion_matrix\n",
      "[[12985     4]\n",
      " [ 1125     2]]\n",
      "done in 32.672857s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13074\n",
      "           1       0.75      0.00      0.01      1117\n",
      "\n",
      "    accuracy                           0.92     14191\n",
      "   macro avg       0.84      0.50      0.48     14191\n",
      "weighted avg       0.91      0.92      0.88     14191\n",
      "\n",
      "Confusion_matrix\n",
      "[[13073     1]\n",
      " [ 1114     3]]\n",
      "done in 33.092299s\n",
      "0.2284294330490572\n",
      "0.2733357057267314\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19904\n",
      "           1       0.17      0.00      0.00      1994\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.54      0.50      0.48     21898\n",
      "weighted avg       0.84      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19899     5]\n",
      " [ 1993     1]]\n",
      "done in 1.052290s\n",
      "0.22842943304905716\n",
      "0.27127852963686294\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19934\n",
      "           1       0.07      0.00      0.00      1964\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.49      0.50      0.48     21898\n",
      "weighted avg       0.84      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19921    13]\n",
      " [ 1963     1]]\n",
      "done in 1.062989s\n",
      "0.2284294330490572\n",
      "0.3193391468667155\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6915\n",
      "           1       0.00      0.00      0.00       867\n",
      "\n",
      "    accuracy                           0.89      7782\n",
      "   macro avg       0.44      0.50      0.47      7782\n",
      "weighted avg       0.79      0.89      0.84      7782\n",
      "\n",
      "Confusion_matrix\n",
      "[[6913    2]\n",
      " [ 867    0]]\n",
      "done in 1.075182s\n",
      "0.22842943304905716\n",
      "0.3136877747901036\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6860\n",
      "           1       0.17      0.00      0.00       847\n",
      "\n",
      "    accuracy                           0.89      7707\n",
      "   macro avg       0.53      0.50      0.47      7707\n",
      "weighted avg       0.81      0.89      0.84      7707\n",
      "\n",
      "Confusion_matrix\n",
      "[[6855    5]\n",
      " [ 846    1]]\n",
      "done in 1.035073s\n",
      "0.2284294330490572\n",
      "0.24797450007701788\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12989\n",
      "           1       0.25      0.00      0.00      1127\n",
      "\n",
      "    accuracy                           0.92     14116\n",
      "   macro avg       0.59      0.50      0.48     14116\n",
      "weighted avg       0.87      0.92      0.88     14116\n",
      "\n",
      "Confusion_matrix\n",
      "[[12986     3]\n",
      " [ 1126     1]]\n",
      "done in 1.041579s\n",
      "0.22842943304905716\n",
      "0.2482464633697904\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13074\n",
      "           1       0.00      0.00      0.00      1117\n",
      "\n",
      "    accuracy                           0.92     14191\n",
      "   macro avg       0.46      0.50      0.48     14191\n",
      "weighted avg       0.85      0.92      0.88     14191\n",
      "\n",
      "Confusion_matrix\n",
      "[[13066     8]\n",
      " [ 1117     0]]\n",
      "done in 1.058749s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19904\n",
      "           1       0.45      0.02      0.05      1994\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19845    59]\n",
      " [ 1945    49]]\n",
      "done in 57.083186s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19934\n",
      "           1       0.45      0.03      0.06      1964\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19862    72]\n",
      " [ 1906    58]]\n",
      "done in 56.960332s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6915\n",
      "           1       0.46      0.02      0.04       867\n",
      "\n",
      "    accuracy                           0.89      7782\n",
      "   macro avg       0.68      0.51      0.49      7782\n",
      "weighted avg       0.84      0.89      0.84      7782\n",
      "\n",
      "Confusion_matrix\n",
      "[[6893   22]\n",
      " [ 848   19]]\n",
      "done in 56.822453s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6860\n",
      "           1       0.45      0.03      0.05       847\n",
      "\n",
      "    accuracy                           0.89      7707\n",
      "   macro avg       0.67      0.51      0.50      7707\n",
      "weighted avg       0.84      0.89      0.84      7707\n",
      "\n",
      "Confusion_matrix\n",
      "[[6833   27]\n",
      " [ 825   22]]\n",
      "done in 58.514864s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12989\n",
      "           1       0.44      0.03      0.05      1127\n",
      "\n",
      "    accuracy                           0.92     14116\n",
      "   macro avg       0.68      0.51      0.50     14116\n",
      "weighted avg       0.88      0.92      0.89     14116\n",
      "\n",
      "Confusion_matrix\n",
      "[[12951    38]\n",
      " [ 1097    30]]\n",
      "done in 58.072401s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13074\n",
      "           1       0.44      0.03      0.06      1117\n",
      "\n",
      "    accuracy                           0.92     14191\n",
      "   macro avg       0.68      0.51      0.51     14191\n",
      "weighted avg       0.89      0.92      0.89     14191\n",
      "\n",
      "Confusion_matrix\n",
      "[[13029    45]\n",
      " [ 1081    36]]\n",
      "done in 56.598103s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.2, J-value:0.247\n",
      "threshold:0.30000000000000004, J-value:0.145\n",
      "threshold:0.4, J-value:0.079\n",
      "threshold:0.5, J-value:0.036000000000000004\n",
      "threshold:0.6000000000000001, J-value:0.015\n",
      "threshold:0.7000000000000001, J-value:0.005\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6956119312519552\n",
      "Balanced accuracy score of test is  0.6861076889785171\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.356\n",
      "threshold:0.2, J-value:0.22\n",
      "threshold:0.30000000000000004, J-value:0.122\n",
      "threshold:0.4, J-value:0.05500000000000001\n",
      "threshold:0.5, J-value:0.029000000000000005\n",
      "threshold:0.6000000000000001, J-value:0.011\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.677898205345683\n",
      "Balanced accuracy score of test is  0.6792761969014288\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41200000000000003\n",
      "threshold:0.2, J-value:0.267\n",
      "threshold:0.30000000000000004, J-value:0.161\n",
      "threshold:0.4, J-value:0.097\n",
      "threshold:0.5, J-value:0.043000000000000003\n",
      "threshold:0.6000000000000001, J-value:0.017\n",
      "threshold:0.7000000000000001, J-value:0.006\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7062399670241757\n",
      "Balanced accuracy score of test is  0.6876656519893851\n",
      "True positive rate of class 1 is  0.615\n",
      "True positive rate of class 2 is  0.585\n",
      "Positive prediction rate of class 1 is  0.296\n",
      "Positive prediction rate of class 2 is  0.239\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.40099999999999997\n",
      "threshold:0.2, J-value:0.27\n",
      "threshold:0.30000000000000004, J-value:0.097\n",
      "threshold:0.4, J-value:0.015\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7001083132839032\n",
      "Balanced accuracy score of test is  0.6939367836467266\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.389\n",
      "threshold:0.2, J-value:0.247\n",
      "threshold:0.30000000000000004, J-value:0.094\n",
      "threshold:0.4, J-value:0.02\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6945955209951787\n",
      "Balanced accuracy score of test is  0.6792623424812664\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.413\n",
      "threshold:0.2, J-value:0.277\n",
      "threshold:0.30000000000000004, J-value:0.097\n",
      "threshold:0.4, J-value:0.020999999999999998\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7065923913641212\n",
      "Balanced accuracy score of test is  0.6983835830721317\n",
      "True positive rate of class 1 is  0.744\n",
      "True positive rate of class 2 is  0.693\n",
      "Positive prediction rate of class 1 is  0.425\n",
      "Positive prediction rate of class 2 is  0.327\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.37000000000000005\n",
      "threshold:0.2, J-value:0.19\n",
      "threshold:0.30000000000000004, J-value:0.074\n",
      "threshold:0.4, J-value:0.003\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6850007921674992\n",
      "Balanced accuracy score of test is  0.681298539763705\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.34\n",
      "threshold:0.2, J-value:0.15899999999999997\n",
      "threshold:0.30000000000000004, J-value:0.065\n",
      "threshold:0.4, J-value:0.002\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.670216694563496\n",
      "Balanced accuracy score of test is  0.6745277449822904\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.383\n",
      "threshold:0.2, J-value:0.21200000000000002\n",
      "threshold:0.30000000000000004, J-value:0.079\n",
      "threshold:0.4, J-value:0.003\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6917347235935014\n",
      "Balanced accuracy score of test is  0.6807548492302409\n",
      "True positive rate of class 1 is  0.685\n",
      "True positive rate of class 2 is  0.623\n",
      "Positive prediction rate of class 1 is  0.374\n",
      "Positive prediction rate of class 2 is  0.29\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41100000000000003\n",
      "threshold:0.2, J-value:0.258\n",
      "threshold:0.30000000000000004, J-value:0.138\n",
      "threshold:0.4, J-value:0.065\n",
      "threshold:0.5, J-value:0.022000000000000002\n",
      "threshold:0.6000000000000001, J-value:0.002\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.705563031538345\n",
      "Balanced accuracy score of test is  0.692573782688575\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.382\n",
      "threshold:0.2, J-value:0.24100000000000002\n",
      "threshold:0.30000000000000004, J-value:0.119\n",
      "threshold:0.4, J-value:0.053000000000000005\n",
      "threshold:0.5, J-value:0.019\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6909349065643866\n",
      "Balanced accuracy score of test is  0.6909072838108089\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.42700000000000005\n",
      "threshold:0.2, J-value:0.269\n",
      "threshold:0.30000000000000004, J-value:0.15\n",
      "threshold:0.4, J-value:0.07400000000000001\n",
      "threshold:0.5, J-value:0.024\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7133991201209569\n",
      "Balanced accuracy score of test is  0.6897777597914166\n",
      "True positive rate of class 1 is  0.646\n",
      "True positive rate of class 2 is  0.59\n",
      "Positive prediction rate of class 1 is  0.306\n",
      "Positive prediction rate of class 2 is  0.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lifuchen/Desktop/research/CVDPrediction-master/src/lib/fairness_tests.py:80: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train ['Class'] = y_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42313,)\n",
      "(42313,)\n",
      "(84626, 87)\n",
      "X train 84626\n",
      "Y train 84626\n",
      "21898 7665 14233\n",
      "21898 7665 14233\n",
      "21898 7807 14091\n",
      "21898 7807 14091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22581283357700208\n",
      "0.2572241086660482\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95     19980\n",
      "           1       0.44      0.04      0.08      1918\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.52      0.51     21898\n",
      "weighted avg       0.87      0.91      0.88     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19879   101]\n",
      " [ 1839    79]]\n",
      "done in 1.532880s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22581283357700208\n",
      "0.2591716541495177\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95     19972\n",
      "           1       0.43      0.04      0.08      1926\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.52      0.52     21898\n",
      "weighted avg       0.87      0.91      0.88     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19860   112]\n",
      " [ 1841    85]]\n",
      "done in 1.355661s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22581283357700208\n",
      "0.2990654332922628\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.94      6836\n",
      "           1       0.50      0.04      0.08       829\n",
      "\n",
      "    accuracy                           0.89      7665\n",
      "   macro avg       0.70      0.52      0.51      7665\n",
      "weighted avg       0.85      0.89      0.85      7665\n",
      "\n",
      "Confusion_matrix\n",
      "[[6802   34]\n",
      " [ 795   34]]\n",
      "done in 1.510953s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22581283357700208\n",
      "0.2999640964916277\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94      6982\n",
      "           1       0.38      0.04      0.07       825\n",
      "\n",
      "    accuracy                           0.89      7807\n",
      "   macro avg       0.64      0.51      0.50      7807\n",
      "weighted avg       0.84      0.89      0.85      7807\n",
      "\n",
      "Confusion_matrix\n",
      "[[6933   49]\n",
      " [ 795   30]]\n",
      "done in 1.478998s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22581283357700208\n",
      "0.23469099876230798\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96     13144\n",
      "           1       0.40      0.04      0.07      1089\n",
      "\n",
      "    accuracy                           0.92     14233\n",
      "   macro avg       0.66      0.52      0.52     14233\n",
      "weighted avg       0.89      0.92      0.89     14233\n",
      "\n",
      "Confusion_matrix\n",
      "[[13077    67]\n",
      " [ 1044    45]]\n",
      "done in 1.330779s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22581283357700208\n",
      "0.23657094466368606\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96     12990\n",
      "           1       0.47      0.05      0.09      1101\n",
      "\n",
      "    accuracy                           0.92     14091\n",
      "   macro avg       0.70      0.52      0.52     14091\n",
      "weighted avg       0.89      0.92      0.89     14091\n",
      "\n",
      "Confusion_matrix\n",
      "[[12927    63]\n",
      " [ 1046    55]]\n",
      "done in 1.387387s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19980\n",
      "           1       0.00      0.00      0.00      1918\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.46      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19980     0]\n",
      " [ 1918     0]]\n",
      "done in 32.655397s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19972\n",
      "           1       0.43      0.00      0.00      1926\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19968     4]\n",
      " [ 1923     3]]\n",
      "done in 32.591597s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6836\n",
      "           1       1.00      0.00      0.00       829\n",
      "\n",
      "    accuracy                           0.89      7665\n",
      "   macro avg       0.95      0.50      0.47      7665\n",
      "weighted avg       0.90      0.89      0.84      7665\n",
      "\n",
      "Confusion_matrix\n",
      "[[6836    0]\n",
      " [ 827    2]]\n",
      "done in 32.522420s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6982\n",
      "           1       0.33      0.00      0.00       825\n",
      "\n",
      "    accuracy                           0.89      7807\n",
      "   macro avg       0.61      0.50      0.47      7807\n",
      "weighted avg       0.84      0.89      0.84      7807\n",
      "\n",
      "Confusion_matrix\n",
      "[[6980    2]\n",
      " [ 824    1]]\n",
      "done in 31.065872s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13144\n",
      "           1       0.67      0.00      0.00      1089\n",
      "\n",
      "    accuracy                           0.92     14233\n",
      "   macro avg       0.80      0.50      0.48     14233\n",
      "weighted avg       0.90      0.92      0.89     14233\n",
      "\n",
      "Confusion_matrix\n",
      "[[13143     1]\n",
      " [ 1087     2]]\n",
      "done in 30.608070s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12990\n",
      "           1       0.50      0.00      0.00      1101\n",
      "\n",
      "    accuracy                           0.92     14091\n",
      "   macro avg       0.71      0.50      0.48     14091\n",
      "weighted avg       0.89      0.92      0.88     14091\n",
      "\n",
      "Confusion_matrix\n",
      "[[12989     1]\n",
      " [ 1100     1]]\n",
      "done in 30.273402s\n",
      "0.23242383036071274\n",
      "0.2653675727230014\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19980\n",
      "           1       0.38      0.00      0.01      1918\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.65      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19967    13]\n",
      " [ 1910     8]]\n",
      "done in 0.983885s\n",
      "0.23242383036071274\n",
      "0.2673047749160258\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19972\n",
      "           1       0.53      0.01      0.01      1926\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.72      0.50      0.48     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19963     9]\n",
      " [ 1916    10]]\n",
      "done in 0.991933s\n",
      "0.23242383036071274\n",
      "0.30710390099033713\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6836\n",
      "           1       0.43      0.00      0.01       829\n",
      "\n",
      "    accuracy                           0.89      7665\n",
      "   macro avg       0.66      0.50      0.47      7665\n",
      "weighted avg       0.84      0.89      0.84      7665\n",
      "\n",
      "Confusion_matrix\n",
      "[[6832    4]\n",
      " [ 826    3]]\n",
      "done in 0.955067s\n",
      "0.23242383036071274\n",
      "0.30957656376120474\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.94      6982\n",
      "           1       0.54      0.01      0.02       825\n",
      "\n",
      "    accuracy                           0.89      7807\n",
      "   macro avg       0.72      0.50      0.48      7807\n",
      "weighted avg       0.86      0.89      0.85      7807\n",
      "\n",
      "Confusion_matrix\n",
      "[[6976    6]\n",
      " [ 818    7]]\n",
      "done in 0.966626s\n",
      "0.23242383036071274\n",
      "0.2428910072646209\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13144\n",
      "           1       0.36      0.00      0.01      1089\n",
      "\n",
      "    accuracy                           0.92     14233\n",
      "   macro avg       0.64      0.50      0.48     14233\n",
      "weighted avg       0.88      0.92      0.89     14233\n",
      "\n",
      "Confusion_matrix\n",
      "[[13135     9]\n",
      " [ 1084     5]]\n",
      "done in 0.957736s\n",
      "0.23242383036071274\n",
      "0.24388444594616482\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12990\n",
      "           1       0.50      0.00      0.01      1101\n",
      "\n",
      "    accuracy                           0.92     14091\n",
      "   macro avg       0.71      0.50      0.48     14091\n",
      "weighted avg       0.89      0.92      0.88     14091\n",
      "\n",
      "Confusion_matrix\n",
      "[[12987     3]\n",
      " [ 1098     3]]\n",
      "done in 0.969604s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19980\n",
      "           1       0.45      0.02      0.04      1918\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19926    54]\n",
      " [ 1874    44]]\n",
      "done in 53.638658s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19972\n",
      "           1       0.46      0.03      0.06      1926\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.69      0.51      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19905    67]\n",
      " [ 1868    58]]\n",
      "done in 52.340629s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6836\n",
      "           1       0.58      0.03      0.05       829\n",
      "\n",
      "    accuracy                           0.89      7665\n",
      "   macro avg       0.74      0.51      0.50      7665\n",
      "weighted avg       0.86      0.89      0.85      7665\n",
      "\n",
      "Confusion_matrix\n",
      "[[6820   16]\n",
      " [ 807   22]]\n",
      "done in 52.561322s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.94      6982\n",
      "           1       0.38      0.03      0.05       825\n",
      "\n",
      "    accuracy                           0.89      7807\n",
      "   macro avg       0.64      0.51      0.50      7807\n",
      "weighted avg       0.84      0.89      0.85      7807\n",
      "\n",
      "Confusion_matrix\n",
      "[[6948   34]\n",
      " [ 804   21]]\n",
      "done in 52.524243s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13144\n",
      "           1       0.37      0.02      0.04      1089\n",
      "\n",
      "    accuracy                           0.92     14233\n",
      "   macro avg       0.65      0.51      0.50     14233\n",
      "weighted avg       0.88      0.92      0.89     14233\n",
      "\n",
      "Confusion_matrix\n",
      "[[13105    39]\n",
      " [ 1066    23]]\n",
      "done in 52.523663s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12990\n",
      "           1       0.54      0.03      0.06      1101\n",
      "\n",
      "    accuracy                           0.92     14091\n",
      "   macro avg       0.73      0.52      0.51     14091\n",
      "weighted avg       0.89      0.92      0.89     14091\n",
      "\n",
      "Confusion_matrix\n",
      "[[12957    33]\n",
      " [ 1063    38]]\n",
      "done in 53.092473s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.388\n",
      "threshold:0.2, J-value:0.258\n",
      "threshold:0.30000000000000004, J-value:0.144\n",
      "threshold:0.4, J-value:0.074\n",
      "threshold:0.5, J-value:0.036000000000000004\n",
      "threshold:0.6000000000000001, J-value:0.016\n",
      "threshold:0.7000000000000001, J-value:0.006\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6935541902695187\n",
      "Balanced accuracy score of test is  0.6902380622591253\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.384\n",
      "threshold:0.2, J-value:0.27199999999999996\n",
      "threshold:0.30000000000000004, J-value:0.147\n",
      "threshold:0.4, J-value:0.068\n",
      "threshold:0.5, J-value:0.036000000000000004\n",
      "threshold:0.6000000000000001, J-value:0.012\n",
      "threshold:0.7000000000000001, J-value:0.005\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6921754092609833\n",
      "Balanced accuracy score of test is  0.6794108660364747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.382\n",
      "threshold:0.2, J-value:0.244\n",
      "threshold:0.30000000000000004, J-value:0.14\n",
      "threshold:0.4, J-value:0.078\n",
      "threshold:0.5, J-value:0.036000000000000004\n",
      "threshold:0.6000000000000001, J-value:0.018000000000000002\n",
      "threshold:0.7000000000000001, J-value:0.007\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6907993996848918\n",
      "Balanced accuracy score of test is  0.694447416058884\n",
      "True positive rate of class 1 is  0.613\n",
      "True positive rate of class 2 is  0.587\n",
      "Positive prediction rate of class 1 is  0.292\n",
      "Positive prediction rate of class 2 is  0.228\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.38599999999999995\n",
      "threshold:0.2, J-value:0.278\n",
      "threshold:0.30000000000000004, J-value:0.096\n",
      "threshold:0.4, J-value:0.018000000000000002\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6932748441872529\n",
      "Balanced accuracy score of test is  0.7028254145627346\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.383\n",
      "threshold:0.2, J-value:0.297\n",
      "threshold:0.30000000000000004, J-value:0.10800000000000001\n",
      "threshold:0.4, J-value:0.018\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6911767404664584\n",
      "Balanced accuracy score of test is  0.6784472626580905\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.39599999999999996\n",
      "threshold:0.2, J-value:0.265\n",
      "threshold:0.30000000000000004, J-value:0.09\n",
      "threshold:0.4, J-value:0.017\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6981881351555728\n",
      "Balanced accuracy score of test is  0.7010833107840237\n",
      "True positive rate of class 1 is  0.743\n",
      "True positive rate of class 2 is  0.698\n",
      "Positive prediction rate of class 1 is  0.424\n",
      "Positive prediction rate of class 2 is  0.327\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.37400000000000005\n",
      "threshold:0.2, J-value:0.162\n",
      "threshold:0.30000000000000004, J-value:0.11299999999999999\n",
      "threshold:0.4, J-value:0.003\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.003\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.001\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6870028266013668\n",
      "Balanced accuracy score of test is  0.6803097285316786\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.36999999999999994\n",
      "threshold:0.2, J-value:0.18000000000000002\n",
      "threshold:0.30000000000000004, J-value:0.134\n",
      "threshold:0.4, J-value:0.003\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.004\n",
      "threshold:0.7000000000000001, J-value:0.004\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6848294278286882\n",
      "Balanced accuracy score of test is  0.672122514170638\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.368\n",
      "threshold:0.2, J-value:0.14600000000000002\n",
      "threshold:0.30000000000000004, J-value:0.096\n",
      "threshold:0.4, J-value:0.004\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.003\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.001\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6837345820289991\n",
      "Balanced accuracy score of test is  0.6816121392897072\n",
      "True positive rate of class 1 is  0.672\n",
      "True positive rate of class 2 is  0.62\n",
      "Positive prediction rate of class 1 is  0.364\n",
      "Positive prediction rate of class 2 is  0.286\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.397\n",
      "threshold:0.2, J-value:0.259\n",
      "threshold:0.30000000000000004, J-value:0.134\n",
      "threshold:0.4, J-value:0.06099999999999999\n",
      "threshold:0.5, J-value:0.02\n",
      "threshold:0.6000000000000001, J-value:0.006\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6982446993395899\n",
      "Balanced accuracy score of test is  0.6939602255202975\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.389\n",
      "threshold:0.2, J-value:0.26599999999999996\n",
      "threshold:0.30000000000000004, J-value:0.133\n",
      "threshold:0.4, J-value:0.069\n",
      "threshold:0.5, J-value:0.025\n",
      "threshold:0.6000000000000001, J-value:0.009000000000000001\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6944225243354384\n",
      "Balanced accuracy score of test is  0.6796814319071551\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.396\n",
      "threshold:0.2, J-value:0.25\n",
      "threshold:0.30000000000000004, J-value:0.134\n",
      "threshold:0.4, J-value:0.055\n",
      "threshold:0.5, J-value:0.018000000000000002\n",
      "threshold:0.6000000000000001, J-value:0.005\n",
      "threshold:0.7000000000000001, J-value:0.003\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6980686352262737\n",
      "Balanced accuracy score of test is  0.7013276823714742\n",
      "True positive rate of class 1 is  0.621\n",
      "True positive rate of class 2 is  0.615\n",
      "Positive prediction rate of class 1 is  0.299\n",
      "Positive prediction rate of class 2 is  0.244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lifuchen/Desktop/research/CVDPrediction-master/src/lib/fairness_tests.py:80: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train ['Class'] = y_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42324,)\n",
      "(42324,)\n",
      "(84648, 87)\n",
      "X train 84648\n",
      "Y train 84648\n",
      "21898 7743 14155\n",
      "21898 7743 14155\n",
      "21898 7740 14158\n",
      "21898 7740 14158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22053863054648368\n",
      "0.26206629481981736\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19950\n",
      "           1       0.45      0.04      0.08      1948\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.52      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19854    96]\n",
      " [ 1868    80]]\n",
      "done in 1.225274s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22053863054648368\n",
      "0.2644811273085288\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19883\n",
      "           1       0.44      0.03      0.06      2015\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19796    87]\n",
      " [ 1947    68]]\n",
      "done in 1.208018s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22053863054648368\n",
      "0.3057689067564908\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6895\n",
      "           1       0.43      0.03      0.06       848\n",
      "\n",
      "    accuracy                           0.89      7743\n",
      "   macro avg       0.66      0.51      0.50      7743\n",
      "weighted avg       0.84      0.89      0.84      7743\n",
      "\n",
      "Confusion_matrix\n",
      "[[6861   34]\n",
      " [ 822   26]]\n",
      "done in 1.125408s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22053863054648368\n",
      "0.3101154489041229\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94      6860\n",
      "           1       0.41      0.03      0.05       880\n",
      "\n",
      "    accuracy                           0.88      7740\n",
      "   macro avg       0.65      0.51      0.49      7740\n",
      "weighted avg       0.83      0.88      0.84      7740\n",
      "\n",
      "Confusion_matrix\n",
      "[[6825   35]\n",
      " [ 856   24]]\n",
      "done in 1.203740s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22053863054648368\n",
      "0.2381603022923949\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96     13055\n",
      "           1       0.47      0.05      0.09      1100\n",
      "\n",
      "    accuracy                           0.92     14155\n",
      "   macro avg       0.70      0.52      0.52     14155\n",
      "weighted avg       0.89      0.92      0.89     14155\n",
      "\n",
      "Confusion_matrix\n",
      "[[12993    62]\n",
      " [ 1046    54]]\n",
      "done in 1.216715s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22053863054648368\n",
      "0.23953341935896688\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13023\n",
      "           1       0.46      0.04      0.07      1135\n",
      "\n",
      "    accuracy                           0.92     14158\n",
      "   macro avg       0.69      0.52      0.51     14158\n",
      "weighted avg       0.89      0.92      0.89     14158\n",
      "\n",
      "Confusion_matrix\n",
      "[[12971    52]\n",
      " [ 1091    44]]\n",
      "done in 1.180919s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19950\n",
      "           1       0.33      0.00      0.00      1948\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.62      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19946     4]\n",
      " [ 1946     2]]\n",
      "done in 30.799092s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19883\n",
      "           1       0.60      0.00      0.00      2015\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.75      0.50      0.48     21898\n",
      "weighted avg       0.88      0.91      0.86     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19881     2]\n",
      " [ 2012     3]]\n",
      "done in 30.332362s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6895\n",
      "           1       0.25      0.00      0.00       848\n",
      "\n",
      "    accuracy                           0.89      7743\n",
      "   macro avg       0.57      0.50      0.47      7743\n",
      "weighted avg       0.82      0.89      0.84      7743\n",
      "\n",
      "Confusion_matrix\n",
      "[[6892    3]\n",
      " [ 847    1]]\n",
      "done in 29.452680s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6860\n",
      "           1       0.50      0.00      0.00       880\n",
      "\n",
      "    accuracy                           0.89      7740\n",
      "   macro avg       0.69      0.50      0.47      7740\n",
      "weighted avg       0.84      0.89      0.83      7740\n",
      "\n",
      "Confusion_matrix\n",
      "[[6858    2]\n",
      " [ 878    2]]\n",
      "done in 29.090009s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13055\n",
      "           1       0.25      0.00      0.00      1100\n",
      "\n",
      "    accuracy                           0.92     14155\n",
      "   macro avg       0.59      0.50      0.48     14155\n",
      "weighted avg       0.87      0.92      0.89     14155\n",
      "\n",
      "Confusion_matrix\n",
      "[[13052     3]\n",
      " [ 1099     1]]\n",
      "done in 29.341378s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13023\n",
      "           1       0.67      0.00      0.00      1135\n",
      "\n",
      "    accuracy                           0.92     14158\n",
      "   macro avg       0.79      0.50      0.48     14158\n",
      "weighted avg       0.90      0.92      0.88     14158\n",
      "\n",
      "Confusion_matrix\n",
      "[[13022     1]\n",
      " [ 1133     2]]\n",
      "done in 29.184032s\n",
      "0.2263839444849166\n",
      "0.27240418117277\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19950\n",
      "           1       0.25      0.00      0.00      1948\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.58      0.50      0.48     21898\n",
      "weighted avg       0.85      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19941     9]\n",
      " [ 1945     3]]\n",
      "done in 0.962753s\n",
      "0.2263839444849166\n",
      "0.2793385480279257\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19883\n",
      "           1       0.12      0.00      0.00      2015\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.51      0.50      0.48     21898\n",
      "weighted avg       0.84      0.91      0.86     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19868    15]\n",
      " [ 2013     2]]\n",
      "done in 0.984254s\n",
      "0.2263839444849166\n",
      "0.31402948908659406\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6895\n",
      "           1       0.00      0.00      0.00       848\n",
      "\n",
      "    accuracy                           0.89      7743\n",
      "   macro avg       0.45      0.50      0.47      7743\n",
      "weighted avg       0.79      0.89      0.84      7743\n",
      "\n",
      "Confusion_matrix\n",
      "[[6894    1]\n",
      " [ 848    0]]\n",
      "done in 0.944928s\n",
      "0.2263839444849166\n",
      "0.33779030573288915\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6860\n",
      "           1       0.00      0.00      0.00       880\n",
      "\n",
      "    accuracy                           0.89      7740\n",
      "   macro avg       0.44      0.50      0.47      7740\n",
      "weighted avg       0.79      0.89      0.83      7740\n",
      "\n",
      "Confusion_matrix\n",
      "[[6852    8]\n",
      " [ 880    0]]\n",
      "done in 0.939258s\n",
      "0.2263839444849166\n",
      "0.2496345054979738\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13055\n",
      "           1       0.27      0.00      0.01      1100\n",
      "\n",
      "    accuracy                           0.92     14155\n",
      "   macro avg       0.60      0.50      0.48     14155\n",
      "weighted avg       0.87      0.92      0.89     14155\n",
      "\n",
      "Confusion_matrix\n",
      "[[13047     8]\n",
      " [ 1097     3]]\n",
      "done in 0.959282s\n",
      "0.2263839444849166\n",
      "0.24979459454935427\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13023\n",
      "           1       0.20      0.00      0.00      1135\n",
      "\n",
      "    accuracy                           0.92     14158\n",
      "   macro avg       0.56      0.50      0.48     14158\n",
      "weighted avg       0.86      0.92      0.88     14158\n",
      "\n",
      "Confusion_matrix\n",
      "[[13015     8]\n",
      " [ 1133     2]]\n",
      "done in 0.947171s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19950\n",
      "           1       0.45      0.03      0.05      1948\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19891    59]\n",
      " [ 1899    49]]\n",
      "done in 52.049820s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19883\n",
      "           1       0.47      0.02      0.04      2015\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.69      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19832    51]\n",
      " [ 1970    45]]\n",
      "done in 51.388316s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6895\n",
      "           1       0.41      0.02      0.03       848\n",
      "\n",
      "    accuracy                           0.89      7743\n",
      "   macro avg       0.65      0.51      0.49      7743\n",
      "weighted avg       0.84      0.89      0.84      7743\n",
      "\n",
      "Confusion_matrix\n",
      "[[6876   19]\n",
      " [ 835   13]]\n",
      "done in 53.606575s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6860\n",
      "           1       0.43      0.02      0.03       880\n",
      "\n",
      "    accuracy                           0.89      7740\n",
      "   macro avg       0.66      0.51      0.49      7740\n",
      "weighted avg       0.84      0.89      0.84      7740\n",
      "\n",
      "Confusion_matrix\n",
      "[[6839   21]\n",
      " [ 864   16]]\n",
      "done in 53.381835s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13055\n",
      "           1       0.48      0.03      0.06      1100\n",
      "\n",
      "    accuracy                           0.92     14155\n",
      "   macro avg       0.70      0.51      0.51     14155\n",
      "weighted avg       0.89      0.92      0.89     14155\n",
      "\n",
      "Confusion_matrix\n",
      "[[13016    39]\n",
      " [ 1064    36]]\n",
      "done in 51.903447s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13023\n",
      "           1       0.49      0.03      0.05      1135\n",
      "\n",
      "    accuracy                           0.92     14158\n",
      "   macro avg       0.71      0.51      0.50     14158\n",
      "weighted avg       0.89      0.92      0.89     14158\n",
      "\n",
      "Confusion_matrix\n",
      "[[12993    30]\n",
      " [ 1106    29]]\n",
      "done in 52.109399s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.2, J-value:0.236\n",
      "threshold:0.30000000000000004, J-value:0.134\n",
      "threshold:0.4, J-value:0.078\n",
      "threshold:0.5, J-value:0.036000000000000004\n",
      "threshold:0.6000000000000001, J-value:0.016\n",
      "threshold:0.7000000000000001, J-value:0.003\n",
      "threshold:0.8, J-value:0.002\n",
      "threshold:0.9, J-value:0.001\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6890955314363938\n",
      "Balanced accuracy score of test is  0.694975669702499\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.373\n",
      "threshold:0.2, J-value:0.23099999999999998\n",
      "threshold:0.30000000000000004, J-value:0.11399999999999999\n",
      "threshold:0.4, J-value:0.068\n",
      "threshold:0.5, J-value:0.026\n",
      "threshold:0.6000000000000001, J-value:0.012\n",
      "threshold:0.7000000000000001, J-value:0.005\n",
      "threshold:0.8, J-value:0.004\n",
      "threshold:0.9, J-value:0.001\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6865262461176407\n",
      "Balanced accuracy score of test is  0.6929979459316193\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.37599999999999995\n",
      "threshold:0.2, J-value:0.237\n",
      "threshold:0.30000000000000004, J-value:0.148\n",
      "threshold:0.4, J-value:0.085\n",
      "threshold:0.5, J-value:0.044000000000000004\n",
      "threshold:0.6000000000000001, J-value:0.019999999999999997\n",
      "threshold:0.7000000000000001, J-value:0.003\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6879086730963406\n",
      "Balanced accuracy score of test is  0.6940840011622947\n",
      "True positive rate of class 1 is  0.617\n",
      "True positive rate of class 2 is  0.589\n",
      "Positive prediction rate of class 1 is  0.275\n",
      "Positive prediction rate of class 2 is  0.232\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.37899999999999995\n",
      "threshold:0.2, J-value:0.258\n",
      "threshold:0.30000000000000004, J-value:0.09\n",
      "threshold:0.4, J-value:0.02\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6893758523619109\n",
      "Balanced accuracy score of test is  0.7006839015685932\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.33799999999999997\n",
      "threshold:0.2, J-value:0.254\n",
      "threshold:0.30000000000000004, J-value:0.068\n",
      "threshold:0.4, J-value:0.016\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.668755986016665\n",
      "Balanced accuracy score of test is  0.6898588656241718\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.39899999999999997\n",
      "threshold:0.2, J-value:0.251\n",
      "threshold:0.30000000000000004, J-value:0.089\n",
      "threshold:0.4, J-value:0.02\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6992935482747815\n",
      "Balanced accuracy score of test is  0.7036274689882793\n",
      "True positive rate of class 1 is  0.734\n",
      "True positive rate of class 2 is  0.706\n",
      "Positive prediction rate of class 1 is  0.398\n",
      "Positive prediction rate of class 2 is  0.331\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.36800000000000005\n",
      "threshold:0.2, J-value:0.195\n",
      "threshold:0.30000000000000004, J-value:0.05500000000000001\n",
      "threshold:0.4, J-value:0.053000000000000005\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6843271165593656\n",
      "Balanced accuracy score of test is  0.6894988536536755\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.349\n",
      "threshold:0.2, J-value:0.187\n",
      "threshold:0.30000000000000004, J-value:0.073\n",
      "threshold:0.4, J-value:0.06999999999999999\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6746772681872288\n",
      "Balanced accuracy score of test is  0.6894099522926054\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.37200000000000005\n",
      "threshold:0.2, J-value:0.201\n",
      "threshold:0.30000000000000004, J-value:0.04\n",
      "threshold:0.4, J-value:0.039\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6860654225131437\n",
      "Balanced accuracy score of test is  0.6849452730360822\n",
      "True positive rate of class 1 is  0.724\n",
      "True positive rate of class 2 is  0.658\n",
      "Positive prediction rate of class 1 is  0.388\n",
      "Positive prediction rate of class 2 is  0.318\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.392\n",
      "threshold:0.2, J-value:0.241\n",
      "threshold:0.30000000000000004, J-value:0.129\n",
      "threshold:0.4, J-value:0.053\n",
      "threshold:0.5, J-value:0.022000000000000002\n",
      "threshold:0.6000000000000001, J-value:0.007\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.695744777755477\n",
      "Balanced accuracy score of test is  0.7001250990752478\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.383\n",
      "threshold:0.2, J-value:0.241\n",
      "threshold:0.30000000000000004, J-value:0.125\n",
      "threshold:0.4, J-value:0.043\n",
      "threshold:0.5, J-value:0.012\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6917197141762557\n",
      "Balanced accuracy score of test is  0.7005118605883912\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.391\n",
      "threshold:0.2, J-value:0.24\n",
      "threshold:0.30000000000000004, J-value:0.131\n",
      "threshold:0.4, J-value:0.06099999999999999\n",
      "threshold:0.5, J-value:0.030000000000000002\n",
      "threshold:0.6000000000000001, J-value:0.009999999999999998\n",
      "threshold:0.7000000000000001, J-value:0.004\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6956418648375753\n",
      "Balanced accuracy score of test is  0.6974972777745643\n",
      "True positive rate of class 1 is  0.644\n",
      "True positive rate of class 2 is  0.61\n",
      "Positive prediction rate of class 1 is  0.289\n",
      "Positive prediction rate of class 2 is  0.246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lifuchen/Desktop/research/CVDPrediction-master/src/lib/fairness_tests.py:80: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train ['Class'] = y_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42349,)\n",
      "(42349,)\n",
      "(84698, 87)\n",
      "X train 84698\n",
      "Y train 84698\n",
      "21898 7751 14147\n",
      "21898 7751 14147\n",
      "21898 7757 14141\n",
      "21898 7757 14141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2207824604336073\n",
      "0.26491106787296925\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95     19908\n",
      "           1       0.44      0.05      0.08      1990\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.52      0.52     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19791   117]\n",
      " [ 1897    93]]\n",
      "done in 1.204686s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2207824604336073\n",
      "0.2626098478270835\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95     19918\n",
      "           1       0.43      0.04      0.07      1980\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.52      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19815   103]\n",
      " [ 1903    77]]\n",
      "done in 1.188530s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2207824604336073\n",
      "0.3047846436004839\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94      6908\n",
      "           1       0.46      0.04      0.08       843\n",
      "\n",
      "    accuracy                           0.89      7751\n",
      "   macro avg       0.68      0.52      0.51      7751\n",
      "weighted avg       0.85      0.89      0.85      7751\n",
      "\n",
      "Confusion_matrix\n",
      "[[6867   41]\n",
      " [ 808   35]]\n",
      "done in 1.210085s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2207824604336073\n",
      "0.3059661172941642\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94      6894\n",
      "           1       0.41      0.04      0.07       863\n",
      "\n",
      "    accuracy                           0.89      7757\n",
      "   macro avg       0.65      0.52      0.50      7757\n",
      "weighted avg       0.84      0.89      0.84      7757\n",
      "\n",
      "Confusion_matrix\n",
      "[[6847   47]\n",
      " [ 831   32]]\n",
      "done in 1.435024s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2207824604336073\n",
      "0.24306473398847317\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96     13000\n",
      "           1       0.43      0.05      0.09      1147\n",
      "\n",
      "    accuracy                           0.92     14147\n",
      "   macro avg       0.68      0.52      0.52     14147\n",
      "weighted avg       0.88      0.92      0.89     14147\n",
      "\n",
      "Confusion_matrix\n",
      "[[12924    76]\n",
      " [ 1089    58]]\n",
      "done in 1.213690s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2207824604336073\n",
      "0.23882690586709868\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13024\n",
      "           1       0.45      0.04      0.07      1117\n",
      "\n",
      "    accuracy                           0.92     14141\n",
      "   macro avg       0.68      0.52      0.52     14141\n",
      "weighted avg       0.89      0.92      0.89     14141\n",
      "\n",
      "Confusion_matrix\n",
      "[[12968    56]\n",
      " [ 1072    45]]\n",
      "done in 1.264318s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19908\n",
      "           1       0.50      0.00      0.01      1990\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.70      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19903     5]\n",
      " [ 1985     5]]\n",
      "done in 29.751810s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19918\n",
      "           1       0.62      0.00      0.01      1980\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.77      0.50      0.48     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19915     3]\n",
      " [ 1975     5]]\n",
      "done in 29.670292s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6908\n",
      "           1       0.33      0.00      0.00       843\n",
      "\n",
      "    accuracy                           0.89      7751\n",
      "   macro avg       0.61      0.50      0.47      7751\n",
      "weighted avg       0.83      0.89      0.84      7751\n",
      "\n",
      "Confusion_matrix\n",
      "[[6904    4]\n",
      " [ 841    2]]\n",
      "done in 28.638276s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6894\n",
      "           1       0.33      0.00      0.00       863\n",
      "\n",
      "    accuracy                           0.89      7757\n",
      "   macro avg       0.61      0.50      0.47      7757\n",
      "weighted avg       0.83      0.89      0.84      7757\n",
      "\n",
      "Confusion_matrix\n",
      "[[6892    2]\n",
      " [ 862    1]]\n",
      "done in 30.371457s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13000\n",
      "           1       0.00      0.00      0.00      1147\n",
      "\n",
      "    accuracy                           0.92     14147\n",
      "   macro avg       0.46      0.50      0.48     14147\n",
      "weighted avg       0.84      0.92      0.88     14147\n",
      "\n",
      "Confusion_matrix\n",
      "[[13000     0]\n",
      " [ 1147     0]]\n",
      "done in 30.499396s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13024\n",
      "           1       0.00      0.00      0.00      1117\n",
      "\n",
      "    accuracy                           0.92     14141\n",
      "   macro avg       0.46      0.50      0.48     14141\n",
      "weighted avg       0.85      0.92      0.88     14141\n",
      "\n",
      "Confusion_matrix\n",
      "[[13022     2]\n",
      " [ 1117     0]]\n",
      "done in 30.794988s\n",
      "0.22663646740429388\n",
      "0.2751975243427594\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19908\n",
      "           1       0.00      0.00      0.00      1990\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.45      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19899     9]\n",
      " [ 1990     0]]\n",
      "done in 0.993203s\n",
      "0.22663646740429388\n",
      "0.2715217113472315\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19918\n",
      "           1       0.20      0.00      0.00      1980\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.55      0.50      0.48     21898\n",
      "weighted avg       0.85      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19910     8]\n",
      " [ 1978     2]]\n",
      "done in 0.992597s\n",
      "0.22663646740429388\n",
      "0.31556927929747874\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6908\n",
      "           1       0.00      0.00      0.00       843\n",
      "\n",
      "    accuracy                           0.89      7751\n",
      "   macro avg       0.45      0.50      0.47      7751\n",
      "weighted avg       0.79      0.89      0.84      7751\n",
      "\n",
      "Confusion_matrix\n",
      "[[6902    6]\n",
      " [ 843    0]]\n",
      "done in 0.958172s\n",
      "0.22663646740429388\n",
      "0.3130643386464363\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6894\n",
      "           1       0.00      0.00      0.00       863\n",
      "\n",
      "    accuracy                           0.89      7757\n",
      "   macro avg       0.44      0.50      0.47      7757\n",
      "weighted avg       0.79      0.89      0.84      7757\n",
      "\n",
      "Confusion_matrix\n",
      "[[6889    5]\n",
      " [ 863    0]]\n",
      "done in 0.979788s\n",
      "0.22663646740429388\n",
      "0.2530782430354837\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13000\n",
      "           1       0.00      0.00      0.00      1147\n",
      "\n",
      "    accuracy                           0.92     14147\n",
      "   macro avg       0.46      0.50      0.48     14147\n",
      "weighted avg       0.84      0.92      0.88     14147\n",
      "\n",
      "Confusion_matrix\n",
      "[[12997     3]\n",
      " [ 1147     0]]\n",
      "done in 1.030946s\n",
      "0.22663646740429388\n",
      "0.2487336369564578\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13024\n",
      "           1       0.40      0.00      0.00      1117\n",
      "\n",
      "    accuracy                           0.92     14141\n",
      "   macro avg       0.66      0.50      0.48     14141\n",
      "weighted avg       0.88      0.92      0.88     14141\n",
      "\n",
      "Confusion_matrix\n",
      "[[13021     3]\n",
      " [ 1115     2]]\n",
      "done in 0.996933s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19908\n",
      "           1       0.47      0.03      0.05      1990\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.69      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19849    59]\n",
      " [ 1938    52]]\n",
      "done in 53.171491s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19918\n",
      "           1       0.35      0.02      0.04      1980\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.63      0.51      0.49     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19846    72]\n",
      " [ 1941    39]]\n",
      "done in 52.337248s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6908\n",
      "           1       0.44      0.03      0.05       843\n",
      "\n",
      "    accuracy                           0.89      7751\n",
      "   macro avg       0.66      0.51      0.50      7751\n",
      "weighted avg       0.84      0.89      0.85      7751\n",
      "\n",
      "Confusion_matrix\n",
      "[[6877   31]\n",
      " [ 819   24]]\n",
      "done in 52.062358s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94      6894\n",
      "           1       0.32      0.02      0.04       863\n",
      "\n",
      "    accuracy                           0.89      7757\n",
      "   macro avg       0.61      0.51      0.49      7757\n",
      "weighted avg       0.83      0.89      0.84      7757\n",
      "\n",
      "Confusion_matrix\n",
      "[[6856   38]\n",
      " [ 845   18]]\n",
      "done in 52.350403s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13000\n",
      "           1       0.49      0.02      0.05      1147\n",
      "\n",
      "    accuracy                           0.92     14147\n",
      "   macro avg       0.71      0.51      0.50     14147\n",
      "weighted avg       0.89      0.92      0.88     14147\n",
      "\n",
      "Confusion_matrix\n",
      "[[12971    29]\n",
      " [ 1119    28]]\n",
      "done in 51.597514s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13024\n",
      "           1       0.38      0.02      0.04      1117\n",
      "\n",
      "    accuracy                           0.92     14141\n",
      "   macro avg       0.65      0.51      0.50     14141\n",
      "weighted avg       0.88      0.92      0.89     14141\n",
      "\n",
      "Confusion_matrix\n",
      "[[12990    34]\n",
      " [ 1096    21]]\n",
      "done in 53.446791s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.381\n",
      "threshold:0.2, J-value:0.247\n",
      "threshold:0.30000000000000004, J-value:0.15\n",
      "threshold:0.4, J-value:0.082\n",
      "threshold:0.5, J-value:0.041\n",
      "threshold:0.6000000000000001, J-value:0.020999999999999998\n",
      "threshold:0.7000000000000001, J-value:0.007\n",
      "threshold:0.8, J-value:0.002\n",
      "threshold:0.9, J-value:0.001\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.690369493640596\n",
      "Balanced accuracy score of test is  0.6940892761331561\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.363\n",
      "threshold:0.2, J-value:0.24000000000000002\n",
      "threshold:0.30000000000000004, J-value:0.13699999999999998\n",
      "threshold:0.4, J-value:0.074\n",
      "threshold:0.5, J-value:0.036000000000000004\n",
      "threshold:0.6000000000000001, J-value:0.019000000000000003\n",
      "threshold:0.7000000000000001, J-value:0.007\n",
      "threshold:0.8, J-value:0.004\n",
      "threshold:0.9, J-value:0.002\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6813373666854184\n",
      "Balanced accuracy score of test is  0.6876824726423401\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.38499999999999995\n",
      "threshold:0.2, J-value:0.25\n",
      "threshold:0.30000000000000004, J-value:0.16\n",
      "threshold:0.4, J-value:0.08800000000000001\n",
      "threshold:0.5, J-value:0.045\n",
      "threshold:0.6000000000000001, J-value:0.022\n",
      "threshold:0.7000000000000001, J-value:0.005\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6927199047682919\n",
      "Balanced accuracy score of test is  0.694572027620931\n",
      "True positive rate of class 1 is  0.623\n",
      "True positive rate of class 2 is  0.581\n",
      "Positive prediction rate of class 1 is  0.29\n",
      "Positive prediction rate of class 2 is  0.223\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.37999999999999995\n",
      "threshold:0.2, J-value:0.257\n",
      "threshold:0.30000000000000004, J-value:0.107\n",
      "threshold:0.4, J-value:0.02\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6902391957779656\n",
      "Balanced accuracy score of test is  0.6990684280296691\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.361\n",
      "threshold:0.2, J-value:0.22599999999999998\n",
      "threshold:0.30000000000000004, J-value:0.10200000000000001\n",
      "threshold:0.4, J-value:0.029\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6807489691666992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy score of test is  0.6807151061883627\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.381\n",
      "threshold:0.2, J-value:0.26399999999999996\n",
      "threshold:0.30000000000000004, J-value:0.112\n",
      "threshold:0.4, J-value:0.019000000000000003\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6902477365703172\n",
      "Balanced accuracy score of test is  0.6974359298665476\n",
      "True positive rate of class 1 is  0.73\n",
      "True positive rate of class 2 is  0.677\n",
      "Positive prediction rate of class 1 is  0.409\n",
      "Positive prediction rate of class 2 is  0.313\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.353\n",
      "threshold:0.2, J-value:0.17400000000000002\n",
      "threshold:0.30000000000000004, J-value:0.056999999999999995\n",
      "threshold:0.4, J-value:0.05700000000000001\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.676235406487935\n",
      "Balanced accuracy score of test is  0.6885420121488\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.341\n",
      "threshold:0.2, J-value:0.176\n",
      "threshold:0.30000000000000004, J-value:0.064\n",
      "threshold:0.4, J-value:0.063\n",
      "threshold:0.5, J-value:-0.001\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6707420042160619\n",
      "Balanced accuracy score of test is  0.6851711784576979\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.351\n",
      "threshold:0.2, J-value:0.17\n",
      "threshold:0.30000000000000004, J-value:0.052000000000000005\n",
      "threshold:0.4, J-value:0.052000000000000005\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6756178995372544\n",
      "Balanced accuracy score of test is  0.6860113221180812\n",
      "True positive rate of class 1 is  0.686\n",
      "True positive rate of class 2 is  0.623\n",
      "Positive prediction rate of class 1 is  0.357\n",
      "Positive prediction rate of class 2 is  0.28\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.377\n",
      "threshold:0.2, J-value:0.257\n",
      "threshold:0.30000000000000004, J-value:0.14400000000000002\n",
      "threshold:0.4, J-value:0.066\n",
      "threshold:0.5, J-value:0.023\n",
      "threshold:0.6000000000000001, J-value:0.005\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6882605967349305\n",
      "Balanced accuracy score of test is  0.7044727321411728\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.369\n",
      "threshold:0.2, J-value:0.233\n",
      "threshold:0.30000000000000004, J-value:0.13\n",
      "threshold:0.4, J-value:0.063\n",
      "threshold:0.5, J-value:0.024\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6844879937026955\n",
      "Balanced accuracy score of test is  0.7005661967465622\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.37299999999999994\n",
      "threshold:0.2, J-value:0.27\n",
      "threshold:0.30000000000000004, J-value:0.153\n",
      "threshold:0.4, J-value:0.067\n",
      "threshold:0.5, J-value:0.022\n",
      "threshold:0.6000000000000001, J-value:0.005\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6866941519683455\n",
      "Balanced accuracy score of test is  0.7030100685959012\n",
      "True positive rate of class 1 is  0.659\n",
      "True positive rate of class 2 is  0.608\n",
      "Positive prediction rate of class 1 is  0.303\n",
      "Positive prediction rate of class 2 is  0.234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lifuchen/Desktop/research/CVDPrediction-master/src/lib/fairness_tests.py:80: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train ['Class'] = y_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42442,)\n",
      "(42442,)\n",
      "(84884, 87)\n",
      "X train 84884\n",
      "Y train 84884\n",
      "21898 7842 14056\n",
      "21898 7842 14056\n",
      "21898 7759 14139\n",
      "21898 7759 14139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2250596048620066\n",
      "0.25575970764514344\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95     20006\n",
      "           1       0.41      0.04      0.08      1892\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.66      0.52      0.52     21898\n",
      "weighted avg       0.87      0.91      0.88     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19888   118]\n",
      " [ 1811    81]]\n",
      "done in 1.463729s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2250596048620066\n",
      "0.2569468582573735\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95     19975\n",
      "           1       0.45      0.05      0.08      1923\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.52      0.52     21898\n",
      "weighted avg       0.87      0.91      0.88     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19863   112]\n",
      " [ 1833    90]]\n",
      "done in 1.230935s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2250596048620066\n",
      "0.2921644866287832\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94      7042\n",
      "           1       0.35      0.04      0.07       800\n",
      "\n",
      "    accuracy                           0.89      7842\n",
      "   macro avg       0.62      0.51      0.50      7842\n",
      "weighted avg       0.84      0.89      0.85      7842\n",
      "\n",
      "Confusion_matrix\n",
      "[[6987   55]\n",
      " [ 771   29]]\n",
      "done in 1.232819s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2250596048620066\n",
      "0.29294215778506716\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94      6943\n",
      "           1       0.45      0.04      0.08       816\n",
      "\n",
      "    accuracy                           0.89      7759\n",
      "   macro avg       0.67      0.52      0.51      7759\n",
      "weighted avg       0.85      0.89      0.85      7759\n",
      "\n",
      "Confusion_matrix\n",
      "[[6899   44]\n",
      " [ 780   36]]\n",
      "done in 1.201160s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2250596048620066\n",
      "0.23544907326909745\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96     12964\n",
      "           1       0.45      0.05      0.09      1092\n",
      "\n",
      "    accuracy                           0.92     14056\n",
      "   macro avg       0.69      0.52      0.52     14056\n",
      "weighted avg       0.89      0.92      0.89     14056\n",
      "\n",
      "Confusion_matrix\n",
      "[[12901    63]\n",
      " [ 1040    52]]\n",
      "done in 1.226619s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2250596048620066\n",
      "0.23719386801510933\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96     13032\n",
      "           1       0.44      0.05      0.09      1107\n",
      "\n",
      "    accuracy                           0.92     14139\n",
      "   macro avg       0.68      0.52      0.52     14139\n",
      "weighted avg       0.89      0.92      0.89     14139\n",
      "\n",
      "Confusion_matrix\n",
      "[[12964    68]\n",
      " [ 1053    54]]\n",
      "done in 1.244630s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     20006\n",
      "           1       0.25      0.00      0.00      1892\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.58      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[20003     3]\n",
      " [ 1891     1]]\n",
      "done in 30.340246s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19975\n",
      "           1       0.36      0.00      0.00      1923\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.64      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19968     7]\n",
      " [ 1919     4]]\n",
      "done in 29.545157s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      7042\n",
      "           1       1.00      0.00      0.00       800\n",
      "\n",
      "    accuracy                           0.90      7842\n",
      "   macro avg       0.95      0.50      0.47      7842\n",
      "weighted avg       0.91      0.90      0.85      7842\n",
      "\n",
      "Confusion_matrix\n",
      "[[7042    0]\n",
      " [ 799    1]]\n",
      "done in 29.299031s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6943\n",
      "           1       0.20      0.00      0.00       816\n",
      "\n",
      "    accuracy                           0.89      7759\n",
      "   macro avg       0.55      0.50      0.47      7759\n",
      "weighted avg       0.82      0.89      0.85      7759\n",
      "\n",
      "Confusion_matrix\n",
      "[[6939    4]\n",
      " [ 815    1]]\n",
      "done in 29.156783s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12964\n",
      "           1       0.50      0.00      0.01      1092\n",
      "\n",
      "    accuracy                           0.92     14056\n",
      "   macro avg       0.71      0.50      0.48     14056\n",
      "weighted avg       0.89      0.92      0.89     14056\n",
      "\n",
      "Confusion_matrix\n",
      "[[12960     4]\n",
      " [ 1088     4]]\n",
      "done in 29.532232s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13032\n",
      "           1       0.50      0.00      0.01      1107\n",
      "\n",
      "    accuracy                           0.92     14139\n",
      "   macro avg       0.71      0.50      0.48     14139\n",
      "weighted avg       0.89      0.92      0.88     14139\n",
      "\n",
      "Confusion_matrix\n",
      "[[13029     3]\n",
      " [ 1104     3]]\n",
      "done in 29.422688s\n",
      "0.23108132220167238\n",
      "0.2636663595512073\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     20006\n",
      "           1       0.00      0.00      0.00      1892\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.46      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[20006     0]\n",
      " [ 1892     0]]\n",
      "done in 0.960805s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23108132220167238\n",
      "0.26645281773241813\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19975\n",
      "           1       0.00      0.00      0.00      1923\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.46      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19975     0]\n",
      " [ 1923     0]]\n",
      "done in 0.967485s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23108132220167238\n",
      "0.30108348007067604\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      7042\n",
      "           1       0.00      0.00      0.00       800\n",
      "\n",
      "    accuracy                           0.90      7842\n",
      "   macro avg       0.45      0.50      0.47      7842\n",
      "weighted avg       0.81      0.90      0.85      7842\n",
      "\n",
      "Confusion_matrix\n",
      "[[7042    0]\n",
      " [ 800    0]]\n",
      "done in 0.948105s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23108132220167238\n",
      "0.30541682862944664\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6943\n",
      "           1       0.00      0.00      0.00       816\n",
      "\n",
      "    accuracy                           0.89      7759\n",
      "   macro avg       0.45      0.50      0.47      7759\n",
      "weighted avg       0.80      0.89      0.85      7759\n",
      "\n",
      "Confusion_matrix\n",
      "[[6943    0]\n",
      " [ 816    0]]\n",
      "done in 0.915743s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23108132220167238\n",
      "0.24279092848165174\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12964\n",
      "           1       0.00      0.00      0.00      1092\n",
      "\n",
      "    accuracy                           0.92     14056\n",
      "   macro avg       0.46      0.50      0.48     14056\n",
      "weighted avg       0.85      0.92      0.89     14056\n",
      "\n",
      "Confusion_matrix\n",
      "[[12964     0]\n",
      " [ 1092     0]]\n",
      "done in 0.952909s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23108132220167238\n",
      "0.24507070014630566\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13032\n",
      "           1       0.00      0.00      0.00      1107\n",
      "\n",
      "    accuracy                           0.92     14139\n",
      "   macro avg       0.46      0.50      0.48     14139\n",
      "weighted avg       0.85      0.92      0.88     14139\n",
      "\n",
      "Confusion_matrix\n",
      "[[13032     0]\n",
      " [ 1107     0]]\n",
      "done in 0.960812s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.95     20006\n",
      "           1       0.47      0.03      0.05      1892\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.69      0.51      0.50     21898\n",
      "weighted avg       0.88      0.91      0.88     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19944    62]\n",
      " [ 1838    54]]\n",
      "done in 52.086796s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19975\n",
      "           1       0.52      0.03      0.06      1923\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.72      0.52      0.51     21898\n",
      "weighted avg       0.88      0.91      0.88     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19915    60]\n",
      " [ 1857    66]]\n",
      "done in 52.447894s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      7042\n",
      "           1       0.36      0.03      0.05       800\n",
      "\n",
      "    accuracy                           0.90      7842\n",
      "   macro avg       0.63      0.51      0.50      7842\n",
      "weighted avg       0.85      0.90      0.85      7842\n",
      "\n",
      "Confusion_matrix\n",
      "[[7007   35]\n",
      " [ 780   20]]\n",
      "done in 54.402825s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.94      6943\n",
      "           1       0.53      0.04      0.07       816\n",
      "\n",
      "    accuracy                           0.90      7759\n",
      "   macro avg       0.71      0.52      0.51      7759\n",
      "weighted avg       0.86      0.90      0.85      7759\n",
      "\n",
      "Confusion_matrix\n",
      "[[6917   26]\n",
      " [ 787   29]]\n",
      "done in 53.321487s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12964\n",
      "           1       0.54      0.03      0.06      1092\n",
      "\n",
      "    accuracy                           0.92     14056\n",
      "   macro avg       0.73      0.51      0.51     14056\n",
      "weighted avg       0.89      0.92      0.89     14056\n",
      "\n",
      "Confusion_matrix\n",
      "[[12936    28]\n",
      " [ 1059    33]]\n",
      "done in 52.729096s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13032\n",
      "           1       0.53      0.03      0.06      1107\n",
      "\n",
      "    accuracy                           0.92     14139\n",
      "   macro avg       0.73      0.52      0.51     14139\n",
      "weighted avg       0.89      0.92      0.89     14139\n",
      "\n",
      "Confusion_matrix\n",
      "[[12998    34]\n",
      " [ 1069    38]]\n",
      "done in 52.664230s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.386\n",
      "threshold:0.2, J-value:0.246\n",
      "threshold:0.30000000000000004, J-value:0.145\n",
      "threshold:0.4, J-value:0.075\n",
      "threshold:0.5, J-value:0.037\n",
      "threshold:0.6000000000000001, J-value:0.015000000000000001\n",
      "threshold:0.7000000000000001, J-value:0.003\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6932092148254044\n",
      "Balanced accuracy score of test is  0.696422712477961\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.362\n",
      "threshold:0.2, J-value:0.23600000000000002\n",
      "threshold:0.30000000000000004, J-value:0.128\n",
      "threshold:0.4, J-value:0.065\n",
      "threshold:0.5, J-value:0.027999999999999997\n",
      "threshold:0.6000000000000001, J-value:0.012\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6812443197955127\n",
      "Balanced accuracy score of test is  0.6942575820476542\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.397\n",
      "threshold:0.2, J-value:0.251\n",
      "threshold:0.30000000000000004, J-value:0.156\n",
      "threshold:0.4, J-value:0.083\n",
      "threshold:0.5, J-value:0.043000000000000003\n",
      "threshold:0.6000000000000001, J-value:0.017\n",
      "threshold:0.7000000000000001, J-value:0.004\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6987189376498232\n",
      "Balanced accuracy score of test is  0.6954273283524732\n",
      "True positive rate of class 1 is  0.637\n",
      "True positive rate of class 2 is  0.601\n",
      "Positive prediction rate of class 1 is  0.29\n",
      "Positive prediction rate of class 2 is  0.24\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.39099999999999996\n",
      "threshold:0.2, J-value:0.27\n",
      "threshold:0.30000000000000004, J-value:0.098\n",
      "threshold:0.4, J-value:0.019\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6954924093596445\n",
      "Balanced accuracy score of test is  0.6910537417742016\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.371\n",
      "threshold:0.2, J-value:0.28099999999999997\n",
      "threshold:0.30000000000000004, J-value:0.101\n",
      "threshold:0.4, J-value:0.026\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6851531880147685\n",
      "Balanced accuracy score of test is  0.6982106395777381\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.39999999999999997\n",
      "threshold:0.2, J-value:0.24900000000000003\n",
      "threshold:0.30000000000000004, J-value:0.09899999999999999\n",
      "threshold:0.4, J-value:0.022\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7003269408776969\n",
      "Balanced accuracy score of test is  0.6909318275963607\n",
      "True positive rate of class 1 is  0.765\n",
      "True positive rate of class 2 is  0.685\n",
      "Positive prediction rate of class 1 is  0.41\n",
      "Positive prediction rate of class 2 is  0.333\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.32\n",
      "threshold:0.2, J-value:0.185\n",
      "threshold:0.30000000000000004, J-value:0.067\n",
      "threshold:0.4, J-value:0.048\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.659790408543399\n",
      "Balanced accuracy score of test is  0.6662725312516882\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.30100000000000005\n",
      "threshold:0.2, J-value:0.17099999999999999\n",
      "threshold:0.30000000000000004, J-value:0.071\n",
      "threshold:0.4, J-value:0.051000000000000004\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6502765549559784\n",
      "Balanced accuracy score of test is  0.661852871279579\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.325\n",
      "threshold:0.2, J-value:0.192\n",
      "threshold:0.30000000000000004, J-value:0.064\n",
      "threshold:0.4, J-value:0.044\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6625121638620559\n",
      "Balanced accuracy score of test is  0.6653419100949758\n",
      "True positive rate of class 1 is  0.57\n",
      "True positive rate of class 2 is  0.514\n",
      "Positive prediction rate of class 1 is  0.28\n",
      "Positive prediction rate of class 2 is  0.209\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.395\n",
      "threshold:0.2, J-value:0.246\n",
      "threshold:0.30000000000000004, J-value:0.143\n",
      "threshold:0.4, J-value:0.07100000000000001\n",
      "threshold:0.5, J-value:0.026000000000000002\n",
      "threshold:0.6000000000000001, J-value:0.004\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.697152429324057\n",
      "Balanced accuracy score of test is  0.7013275174311102\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.386\n",
      "threshold:0.2, J-value:0.234\n",
      "threshold:0.30000000000000004, J-value:0.129\n",
      "threshold:0.4, J-value:0.065\n",
      "threshold:0.5, J-value:0.02\n",
      "threshold:0.6000000000000001, J-value:0.005\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6930912737858563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy score of test is  0.6924267600602102\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.394\n",
      "threshold:0.2, J-value:0.252\n",
      "threshold:0.30000000000000004, J-value:0.152\n",
      "threshold:0.4, J-value:0.07400000000000001\n",
      "threshold:0.5, J-value:0.027999999999999997\n",
      "threshold:0.6000000000000001, J-value:0.005\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6970842332613391\n",
      "Balanced accuracy score of test is  0.7047065509789536\n",
      "True positive rate of class 1 is  0.648\n",
      "True positive rate of class 2 is  0.625\n",
      "Positive prediction rate of class 1 is  0.304\n",
      "Positive prediction rate of class 2 is  0.248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lifuchen/Desktop/research/CVDPrediction-master/src/lib/fairness_tests.py:80: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train ['Class'] = y_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42433,)\n",
      "(42433,)\n",
      "(84866, 87)\n",
      "X train 84866\n",
      "Y train 84866\n",
      "21898 7814 14084\n",
      "21898 7814 14084\n",
      "21898 7778 14120\n",
      "21898 7778 14120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22128246618229305\n",
      "0.26512694483201255\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95     19911\n",
      "           1       0.43      0.04      0.08      1987\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.52      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19801   110]\n",
      " [ 1903    84]]\n",
      "done in 1.534288s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22128246618229305\n",
      "0.26242689227579763\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19927\n",
      "           1       0.44      0.04      0.07      1971\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.52      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19838    89]\n",
      " [ 1900    71]]\n",
      "done in 1.248901s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22128246618229305\n",
      "0.29967569584515075\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94      6979\n",
      "           1       0.38      0.03      0.06       835\n",
      "\n",
      "    accuracy                           0.89      7814\n",
      "   macro avg       0.64      0.51      0.50      7814\n",
      "weighted avg       0.84      0.89      0.85      7814\n",
      "\n",
      "Confusion_matrix\n",
      "[[6938   41]\n",
      " [ 810   25]]\n",
      "done in 1.231646s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22128246618229305\n",
      "0.3058432954070013\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6927\n",
      "           1       0.48      0.03      0.06       851\n",
      "\n",
      "    accuracy                           0.89      7778\n",
      "   macro avg       0.68      0.51      0.50      7778\n",
      "weighted avg       0.85      0.89      0.85      7778\n",
      "\n",
      "Confusion_matrix\n",
      "[[6895   32]\n",
      " [ 822   29]]\n",
      "done in 1.273875s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22128246618229305\n",
      "0.24595881500975594\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96     12932\n",
      "           1       0.46      0.05      0.09      1152\n",
      "\n",
      "    accuracy                           0.92     14084\n",
      "   macro avg       0.69      0.52      0.52     14084\n",
      "weighted avg       0.88      0.92      0.89     14084\n",
      "\n",
      "Confusion_matrix\n",
      "[[12863    69]\n",
      " [ 1093    59]]\n",
      "done in 1.312732s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22128246618229305\n",
      "0.23851097276060623\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13000\n",
      "           1       0.42      0.04      0.07      1120\n",
      "\n",
      "    accuracy                           0.92     14120\n",
      "   macro avg       0.67      0.52      0.51     14120\n",
      "weighted avg       0.88      0.92      0.89     14120\n",
      "\n",
      "Confusion_matrix\n",
      "[[12943    57]\n",
      " [ 1078    42]]\n",
      "done in 1.231135s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19911\n",
      "           1       0.50      0.00      0.00      1987\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.70      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19908     3]\n",
      " [ 1984     3]]\n",
      "done in 29.825168s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19927\n",
      "           1       0.33      0.00      0.00      1971\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.62      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19923     4]\n",
      " [ 1969     2]]\n",
      "done in 29.095496s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6979\n",
      "           1       0.33      0.00      0.00       835\n",
      "\n",
      "    accuracy                           0.89      7814\n",
      "   macro avg       0.61      0.50      0.47      7814\n",
      "weighted avg       0.83      0.89      0.84      7814\n",
      "\n",
      "Confusion_matrix\n",
      "[[6977    2]\n",
      " [ 834    1]]\n",
      "done in 30.090982s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6927\n",
      "           1       0.75      0.00      0.01       851\n",
      "\n",
      "    accuracy                           0.89      7778\n",
      "   macro avg       0.82      0.50      0.47      7778\n",
      "weighted avg       0.88      0.89      0.84      7778\n",
      "\n",
      "Confusion_matrix\n",
      "[[6926    1]\n",
      " [ 848    3]]\n",
      "done in 30.697077s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12932\n",
      "           1       0.50      0.00      0.00      1152\n",
      "\n",
      "    accuracy                           0.92     14084\n",
      "   macro avg       0.71      0.50      0.48     14084\n",
      "weighted avg       0.88      0.92      0.88     14084\n",
      "\n",
      "Confusion_matrix\n",
      "[[12931     1]\n",
      " [ 1151     1]]\n",
      "done in 30.597589s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13000\n",
      "           1       0.40      0.00      0.00      1120\n",
      "\n",
      "    accuracy                           0.92     14120\n",
      "   macro avg       0.66      0.50      0.48     14120\n",
      "weighted avg       0.88      0.92      0.88     14120\n",
      "\n",
      "Confusion_matrix\n",
      "[[12997     3]\n",
      " [ 1118     2]]\n",
      "done in 30.348683s\n",
      "0.2278130364896202\n",
      "0.27414194560769245\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19911\n",
      "           1       0.11      0.00      0.00      1987\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.51      0.50      0.48     21898\n",
      "weighted avg       0.84      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19903     8]\n",
      " [ 1986     1]]\n",
      "done in 0.983436s\n",
      "0.2278130364896202\n",
      "0.27320275414533257\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19927\n",
      "           1       0.14      0.00      0.00      1971\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.53      0.50      0.48     21898\n",
      "weighted avg       0.84      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19921     6]\n",
      " [ 1970     1]]\n",
      "done in 0.989004s\n",
      "0.2278130364896202\n",
      "0.30728105185420757\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6979\n",
      "           1       0.17      0.00      0.00       835\n",
      "\n",
      "    accuracy                           0.89      7814\n",
      "   macro avg       0.53      0.50      0.47      7814\n",
      "weighted avg       0.82      0.89      0.84      7814\n",
      "\n",
      "Confusion_matrix\n",
      "[[6974    5]\n",
      " [ 834    1]]\n",
      "done in 0.943946s\n",
      "0.2278130364896202\n",
      "0.31803791559619027\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6927\n",
      "           1       0.00      0.00      0.00       851\n",
      "\n",
      "    accuracy                           0.89      7778\n",
      "   macro avg       0.45      0.50      0.47      7778\n",
      "weighted avg       0.79      0.89      0.84      7778\n",
      "\n",
      "Confusion_matrix\n",
      "[[6926    1]\n",
      " [ 851    0]]\n",
      "done in 0.962991s\n",
      "0.2278130364896202\n",
      "0.25575590639935186\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12932\n",
      "           1       0.00      0.00      0.00      1152\n",
      "\n",
      "    accuracy                           0.92     14084\n",
      "   macro avg       0.46      0.50      0.48     14084\n",
      "weighted avg       0.84      0.92      0.88     14084\n",
      "\n",
      "Confusion_matrix\n",
      "[[12929     3]\n",
      " [ 1152     0]]\n",
      "done in 1.024903s\n",
      "0.2278130364896202\n",
      "0.248505311810717\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13000\n",
      "           1       0.17      0.00      0.00      1120\n",
      "\n",
      "    accuracy                           0.92     14120\n",
      "   macro avg       0.54      0.50      0.48     14120\n",
      "weighted avg       0.86      0.92      0.88     14120\n",
      "\n",
      "Confusion_matrix\n",
      "[[12995     5]\n",
      " [ 1119     1]]\n",
      "done in 0.959054s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19911\n",
      "           1       0.43      0.03      0.05      1987\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19843    68]\n",
      " [ 1936    51]]\n",
      "done in 52.424141s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19927\n",
      "           1       0.48      0.02      0.05      1971\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.70      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19874    53]\n",
      " [ 1922    49]]\n",
      "done in 52.186814s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6979\n",
      "           1       0.41      0.02      0.04       835\n",
      "\n",
      "    accuracy                           0.89      7814\n",
      "   macro avg       0.65      0.51      0.49      7814\n",
      "weighted avg       0.84      0.89      0.85      7814\n",
      "\n",
      "Confusion_matrix\n",
      "[[6953   26]\n",
      " [ 817   18]]\n",
      "done in 52.418570s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6927\n",
      "           1       0.44      0.02      0.05       851\n",
      "\n",
      "    accuracy                           0.89      7778\n",
      "   macro avg       0.67      0.51      0.49      7778\n",
      "weighted avg       0.84      0.89      0.84      7778\n",
      "\n",
      "Confusion_matrix\n",
      "[[6900   27]\n",
      " [ 830   21]]\n",
      "done in 52.023738s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12932\n",
      "           1       0.45      0.03      0.05      1152\n",
      "\n",
      "    accuracy                           0.92     14084\n",
      "   macro avg       0.68      0.51      0.51     14084\n",
      "weighted avg       0.88      0.92      0.88     14084\n",
      "\n",
      "Confusion_matrix\n",
      "[[12891    41]\n",
      " [ 1119    33]]\n",
      "done in 52.839282s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13000\n",
      "           1       0.52      0.03      0.05      1120\n",
      "\n",
      "    accuracy                           0.92     14120\n",
      "   macro avg       0.72      0.51      0.50     14120\n",
      "weighted avg       0.89      0.92      0.89     14120\n",
      "\n",
      "Confusion_matrix\n",
      "[[12974    26]\n",
      " [ 1092    28]]\n",
      "done in 53.762607s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.2, J-value:0.243\n",
      "threshold:0.30000000000000004, J-value:0.143\n",
      "threshold:0.4, J-value:0.078\n",
      "threshold:0.5, J-value:0.036000000000000004\n",
      "threshold:0.6000000000000001, J-value:0.016\n",
      "threshold:0.7000000000000001, J-value:0.007\n",
      "threshold:0.8, J-value:0.003\n",
      "threshold:0.9, J-value:0.001\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.686539322430715\n",
      "Balanced accuracy score of test is  0.6934371465488811\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.368\n",
      "threshold:0.2, J-value:0.24600000000000002\n",
      "threshold:0.30000000000000004, J-value:0.13\n",
      "threshold:0.4, J-value:0.066\n",
      "threshold:0.5, J-value:0.024\n",
      "threshold:0.6000000000000001, J-value:0.014\n",
      "threshold:0.7000000000000001, J-value:0.006\n",
      "threshold:0.8, J-value:0.004\n",
      "threshold:0.9, J-value:0.001\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6842303643179324\n",
      "Balanced accuracy score of test is  0.6818662204487049\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.371\n",
      "threshold:0.2, J-value:0.238\n",
      "threshold:0.30000000000000004, J-value:0.151\n",
      "threshold:0.4, J-value:0.08600000000000001\n",
      "threshold:0.5, J-value:0.046\n",
      "threshold:0.6000000000000001, J-value:0.018000000000000002\n",
      "threshold:0.7000000000000001, J-value:0.008\n",
      "threshold:0.8, J-value:0.002\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6853787278327663\n",
      "Balanced accuracy score of test is  0.6985054945054945\n",
      "True positive rate of class 1 is  0.61\n",
      "True positive rate of class 2 is  0.593\n",
      "Positive prediction rate of class 1 is  0.286\n",
      "Positive prediction rate of class 2 is  0.227\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.39099999999999996\n",
      "threshold:0.2, J-value:0.263\n",
      "threshold:0.30000000000000004, J-value:0.102\n",
      "threshold:0.4, J-value:0.02\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6956767251915715\n",
      "Balanced accuracy score of test is  0.6999662797623298\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.37\n",
      "threshold:0.2, J-value:0.264\n",
      "threshold:0.30000000000000004, J-value:0.099\n",
      "threshold:0.4, J-value:0.024\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6850206736548397\n",
      "Balanced accuracy score of test is  0.689511672592999\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.40499999999999997\n",
      "threshold:0.2, J-value:0.266\n",
      "threshold:0.30000000000000004, J-value:0.09\n",
      "threshold:0.4, J-value:0.015000000000000001\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7026296203216826\n",
      "Balanced accuracy score of test is  0.7014739010989011\n",
      "True positive rate of class 1 is  0.752\n",
      "True positive rate of class 2 is  0.69\n",
      "Positive prediction rate of class 1 is  0.415\n",
      "Positive prediction rate of class 2 is  0.319\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.35600000000000004\n",
      "threshold:0.2, J-value:0.16\n",
      "threshold:0.30000000000000004, J-value:0.082\n",
      "threshold:0.4, J-value:0.009000000000000001\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6780666163723992\n",
      "Balanced accuracy score of test is  0.6759124126247001\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.344\n",
      "threshold:0.2, J-value:0.171\n",
      "threshold:0.30000000000000004, J-value:0.099\n",
      "threshold:0.4, J-value:0.011\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6721423466292805\n",
      "Balanced accuracy score of test is  0.6697881058417334\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.355\n",
      "threshold:0.2, J-value:0.152\n",
      "threshold:0.30000000000000004, J-value:0.067\n",
      "threshold:0.4, J-value:0.005\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6775209858404647\n",
      "Balanced accuracy score of test is  0.6753379120879122\n",
      "True positive rate of class 1 is  0.683\n",
      "True positive rate of class 2 is  0.623\n",
      "Positive prediction rate of class 1 is  0.38\n",
      "Positive prediction rate of class 2 is  0.3\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.38\n",
      "threshold:0.2, J-value:0.248\n",
      "threshold:0.30000000000000004, J-value:0.133\n",
      "threshold:0.4, J-value:0.067\n",
      "threshold:0.5, J-value:0.023\n",
      "threshold:0.6000000000000001, J-value:0.009999999999999998\n",
      "threshold:0.7000000000000001, J-value:0.004\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6903436320817371\n",
      "Balanced accuracy score of test is  0.7011418796822506\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.373\n",
      "threshold:0.2, J-value:0.24000000000000002\n",
      "threshold:0.30000000000000004, J-value:0.118\n",
      "threshold:0.4, J-value:0.063\n",
      "threshold:0.5, J-value:0.018\n",
      "threshold:0.6000000000000001, J-value:0.009000000000000001\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6866822022955092\n",
      "Balanced accuracy score of test is  0.6959657512786102\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.38\n",
      "threshold:0.2, J-value:0.252\n",
      "threshold:0.30000000000000004, J-value:0.14400000000000002\n",
      "threshold:0.4, J-value:0.069\n",
      "threshold:0.5, J-value:0.026000000000000002\n",
      "threshold:0.6000000000000001, J-value:0.011\n",
      "threshold:0.7000000000000001, J-value:0.003\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6899946192906485\n",
      "Balanced accuracy score of test is  0.7012788461538462\n",
      "True positive rate of class 1 is  0.646\n",
      "True positive rate of class 2 is  0.606\n",
      "Positive prediction rate of class 1 is  0.297\n",
      "Positive prediction rate of class 2 is  0.236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lifuchen/Desktop/research/CVDPrediction-master/src/lib/fairness_tests.py:80: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train ['Class'] = y_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42366,)\n",
      "(42366,)\n",
      "(84732, 87)\n",
      "X train 84732\n",
      "Y train 84732\n",
      "21898 7644 14254\n",
      "21898 7644 14254\n",
      "21898 7881 14017\n",
      "21898 7881 14017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22295915666532937\n",
      "0.25918609629928574\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95     19944\n",
      "           1       0.43      0.04      0.07      1954\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.52      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19840   104]\n",
      " [ 1876    78]]\n",
      "done in 1.557311s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22295915666532937\n",
      "0.2597792526162136\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95     19955\n",
      "           1       0.43      0.04      0.08      1943\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.52      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19849   106]\n",
      " [ 1863    80]]\n",
      "done in 1.317491s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22295915666532937\n",
      "0.30480824290155883\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94      6814\n",
      "           1       0.36      0.03      0.05       830\n",
      "\n",
      "    accuracy                           0.89      7644\n",
      "   macro avg       0.63      0.51      0.49      7644\n",
      "weighted avg       0.84      0.89      0.84      7644\n",
      "\n",
      "Confusion_matrix\n",
      "[[6777   37]\n",
      " [ 809   21]]\n",
      "done in 1.170628s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22295915666532937\n",
      "0.2993102230217847\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94      7022\n",
      "           1       0.43      0.04      0.07       859\n",
      "\n",
      "    accuracy                           0.89      7881\n",
      "   macro avg       0.66      0.52      0.51      7881\n",
      "weighted avg       0.84      0.89      0.85      7881\n",
      "\n",
      "Confusion_matrix\n",
      "[[6978   44]\n",
      " [ 826   33]]\n",
      "done in 1.204529s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22295915666532937\n",
      "0.23472028399201933\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96     13130\n",
      "           1       0.46      0.05      0.09      1124\n",
      "\n",
      "    accuracy                           0.92     14254\n",
      "   macro avg       0.69      0.52      0.52     14254\n",
      "weighted avg       0.89      0.92      0.89     14254\n",
      "\n",
      "Confusion_matrix\n",
      "[[13063    67]\n",
      " [ 1067    57]]\n",
      "done in 1.250700s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22295915666532937\n",
      "0.23755312878327456\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96     12933\n",
      "           1       0.43      0.04      0.08      1084\n",
      "\n",
      "    accuracy                           0.92     14017\n",
      "   macro avg       0.68      0.52      0.52     14017\n",
      "weighted avg       0.89      0.92      0.89     14017\n",
      "\n",
      "Confusion_matrix\n",
      "[[12871    62]\n",
      " [ 1037    47]]\n",
      "done in 1.313968s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19944\n",
      "           1       0.60      0.00      0.00      1954\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.76      0.50      0.48     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19942     2]\n",
      " [ 1951     3]]\n",
      "done in 29.440069s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19955\n",
      "           1       1.00      0.00      0.00      1943\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.96      0.50      0.48     21898\n",
      "weighted avg       0.92      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19955     0]\n",
      " [ 1940     3]]\n",
      "done in 29.551343s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6814\n",
      "           1       0.25      0.00      0.00       830\n",
      "\n",
      "    accuracy                           0.89      7644\n",
      "   macro avg       0.57      0.50      0.47      7644\n",
      "weighted avg       0.82      0.89      0.84      7644\n",
      "\n",
      "Confusion_matrix\n",
      "[[6811    3]\n",
      " [ 829    1]]\n",
      "done in 29.239908s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      7022\n",
      "           1       0.00      0.00      0.00       859\n",
      "\n",
      "    accuracy                           0.89      7881\n",
      "   macro avg       0.45      0.50      0.47      7881\n",
      "weighted avg       0.79      0.89      0.84      7881\n",
      "\n",
      "Confusion_matrix\n",
      "[[7022    0]\n",
      " [ 859    0]]\n",
      "done in 29.342308s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13130\n",
      "           1       0.60      0.00      0.01      1124\n",
      "\n",
      "    accuracy                           0.92     14254\n",
      "   macro avg       0.76      0.50      0.48     14254\n",
      "weighted avg       0.90      0.92      0.88     14254\n",
      "\n",
      "Confusion_matrix\n",
      "[[13128     2]\n",
      " [ 1121     3]]\n",
      "done in 29.331349s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12933\n",
      "           1       0.67      0.00      0.00      1084\n",
      "\n",
      "    accuracy                           0.92     14017\n",
      "   macro avg       0.79      0.50      0.48     14017\n",
      "weighted avg       0.90      0.92      0.89     14017\n",
      "\n",
      "Confusion_matrix\n",
      "[[12932     1]\n",
      " [ 1082     2]]\n",
      "done in 29.396475s\n",
      "0.22936825376415215\n",
      "0.26887648500481687\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19944\n",
      "           1       0.29      0.01      0.01      1954\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.60      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19920    24]\n",
      " [ 1944    10]]\n",
      "done in 0.965691s\n",
      "0.22936825376415215\n",
      "0.27047057800086916\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19955\n",
      "           1       0.48      0.01      0.02      1943\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.70      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19938    17]\n",
      " [ 1927    16]]\n",
      "done in 1.018635s\n",
      "0.22936825376415215\n",
      "0.31659298907138117\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6814\n",
      "           1       0.25      0.00      0.01       830\n",
      "\n",
      "    accuracy                           0.89      7644\n",
      "   macro avg       0.57      0.50      0.48      7644\n",
      "weighted avg       0.82      0.89      0.84      7644\n",
      "\n",
      "Confusion_matrix\n",
      "[[6802   12]\n",
      " [ 826    4]]\n",
      "done in 0.955602s\n",
      "0.22936825376415215\n",
      "0.3144125215382992\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      7022\n",
      "           1       0.44      0.01      0.02       859\n",
      "\n",
      "    accuracy                           0.89      7881\n",
      "   macro avg       0.67      0.50      0.48      7881\n",
      "weighted avg       0.84      0.89      0.84      7881\n",
      "\n",
      "Confusion_matrix\n",
      "[[7012   10]\n",
      " [ 851    8]]\n",
      "done in 0.982289s\n",
      "0.22936825376415215\n",
      "0.2432875305299454\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13130\n",
      "           1       0.33      0.01      0.01      1124\n",
      "\n",
      "    accuracy                           0.92     14254\n",
      "   macro avg       0.63      0.50      0.48     14254\n",
      "weighted avg       0.88      0.92      0.88     14254\n",
      "\n",
      "Confusion_matrix\n",
      "[[13118    12]\n",
      " [ 1118     6]]\n",
      "done in 0.962480s\n",
      "0.22936825376415215\n",
      "0.24576440285508294\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12933\n",
      "           1       0.53      0.01      0.01      1084\n",
      "\n",
      "    accuracy                           0.92     14017\n",
      "   macro avg       0.73      0.50      0.49     14017\n",
      "weighted avg       0.89      0.92      0.89     14017\n",
      "\n",
      "Confusion_matrix\n",
      "[[12926     7]\n",
      " [ 1076     8]]\n",
      "done in 0.960541s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19944\n",
      "           1       0.40      0.02      0.04      1954\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.66      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19881    63]\n",
      " [ 1912    42]]\n",
      "done in 50.130897s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19955\n",
      "           1       0.52      0.03      0.05      1943\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.71      0.51      0.50     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19907    48]\n",
      " [ 1892    51]]\n",
      "done in 48.434467s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6814\n",
      "           1       0.34      0.01      0.03       830\n",
      "\n",
      "    accuracy                           0.89      7644\n",
      "   macro avg       0.62      0.51      0.48      7644\n",
      "weighted avg       0.83      0.89      0.84      7644\n",
      "\n",
      "Confusion_matrix\n",
      "[[6791   23]\n",
      " [ 818   12]]\n",
      "done in 48.076958s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      7022\n",
      "           1       0.49      0.03      0.05       859\n",
      "\n",
      "    accuracy                           0.89      7881\n",
      "   macro avg       0.69      0.51      0.50      7881\n",
      "weighted avg       0.85      0.89      0.84      7881\n",
      "\n",
      "Confusion_matrix\n",
      "[[6998   24]\n",
      " [ 836   23]]\n",
      "done in 47.625258s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13130\n",
      "           1       0.43      0.03      0.05      1124\n",
      "\n",
      "    accuracy                           0.92     14254\n",
      "   macro avg       0.68      0.51      0.50     14254\n",
      "weighted avg       0.88      0.92      0.89     14254\n",
      "\n",
      "Confusion_matrix\n",
      "[[13090    40]\n",
      " [ 1094    30]]\n",
      "done in 47.635241s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12933\n",
      "           1       0.55      0.03      0.05      1084\n",
      "\n",
      "    accuracy                           0.92     14017\n",
      "   macro avg       0.74      0.51      0.50     14017\n",
      "weighted avg       0.90      0.92      0.89     14017\n",
      "\n",
      "Confusion_matrix\n",
      "[[12910    23]\n",
      " [ 1056    28]]\n",
      "done in 47.627359s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.394\n",
      "threshold:0.2, J-value:0.252\n",
      "threshold:0.30000000000000004, J-value:0.138\n",
      "threshold:0.4, J-value:0.074\n",
      "threshold:0.5, J-value:0.035\n",
      "threshold:0.6000000000000001, J-value:0.016\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6970630867760332\n",
      "Balanced accuracy score of test is  0.6967338374440794\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.352\n",
      "threshold:0.2, J-value:0.22999999999999998\n",
      "threshold:0.30000000000000004, J-value:0.122\n",
      "threshold:0.4, J-value:0.059\n",
      "threshold:0.5, J-value:0.02\n",
      "threshold:0.6000000000000001, J-value:0.009\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6758556975185745\n",
      "Balanced accuracy score of test is  0.7034011516772996\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.419\n",
      "threshold:0.2, J-value:0.267\n",
      "threshold:0.30000000000000004, J-value:0.151\n",
      "threshold:0.4, J-value:0.085\n",
      "threshold:0.5, J-value:0.046\n",
      "threshold:0.6000000000000001, J-value:0.022\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7096985252864186\n",
      "Balanced accuracy score of test is  0.6887578844473204\n",
      "True positive rate of class 1 is  0.644\n",
      "True positive rate of class 2 is  0.581\n",
      "Positive prediction rate of class 1 is  0.281\n",
      "Positive prediction rate of class 2 is  0.233\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.40099999999999997\n",
      "threshold:0.2, J-value:0.263\n",
      "threshold:0.30000000000000004, J-value:0.09799999999999999\n",
      "threshold:0.4, J-value:0.016\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7001147994322692\n",
      "Balanced accuracy score of test is  0.6962194789021567\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.371\n",
      "threshold:0.2, J-value:0.25\n",
      "threshold:0.30000000000000004, J-value:0.098\n",
      "threshold:0.4, J-value:0.016\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6857306537567942\n",
      "Balanced accuracy score of test is  0.6939389558643068\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.411\n",
      "threshold:0.2, J-value:0.261\n",
      "threshold:0.30000000000000004, J-value:0.097\n",
      "threshold:0.4, J-value:0.015000000000000001\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7052332546421902\n",
      "Balanced accuracy score of test is  0.6940813753996968\n",
      "True positive rate of class 1 is  0.758\n",
      "True positive rate of class 2 is  0.692\n",
      "Positive prediction rate of class 1 is  0.412\n",
      "Positive prediction rate of class 2 is  0.334\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.36200000000000004\n",
      "threshold:0.2, J-value:0.199\n",
      "threshold:0.30000000000000004, J-value:0.103\n",
      "threshold:0.4, J-value:0.009\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.004\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6807853443069458\n",
      "Balanced accuracy score of test is  0.6829018920981884\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.343\n",
      "threshold:0.2, J-value:0.179\n",
      "threshold:0.30000000000000004, J-value:0.10500000000000001\n",
      "threshold:0.4, J-value:0.004\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6713794420417214\n",
      "Balanced accuracy score of test is  0.680004204315126\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.366\n",
      "threshold:0.2, J-value:0.21300000000000002\n",
      "threshold:0.30000000000000004, J-value:0.10099999999999999\n",
      "threshold:0.4, J-value:0.013\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.004\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6833672581602535\n",
      "Balanced accuracy score of test is  0.6810745873638278\n",
      "True positive rate of class 1 is  0.68\n",
      "True positive rate of class 2 is  0.631\n",
      "Positive prediction rate of class 1 is  0.359\n",
      "Positive prediction rate of class 2 is  0.297\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.40900000000000003\n",
      "threshold:0.2, J-value:0.259\n",
      "threshold:0.30000000000000004, J-value:0.138\n",
      "threshold:0.4, J-value:0.057\n",
      "threshold:0.5, J-value:0.018000000000000002\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7041767871226743\n",
      "Balanced accuracy score of test is  0.7013095986814388\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.382\n",
      "threshold:0.2, J-value:0.236\n",
      "threshold:0.30000000000000004, J-value:0.139\n",
      "threshold:0.4, J-value:0.049999999999999996\n",
      "threshold:0.5, J-value:0.011\n",
      "threshold:0.6000000000000001, J-value:0.005\n",
      "threshold:0.7000000000000001, J-value:-0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6905715023286572\n",
      "Balanced accuracy score of test is  0.7092501398398978\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.42200000000000004\n",
      "threshold:0.2, J-value:0.275\n",
      "threshold:0.30000000000000004, J-value:0.139\n",
      "threshold:0.4, J-value:0.060000000000000005\n",
      "threshold:0.5, J-value:0.024\n",
      "threshold:0.6000000000000001, J-value:0.002\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7110657726051828\n",
      "Balanced accuracy score of test is  0.6927890564570225\n",
      "True positive rate of class 1 is  0.665\n",
      "True positive rate of class 2 is  0.604\n",
      "Positive prediction rate of class 1 is  0.292\n",
      "Positive prediction rate of class 2 is  0.248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lifuchen/Desktop/research/CVDPrediction-master/src/lib/fairness_tests.py:80: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train ['Class'] = y_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42398,)\n",
      "(42398,)\n",
      "(84796, 87)\n",
      "X train 84796\n",
      "Y train 84796\n",
      "21898 7795 14103\n",
      "21898 7795 14103\n",
      "21898 7762 14136\n",
      "21898 7762 14136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22075916784497418\n",
      "0.26490707163592264\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95     19893\n",
      "           1       0.42      0.04      0.08      2005\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.66      0.52      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19777   116]\n",
      " [ 1922    83]]\n",
      "done in 0.639579s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22075916784497418\n",
      "0.2646213885487365\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19907\n",
      "           1       0.49      0.04      0.08      1991\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.70      0.52      0.52     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19818    89]\n",
      " [ 1905    86]]\n",
      "done in 0.678351s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22075916784497418\n",
      "0.3095220682116796\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94      6922\n",
      "           1       0.35      0.03      0.05       873\n",
      "\n",
      "    accuracy                           0.89      7795\n",
      "   macro avg       0.62      0.51      0.50      7795\n",
      "weighted avg       0.83      0.89      0.84      7795\n",
      "\n",
      "Confusion_matrix\n",
      "[[6878   44]\n",
      " [ 849   24]]\n",
      "done in 0.638005s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22075916784497418\n",
      "0.31048383244814415\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6882\n",
      "           1       0.51      0.04      0.07       880\n",
      "\n",
      "    accuracy                           0.89      7762\n",
      "   macro avg       0.70      0.52      0.50      7762\n",
      "weighted avg       0.85      0.89      0.84      7762\n",
      "\n",
      "Confusion_matrix\n",
      "[[6850   32]\n",
      " [ 847   33]]\n",
      "done in 0.638983s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22075916784497418\n",
      "0.24024750286984267\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96     12971\n",
      "           1       0.45      0.05      0.09      1132\n",
      "\n",
      "    accuracy                           0.92     14103\n",
      "   macro avg       0.69      0.52      0.53     14103\n",
      "weighted avg       0.89      0.92      0.89     14103\n",
      "\n",
      "Confusion_matrix\n",
      "[[12899    72]\n",
      " [ 1073    59]]\n",
      "done in 0.659646s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22075916784497418\n",
      "0.2394385723668462\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13025\n",
      "           1       0.48      0.05      0.09      1111\n",
      "\n",
      "    accuracy                           0.92     14136\n",
      "   macro avg       0.70      0.52      0.52     14136\n",
      "weighted avg       0.89      0.92      0.89     14136\n",
      "\n",
      "Confusion_matrix\n",
      "[[12968    57]\n",
      " [ 1058    53]]\n",
      "done in 0.641068s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19893\n",
      "           1       0.79      0.01      0.01      2005\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.85      0.50      0.48     21898\n",
      "weighted avg       0.90      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19890     3]\n",
      " [ 1994    11]]\n",
      "done in 26.284426s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19907\n",
      "           1       0.33      0.00      0.00      1991\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.62      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19903     4]\n",
      " [ 1989     2]]\n",
      "done in 25.557906s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6922\n",
      "           1       0.75      0.00      0.01       873\n",
      "\n",
      "    accuracy                           0.89      7795\n",
      "   macro avg       0.82      0.50      0.47      7795\n",
      "weighted avg       0.87      0.89      0.84      7795\n",
      "\n",
      "Confusion_matrix\n",
      "[[6921    1]\n",
      " [ 870    3]]\n",
      "done in 24.966999s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6882\n",
      "           1       1.00      0.00      0.00       880\n",
      "\n",
      "    accuracy                           0.89      7762\n",
      "   macro avg       0.94      0.50      0.47      7762\n",
      "weighted avg       0.90      0.89      0.83      7762\n",
      "\n",
      "Confusion_matrix\n",
      "[[6882    0]\n",
      " [ 879    1]]\n",
      "done in 24.792652s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12971\n",
      "           1       0.57      0.00      0.01      1132\n",
      "\n",
      "    accuracy                           0.92     14103\n",
      "   macro avg       0.75      0.50      0.48     14103\n",
      "weighted avg       0.89      0.92      0.88     14103\n",
      "\n",
      "Confusion_matrix\n",
      "[[12968     3]\n",
      " [ 1128     4]]\n",
      "done in 24.956999s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13025\n",
      "           1       0.00      0.00      0.00      1111\n",
      "\n",
      "    accuracy                           0.92     14136\n",
      "   macro avg       0.46      0.50      0.48     14136\n",
      "weighted avg       0.85      0.92      0.88     14136\n",
      "\n",
      "Confusion_matrix\n",
      "[[13022     3]\n",
      " [ 1111     0]]\n",
      "done in 24.874347s\n",
      "0.22750506832151324\n",
      "0.2751469538517568\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19893\n",
      "           1       0.39      0.00      0.01      2005\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.65      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19882    11]\n",
      " [ 1998     7]]\n",
      "done in 0.849145s\n",
      "0.22750506832151324\n",
      "0.27267684314397855\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19907\n",
      "           1       0.38      0.00      0.00      1991\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.65      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19899     8]\n",
      " [ 1986     5]]\n",
      "done in 0.851112s\n",
      "0.22750506832151324\n",
      "0.3159419168730926\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6922\n",
      "           1       1.00      0.00      0.00       873\n",
      "\n",
      "    accuracy                           0.89      7795\n",
      "   macro avg       0.94      0.50      0.47      7795\n",
      "weighted avg       0.90      0.89      0.84      7795\n",
      "\n",
      "Confusion_matrix\n",
      "[[6922    0]\n",
      " [ 871    2]]\n",
      "done in 0.825631s\n",
      "0.22750506832151324\n",
      "0.3220211270665586\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6882\n",
      "           1       0.00      0.00      0.00       880\n",
      "\n",
      "    accuracy                           0.89      7762\n",
      "   macro avg       0.44      0.50      0.47      7762\n",
      "weighted avg       0.79      0.89      0.83      7762\n",
      "\n",
      "Confusion_matrix\n",
      "[[6878    4]\n",
      " [ 880    0]]\n",
      "done in 0.825316s\n",
      "0.22750506832151324\n",
      "0.2525987912798705\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12971\n",
      "           1       0.31      0.00      0.01      1132\n",
      "\n",
      "    accuracy                           0.92     14103\n",
      "   macro avg       0.62      0.50      0.48     14103\n",
      "weighted avg       0.87      0.92      0.88     14103\n",
      "\n",
      "Confusion_matrix\n",
      "[[12960    11]\n",
      " [ 1127     5]]\n",
      "done in 0.834706s\n",
      "0.22750506832151324\n",
      "0.24558216771903046\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13025\n",
      "           1       0.56      0.00      0.01      1111\n",
      "\n",
      "    accuracy                           0.92     14136\n",
      "   macro avg       0.74      0.50      0.48     14136\n",
      "weighted avg       0.89      0.92      0.88     14136\n",
      "\n",
      "Confusion_matrix\n",
      "[[13021     4]\n",
      " [ 1106     5]]\n",
      "done in 0.840618s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19893\n",
      "           1       0.45      0.03      0.05      2005\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19822    71]\n",
      " [ 1948    57]]\n",
      "done in 46.715555s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19907\n",
      "           1       0.49      0.03      0.05      1991\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.70      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19850    57]\n",
      " [ 1937    54]]\n",
      "done in 46.713345s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6922\n",
      "           1       0.43      0.03      0.05       873\n",
      "\n",
      "    accuracy                           0.89      7795\n",
      "   macro avg       0.66      0.51      0.49      7795\n",
      "weighted avg       0.84      0.89      0.84      7795\n",
      "\n",
      "Confusion_matrix\n",
      "[[6893   29]\n",
      " [ 851   22]]\n",
      "done in 47.500730s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6882\n",
      "           1       0.49      0.03      0.05       880\n",
      "\n",
      "    accuracy                           0.89      7762\n",
      "   macro avg       0.69      0.51      0.49      7762\n",
      "weighted avg       0.84      0.89      0.84      7762\n",
      "\n",
      "Confusion_matrix\n",
      "[[6859   23]\n",
      " [ 858   22]]\n",
      "done in 46.902510s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12971\n",
      "           1       0.45      0.03      0.06      1132\n",
      "\n",
      "    accuracy                           0.92     14103\n",
      "   macro avg       0.69      0.51      0.51     14103\n",
      "weighted avg       0.88      0.92      0.89     14103\n",
      "\n",
      "Confusion_matrix\n",
      "[[12928    43]\n",
      " [ 1097    35]]\n",
      "done in 46.883551s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13025\n",
      "           1       0.48      0.03      0.05      1111\n",
      "\n",
      "    accuracy                           0.92     14136\n",
      "   macro avg       0.70      0.51      0.51     14136\n",
      "weighted avg       0.89      0.92      0.89     14136\n",
      "\n",
      "Confusion_matrix\n",
      "[[12991    34]\n",
      " [ 1079    32]]\n",
      "done in 46.858992s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.392\n",
      "threshold:0.2, J-value:0.252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.30000000000000004, J-value:0.142\n",
      "threshold:0.4, J-value:0.076\n",
      "threshold:0.5, J-value:0.035\n",
      "threshold:0.6000000000000001, J-value:0.012\n",
      "threshold:0.7000000000000001, J-value:0.005\n",
      "threshold:0.8, J-value:0.002\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6960044718044531\n",
      "Balanced accuracy score of test is  0.6848659299393611\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.366\n",
      "threshold:0.2, J-value:0.237\n",
      "threshold:0.30000000000000004, J-value:0.124\n",
      "threshold:0.4, J-value:0.057999999999999996\n",
      "threshold:0.5, J-value:0.020999999999999998\n",
      "threshold:0.6000000000000001, J-value:0.008\n",
      "threshold:0.7000000000000001, J-value:0.003\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6828129545619277\n",
      "Balanced accuracy score of test is  0.6847327349343478\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.40499999999999997\n",
      "threshold:0.2, J-value:0.261\n",
      "threshold:0.30000000000000004, J-value:0.154\n",
      "threshold:0.4, J-value:0.09\n",
      "threshold:0.5, J-value:0.046\n",
      "threshold:0.6000000000000001, J-value:0.015000000000000001\n",
      "threshold:0.7000000000000001, J-value:0.008\n",
      "threshold:0.8, J-value:0.003\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7024330301381745\n",
      "Balanced accuracy score of test is  0.6821953903643723\n",
      "True positive rate of class 1 is  0.603\n",
      "True positive rate of class 2 is  0.566\n",
      "Positive prediction rate of class 1 is  0.276\n",
      "Positive prediction rate of class 2 is  0.23\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.40199999999999997\n",
      "threshold:0.2, J-value:0.28\n",
      "threshold:0.30000000000000004, J-value:0.1\n",
      "threshold:0.4, J-value:0.024\n",
      "threshold:0.5, J-value:0.005\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7012499039437048\n",
      "Balanced accuracy score of test is  0.6911115340275021\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.374\n",
      "threshold:0.2, J-value:0.269\n",
      "threshold:0.30000000000000004, J-value:0.08900000000000001\n",
      "threshold:0.4, J-value:0.022\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6868767278524603\n",
      "Balanced accuracy score of test is  0.6879420292726744\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.413\n",
      "threshold:0.2, J-value:0.27299999999999996\n",
      "threshold:0.30000000000000004, J-value:0.09899999999999999\n",
      "threshold:0.4, J-value:0.025\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7065293521045726\n",
      "Balanced accuracy score of test is  0.6956446700332222\n",
      "True positive rate of class 1 is  0.735\n",
      "True positive rate of class 2 is  0.682\n",
      "Positive prediction rate of class 1 is  0.402\n",
      "Positive prediction rate of class 2 is  0.322\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.377\n",
      "threshold:0.2, J-value:0.15200000000000002\n",
      "threshold:0.30000000000000004, J-value:0.11100000000000002\n",
      "threshold:0.4, J-value:0.035\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6884535506856946\n",
      "Balanced accuracy score of test is  0.6799897524493415\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.36200000000000004\n",
      "threshold:0.2, J-value:0.135\n",
      "threshold:0.30000000000000004, J-value:0.10600000000000001\n",
      "threshold:0.4, J-value:0.033\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6810604864613151\n",
      "Balanced accuracy score of test is  0.6770275223904256\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.377\n",
      "threshold:0.2, J-value:0.16199999999999998\n",
      "threshold:0.30000000000000004, J-value:0.11500000000000002\n",
      "threshold:0.4, J-value:0.037\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6884821617563289\n",
      "Balanced accuracy score of test is  0.6765821802909657\n",
      "True positive rate of class 1 is  0.667\n",
      "True positive rate of class 2 is  0.599\n",
      "Positive prediction rate of class 1 is  0.353\n",
      "Positive prediction rate of class 2 is  0.274\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41200000000000003\n",
      "threshold:0.2, J-value:0.259\n",
      "threshold:0.30000000000000004, J-value:0.144\n",
      "threshold:0.4, J-value:0.067\n",
      "threshold:0.5, J-value:0.024\n",
      "threshold:0.6000000000000001, J-value:0.009999999999999998\n",
      "threshold:0.7000000000000001, J-value:0.003\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7060273836596866\n",
      "Balanced accuracy score of test is  0.7014901057874919\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.388\n",
      "threshold:0.2, J-value:0.226\n",
      "threshold:0.30000000000000004, J-value:0.133\n",
      "threshold:0.4, J-value:0.05600000000000001\n",
      "threshold:0.5, J-value:0.021\n",
      "threshold:0.6000000000000001, J-value:0.005\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6942989018859469\n",
      "Balanced accuracy score of test is  0.6981529550077937\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.42300000000000004\n",
      "threshold:0.2, J-value:0.28099999999999997\n",
      "threshold:0.30000000000000004, J-value:0.153\n",
      "threshold:0.4, J-value:0.077\n",
      "threshold:0.5, J-value:0.028\n",
      "threshold:0.6000000000000001, J-value:0.013999999999999999\n",
      "threshold:0.7000000000000001, J-value:0.004\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.711544855566631\n",
      "Balanced accuracy score of test is  0.7007649210218526\n",
      "True positive rate of class 1 is  0.643\n",
      "True positive rate of class 2 is  0.609\n",
      "Positive prediction rate of class 1 is  0.292\n",
      "Positive prediction rate of class 2 is  0.239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lifuchen/Desktop/research/CVDPrediction-master/src/lib/fairness_tests.py:80: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train ['Class'] = y_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42494,)\n",
      "(42494,)\n",
      "(84988, 87)\n",
      "X train 84988\n",
      "Y train 84988\n",
      "21898 7804 14094\n",
      "21898 7804 14094\n",
      "21898 7849 14049\n",
      "21898 7849 14049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22206341133870114\n",
      "0.2643019353791209\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95     19931\n",
      "           1       0.44      0.04      0.08      1967\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.52      0.52     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19821   110]\n",
      " [ 1881    86]]\n",
      "done in 0.639127s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22206341133870114\n",
      "0.2607350824941761\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95     19956\n",
      "           1       0.46      0.05      0.08      1942\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.69      0.52      0.52     21898\n",
      "weighted avg       0.87      0.91      0.88     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19853   103]\n",
      " [ 1853    89]]\n",
      "done in 0.632753s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22206341133870114\n",
      "0.3114025799490676\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94      6937\n",
      "           1       0.44      0.04      0.08       867\n",
      "\n",
      "    accuracy                           0.89      7804\n",
      "   macro avg       0.66      0.52      0.51      7804\n",
      "weighted avg       0.84      0.89      0.84      7804\n",
      "\n",
      "Confusion_matrix\n",
      "[[6889   48]\n",
      " [ 830   37]]\n",
      "done in 0.631628s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22206341133870114\n",
      "0.300017584808296\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94      7008\n",
      "           1       0.47      0.04      0.08       841\n",
      "\n",
      "    accuracy                           0.89      7849\n",
      "   macro avg       0.68      0.52      0.51      7849\n",
      "weighted avg       0.85      0.89      0.85      7849\n",
      "\n",
      "Confusion_matrix\n",
      "[[6968   40]\n",
      " [ 806   35]]\n",
      "done in 0.624235s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22206341133870114\n",
      "0.23822179984457684\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12994\n",
      "           1       0.44      0.04      0.08      1100\n",
      "\n",
      "    accuracy                           0.92     14094\n",
      "   macro avg       0.68      0.52      0.52     14094\n",
      "weighted avg       0.89      0.92      0.89     14094\n",
      "\n",
      "Confusion_matrix\n",
      "[[12932    62]\n",
      " [ 1051    49]]\n",
      "done in 0.637153s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22206341133870114\n",
      "0.23878844140487954\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12948\n",
      "           1       0.46      0.05      0.09      1101\n",
      "\n",
      "    accuracy                           0.92     14049\n",
      "   macro avg       0.69      0.52      0.52     14049\n",
      "weighted avg       0.89      0.92      0.89     14049\n",
      "\n",
      "Confusion_matrix\n",
      "[[12885    63]\n",
      " [ 1047    54]]\n",
      "done in 0.625340s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19931\n",
      "           1       0.36      0.00      0.00      1967\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.64      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19924     7]\n",
      " [ 1963     4]]\n",
      "done in 25.641422s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19956\n",
      "           1       0.33      0.00      0.00      1942\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.62      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19952     4]\n",
      " [ 1940     2]]\n",
      "done in 25.334120s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6937\n",
      "           1       0.00      0.00      0.00       867\n",
      "\n",
      "    accuracy                           0.89      7804\n",
      "   macro avg       0.44      0.50      0.47      7804\n",
      "weighted avg       0.79      0.89      0.84      7804\n",
      "\n",
      "Confusion_matrix\n",
      "[[6934    3]\n",
      " [ 867    0]]\n",
      "done in 24.893958s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      7008\n",
      "           1       1.00      0.00      0.00       841\n",
      "\n",
      "    accuracy                           0.89      7849\n",
      "   macro avg       0.95      0.50      0.47      7849\n",
      "weighted avg       0.90      0.89      0.84      7849\n",
      "\n",
      "Confusion_matrix\n",
      "[[7008    0]\n",
      " [ 839    2]]\n",
      "done in 25.146940s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12994\n",
      "           1       0.67      0.00      0.00      1100\n",
      "\n",
      "    accuracy                           0.92     14094\n",
      "   macro avg       0.79      0.50      0.48     14094\n",
      "weighted avg       0.90      0.92      0.88     14094\n",
      "\n",
      "Confusion_matrix\n",
      "[[12993     1]\n",
      " [ 1098     2]]\n",
      "done in 25.180026s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12948\n",
      "           1       0.33      0.00      0.00      1101\n",
      "\n",
      "    accuracy                           0.92     14049\n",
      "   macro avg       0.63      0.50      0.48     14049\n",
      "weighted avg       0.88      0.92      0.88     14049\n",
      "\n",
      "Confusion_matrix\n",
      "[[12944     4]\n",
      " [ 1099     2]]\n",
      "done in 25.421628s\n",
      "0.2282689194569847\n",
      "0.2732091353915162\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19931\n",
      "           1       0.22      0.00      0.00      1967\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.57      0.50      0.48     21898\n",
      "weighted avg       0.85      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19924     7]\n",
      " [ 1965     2]]\n",
      "done in 0.848181s\n",
      "0.2282689194569847\n",
      "0.2705114254522041\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19956\n",
      "           1       0.29      0.00      0.00      1942\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.60      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19946    10]\n",
      " [ 1938     4]]\n",
      "done in 0.848458s\n",
      "0.2282689194569847\n",
      "0.32017256700607977\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6937\n",
      "           1       0.25      0.00      0.00       867\n",
      "\n",
      "    accuracy                           0.89      7804\n",
      "   macro avg       0.57      0.50      0.47      7804\n",
      "weighted avg       0.82      0.89      0.84      7804\n",
      "\n",
      "Confusion_matrix\n",
      "[[6934    3]\n",
      " [ 866    1]]\n",
      "done in 0.829911s\n",
      "0.2282689194569847\n",
      "0.31018266961006996\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      7008\n",
      "           1       0.33      0.00      0.00       841\n",
      "\n",
      "    accuracy                           0.89      7849\n",
      "   macro avg       0.61      0.50      0.47      7849\n",
      "weighted avg       0.83      0.89      0.84      7849\n",
      "\n",
      "Confusion_matrix\n",
      "[[7006    2]\n",
      " [ 840    1]]\n",
      "done in 0.823651s\n",
      "0.2282689194569847\n",
      "0.24733868175856666\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12994\n",
      "           1       0.14      0.00      0.00      1100\n",
      "\n",
      "    accuracy                           0.92     14094\n",
      "   macro avg       0.53      0.50      0.48     14094\n",
      "weighted avg       0.86      0.92      0.88     14094\n",
      "\n",
      "Confusion_matrix\n",
      "[[12988     6]\n",
      " [ 1099     1]]\n",
      "done in 0.840825s\n",
      "0.2282689194569847\n",
      "0.2482703624807937\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12948\n",
      "           1       0.30      0.00      0.01      1101\n",
      "\n",
      "    accuracy                           0.92     14049\n",
      "   macro avg       0.61      0.50      0.48     14049\n",
      "weighted avg       0.87      0.92      0.88     14049\n",
      "\n",
      "Confusion_matrix\n",
      "[[12941     7]\n",
      " [ 1098     3]]\n",
      "done in 0.836930s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19931\n",
      "           1       0.45      0.03      0.05      1967\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19869    62]\n",
      " [ 1916    51]]\n",
      "done in 46.853029s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19956\n",
      "           1       0.43      0.03      0.05      1942\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19885    71]\n",
      " [ 1889    53]]\n",
      "done in 46.858749s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6937\n",
      "           1       0.48      0.03      0.05       867\n",
      "\n",
      "    accuracy                           0.89      7804\n",
      "   macro avg       0.68      0.51      0.49      7804\n",
      "weighted avg       0.85      0.89      0.84      7804\n",
      "\n",
      "Confusion_matrix\n",
      "[[6913   24]\n",
      " [ 845   22]]\n",
      "done in 46.826181s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      7008\n",
      "           1       0.37      0.02      0.04       841\n",
      "\n",
      "    accuracy                           0.89      7849\n",
      "   macro avg       0.63      0.51      0.49      7849\n",
      "weighted avg       0.84      0.89      0.85      7849\n",
      "\n",
      "Confusion_matrix\n",
      "[[6975   33]\n",
      " [ 822   19]]\n",
      "done in 46.776550s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12994\n",
      "           1       0.42      0.03      0.05      1100\n",
      "\n",
      "    accuracy                           0.92     14094\n",
      "   macro avg       0.67      0.51      0.50     14094\n",
      "weighted avg       0.88      0.92      0.89     14094\n",
      "\n",
      "Confusion_matrix\n",
      "[[12954    40]\n",
      " [ 1071    29]]\n",
      "done in 46.834465s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12948\n",
      "           1       0.47      0.03      0.06      1101\n",
      "\n",
      "    accuracy                           0.92     14049\n",
      "   macro avg       0.70      0.51      0.51     14049\n",
      "weighted avg       0.89      0.92      0.89     14049\n",
      "\n",
      "Confusion_matrix\n",
      "[[12910    38]\n",
      " [ 1067    34]]\n",
      "done in 46.836662s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.369\n",
      "threshold:0.2, J-value:0.246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.30000000000000004, J-value:0.143\n",
      "threshold:0.4, J-value:0.07200000000000001\n",
      "threshold:0.5, J-value:0.038\n",
      "threshold:0.6000000000000001, J-value:0.012\n",
      "threshold:0.7000000000000001, J-value:0.005\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6843774596327845\n",
      "Balanced accuracy score of test is  0.69383405593232\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.33999999999999997\n",
      "threshold:0.2, J-value:0.23900000000000002\n",
      "threshold:0.30000000000000004, J-value:0.147\n",
      "threshold:0.4, J-value:0.071\n",
      "threshold:0.5, J-value:0.036\n",
      "threshold:0.6000000000000001, J-value:0.011\n",
      "threshold:0.7000000000000001, J-value:0.005\n",
      "threshold:0.8, J-value:0.002\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6700731696489364\n",
      "Balanced accuracy score of test is  0.6906004993783221\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.38299999999999995\n",
      "threshold:0.2, J-value:0.247\n",
      "threshold:0.30000000000000004, J-value:0.137\n",
      "threshold:0.4, J-value:0.07300000000000001\n",
      "threshold:0.5, J-value:0.04\n",
      "threshold:0.6000000000000001, J-value:0.013\n",
      "threshold:0.7000000000000001, J-value:0.005\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6911948171883526\n",
      "Balanced accuracy score of test is  0.692784236926747\n",
      "True positive rate of class 1 is  0.63\n",
      "True positive rate of class 2 is  0.586\n",
      "Positive prediction rate of class 1 is  0.29\n",
      "Positive prediction rate of class 2 is  0.23\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.38199999999999995\n",
      "threshold:0.2, J-value:0.275\n",
      "threshold:0.30000000000000004, J-value:0.10900000000000001\n",
      "threshold:0.4, J-value:0.02\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6907225071386982\n",
      "Balanced accuracy score of test is  0.699159494863984\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.352\n",
      "threshold:0.2, J-value:0.265\n",
      "threshold:0.30000000000000004, J-value:0.12\n",
      "threshold:0.4, J-value:0.02\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6757042580788474\n",
      "Balanced accuracy score of test is  0.6909782738531537\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.39100000000000007\n",
      "threshold:0.2, J-value:0.262\n",
      "threshold:0.30000000000000004, J-value:0.104\n",
      "threshold:0.4, J-value:0.019000000000000003\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6954525865084584\n",
      "Balanced accuracy score of test is  0.6998504392754417\n",
      "True positive rate of class 1 is  0.746\n",
      "True positive rate of class 2 is  0.696\n",
      "Positive prediction rate of class 1 is  0.405\n",
      "Positive prediction rate of class 2 is  0.327\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.34099999999999997\n",
      "threshold:0.2, J-value:0.185\n",
      "threshold:0.30000000000000004, J-value:0.062\n",
      "threshold:0.4, J-value:0.002\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6704508541249211\n",
      "Balanced accuracy score of test is  0.6693810574819701\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.316\n",
      "threshold:0.2, J-value:0.18\n",
      "threshold:0.30000000000000004, J-value:0.06999999999999999\n",
      "threshold:0.4, J-value:0.0\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6576767110951938\n",
      "Balanced accuracy score of test is  0.6689350102346088\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.351\n",
      "threshold:0.2, J-value:0.187\n",
      "threshold:0.30000000000000004, J-value:0.053000000000000005\n",
      "threshold:0.4, J-value:0.003\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.675851232037164\n",
      "Balanced accuracy score of test is  0.6668882614928378\n",
      "True positive rate of class 1 is  0.621\n",
      "True positive rate of class 2 is  0.577\n",
      "Positive prediction rate of class 1 is  0.319\n",
      "Positive prediction rate of class 2 is  0.269\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.378\n",
      "threshold:0.2, J-value:0.254\n",
      "threshold:0.30000000000000004, J-value:0.14100000000000001\n",
      "threshold:0.4, J-value:0.069\n",
      "threshold:0.5, J-value:0.023\n",
      "threshold:0.6000000000000001, J-value:0.005\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6886716467185455\n",
      "Balanced accuracy score of test is  0.7000997457021307\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.361\n",
      "threshold:0.2, J-value:0.254\n",
      "threshold:0.30000000000000004, J-value:0.148\n",
      "threshold:0.4, J-value:0.078\n",
      "threshold:0.5, J-value:0.022000000000000002\n",
      "threshold:0.6000000000000001, J-value:0.002\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6803105524277735\n",
      "Balanced accuracy score of test is  0.6982577071761711\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.381\n",
      "threshold:0.2, J-value:0.251\n",
      "threshold:0.30000000000000004, J-value:0.133\n",
      "threshold:0.4, J-value:0.062000000000000006\n",
      "threshold:0.5, J-value:0.023\n",
      "threshold:0.6000000000000001, J-value:0.006\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6905840457833685\n",
      "Balanced accuracy score of test is  0.6979111162739409\n",
      "True positive rate of class 1 is  0.66\n",
      "True positive rate of class 2 is  0.609\n",
      "Positive prediction rate of class 1 is  0.306\n",
      "Positive prediction rate of class 2 is  0.245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lifuchen/Desktop/research/CVDPrediction-master/src/lib/fairness_tests.py:80: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train ['Class'] = y_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42377,)\n",
      "(42377,)\n",
      "(84754, 87)\n",
      "X train 84754\n",
      "Y train 84754\n",
      "21898 7696 14202\n",
      "21898 7696 14202\n",
      "21898 7840 14058\n",
      "21898 7840 14058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2228100399507769\n",
      "0.25525012822911597\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.95     19973\n",
      "           1       0.48      0.04      0.08      1925\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.70      0.52      0.52     21898\n",
      "weighted avg       0.88      0.91      0.88     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19879    94]\n",
      " [ 1839    86]]\n",
      "done in 0.624506s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2228100399507769\n",
      "0.2667030158787792\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95     19866\n",
      "           1       0.45      0.04      0.08      2032\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.52      0.52     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19759   107]\n",
      " [ 1943    89]]\n",
      "done in 0.606410s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2228100399507769\n",
      "0.2848032456857157\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      6911\n",
      "           1       0.50      0.04      0.08       785\n",
      "\n",
      "    accuracy                           0.90      7696\n",
      "   macro avg       0.70      0.52      0.51      7696\n",
      "weighted avg       0.86      0.90      0.86      7696\n",
      "\n",
      "Confusion_matrix\n",
      "[[6879   32]\n",
      " [ 753   32]]\n",
      "done in 0.588399s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2228100399507769\n",
      "0.3084279385191205\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94      6966\n",
      "           1       0.40      0.04      0.07       874\n",
      "\n",
      "    accuracy                           0.89      7840\n",
      "   macro avg       0.65      0.52      0.50      7840\n",
      "weighted avg       0.84      0.89      0.84      7840\n",
      "\n",
      "Confusion_matrix\n",
      "[[6917   49]\n",
      " [ 841   33]]\n",
      "done in 0.621266s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2228100399507769\n",
      "0.23923542664159372\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13062\n",
      "           1       0.47      0.05      0.09      1140\n",
      "\n",
      "    accuracy                           0.92     14202\n",
      "   macro avg       0.69      0.52      0.52     14202\n",
      "weighted avg       0.89      0.92      0.89     14202\n",
      "\n",
      "Confusion_matrix\n",
      "[[13000    62]\n",
      " [ 1086    54]]\n",
      "done in 0.610471s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2228100399507769\n",
      "0.24343346163918078\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12900\n",
      "           1       0.49      0.05      0.09      1158\n",
      "\n",
      "    accuracy                           0.92     14058\n",
      "   macro avg       0.71      0.52      0.52     14058\n",
      "weighted avg       0.89      0.92      0.89     14058\n",
      "\n",
      "Confusion_matrix\n",
      "[[12842    58]\n",
      " [ 1102    56]]\n",
      "done in 0.617463s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19973\n",
      "           1       0.50      0.00      0.00      1925\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.71      0.50      0.48     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19972     1]\n",
      " [ 1924     1]]\n",
      "done in 25.387751s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19866\n",
      "           1       0.50      0.00      0.00      2032\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.70      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.86     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19865     1]\n",
      " [ 2031     1]]\n",
      "done in 26.345801s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      6911\n",
      "           1       0.50      0.00      0.00       785\n",
      "\n",
      "    accuracy                           0.90      7696\n",
      "   macro avg       0.70      0.50      0.47      7696\n",
      "weighted avg       0.86      0.90      0.85      7696\n",
      "\n",
      "Confusion_matrix\n",
      "[[6910    1]\n",
      " [ 784    1]]\n",
      "done in 25.616537s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6966\n",
      "           1       0.56      0.01      0.01       874\n",
      "\n",
      "    accuracy                           0.89      7840\n",
      "   macro avg       0.72      0.50      0.48      7840\n",
      "weighted avg       0.85      0.89      0.84      7840\n",
      "\n",
      "Confusion_matrix\n",
      "[[6962    4]\n",
      " [ 869    5]]\n",
      "done in 25.581314s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13062\n",
      "           1       0.50      0.00      0.00      1140\n",
      "\n",
      "    accuracy                           0.92     14202\n",
      "   macro avg       0.71      0.50      0.48     14202\n",
      "weighted avg       0.89      0.92      0.88     14202\n",
      "\n",
      "Confusion_matrix\n",
      "[[13061     1]\n",
      " [ 1139     1]]\n",
      "done in 25.654606s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12900\n",
      "           1       0.33      0.00      0.00      1158\n",
      "\n",
      "    accuracy                           0.92     14058\n",
      "   macro avg       0.63      0.50      0.48     14058\n",
      "weighted avg       0.87      0.92      0.88     14058\n",
      "\n",
      "Confusion_matrix\n",
      "[[12898     2]\n",
      " [ 1157     1]]\n",
      "done in 25.742941s\n",
      "0.2288736001725474\n",
      "0.26611389014566206\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19973\n",
      "           1       0.00      0.00      0.00      1925\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.46      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19962    11]\n",
      " [ 1925     0]]\n",
      "done in 0.858209s\n",
      "0.2288736001725474\n",
      "0.27673800874769555\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19866\n",
      "           1       0.00      0.00      0.00      2032\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.45      0.50      0.48     21898\n",
      "weighted avg       0.82      0.91      0.86     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19846    20]\n",
      " [ 2032     0]]\n",
      "done in 0.845295s\n",
      "0.2288736001725474\n",
      "0.29638332260970346\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      6911\n",
      "           1       0.00      0.00      0.00       785\n",
      "\n",
      "    accuracy                           0.90      7696\n",
      "   macro avg       0.45      0.50      0.47      7696\n",
      "weighted avg       0.81      0.90      0.85      7696\n",
      "\n",
      "Confusion_matrix\n",
      "[[6906    5]\n",
      " [ 785    0]]\n",
      "done in 0.832043s\n",
      "0.2288736001725474\n",
      "0.31838119154619504\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6966\n",
      "           1       0.00      0.00      0.00       874\n",
      "\n",
      "    accuracy                           0.89      7840\n",
      "   macro avg       0.44      0.50      0.47      7840\n",
      "weighted avg       0.79      0.89      0.84      7840\n",
      "\n",
      "Confusion_matrix\n",
      "[[6956   10]\n",
      " [ 874    0]]\n",
      "done in 0.826891s\n",
      "0.2288736001725474\n",
      "0.2497110206735269\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13062\n",
      "           1       0.00      0.00      0.00      1140\n",
      "\n",
      "    accuracy                           0.92     14202\n",
      "   macro avg       0.46      0.50      0.48     14202\n",
      "weighted avg       0.85      0.92      0.88     14202\n",
      "\n",
      "Confusion_matrix\n",
      "[[13056     6]\n",
      " [ 1140     0]]\n",
      "done in 0.831750s\n",
      "0.2288736001725474\n",
      "0.2535140399654906\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12900\n",
      "           1       0.00      0.00      0.00      1158\n",
      "\n",
      "    accuracy                           0.92     14058\n",
      "   macro avg       0.46      0.50      0.48     14058\n",
      "weighted avg       0.84      0.92      0.88     14058\n",
      "\n",
      "Confusion_matrix\n",
      "[[12890    10]\n",
      " [ 1158     0]]\n",
      "done in 0.835666s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19973\n",
      "           1       0.46      0.02      0.05      1925\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.69      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19920    53]\n",
      " [ 1879    46]]\n",
      "done in 46.799034s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19866\n",
      "           1       0.45      0.03      0.05      2032\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19803    63]\n",
      " [ 1980    52]]\n",
      "done in 46.814582s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      6911\n",
      "           1       0.56      0.03      0.06       785\n",
      "\n",
      "    accuracy                           0.90      7696\n",
      "   macro avg       0.73      0.51      0.50      7696\n",
      "weighted avg       0.87      0.90      0.86      7696\n",
      "\n",
      "Confusion_matrix\n",
      "[[6893   18]\n",
      " [ 762   23]]\n",
      "done in 46.636050s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94      6966\n",
      "           1       0.42      0.03      0.05       874\n",
      "\n",
      "    accuracy                           0.89      7840\n",
      "   macro avg       0.65      0.51      0.50      7840\n",
      "weighted avg       0.84      0.89      0.84      7840\n",
      "\n",
      "Confusion_matrix\n",
      "[[6931   35]\n",
      " [ 849   25]]\n",
      "done in 46.546407s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13062\n",
      "           1       0.39      0.02      0.04      1140\n",
      "\n",
      "    accuracy                           0.92     14202\n",
      "   macro avg       0.65      0.51      0.50     14202\n",
      "weighted avg       0.88      0.92      0.88     14202\n",
      "\n",
      "Confusion_matrix\n",
      "[[13027    35]\n",
      " [ 1118    22]]\n",
      "done in 46.574249s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12900\n",
      "           1       0.48      0.02      0.04      1158\n",
      "\n",
      "    accuracy                           0.92     14058\n",
      "   macro avg       0.70      0.51      0.50     14058\n",
      "weighted avg       0.88      0.92      0.88     14058\n",
      "\n",
      "Confusion_matrix\n",
      "[[12871    29]\n",
      " [ 1131    27]]\n",
      "done in 46.614786s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.385\n",
      "threshold:0.2, J-value:0.252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.30000000000000004, J-value:0.159\n",
      "threshold:0.4, J-value:0.08700000000000001\n",
      "threshold:0.5, J-value:0.04\n",
      "threshold:0.6000000000000001, J-value:0.016999999999999998\n",
      "threshold:0.7000000000000001, J-value:0.007\n",
      "threshold:0.8, J-value:0.002\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6925048815901467\n",
      "Balanced accuracy score of test is  0.697284453476085\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.381\n",
      "threshold:0.2, J-value:0.249\n",
      "threshold:0.30000000000000004, J-value:0.156\n",
      "threshold:0.4, J-value:0.08600000000000001\n",
      "threshold:0.5, J-value:0.036000000000000004\n",
      "threshold:0.6000000000000001, J-value:0.016999999999999998\n",
      "threshold:0.7000000000000001, J-value:0.006\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6903408855263509\n",
      "Balanced accuracy score of test is  0.6923959197698399\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.38199999999999995\n",
      "threshold:0.2, J-value:0.252\n",
      "threshold:0.30000000000000004, J-value:0.161\n",
      "threshold:0.4, J-value:0.08700000000000001\n",
      "threshold:0.5, J-value:0.042\n",
      "threshold:0.6000000000000001, J-value:0.016999999999999998\n",
      "threshold:0.7000000000000001, J-value:0.007\n",
      "threshold:0.8, J-value:0.002\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6912115497747584\n",
      "Balanced accuracy score of test is  0.6972468570510504\n",
      "True positive rate of class 1 is  0.636\n",
      "True positive rate of class 2 is  0.592\n",
      "Positive prediction rate of class 1 is  0.294\n",
      "Positive prediction rate of class 2 is  0.23\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.40199999999999997\n",
      "threshold:0.2, J-value:0.265\n",
      "threshold:0.30000000000000004, J-value:0.087\n",
      "threshold:0.4, J-value:0.016\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7009886203517606\n",
      "Balanced accuracy score of test is  0.7048780223164494\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.392\n",
      "threshold:0.2, J-value:0.272\n",
      "threshold:0.30000000000000004, J-value:0.10200000000000001\n",
      "threshold:0.4, J-value:0.014000000000000002\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6959279354338648\n",
      "Balanced accuracy score of test is  0.6867884283978868\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.3960000000000001\n",
      "threshold:0.2, J-value:0.259\n",
      "threshold:0.30000000000000004, J-value:0.088\n",
      "threshold:0.4, J-value:0.018000000000000002\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6978876048642506\n",
      "Balanced accuracy score of test is  0.7072161304574849\n",
      "True positive rate of class 1 is  0.756\n",
      "True positive rate of class 2 is  0.699\n",
      "Positive prediction rate of class 1 is  0.424\n",
      "Positive prediction rate of class 2 is  0.318\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.352\n",
      "threshold:0.2, J-value:0.138\n",
      "threshold:0.30000000000000004, J-value:0.086\n",
      "threshold:0.4, J-value:0.0\n",
      "threshold:0.5, J-value:-0.001\n",
      "threshold:0.6000000000000001, J-value:-0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6756478518727556\n",
      "Balanced accuracy score of test is  0.6807623132071493\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.34600000000000003\n",
      "threshold:0.2, J-value:0.134\n",
      "threshold:0.30000000000000004, J-value:0.08299999999999999\n",
      "threshold:0.4, J-value:-0.002\n",
      "threshold:0.5, J-value:-0.001\n",
      "threshold:0.6000000000000001, J-value:-0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.673093572786668\n",
      "Balanced accuracy score of test is  0.6728028784465376\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.349\n",
      "threshold:0.2, J-value:0.141\n",
      "threshold:0.30000000000000004, J-value:0.088\n",
      "threshold:0.4, J-value:0.001\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6746478334098913\n",
      "Balanced accuracy score of test is  0.6830871189299916\n",
      "True positive rate of class 1 is  0.635\n",
      "True positive rate of class 2 is  0.603\n",
      "Positive prediction rate of class 1 is  0.328\n",
      "Positive prediction rate of class 2 is  0.267\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.404\n",
      "threshold:0.2, J-value:0.258\n",
      "threshold:0.30000000000000004, J-value:0.149\n",
      "threshold:0.4, J-value:0.07\n",
      "threshold:0.5, J-value:0.021\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7019370955985386\n",
      "Balanced accuracy score of test is  0.7029181886751471\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.40700000000000003\n",
      "threshold:0.2, J-value:0.261\n",
      "threshold:0.30000000000000004, J-value:0.153\n",
      "threshold:0.4, J-value:0.07300000000000001\n",
      "threshold:0.5, J-value:0.026000000000000002\n",
      "threshold:0.6000000000000001, J-value:0.005\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7032853560326149\n",
      "Balanced accuracy score of test is  0.6926552703520401\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.39599999999999996\n",
      "threshold:0.2, J-value:0.254\n",
      "threshold:0.30000000000000004, J-value:0.14500000000000002\n",
      "threshold:0.4, J-value:0.067\n",
      "threshold:0.5, J-value:0.016\n",
      "threshold:0.6000000000000001, J-value:0.002\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.697669213225991\n",
      "Balanced accuracy score of test is  0.7063909306342129\n",
      "True positive rate of class 1 is  0.651\n",
      "True positive rate of class 2 is  0.617\n",
      "Positive prediction rate of class 1 is  0.309\n",
      "Positive prediction rate of class 2 is  0.238\n"
     ]
    }
   ],
   "source": [
    "records_lr = []\n",
    "records_rf = []\n",
    "records_dt = []\n",
    "records_gbt = []\n",
    "for random_state in range(10):\n",
    "    fairness_metrics (X, y, \"GENDER\", random_state)\n",
    "\n",
    "result_lr = pd.DataFrame(records_lr)\n",
    "result_rf = pd.DataFrame(records_rf)\n",
    "result_dt = pd.DataFrame(records_dt)\n",
    "result_gbt = pd.DataFrame(records_gbt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def add_mean_sd(records, result_table, overall_records, type):\n",
    "    records.append({\n",
    "        'auroc': result_table[\"auroc\"].mean(),\n",
    "        'overall threshold': result_table[\"overall threshold\"].mean(),\n",
    "        'male threshold': result_table[\"male threshold\"].mean(),\n",
    "        'female threshold': result_table[\"female threshold\"].mean(),\n",
    "        'overall ba validation': result_table[\"overall ba validation\"].mean(),\n",
    "        'overall ba test': result_table[\"overall ba test\"].mean(),\n",
    "        'male ba validation': result_table[\"male ba validation\"].mean(),\n",
    "        'male ba test': result_table[\"male ba test\"].mean(),\n",
    "        'female ba validation': result_table[\"female ba validation\"].mean(),\n",
    "        'female ba test': result_table[\"female ba test\"].mean(),\n",
    "        'overall precision':result_table[\"overall precision\"].mean(),\n",
    "        'overall recall':result_table[\"overall recall\"].mean(),\n",
    "        'overall tpr':result_table[\"overall tpr\"].mean(),\n",
    "        'overall tnr':result_table[\"overall tnr\"].mean(),\n",
    "        'overall pd':result_table[\"overall pd\"].mean(),\n",
    "        'male precision':result_table[\"male precision\"].mean(),\n",
    "        'male recall':result_table[\"male recall\"].mean(),\n",
    "        'male tpr':result_table[\"male tpr\"].mean(),\n",
    "        'male tnr':result_table[\"male tnr\"].mean(),\n",
    "        'male pd':result_table[\"male pd\"].mean(),\n",
    "        'female precision':result_table[\"female precision\"].mean(),\n",
    "        'female recall':result_table[\"female recall\"].mean(),\n",
    "        'female tpr':result_table[\"female tpr\"].mean(),\n",
    "        'female tnr':result_table[\"female tnr\"].mean(),\n",
    "        'female pd':result_table[\"female pd\"].mean(),\n",
    "        'eod': result_table[\"eod\"].mean(),\n",
    "        'di': result_table[\"di\"].mean(),\n",
    "        })\n",
    "    records.append({\n",
    "        'auroc': result_table[\"auroc\"].std(),\n",
    "        'overall threshold': result_table[\"overall threshold\"].std(),\n",
    "        'male threshold': result_table[\"male threshold\"].std(),\n",
    "        'female threshold': result_table[\"female threshold\"].std(),\n",
    "        'overall ba validation': result_table[\"overall ba validation\"].std(),\n",
    "        'overall ba test': result_table[\"overall ba test\"].std(),\n",
    "        'male ba validation': result_table[\"male ba validation\"].std(),\n",
    "        'male ba test': result_table[\"male ba test\"].std(),\n",
    "        'female ba validation': result_table[\"female ba validation\"].std(),\n",
    "        'female ba test': result_table[\"female ba test\"].std(),\n",
    "        'overall precision':result_table[\"overall precision\"].std(),\n",
    "        'overall recall':result_table[\"overall recall\"].std(),\n",
    "        'overall tpr':result_table[\"overall tpr\"].std(),\n",
    "        'overall tnr':result_table[\"overall tnr\"].std(),\n",
    "        'overall pd':result_table[\"overall pd\"].std(),\n",
    "        'male precision':result_table[\"male precision\"].std(),\n",
    "        'male recall':result_table[\"male recall\"].std(),\n",
    "        'male tpr':result_table[\"male tpr\"].std(),\n",
    "        'male tnr':result_table[\"male tnr\"].std(),\n",
    "        'male pd':result_table[\"male pd\"].std(),\n",
    "        'female precision':result_table[\"female precision\"].std(),\n",
    "        'female recall':result_table[\"female recall\"].std(),\n",
    "        'female tpr':result_table[\"female tpr\"].std(),\n",
    "        'female tnr':result_table[\"female tnr\"].std(),\n",
    "        'female pd':result_table[\"female pd\"].std(),\n",
    "        'eod': result_table[\"eod\"].std(),\n",
    "        'di': result_table[\"di\"].std(),\n",
    "        })\n",
    "    overall_records.append({\n",
    "        'type': type,\n",
    "        'auroc': result_table[\"auroc\"].mean(),\n",
    "        'overall threshold': result_table[\"overall threshold\"].mean(),\n",
    "        'male threshold': result_table[\"male threshold\"].mean(),\n",
    "        'female threshold': result_table[\"female threshold\"].mean(),\n",
    "        'overall ba test': result_table[\"overall ba test\"].mean(),\n",
    "        'male ba test': result_table[\"male ba test\"].mean(),\n",
    "        'female ba test': result_table[\"female ba test\"].mean(),\n",
    "        'overall tpr':result_table[\"overall tpr\"].mean(),\n",
    "        'overall pd':result_table[\"overall pd\"].mean(),\n",
    "        'male tpr':result_table[\"male tpr\"].mean(),\n",
    "        'male pd':result_table[\"male pd\"].mean(),\n",
    "        'female tpr':result_table[\"female tpr\"].mean(),\n",
    "        'female pd':result_table[\"female pd\"].mean(),\n",
    "        'eod': result_table[\"eod\"].mean(),\n",
    "        'di': result_table[\"di\"].mean(),\n",
    "        })\n",
    "    pd_result = pd.DataFrame(records)\n",
    "    return pd_result, overall_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_table = []\n",
    "result_lr, overall_records = add_mean_sd (records_lr, result_lr, overall_table, 'lr')\n",
    "result_rf, overall_records = add_mean_sd (records_rf, result_rf, overall_records, 'rf')\n",
    "result_dt, overall_records = add_mean_sd (records_dt, result_dt, overall_records, 'dt')\n",
    "result_gbt, overall_records = add_mean_sd (records_gbt, result_gbt, overall_records, 'gbt')\n",
    "\n",
    "result_path='/Users/lifuchen/Desktop/research/resample_data/'\n",
    "result_lr.to_csv(path.join(result_path,'gender-lr-resample-size-result.csv'), index=False)\n",
    "result_rf.to_csv(path.join(result_path,'gender-rf-resample-size-result.csv'), index=False)\n",
    "result_dt.to_csv(path.join(result_path,'gender-dt-resample-size-result.csv'), index=False)\n",
    "result_gbt.to_csv(path.join(result_path,'gender-gbt-resample-size-result.csv'), index=False)\n",
    "\n",
    "overall_result = pd.DataFrame(overall_table)\n",
    "result_path='/Users/lifuchen/Desktop/research/resample_result/'\n",
    "overall_result.to_csv(path.join(result_path,'gender-resample-size.csv'), index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
