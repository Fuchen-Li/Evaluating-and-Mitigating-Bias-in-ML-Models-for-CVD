{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import imblearn\n",
    "from os import path\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score\n",
    "import sklearn.preprocessing\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import src.lib.utility_classfier as uclf\n",
    "import src.lib.optimal_threhold_related as thres\n",
    "import src.lib.fairness_tests as fair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109490, 89)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path='/Users/lifuchen/Desktop/research/data.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109490, 87)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df.Class.values\n",
    "X = df.drop(['GRID','Class'], axis=1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def save_prediction(classifier, characteristic, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_male_scaled, y_val_male, X_test_male_scaled, y_test_male, X_val_female_scaled, y_val_female, X_test_female_scaled, y_test_female):\n",
    "    method_to_call = getattr(uclf, classifier)\n",
    "    y_val_score = method_to_call(X_train_scaled, y_train,X_val_scaled, y_val)\n",
    "    y_test_score = method_to_call(X_train_scaled, y_train,X_test_scaled, y_test)\n",
    "\n",
    "    y_val_score_male = method_to_call(X_train_scaled, y_train, X_val_male_scaled, y_val_male)\n",
    "    y_test_score_male = method_to_call(X_train_scaled, y_train,X_test_male_scaled, y_test_male)\n",
    "\n",
    "    y_val_score_female = method_to_call(X_train_scaled, y_train, X_val_female_scaled, y_val_female)\n",
    "    y_test_score_female = method_to_call(X_train_scaled, y_train,X_test_female_scaled, y_test_female)\n",
    "\n",
    "    my_dict = dict(val_score = y_val_score, test_score = y_test_score, val_1_score = y_val_score_male, test_1_score = y_test_score_male, val_2_score = y_val_score_female, test_2_score = y_test_score_female)\n",
    "    overall_prediction = pd.DataFrame.from_dict(my_dict, orient='index')\n",
    "    overall_prediction = overall_prediction.transpose()\n",
    "\n",
    "    result_path='/Users/lifuchen/Desktop/research/predictions/'\n",
    "    filename = str(classifier) + str(characteristic) + \"prediction.csv\"\n",
    "    overall_prediction.to_csv(path.join(result_path, filename), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_result (classifier, characteristic, records, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_male_scaled, y_val_male, X_test_male_scaled, y_test_male, X_val_female_scaled, y_val_female, X_test_female_scaled, y_test_female):\n",
    "    result_path='/Users/lifuchen/Desktop/research/predictions/'\n",
    "    filename = str(classifier) + characteristic + \"prediction.csv\"\n",
    "    prediction = pd.read_csv(path.join(result_path, filename))\n",
    "\n",
    "    y_val_score = prediction['val_score'][prediction['val_score'].notna()]\n",
    "    y_test_score = prediction['test_score'][prediction['test_score'].notna()]\n",
    "\n",
    "    y_val_score_male = prediction['val_1_score'][prediction['val_1_score'].notna()]\n",
    "    y_test_score_male = prediction['test_1_score'][prediction['test_1_score'].notna()]\n",
    "\n",
    "    y_val_score_female = prediction['val_2_score'][prediction['val_2_score'].notna()]\n",
    "    y_test_score_female = prediction['test_2_score'][prediction['test_2_score'].notna()]\n",
    "\n",
    "    threshold, ba_val, ba_test = balance_accuracy (y_val, y_val_score,y_test, y_test_score)\n",
    "    auroc = roc_auc_score(y_test, y_test_score)\n",
    "    precision, recall, tpr, tnr, pd_overall = thres.calculate_precision_metrics(y_test, y_test_score,threshold)\n",
    "\n",
    "    threshold_male, ba_val_male, ba_test_male = balance_accuracy (y_val_male, y_val_score_male,y_test_male, y_test_score_male)\n",
    "    precision_male, recall_male, tpr_male, tnr_male, pd_male = thres.calculate_precision_metrics(y_test_male, y_test_score_male,threshold_male)\n",
    "\n",
    "    threshold_female, ba_val_female, ba_test_female = balance_accuracy (y_val_female, y_val_score_female, y_test_female, y_test_score_female)\n",
    "    precision_female, recall_female, tpr_female, tnr_female, pd_female = thres.calculate_precision_metrics(y_test_female, y_test_score_female,threshold_female)\n",
    "\n",
    "    eod = fair.get_EOD(y_test_male, y_test_score_male,threshold_male, y_test_female, y_test_score_female, threshold_female)\n",
    "    sp = fair.get_SP(y_test_male, y_test_score_male,threshold_male, y_test_female, y_test_score_female, threshold_female)\n",
    "\n",
    "    records.append({\n",
    "        'auroc': auroc,\n",
    "        'overall threshold': threshold,\n",
    "        'male threshold': threshold_male,\n",
    "        'female threshold': threshold_female,\n",
    "        'overall ba validation': ba_val,\n",
    "        'overall ba test': ba_test,\n",
    "        'male ba validation': ba_val_male,\n",
    "        'male ba test': ba_test_male,\n",
    "        'female ba validation': ba_val_female,\n",
    "        'female ba test': ba_test_female,\n",
    "        'overall precision':precision,\n",
    "        'overall recall':recall,\n",
    "        'overall tpr':tpr,\n",
    "        'overall tnr':tnr,\n",
    "        'overall pd':pd_overall,\n",
    "        'male precision':precision_male,\n",
    "        'male recall':recall_male,\n",
    "        'male tpr':tpr_male,\n",
    "        'male tnr':tnr_male,\n",
    "        'male pd':pd_male,\n",
    "        'female precision':precision_female,\n",
    "        'female recall':recall_female,\n",
    "        'female tpr':tpr_female,\n",
    "        'female tnr':tnr_female,\n",
    "        'female pd':pd_female,\n",
    "        'eod': eod,\n",
    "        'di': sp,\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def balance_accuracy (y_val, y_val_score,y_test, y_test_score):\n",
    "    \n",
    "    threshold, _ = thres.get_optimal_threshold_Jvalue (y_val, y_val_score)\n",
    "    print (\"Optimal threshold by J value is \",threshold)\n",
    "\n",
    "    ba_val = thres.calculate_balanced_accuracy(y_val, y_val_score, threshold)\n",
    "    print (\"Balanced accuracy score of val is \", ba_val)\n",
    "\n",
    "    ba_test = thres.calculate_balanced_accuracy(y_test, y_test_score, threshold)\n",
    "    print (\"Balanced accuracy score of test is \",ba_test)\n",
    "\n",
    "    return threshold, ba_val, ba_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def fairness_metrics (X, y, attribute, random_state):\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, X_val_female, X_val_male, y_val_female, y_val_male, X_test_female, X_test_male, y_test_female, y_test_male \\\n",
    "        = fair.split_by_trait_balance_proportion(X, y, attribute, random_state)\n",
    "    print(\"X train\", X_train.shape[0])\n",
    "    print(\"Y train\", y_train.shape[0])\n",
    "    print(X_val.shape[0], X_val_male.shape[0], X_val_female.shape[0])\n",
    "    print(y_val.shape[0], y_val_male.shape[0], y_val_female.shape[0])\n",
    "    print(X_test.shape[0], X_test_male.shape[0], X_test_female.shape[0])\n",
    "    print(y_test.shape[0], y_test_male.shape[0], y_test_female.shape[0])\n",
    "\n",
    "    max_abs_scaler = preprocessing.MaxAbsScaler()\n",
    "    X_train_scaled = max_abs_scaler.fit_transform(X_train)\n",
    "    X_test_scaled = max_abs_scaler.transform(X_test)\n",
    "    X_test_male_scaled = max_abs_scaler.transform(X_test_male)\n",
    "    X_test_female_scaled = max_abs_scaler.transform(X_test_female)\n",
    "    X_val_scaled = max_abs_scaler.transform(X_val)\n",
    "    X_val_male_scaled = max_abs_scaler.transform(X_val_male)\n",
    "    X_val_female_scaled = max_abs_scaler.transform(X_val_female)\n",
    "\n",
    "    characteristic = attribute + \"resample-by-proportion\" + str(random_state)\n",
    "    save_prediction (\"logic_regression\", characteristic, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_male_scaled, y_val_male, X_test_male_scaled, y_test_male, X_val_female_scaled, y_val_female, X_test_female_scaled, y_test_female)\n",
    "    save_prediction (\"random_forest\", characteristic, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_male_scaled, y_val_male, X_test_male_scaled, y_test_male, X_val_female_scaled, y_val_female, X_test_female_scaled, y_test_female)\n",
    "    save_prediction (\"decision_tree\", characteristic, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_male_scaled, y_val_male, X_test_male_scaled, y_test_male, X_val_female_scaled, y_val_female, X_test_female_scaled, y_test_female)\n",
    "    save_prediction (\"gradiant_boosting\", characteristic, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_male_scaled, y_val_male, X_test_male_scaled, y_test_male, X_val_female_scaled, y_val_female, X_test_female_scaled, y_test_female)\n",
    "\n",
    "    get_result (\"logic_regression\", characteristic, records_lr, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_male_scaled, y_val_male, X_test_male_scaled, y_test_male, X_val_female_scaled, y_val_female, X_test_female_scaled, y_test_female)\n",
    "    get_result (\"random_forest\", characteristic, records_rf, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_male_scaled, y_val_male, X_test_male_scaled, y_test_male, X_val_female_scaled, y_val_female, X_test_female_scaled, y_test_female)\n",
    "    get_result (\"decision_tree\", characteristic, records_dt, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_male_scaled, y_val_male, X_test_male_scaled, y_test_male, X_val_female_scaled, y_val_female, X_test_female_scaled, y_test_female)\n",
    "    get_result (\"gradiant_boosting\", characteristic, records_gbt, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_male_scaled, y_val_male, X_test_male_scaled, y_test_male, X_val_female_scaled, y_val_female, X_test_female_scaled, y_test_female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lifuchen/Desktop/research/CVDPrediction-master/src/lib/fairness_tests.py:125: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train ['Class'] = y_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23364, 88)\n",
      "(42330, 88)\n",
      "0.12175917034760898 0.08538461538461538\n",
      "0.12174358974358974\n",
      "(67112, 87)\n",
      "X train 67112\n",
      "Y train 67112\n",
      "21898 7782 14116\n",
      "21898 7782 14116\n",
      "21898 7707 14191\n",
      "21898 7707 14191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29028900897007237\n",
      "0.26614654912872004\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19904\n",
      "           1       0.44      0.03      0.06      1994\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.52      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19817    87]\n",
      " [ 1925    69]]\n",
      "done in 1.598602s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29028900897007237\n",
      "0.2680579828493057\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95     19934\n",
      "           1       0.38      0.03      0.06      1964\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.65      0.51      0.51     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19831   103]\n",
      " [ 1901    63]]\n",
      "done in 1.625877s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29028900897007237\n",
      "0.3076115813869865\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6915\n",
      "           1       0.45      0.03      0.05       867\n",
      "\n",
      "    accuracy                           0.89      7782\n",
      "   macro avg       0.67      0.51      0.50      7782\n",
      "weighted avg       0.84      0.89      0.84      7782\n",
      "\n",
      "Confusion_matrix\n",
      "[[6887   28]\n",
      " [ 844   23]]\n",
      "done in 1.443381s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29028900897007237\n",
      "0.30550992561968643\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6860\n",
      "           1       0.44      0.02      0.05       847\n",
      "\n",
      "    accuracy                           0.89      7707\n",
      "   macro avg       0.66      0.51      0.49      7707\n",
      "weighted avg       0.84      0.89      0.84      7707\n",
      "\n",
      "Confusion_matrix\n",
      "[[6833   27]\n",
      " [ 826   21]]\n",
      "done in 1.334855s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29028900897007237\n",
      "0.24328731981207016\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12989\n",
      "           1       0.44      0.04      0.07      1127\n",
      "\n",
      "    accuracy                           0.92     14116\n",
      "   macro avg       0.68      0.52      0.52     14116\n",
      "weighted avg       0.88      0.92      0.89     14116\n",
      "\n",
      "Confusion_matrix\n",
      "[[12930    59]\n",
      " [ 1081    46]]\n",
      "done in 1.482766s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29028900897007237\n",
      "0.24771818136024057\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96     13074\n",
      "           1       0.36      0.04      0.07      1117\n",
      "\n",
      "    accuracy                           0.92     14191\n",
      "   macro avg       0.64      0.52      0.51     14191\n",
      "weighted avg       0.88      0.92      0.89     14191\n",
      "\n",
      "Confusion_matrix\n",
      "[[12998    76]\n",
      " [ 1075    42]]\n",
      "done in 1.885038s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19904\n",
      "           1       0.42      0.01      0.01      1994\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19889    15]\n",
      " [ 1983    11]]\n",
      "done in 22.343959s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19934\n",
      "           1       0.36      0.00      0.01      1964\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.63      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19925     9]\n",
      " [ 1959     5]]\n",
      "done in 22.477599s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6915\n",
      "           1       0.20      0.00      0.00       867\n",
      "\n",
      "    accuracy                           0.89      7782\n",
      "   macro avg       0.54      0.50      0.47      7782\n",
      "weighted avg       0.81      0.89      0.84      7782\n",
      "\n",
      "Confusion_matrix\n",
      "[[6907    8]\n",
      " [ 865    2]]\n",
      "done in 22.399876s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6860\n",
      "           1       0.43      0.00      0.01       847\n",
      "\n",
      "    accuracy                           0.89      7707\n",
      "   macro avg       0.66      0.50      0.47      7707\n",
      "weighted avg       0.84      0.89      0.84      7707\n",
      "\n",
      "Confusion_matrix\n",
      "[[6856    4]\n",
      " [ 844    3]]\n",
      "done in 23.488679s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12989\n",
      "           1       0.45      0.00      0.01      1127\n",
      "\n",
      "    accuracy                           0.92     14116\n",
      "   macro avg       0.69      0.50      0.48     14116\n",
      "weighted avg       0.88      0.92      0.88     14116\n",
      "\n",
      "Confusion_matrix\n",
      "[[12983     6]\n",
      " [ 1122     5]]\n",
      "done in 23.787169s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13074\n",
      "           1       0.25      0.00      0.01      1117\n",
      "\n",
      "    accuracy                           0.92     14191\n",
      "   macro avg       0.59      0.50      0.48     14191\n",
      "weighted avg       0.87      0.92      0.88     14191\n",
      "\n",
      "Confusion_matrix\n",
      "[[13065     9]\n",
      " [ 1114     3]]\n",
      "done in 23.373421s\n",
      "0.3018115853691867\n",
      "0.275613083738007\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19904\n",
      "           1       0.00      0.00      0.00      1994\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.45      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19903     1]\n",
      " [ 1994     0]]\n",
      "done in 0.793887s\n",
      "0.3018115853691867\n",
      "0.2781652584175675\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19934\n",
      "           1       0.00      0.00      0.00      1964\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.46      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19929     5]\n",
      " [ 1964     0]]\n",
      "done in 0.779659s\n",
      "0.3018115853691867\n",
      "0.3186316669460859\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6915\n",
      "           1       0.00      0.00      0.00       867\n",
      "\n",
      "    accuracy                           0.89      7782\n",
      "   macro avg       0.44      0.50      0.47      7782\n",
      "weighted avg       0.79      0.89      0.84      7782\n",
      "\n",
      "Confusion_matrix\n",
      "[[6915    0]\n",
      " [ 867    0]]\n",
      "done in 0.701176s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3018115853691867\n",
      "0.321895849803165\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6860\n",
      "           1       0.00      0.00      0.00       847\n",
      "\n",
      "    accuracy                           0.89      7707\n",
      "   macro avg       0.45      0.50      0.47      7707\n",
      "weighted avg       0.79      0.89      0.84      7707\n",
      "\n",
      "Confusion_matrix\n",
      "[[6857    3]\n",
      " [ 847    0]]\n",
      "done in 0.675675s\n",
      "0.3018115853691867\n",
      "0.2518973983791752\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12989\n",
      "           1       0.00      0.00      0.00      1127\n",
      "\n",
      "    accuracy                           0.92     14116\n",
      "   macro avg       0.46      0.50      0.48     14116\n",
      "weighted avg       0.85      0.92      0.88     14116\n",
      "\n",
      "Confusion_matrix\n",
      "[[12988     1]\n",
      " [ 1127     0]]\n",
      "done in 0.670813s\n",
      "0.3018115853691867\n",
      "0.25441558131173986\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13074\n",
      "           1       0.00      0.00      0.00      1117\n",
      "\n",
      "    accuracy                           0.92     14191\n",
      "   macro avg       0.46      0.50      0.48     14191\n",
      "weighted avg       0.85      0.92      0.88     14191\n",
      "\n",
      "Confusion_matrix\n",
      "[[13072     2]\n",
      " [ 1117     0]]\n",
      "done in 0.689844s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19904\n",
      "           1       0.44      0.01      0.01      1994\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19885    19]\n",
      " [ 1979    15]]\n",
      "done in 40.069551s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19934\n",
      "           1       0.39      0.01      0.02      1964\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.65      0.50      0.49     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19899    35]\n",
      " [ 1942    22]]\n",
      "done in 40.598462s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6915\n",
      "           1       0.50      0.01      0.02       867\n",
      "\n",
      "    accuracy                           0.89      7782\n",
      "   macro avg       0.69      0.50      0.48      7782\n",
      "weighted avg       0.85      0.89      0.84      7782\n",
      "\n",
      "Confusion_matrix\n",
      "[[6906    9]\n",
      " [ 858    9]]\n",
      "done in 39.488352s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6860\n",
      "           1       0.46      0.01      0.03       847\n",
      "\n",
      "    accuracy                           0.89      7707\n",
      "   macro avg       0.68      0.51      0.48      7707\n",
      "weighted avg       0.84      0.89      0.84      7707\n",
      "\n",
      "Confusion_matrix\n",
      "[[6846   14]\n",
      " [ 835   12]]\n",
      "done in 38.404812s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12989\n",
      "           1       0.38      0.01      0.01      1127\n",
      "\n",
      "    accuracy                           0.92     14116\n",
      "   macro avg       0.65      0.50      0.48     14116\n",
      "weighted avg       0.88      0.92      0.88     14116\n",
      "\n",
      "Confusion_matrix\n",
      "[[12979    10]\n",
      " [ 1121     6]]\n",
      "done in 38.192806s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13074\n",
      "           1       0.33      0.01      0.02      1117\n",
      "\n",
      "    accuracy                           0.92     14191\n",
      "   macro avg       0.63      0.50      0.49     14191\n",
      "weighted avg       0.88      0.92      0.88     14191\n",
      "\n",
      "Confusion_matrix\n",
      "[[13054    20]\n",
      " [ 1107    10]]\n",
      "done in 38.810878s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.407\n",
      "threshold:0.2, J-value:0.28500000000000003\n",
      "threshold:0.30000000000000004, J-value:0.152\n",
      "threshold:0.4, J-value:0.07200000000000001\n",
      "threshold:0.5, J-value:0.031000000000000003\n",
      "threshold:0.6000000000000001, J-value:0.012\n",
      "threshold:0.7000000000000001, J-value:0.003\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7034092631592527\n",
      "Balanced accuracy score of test is  0.6919651550728402\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.377\n",
      "threshold:0.2, J-value:0.254\n",
      "threshold:0.30000000000000004, J-value:0.11800000000000001\n",
      "threshold:0.4, J-value:0.048\n",
      "threshold:0.5, J-value:0.023\n",
      "threshold:0.6000000000000001, J-value:0.008\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6887316825415888\n",
      "Balanced accuracy score of test is  0.6861931667590295\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.419\n",
      "threshold:0.2, J-value:0.305\n",
      "threshold:0.30000000000000004, J-value:0.177\n",
      "threshold:0.4, J-value:0.091\n",
      "threshold:0.5, J-value:0.036000000000000004\n",
      "threshold:0.6000000000000001, J-value:0.015\n",
      "threshold:0.7000000000000001, J-value:0.004\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.709671168758385\n",
      "Balanced accuracy score of test is  0.690930381963204\n",
      "True positive rate of class 1 is  0.757\n",
      "True positive rate of class 2 is  0.696\n",
      "Positive prediction rate of class 1 is  0.425\n",
      "Positive prediction rate of class 2 is  0.344\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.386\n",
      "threshold:0.2, J-value:0.299\n",
      "threshold:0.30000000000000004, J-value:0.121\n",
      "threshold:0.4, J-value:0.036000000000000004\n",
      "threshold:0.5, J-value:0.005\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6927062588488939\n",
      "Balanced accuracy score of test is  0.6839267903838266\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.36800000000000005\n",
      "threshold:0.2, J-value:0.29000000000000004\n",
      "threshold:0.30000000000000004, J-value:0.111\n",
      "threshold:0.4, J-value:0.039\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6839459376962473\n",
      "Balanced accuracy score of test is  0.674477748596487\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.383\n",
      "threshold:0.2, J-value:0.298\n",
      "threshold:0.30000000000000004, J-value:0.128\n",
      "threshold:0.4, J-value:0.036000000000000004\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.002\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6916473860244725\n",
      "Balanced accuracy score of test is  0.6857970448226054\n",
      "True positive rate of class 1 is  0.808\n",
      "True positive rate of class 2 is  0.73\n",
      "Positive prediction rate of class 1 is  0.497\n",
      "Positive prediction rate of class 2 is  0.387\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.374\n",
      "threshold:0.2, J-value:0.21800000000000003\n",
      "threshold:0.30000000000000004, J-value:0.123\n",
      "threshold:0.4, J-value:0.028999999999999998\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6869737780463576\n",
      "Balanced accuracy score of test is  0.6790769519046254\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.331\n",
      "threshold:0.2, J-value:0.194\n",
      "threshold:0.30000000000000004, J-value:0.11099999999999999\n",
      "threshold:0.4, J-value:0.04\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6651724974792775\n",
      "Balanced accuracy score of test is  0.6623057369346794\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.393\n",
      "threshold:0.2, J-value:0.23500000000000001\n",
      "threshold:0.30000000000000004, J-value:0.132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.4, J-value:0.018000000000000002\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6965412273288647\n",
      "Balanced accuracy score of test is  0.6831173737429348\n",
      "True positive rate of class 1 is  0.808\n",
      "True positive rate of class 2 is  0.736\n",
      "Positive prediction rate of class 1 is  0.519\n",
      "Positive prediction rate of class 2 is  0.398\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41700000000000004\n",
      "threshold:0.2, J-value:0.305\n",
      "threshold:0.30000000000000004, J-value:0.141\n",
      "threshold:0.4, J-value:0.047\n",
      "threshold:0.5, J-value:0.007\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7086646293381753\n",
      "Balanced accuracy score of test is  0.6943577757720641\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.391\n",
      "threshold:0.2, J-value:0.294\n",
      "threshold:0.30000000000000004, J-value:0.124\n",
      "threshold:0.4, J-value:0.040999999999999995\n",
      "threshold:0.5, J-value:0.009000000000000001\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6955430124072086\n",
      "Balanced accuracy score of test is  0.6833710816085584\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.425\n",
      "threshold:0.2, J-value:0.309\n",
      "threshold:0.30000000000000004, J-value:0.151\n",
      "threshold:0.4, J-value:0.052\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7122802291994667\n",
      "Balanced accuracy score of test is  0.6950668113427472\n",
      "True positive rate of class 1 is  0.784\n",
      "True positive rate of class 2 is  0.707\n",
      "Positive prediction rate of class 1 is  0.458\n",
      "Positive prediction rate of class 2 is  0.348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lifuchen/Desktop/research/CVDPrediction-master/src/lib/fairness_tests.py:125: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train ['Class'] = y_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23381, 88)\n",
      "(42313, 88)\n",
      "0.12489776280971855 0.0869274833671556\n",
      "0.12489403786380333\n",
      "(67172, 87)\n",
      "X train 67172\n",
      "Y train 67172\n",
      "21898 7665 14233\n",
      "21898 7665 14233\n",
      "21898 7807 14091\n",
      "21898 7807 14091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2937187489738977\n",
      "0.26067048133064985\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19980\n",
      "           1       0.41      0.03      0.06      1918\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.66      0.51      0.51     21898\n",
      "weighted avg       0.87      0.91      0.88     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19895    85]\n",
      " [ 1858    60]]\n",
      "done in 1.206413s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2937187489738977\n",
      "0.26147172173620603\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19972\n",
      "           1       0.42      0.03      0.06      1926\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19888    84]\n",
      " [ 1865    61]]\n",
      "done in 1.546673s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2937187489738977\n",
      "0.2992847910171212\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6836\n",
      "           1       0.47      0.03      0.05       829\n",
      "\n",
      "    accuracy                           0.89      7665\n",
      "   macro avg       0.68      0.51      0.50      7665\n",
      "weighted avg       0.85      0.89      0.85      7665\n",
      "\n",
      "Confusion_matrix\n",
      "[[6810   26]\n",
      " [ 806   23]]\n",
      "done in 1.402071s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2937187489738977\n",
      "0.2986713641514027\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.94      6982\n",
      "           1       0.35      0.02      0.04       825\n",
      "\n",
      "    accuracy                           0.89      7807\n",
      "   macro avg       0.62      0.51      0.49      7807\n",
      "weighted avg       0.84      0.89      0.85      7807\n",
      "\n",
      "Confusion_matrix\n",
      "[[6948   34]\n",
      " [ 807   18]]\n",
      "done in 1.166986s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2937187489738977\n",
      "0.23987523902426308\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96     13144\n",
      "           1       0.39      0.03      0.06      1089\n",
      "\n",
      "    accuracy                           0.92     14233\n",
      "   macro avg       0.66      0.51      0.51     14233\n",
      "weighted avg       0.88      0.92      0.89     14233\n",
      "\n",
      "Confusion_matrix\n",
      "[[13085    59]\n",
      " [ 1052    37]]\n",
      "done in 1.202951s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2937187489738977\n",
      "0.24086157282303877\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12990\n",
      "           1       0.46      0.04      0.07      1101\n",
      "\n",
      "    accuracy                           0.92     14091\n",
      "   macro avg       0.69      0.52      0.52     14091\n",
      "weighted avg       0.89      0.92      0.89     14091\n",
      "\n",
      "Confusion_matrix\n",
      "[[12940    50]\n",
      " [ 1058    43]]\n",
      "done in 1.189059s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19980\n",
      "           1       0.50      0.00      0.01      1918\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.71      0.50      0.48     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19973     7]\n",
      " [ 1911     7]]\n",
      "done in 22.457220s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19972\n",
      "           1       0.45      0.01      0.01      1926\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19960    12]\n",
      " [ 1916    10]]\n",
      "done in 22.258238s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6836\n",
      "           1       0.80      0.00      0.01       829\n",
      "\n",
      "    accuracy                           0.89      7665\n",
      "   macro avg       0.85      0.50      0.48      7665\n",
      "weighted avg       0.88      0.89      0.84      7665\n",
      "\n",
      "Confusion_matrix\n",
      "[[6835    1]\n",
      " [ 825    4]]\n",
      "done in 21.818358s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6982\n",
      "           1       0.60      0.00      0.01       825\n",
      "\n",
      "    accuracy                           0.89      7807\n",
      "   macro avg       0.75      0.50      0.48      7807\n",
      "weighted avg       0.86      0.89      0.85      7807\n",
      "\n",
      "Confusion_matrix\n",
      "[[6980    2]\n",
      " [ 822    3]]\n",
      "done in 21.988829s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13144\n",
      "           1       0.25      0.00      0.00      1089\n",
      "\n",
      "    accuracy                           0.92     14233\n",
      "   macro avg       0.59      0.50      0.48     14233\n",
      "weighted avg       0.87      0.92      0.89     14233\n",
      "\n",
      "Confusion_matrix\n",
      "[[13141     3]\n",
      " [ 1088     1]]\n",
      "done in 21.960178s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12990\n",
      "           1       0.50      0.00      0.01      1101\n",
      "\n",
      "    accuracy                           0.92     14091\n",
      "   macro avg       0.71      0.50      0.48     14091\n",
      "weighted avg       0.89      0.92      0.89     14091\n",
      "\n",
      "Confusion_matrix\n",
      "[[12985     5]\n",
      " [ 1096     5]]\n",
      "done in 21.387679s\n",
      "0.3065053161792803\n",
      "0.27357216941318463\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19980\n",
      "           1       0.00      0.00      0.00      1918\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.46      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19978     2]\n",
      " [ 1918     0]]\n",
      "done in 0.737952s\n",
      "0.3065053161792803\n",
      "0.27059923885290704\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19972\n",
      "           1       0.00      0.00      0.00      1926\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.46      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19972     0]\n",
      " [ 1926     0]]\n",
      "done in 0.724547s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3065053161792803\n",
      "0.31664879115354827\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6836\n",
      "           1       0.00      0.00      0.00       829\n",
      "\n",
      "    accuracy                           0.89      7665\n",
      "   macro avg       0.45      0.50      0.47      7665\n",
      "weighted avg       0.80      0.89      0.84      7665\n",
      "\n",
      "Confusion_matrix\n",
      "[[6834    2]\n",
      " [ 829    0]]\n",
      "done in 0.814791s\n",
      "0.3065053161792803\n",
      "0.3077161980539386\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6982\n",
      "           1       0.00      0.00      0.00       825\n",
      "\n",
      "    accuracy                           0.89      7807\n",
      "   macro avg       0.45      0.50      0.47      7807\n",
      "weighted avg       0.80      0.89      0.84      7807\n",
      "\n",
      "Confusion_matrix\n",
      "[[6982    0]\n",
      " [ 825    0]]\n",
      "done in 0.691084s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3065053161792803\n",
      "0.25037380605761045\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13144\n",
      "           1       0.00      0.00      0.00      1089\n",
      "\n",
      "    accuracy                           0.92     14233\n",
      "   macro avg       0.46      0.50      0.48     14233\n",
      "weighted avg       0.85      0.92      0.89     14233\n",
      "\n",
      "Confusion_matrix\n",
      "[[13144     0]\n",
      " [ 1089     0]]\n",
      "done in 0.711840s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3065053161792803\n",
      "0.25248602303518347\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12990\n",
      "           1       0.00      0.00      0.00      1101\n",
      "\n",
      "    accuracy                           0.92     14091\n",
      "   macro avg       0.46      0.50      0.48     14091\n",
      "weighted avg       0.85      0.92      0.88     14091\n",
      "\n",
      "Confusion_matrix\n",
      "[[12989     1]\n",
      " [ 1101     0]]\n",
      "done in 0.661969s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19980\n",
      "           1       0.40      0.01      0.02      1918\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.66      0.50      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19956    24]\n",
      " [ 1902    16]]\n",
      "done in 38.045494s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19972\n",
      "           1       0.48      0.01      0.03      1926\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.70      0.51      0.49     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19944    28]\n",
      " [ 1900    26]]\n",
      "done in 37.837665s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6836\n",
      "           1       0.42      0.01      0.01       829\n",
      "\n",
      "    accuracy                           0.89      7665\n",
      "   macro avg       0.65      0.50      0.48      7665\n",
      "weighted avg       0.84      0.89      0.84      7665\n",
      "\n",
      "Confusion_matrix\n",
      "[[6829    7]\n",
      " [ 824    5]]\n",
      "done in 38.261209s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.94      6982\n",
      "           1       0.46      0.01      0.03       825\n",
      "\n",
      "    accuracy                           0.89      7807\n",
      "   macro avg       0.68      0.51      0.48      7807\n",
      "weighted avg       0.85      0.89      0.85      7807\n",
      "\n",
      "Confusion_matrix\n",
      "[[6969   13]\n",
      " [ 814   11]]\n",
      "done in 38.385740s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13144\n",
      "           1       0.39      0.01      0.02      1089\n",
      "\n",
      "    accuracy                           0.92     14233\n",
      "   macro avg       0.66      0.50      0.49     14233\n",
      "weighted avg       0.88      0.92      0.89     14233\n",
      "\n",
      "Confusion_matrix\n",
      "[[13127    17]\n",
      " [ 1078    11]]\n",
      "done in 37.850917s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12990\n",
      "           1       0.52      0.01      0.03      1101\n",
      "\n",
      "    accuracy                           0.92     14091\n",
      "   macro avg       0.72      0.51      0.49     14091\n",
      "weighted avg       0.89      0.92      0.89     14091\n",
      "\n",
      "Confusion_matrix\n",
      "[[12975    15]\n",
      " [ 1085    16]]\n",
      "done in 37.584755s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.39499999999999996\n",
      "threshold:0.2, J-value:0.298\n",
      "threshold:0.30000000000000004, J-value:0.178\n",
      "threshold:0.4, J-value:0.076\n",
      "threshold:0.5, J-value:0.027\n",
      "threshold:0.6000000000000001, J-value:0.009999999999999998\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6975379185233199\n",
      "Balanced accuracy score of test is  0.6938954931504313\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.387\n",
      "threshold:0.2, J-value:0.303\n",
      "threshold:0.30000000000000004, J-value:0.19\n",
      "threshold:0.4, J-value:0.066\n",
      "threshold:0.5, J-value:0.024\n",
      "threshold:0.6000000000000001, J-value:0.005\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6935329953323108\n",
      "Balanced accuracy score of test is  0.6779565636311554\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.39099999999999996\n",
      "threshold:0.2, J-value:0.29200000000000004\n",
      "threshold:0.30000000000000004, J-value:0.16899999999999998\n",
      "threshold:0.4, J-value:0.084\n",
      "threshold:0.5, J-value:0.030000000000000002\n",
      "threshold:0.6000000000000001, J-value:0.013999999999999999\n",
      "threshold:0.7000000000000001, J-value:0.003\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.69526082352882\n",
      "Balanced accuracy score of test is  0.7008821499665431\n",
      "True positive rate of class 1 is  0.738\n",
      "True positive rate of class 2 is  0.712\n",
      "Positive prediction rate of class 1 is  0.42\n",
      "Positive prediction rate of class 2 is  0.342\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.377\n",
      "threshold:0.2, J-value:0.31500000000000006\n",
      "threshold:0.30000000000000004, J-value:0.13899999999999998\n",
      "threshold:0.4, J-value:0.030000000000000002\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.688731901870588\n",
      "Balanced accuracy score of test is  0.6896370650998626\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.36099999999999993\n",
      "threshold:0.2, J-value:0.30999999999999994\n",
      "threshold:0.30000000000000004, J-value:0.141\n",
      "threshold:0.4, J-value:0.020999999999999998\n",
      "threshold:0.5, J-value:0.005\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6805765051409518\n",
      "Balanced accuracy score of test is  0.6666963533935748\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.378\n",
      "threshold:0.2, J-value:0.3\n",
      "threshold:0.30000000000000004, J-value:0.121\n",
      "threshold:0.4, J-value:0.024\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6892593491491018\n",
      "Balanced accuracy score of test is  0.6951062754204136\n",
      "True positive rate of class 1 is  0.795\n",
      "True positive rate of class 2 is  0.744\n",
      "Positive prediction rate of class 1 is  0.497\n",
      "Positive prediction rate of class 2 is  0.384\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.364\n",
      "threshold:0.2, J-value:0.264\n",
      "threshold:0.30000000000000004, J-value:0.125\n",
      "threshold:0.4, J-value:0.0\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6815368809894358\n",
      "Balanced accuracy score of test is  0.6728786344496002\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.34500000000000003\n",
      "threshold:0.2, J-value:0.253\n",
      "threshold:0.30000000000000004, J-value:0.137\n",
      "threshold:0.4, J-value:0.0\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6726851776693458\n",
      "Balanced accuracy score of test is  0.6641380866817704\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.366\n",
      "threshold:0.2, J-value:0.272\n",
      "threshold:0.30000000000000004, J-value:0.11300000000000002\n",
      "threshold:0.4, J-value:0.0\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6828172864594599\n",
      "Balanced accuracy score of test is  0.6738846482202827\n",
      "True positive rate of class 1 is  0.77\n",
      "True positive rate of class 2 is  0.709\n",
      "Positive prediction rate of class 1 is  0.476\n",
      "Positive prediction rate of class 2 is  0.389\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.399\n",
      "threshold:0.2, J-value:0.299\n",
      "threshold:0.30000000000000004, J-value:0.159\n",
      "threshold:0.4, J-value:0.044\n",
      "threshold:0.5, J-value:0.007\n",
      "threshold:0.6000000000000001, J-value:0.002\n",
      "threshold:0.7000000000000001, J-value:0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6993609876821556\n",
      "Balanced accuracy score of test is  0.7006197305511205\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.38100000000000006\n",
      "threshold:0.2, J-value:0.297\n",
      "threshold:0.30000000000000004, J-value:0.168\n",
      "threshold:0.4, J-value:0.045\n",
      "threshold:0.5, J-value:0.005\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6903832933007049\n",
      "Balanced accuracy score of test is  0.6898152825881271\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.39899999999999997\n",
      "threshold:0.2, J-value:0.297\n",
      "threshold:0.30000000000000004, J-value:0.153\n",
      "threshold:0.4, J-value:0.044\n",
      "threshold:0.5, J-value:0.009000000000000001\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6996938482372554\n",
      "Balanced accuracy score of test is  0.7028827456878378\n",
      "True positive rate of class 1 is  0.784\n",
      "True positive rate of class 2 is  0.726\n",
      "Positive prediction rate of class 1 is  0.445\n",
      "Positive prediction rate of class 2 is  0.352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lifuchen/Desktop/research/CVDPrediction-master/src/lib/fairness_tests.py:125: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train ['Class'] = y_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23370, 88)\n",
      "(42324, 88)\n",
      "0.12097083653108212 0.0856483262793382\n",
      "0.12096960369372836\n",
      "(67071, 87)\n",
      "X train 67071\n",
      "Y train 67071\n",
      "21898 7743 14155\n",
      "21898 7743 14155\n",
      "21898 7740 14158\n",
      "21898 7740 14158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28928392051221935\n",
      "0.26402943649647703\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19950\n",
      "           1       0.40      0.03      0.05      1948\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.66      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19867    83]\n",
      " [ 1893    55]]\n",
      "done in 1.250360s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28928392051221935\n",
      "0.2667004945044878\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19883\n",
      "           1       0.44      0.03      0.05      2015\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19816    67]\n",
      " [ 1963    52]]\n",
      "done in 1.224637s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28928392051221935\n",
      "0.304325342264293\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6895\n",
      "           1       0.43      0.02      0.05       848\n",
      "\n",
      "    accuracy                           0.89      7743\n",
      "   macro avg       0.66      0.51      0.49      7743\n",
      "weighted avg       0.84      0.89      0.84      7743\n",
      "\n",
      "Confusion_matrix\n",
      "[[6867   28]\n",
      " [ 827   21]]\n",
      "done in 1.151595s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28928392051221935\n",
      "0.30803488927585243\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6860\n",
      "           1       0.40      0.02      0.04       880\n",
      "\n",
      "    accuracy                           0.89      7740\n",
      "   macro avg       0.65      0.51      0.49      7740\n",
      "weighted avg       0.83      0.89      0.84      7740\n",
      "\n",
      "Confusion_matrix\n",
      "[[6835   25]\n",
      " [ 863   17]]\n",
      "done in 1.169829s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28928392051221935\n",
      "0.2419869639878089\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13055\n",
      "           1       0.38      0.03      0.06      1100\n",
      "\n",
      "    accuracy                           0.92     14155\n",
      "   macro avg       0.65      0.51      0.51     14155\n",
      "weighted avg       0.88      0.92      0.89     14155\n",
      "\n",
      "Confusion_matrix\n",
      "[[13000    55]\n",
      " [ 1066    34]]\n",
      "done in 1.180293s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28928392051221935\n",
      "0.24410350230711794\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13023\n",
      "           1       0.45      0.03      0.06      1135\n",
      "\n",
      "    accuracy                           0.92     14158\n",
      "   macro avg       0.69      0.51      0.51     14158\n",
      "weighted avg       0.88      0.92      0.89     14158\n",
      "\n",
      "Confusion_matrix\n",
      "[[12981    42]\n",
      " [ 1100    35]]\n",
      "done in 1.292248s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19950\n",
      "           1       0.39      0.00      0.01      1948\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.65      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19939    11]\n",
      " [ 1941     7]]\n",
      "done in 22.202573s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19883\n",
      "           1       0.50      0.00      0.00      2015\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.70      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.86     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19879     4]\n",
      " [ 2011     4]]\n",
      "done in 22.438368s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6895\n",
      "           1       0.33      0.00      0.00       848\n",
      "\n",
      "    accuracy                           0.89      7743\n",
      "   macro avg       0.61      0.50      0.47      7743\n",
      "weighted avg       0.83      0.89      0.84      7743\n",
      "\n",
      "Confusion_matrix\n",
      "[[6891    4]\n",
      " [ 846    2]]\n",
      "done in 21.979063s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6860\n",
      "           1       0.40      0.00      0.00       880\n",
      "\n",
      "    accuracy                           0.89      7740\n",
      "   macro avg       0.64      0.50      0.47      7740\n",
      "weighted avg       0.83      0.89      0.83      7740\n",
      "\n",
      "Confusion_matrix\n",
      "[[6857    3]\n",
      " [ 878    2]]\n",
      "done in 21.767130s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13055\n",
      "           1       0.22      0.00      0.00      1100\n",
      "\n",
      "    accuracy                           0.92     14155\n",
      "   macro avg       0.57      0.50      0.48     14155\n",
      "weighted avg       0.87      0.92      0.89     14155\n",
      "\n",
      "Confusion_matrix\n",
      "[[13048     7]\n",
      " [ 1098     2]]\n",
      "done in 21.798146s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13023\n",
      "           1       0.67      0.00      0.01      1135\n",
      "\n",
      "    accuracy                           0.92     14158\n",
      "   macro avg       0.79      0.50      0.48     14158\n",
      "weighted avg       0.90      0.92      0.88     14158\n",
      "\n",
      "Confusion_matrix\n",
      "[[13021     2]\n",
      " [ 1131     4]]\n",
      "done in 21.204661s\n",
      "0.30196725881862846\n",
      "0.27431929461133553\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19950\n",
      "           1       0.29      0.00      0.00      1948\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.60      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19945     5]\n",
      " [ 1946     2]]\n",
      "done in 0.756168s\n",
      "0.30196725881862846\n",
      "0.2795138777465069\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19883\n",
      "           1       0.00      0.00      0.00      2015\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.45      0.50      0.48     21898\n",
      "weighted avg       0.82      0.91      0.86     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19879     4]\n",
      " [ 2015     0]]\n",
      "done in 0.731738s\n",
      "0.30196725881862846\n",
      "0.3166371117687413\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6895\n",
      "           1       0.00      0.00      0.00       848\n",
      "\n",
      "    accuracy                           0.89      7743\n",
      "   macro avg       0.45      0.50      0.47      7743\n",
      "weighted avg       0.79      0.89      0.84      7743\n",
      "\n",
      "Confusion_matrix\n",
      "[[6890    5]\n",
      " [ 848    0]]\n",
      "done in 0.725921s\n",
      "0.30196725881862846\n",
      "0.325653419554958\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6860\n",
      "           1       0.00      0.00      0.00       880\n",
      "\n",
      "    accuracy                           0.89      7740\n",
      "   macro avg       0.44      0.50      0.47      7740\n",
      "weighted avg       0.79      0.89      0.83      7740\n",
      "\n",
      "Confusion_matrix\n",
      "[[6858    2]\n",
      " [ 880    0]]\n",
      "done in 0.687290s\n",
      "0.30196725881862846\n",
      "0.25117080586179164\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13055\n",
      "           1       1.00      0.00      0.00      1100\n",
      "\n",
      "    accuracy                           0.92     14155\n",
      "   macro avg       0.96      0.50      0.48     14155\n",
      "weighted avg       0.93      0.92      0.89     14155\n",
      "\n",
      "Confusion_matrix\n",
      "[[13055     0]\n",
      " [ 1098     2]]\n",
      "done in 0.700077s\n",
      "0.30196725881862846\n",
      "0.25428997227981587\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13023\n",
      "           1       0.00      0.00      0.00      1135\n",
      "\n",
      "    accuracy                           0.92     14158\n",
      "   macro avg       0.46      0.50      0.48     14158\n",
      "weighted avg       0.85      0.92      0.88     14158\n",
      "\n",
      "Confusion_matrix\n",
      "[[13021     2]\n",
      " [ 1135     0]]\n",
      "done in 0.692623s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19950\n",
      "           1       0.40      0.01      0.02      1948\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.65      0.50      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19924    26]\n",
      " [ 1931    17]]\n",
      "done in 37.614898s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19883\n",
      "           1       0.36      0.01      0.01      2015\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.63      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19860    23]\n",
      " [ 2002    13]]\n",
      "done in 38.156701s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6895\n",
      "           1       0.50      0.01      0.02       848\n",
      "\n",
      "    accuracy                           0.89      7743\n",
      "   macro avg       0.70      0.50      0.48      7743\n",
      "weighted avg       0.85      0.89      0.84      7743\n",
      "\n",
      "Confusion_matrix\n",
      "[[6888    7]\n",
      " [ 841    7]]\n",
      "done in 38.180089s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6860\n",
      "           1       0.25      0.00      0.01       880\n",
      "\n",
      "    accuracy                           0.89      7740\n",
      "   macro avg       0.57      0.50      0.47      7740\n",
      "weighted avg       0.81      0.89      0.83      7740\n",
      "\n",
      "Confusion_matrix\n",
      "[[6848   12]\n",
      " [ 876    4]]\n",
      "done in 37.818398s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13055\n",
      "           1       0.34      0.01      0.02      1100\n",
      "\n",
      "    accuracy                           0.92     14155\n",
      "   macro avg       0.63      0.50      0.49     14155\n",
      "weighted avg       0.88      0.92      0.89     14155\n",
      "\n",
      "Confusion_matrix\n",
      "[[13036    19]\n",
      " [ 1090    10]]\n",
      "done in 37.283613s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13023\n",
      "           1       0.47      0.01      0.02      1135\n",
      "\n",
      "    accuracy                           0.92     14158\n",
      "   macro avg       0.70      0.50      0.49     14158\n",
      "weighted avg       0.88      0.92      0.88     14158\n",
      "\n",
      "Confusion_matrix\n",
      "[[13013    10]\n",
      " [ 1126     9]]\n",
      "done in 37.943016s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.38499999999999995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.2, J-value:0.274\n",
      "threshold:0.30000000000000004, J-value:0.147\n",
      "threshold:0.4, J-value:0.07100000000000001\n",
      "threshold:0.5, J-value:0.024\n",
      "threshold:0.6000000000000001, J-value:0.009000000000000001\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6927842964701281\n",
      "Balanced accuracy score of test is  0.7038397329089816\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.368\n",
      "threshold:0.2, J-value:0.27\n",
      "threshold:0.30000000000000004, J-value:0.132\n",
      "threshold:0.4, J-value:0.053000000000000005\n",
      "threshold:0.5, J-value:0.021\n",
      "threshold:0.6000000000000001, J-value:0.006\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6839160863080986\n",
      "Balanced accuracy score of test is  0.696412006360986\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.38799999999999996\n",
      "threshold:0.2, J-value:0.275\n",
      "threshold:0.30000000000000004, J-value:0.159\n",
      "threshold:0.4, J-value:0.084\n",
      "threshold:0.5, J-value:0.027\n",
      "threshold:0.6000000000000001, J-value:0.011\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6943760662929563\n",
      "Balanced accuracy score of test is  0.7049774695464244\n",
      "True positive rate of class 1 is  0.757\n",
      "True positive rate of class 2 is  0.717\n",
      "Positive prediction rate of class 1 is  0.409\n",
      "Positive prediction rate of class 2 is  0.34\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.373\n",
      "threshold:0.2, J-value:0.297\n",
      "threshold:0.30000000000000004, J-value:0.10700000000000001\n",
      "threshold:0.4, J-value:0.024999999999999998\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6864164003437753\n",
      "Balanced accuracy score of test is  0.6917337141882993\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.34800000000000003\n",
      "threshold:0.2, J-value:0.29000000000000004\n",
      "threshold:0.30000000000000004, J-value:0.11199999999999999\n",
      "threshold:0.4, J-value:0.026000000000000002\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6740269302338309\n",
      "Balanced accuracy score of test is  0.6786310628147363\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.384\n",
      "threshold:0.2, J-value:0.302\n",
      "threshold:0.30000000000000004, J-value:0.11199999999999999\n",
      "threshold:0.4, J-value:0.023\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6922570592945928\n",
      "Balanced accuracy score of test is  0.6942095330491191\n",
      "True positive rate of class 1 is  0.795\n",
      "True positive rate of class 2 is  0.75\n",
      "Positive prediction rate of class 1 is  0.479\n",
      "Positive prediction rate of class 2 is  0.392\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.35700000000000004\n",
      "threshold:0.2, J-value:0.28\n",
      "threshold:0.30000000000000004, J-value:0.10200000000000001\n",
      "threshold:0.4, J-value:0.0\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6782606156047202\n",
      "Balanced accuracy score of test is  0.6807077732277247\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.337\n",
      "threshold:0.2, J-value:0.273\n",
      "threshold:0.30000000000000004, J-value:0.10200000000000001\n",
      "threshold:0.4, J-value:-0.001\n",
      "threshold:0.5, J-value:-0.001\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.668484562918166\n",
      "Balanced accuracy score of test is  0.6663861648555526\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.359\n",
      "threshold:0.2, J-value:0.28600000000000003\n",
      "threshold:0.30000000000000004, J-value:0.10300000000000001\n",
      "threshold:0.4, J-value:0.002\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6795626893214024\n",
      "Balanced accuracy score of test is  0.6857327649049242\n",
      "True positive rate of class 1 is  0.795\n",
      "True positive rate of class 2 is  0.759\n",
      "Positive prediction rate of class 1 is  0.501\n",
      "Positive prediction rate of class 2 is  0.418\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.402\n",
      "threshold:0.2, J-value:0.29200000000000004\n",
      "threshold:0.30000000000000004, J-value:0.139\n",
      "threshold:0.4, J-value:0.044\n",
      "threshold:0.5, J-value:0.008\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7008828024887681\n",
      "Balanced accuracy score of test is  0.7110097294982096\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.393\n",
      "threshold:0.2, J-value:0.273\n",
      "threshold:0.30000000000000004, J-value:0.13899999999999998\n",
      "threshold:0.4, J-value:0.041\n",
      "threshold:0.5, J-value:0.007\n",
      "threshold:0.6000000000000001, J-value:0.004\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6968790619398799\n",
      "Balanced accuracy score of test is  0.7018105618870925\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.39599999999999996\n",
      "threshold:0.2, J-value:0.30400000000000005\n",
      "threshold:0.30000000000000004, J-value:0.138\n",
      "threshold:0.4, J-value:0.047\n",
      "threshold:0.5, J-value:0.008\n",
      "threshold:0.6000000000000001, J-value:0.002\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6980314055917273\n",
      "Balanced accuracy score of test is  0.7131173887202614\n",
      "True positive rate of class 1 is  0.79\n",
      "True positive rate of class 2 is  0.751\n",
      "Positive prediction rate of class 1 is  0.432\n",
      "Positive prediction rate of class 2 is  0.359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lifuchen/Desktop/research/CVDPrediction-master/src/lib/fairness_tests.py:125: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train ['Class'] = y_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23345, 88)\n",
      "(42349, 88)\n",
      "0.12230181241286477 0.08478700786393094\n",
      "0.1222879684418146\n",
      "(67158, 87)\n",
      "X train 67158\n",
      "Y train 67158\n",
      "21898 7751 14147\n",
      "21898 7751 14147\n",
      "21898 7757 14141\n",
      "21898 7757 14141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2914610567957225\n",
      "0.26539961873464313\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19908\n",
      "           1       0.47      0.04      0.07      1990\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.69      0.52      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19827    81]\n",
      " [ 1917    73]]\n",
      "done in 1.178845s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2914610567957225\n",
      "0.2644479582944697\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19918\n",
      "           1       0.40      0.03      0.05      1980\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.66      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19832    86]\n",
      " [ 1922    58]]\n",
      "done in 1.186289s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2914610567957225\n",
      "0.30289954980154604\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6908\n",
      "           1       0.46      0.03      0.06       843\n",
      "\n",
      "    accuracy                           0.89      7751\n",
      "   macro avg       0.67      0.51      0.50      7751\n",
      "weighted avg       0.85      0.89      0.85      7751\n",
      "\n",
      "Confusion_matrix\n",
      "[[6877   31]\n",
      " [ 817   26]]\n",
      "done in 1.231777s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2914610567957225\n",
      "0.3050406378597295\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6894\n",
      "           1       0.41      0.03      0.05       863\n",
      "\n",
      "    accuracy                           0.89      7757\n",
      "   macro avg       0.65      0.51      0.49      7757\n",
      "weighted avg       0.84      0.89      0.84      7757\n",
      "\n",
      "Confusion_matrix\n",
      "[[6862   32]\n",
      " [ 841   22]]\n",
      "done in 1.197585s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2914610567957225\n",
      "0.24485378105177294\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13000\n",
      "           1       0.48      0.04      0.08      1147\n",
      "\n",
      "    accuracy                           0.92     14147\n",
      "   macro avg       0.70      0.52      0.52     14147\n",
      "weighted avg       0.89      0.92      0.89     14147\n",
      "\n",
      "Confusion_matrix\n",
      "[[12950    50]\n",
      " [ 1100    47]]\n",
      "done in 1.170061s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2914610567957225\n",
      "0.2421809746732462\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13024\n",
      "           1       0.40      0.03      0.06      1117\n",
      "\n",
      "    accuracy                           0.92     14141\n",
      "   macro avg       0.66      0.51      0.51     14141\n",
      "weighted avg       0.88      0.92      0.89     14141\n",
      "\n",
      "Confusion_matrix\n",
      "[[12970    54]\n",
      " [ 1081    36]]\n",
      "done in 1.177597s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19908\n",
      "           1       0.45      0.00      0.00      1990\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19902     6]\n",
      " [ 1985     5]]\n",
      "done in 21.995559s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19918\n",
      "           1       0.38      0.00      0.00      1980\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.64      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19913     5]\n",
      " [ 1977     3]]\n",
      "done in 22.618737s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6908\n",
      "           1       0.38      0.01      0.01       843\n",
      "\n",
      "    accuracy                           0.89      7751\n",
      "   macro avg       0.64      0.50      0.48      7751\n",
      "weighted avg       0.84      0.89      0.84      7751\n",
      "\n",
      "Confusion_matrix\n",
      "[[6900    8]\n",
      " [ 838    5]]\n",
      "done in 23.213579s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6894\n",
      "           1       0.67      0.00      0.01       863\n",
      "\n",
      "    accuracy                           0.89      7757\n",
      "   macro avg       0.78      0.50      0.48      7757\n",
      "weighted avg       0.86      0.89      0.84      7757\n",
      "\n",
      "Confusion_matrix\n",
      "[[6892    2]\n",
      " [ 859    4]]\n",
      "done in 23.063312s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13000\n",
      "           1       0.33      0.00      0.01      1147\n",
      "\n",
      "    accuracy                           0.92     14147\n",
      "   macro avg       0.63      0.50      0.48     14147\n",
      "weighted avg       0.87      0.92      0.88     14147\n",
      "\n",
      "Confusion_matrix\n",
      "[[12994     6]\n",
      " [ 1144     3]]\n",
      "done in 22.344838s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13024\n",
      "           1       0.00      0.00      0.00      1117\n",
      "\n",
      "    accuracy                           0.92     14141\n",
      "   macro avg       0.46      0.50      0.48     14141\n",
      "weighted avg       0.85      0.92      0.88     14141\n",
      "\n",
      "Confusion_matrix\n",
      "[[13022     2]\n",
      " [ 1117     0]]\n",
      "done in 22.739396s\n",
      "0.30297531734354716\n",
      "0.2759525533828525\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19908\n",
      "           1       0.00      0.00      0.00      1990\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.45      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19905     3]\n",
      " [ 1990     0]]\n",
      "done in 0.730152s\n",
      "0.30297531734354716\n",
      "0.2751097892676905\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19918\n",
      "           1       0.20      0.00      0.00      1980\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.55      0.50      0.48     21898\n",
      "weighted avg       0.85      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19914     4]\n",
      " [ 1979     1]]\n",
      "done in 0.810106s\n",
      "0.30297531734354716\n",
      "0.312257712931082\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6908\n",
      "           1       0.00      0.00      0.00       843\n",
      "\n",
      "    accuracy                           0.89      7751\n",
      "   macro avg       0.45      0.50      0.47      7751\n",
      "weighted avg       0.79      0.89      0.84      7751\n",
      "\n",
      "Confusion_matrix\n",
      "[[6906    2]\n",
      " [ 843    0]]\n",
      "done in 0.718056s\n",
      "0.30297531734354716\n",
      "0.3150758091108276\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6894\n",
      "           1       0.00      0.00      0.00       863\n",
      "\n",
      "    accuracy                           0.89      7757\n",
      "   macro avg       0.44      0.50      0.47      7757\n",
      "weighted avg       0.79      0.89      0.84      7757\n",
      "\n",
      "Confusion_matrix\n",
      "[[6891    3]\n",
      " [ 863    0]]\n",
      "done in 0.755844s\n",
      "0.30297531734354716\n",
      "0.2560055232085255\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13000\n",
      "           1       0.00      0.00      0.00      1147\n",
      "\n",
      "    accuracy                           0.92     14147\n",
      "   macro avg       0.46      0.50      0.48     14147\n",
      "weighted avg       0.84      0.92      0.88     14147\n",
      "\n",
      "Confusion_matrix\n",
      "[[13000     0]\n",
      " [ 1147     0]]\n",
      "done in 0.747145s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30297531734354716\n",
      "0.25329819691301525\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13024\n",
      "           1       0.25      0.00      0.00      1117\n",
      "\n",
      "    accuracy                           0.92     14141\n",
      "   macro avg       0.59      0.50      0.48     14141\n",
      "weighted avg       0.87      0.92      0.88     14141\n",
      "\n",
      "Confusion_matrix\n",
      "[[13021     3]\n",
      " [ 1116     1]]\n",
      "done in 0.749306s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19908\n",
      "           1       0.49      0.01      0.02      1990\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.70      0.51      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19882    26]\n",
      " [ 1965    25]]\n",
      "done in 68.146715s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19918\n",
      "           1       0.36      0.01      0.02      1980\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.64      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19886    32]\n",
      " [ 1962    18]]\n",
      "done in 74.052531s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6908\n",
      "           1       0.52      0.02      0.03       843\n",
      "\n",
      "    accuracy                           0.89      7751\n",
      "   macro avg       0.71      0.51      0.49      7751\n",
      "weighted avg       0.85      0.89      0.84      7751\n",
      "\n",
      "Confusion_matrix\n",
      "[[6896   12]\n",
      " [ 830   13]]\n",
      "done in 42.282663s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6894\n",
      "           1       0.32      0.01      0.02       863\n",
      "\n",
      "    accuracy                           0.89      7757\n",
      "   macro avg       0.60      0.50      0.48      7757\n",
      "weighted avg       0.83      0.89      0.84      7757\n",
      "\n",
      "Confusion_matrix\n",
      "[[6877   17]\n",
      " [ 855    8]]\n",
      "done in 39.640481s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13000\n",
      "           1       0.46      0.01      0.02      1147\n",
      "\n",
      "    accuracy                           0.92     14147\n",
      "   macro avg       0.69      0.50      0.49     14147\n",
      "weighted avg       0.88      0.92      0.88     14147\n",
      "\n",
      "Confusion_matrix\n",
      "[[12986    14]\n",
      " [ 1135    12]]\n",
      "done in 40.455811s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13024\n",
      "           1       0.42      0.01      0.02      1117\n",
      "\n",
      "    accuracy                           0.92     14141\n",
      "   macro avg       0.67      0.50      0.49     14141\n",
      "weighted avg       0.88      0.92      0.88     14141\n",
      "\n",
      "Confusion_matrix\n",
      "[[13010    14]\n",
      " [ 1107    10]]\n",
      "done in 40.787027s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.40099999999999997\n",
      "threshold:0.2, J-value:0.29700000000000004\n",
      "threshold:0.30000000000000004, J-value:0.16799999999999998\n",
      "threshold:0.4, J-value:0.08\n",
      "threshold:0.5, J-value:0.033\n",
      "threshold:0.6000000000000001, J-value:0.012\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7007691663057098\n",
      "Balanced accuracy score of test is  0.6990544566054155\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.375\n",
      "threshold:0.2, J-value:0.282\n",
      "threshold:0.30000000000000004, J-value:0.157\n",
      "threshold:0.4, J-value:0.064\n",
      "threshold:0.5, J-value:0.027\n",
      "threshold:0.6000000000000001, J-value:0.009999999999999998\n",
      "threshold:0.7000000000000001, J-value:0.004\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6875146391035958\n",
      "Balanced accuracy score of test is  0.6914221848410679\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.409\n",
      "threshold:0.2, J-value:0.30300000000000005\n",
      "threshold:0.30000000000000004, J-value:0.175\n",
      "threshold:0.4, J-value:0.091\n",
      "threshold:0.5, J-value:0.037000000000000005\n",
      "threshold:0.6000000000000001, J-value:0.013999999999999999\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7045308832405607\n",
      "Balanced accuracy score of test is  0.6989881912106621\n",
      "True positive rate of class 1 is  0.767\n",
      "True positive rate of class 2 is  0.707\n",
      "Positive prediction rate of class 1 is  0.427\n",
      "Positive prediction rate of class 2 is  0.341\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.371\n",
      "threshold:0.2, J-value:0.289\n",
      "threshold:0.30000000000000004, J-value:0.128\n",
      "threshold:0.4, J-value:0.030999999999999996\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.685228003590385\n",
      "Balanced accuracy score of test is  0.6905001668456835\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.338\n",
      "threshold:0.2, J-value:0.30100000000000005\n",
      "threshold:0.30000000000000004, J-value:0.128\n",
      "threshold:0.4, J-value:0.036\n",
      "threshold:0.5, J-value:0.005\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6690459288352391\n",
      "Balanced accuracy score of test is  0.6774642567923944\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.39599999999999996\n",
      "threshold:0.2, J-value:0.306\n",
      "threshold:0.30000000000000004, J-value:0.145\n",
      "threshold:0.4, J-value:0.026\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.698377908926296\n",
      "Balanced accuracy score of test is  0.6944747277390518\n",
      "True positive rate of class 1 is  0.812\n",
      "True positive rate of class 2 is  0.738\n",
      "Positive prediction rate of class 1 is  0.497\n",
      "Positive prediction rate of class 2 is  0.379\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.329\n",
      "threshold:0.2, J-value:0.22400000000000003\n",
      "threshold:0.30000000000000004, J-value:0.122\n",
      "threshold:0.4, J-value:0.024\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6642899296563186\n",
      "Balanced accuracy score of test is  0.6627343319732113\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.30600000000000005\n",
      "threshold:0.2, J-value:0.22999999999999998\n",
      "threshold:0.30000000000000004, J-value:0.10800000000000001\n",
      "threshold:0.4, J-value:0.032\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6530257696304799\n",
      "Balanced accuracy score of test is  0.6615968476122955\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.343\n",
      "threshold:0.2, J-value:0.21700000000000003\n",
      "threshold:0.30000000000000004, J-value:0.131\n",
      "threshold:0.4, J-value:0.018000000000000002\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6717642679900744\n",
      "Balanced accuracy score of test is  0.6637064154269839\n",
      "True positive rate of class 1 is  0.79\n",
      "True positive rate of class 2 is  0.797\n",
      "Positive prediction rate of class 1 is  0.503\n",
      "Positive prediction rate of class 2 is  0.495\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.40800000000000003\n",
      "threshold:0.2, J-value:0.303\n",
      "threshold:0.30000000000000004, J-value:0.154\n",
      "threshold:0.4, J-value:0.049\n",
      "threshold:0.5, J-value:0.012\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7041646094648448\n",
      "Balanced accuracy score of test is  0.7092932792124478\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.37600000000000006\n",
      "threshold:0.2, J-value:0.28200000000000003\n",
      "threshold:0.30000000000000004, J-value:0.143\n",
      "threshold:0.4, J-value:0.047\n",
      "threshold:0.5, J-value:0.013\n",
      "threshold:0.6000000000000001, J-value:0.004\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6880857787934425\n",
      "Balanced accuracy score of test is  0.7045176066245322\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.419\n",
      "threshold:0.2, J-value:0.31599999999999995\n",
      "threshold:0.30000000000000004, J-value:0.161\n",
      "threshold:0.4, J-value:0.051000000000000004\n",
      "threshold:0.5, J-value:0.009000000000000001\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7095058681510295\n",
      "Balanced accuracy score of test is  0.7063520841077914\n",
      "True positive rate of class 1 is  0.811\n",
      "True positive rate of class 2 is  0.731\n",
      "Positive prediction rate of class 1 is  0.448\n",
      "Positive prediction rate of class 2 is  0.351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lifuchen/Desktop/research/CVDPrediction-master/src/lib/fairness_tests.py:125: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train ['Class'] = y_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23252, 88)\n",
      "(42442, 88)\n",
      "0.12775244931613153 0.08639004786648578\n",
      "0.12772928558630045\n",
      "(67309, 87)\n",
      "X train 67309\n",
      "Y train 67309\n",
      "21898 7842 14056\n",
      "21898 7842 14056\n",
      "21898 7759 14139\n",
      "21898 7759 14139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2982457025109129\n",
      "0.2593408384458279\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.95     20006\n",
      "           1       0.44      0.04      0.07      1892\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.52      0.51     21898\n",
      "weighted avg       0.87      0.91      0.88     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19919    87]\n",
      " [ 1825    67]]\n",
      "done in 1.394287s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2982457025109129\n",
      "0.26262690135454747\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19975\n",
      "           1       0.42      0.04      0.07      1923\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.52      0.51     21898\n",
      "weighted avg       0.87      0.91      0.88     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19883    92]\n",
      " [ 1855    68]]\n",
      "done in 1.377865s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2982457025109129\n",
      "0.2928394319733279\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      7042\n",
      "           1       0.42      0.03      0.06       800\n",
      "\n",
      "    accuracy                           0.90      7842\n",
      "   macro avg       0.66      0.51      0.50      7842\n",
      "weighted avg       0.85      0.90      0.85      7842\n",
      "\n",
      "Confusion_matrix\n",
      "[[7009   33]\n",
      " [ 776   24]]\n",
      "done in 1.242016s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2982457025109129\n",
      "0.2950333930381373\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.94      6943\n",
      "           1       0.52      0.03      0.06       816\n",
      "\n",
      "    accuracy                           0.90      7759\n",
      "   macro avg       0.71      0.51      0.50      7759\n",
      "weighted avg       0.86      0.90      0.85      7759\n",
      "\n",
      "Confusion_matrix\n",
      "[[6918   25]\n",
      " [ 789   27]]\n",
      "done in 1.213140s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2982457025109129\n",
      "0.24065159752076706\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12964\n",
      "           1       0.44      0.04      0.07      1092\n",
      "\n",
      "    accuracy                           0.92     14056\n",
      "   macro avg       0.68      0.52      0.52     14056\n",
      "weighted avg       0.89      0.92      0.89     14056\n",
      "\n",
      "Confusion_matrix\n",
      "[[12910    54]\n",
      " [ 1049    43]]\n",
      "done in 1.157548s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2982457025109129\n",
      "0.24484332620970173\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96     13032\n",
      "           1       0.38      0.04      0.07      1107\n",
      "\n",
      "    accuracy                           0.92     14139\n",
      "   macro avg       0.65      0.52      0.51     14139\n",
      "weighted avg       0.88      0.92      0.89     14139\n",
      "\n",
      "Confusion_matrix\n",
      "[[12965    67]\n",
      " [ 1066    41]]\n",
      "done in 1.439394s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     20006\n",
      "           1       0.50      0.00      0.01      1892\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.71      0.50      0.48     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[20001     5]\n",
      " [ 1887     5]]\n",
      "done in 23.441269s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19975\n",
      "           1       0.40      0.00      0.00      1923\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.66      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19969     6]\n",
      " [ 1919     4]]\n",
      "done in 24.320416s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      7042\n",
      "           1       0.33      0.00      0.01       800\n",
      "\n",
      "    accuracy                           0.90      7842\n",
      "   macro avg       0.62      0.50      0.48      7842\n",
      "weighted avg       0.84      0.90      0.85      7842\n",
      "\n",
      "Confusion_matrix\n",
      "[[7036    6]\n",
      " [ 797    3]]\n",
      "done in 33.964849s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.94      6943\n",
      "           1       0.38      0.01      0.01       816\n",
      "\n",
      "    accuracy                           0.89      7759\n",
      "   macro avg       0.64      0.50      0.48      7759\n",
      "weighted avg       0.84      0.89      0.85      7759\n",
      "\n",
      "Confusion_matrix\n",
      "[[6935    8]\n",
      " [ 811    5]]\n",
      "done in 135.982438s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12964\n",
      "           1       0.57      0.00      0.01      1092\n",
      "\n",
      "    accuracy                           0.92     14056\n",
      "   macro avg       0.75      0.50      0.48     14056\n",
      "weighted avg       0.90      0.92      0.89     14056\n",
      "\n",
      "Confusion_matrix\n",
      "[[12961     3]\n",
      " [ 1088     4]]\n",
      "done in 53.197959s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13032\n",
      "           1       0.25      0.00      0.00      1107\n",
      "\n",
      "    accuracy                           0.92     14139\n",
      "   macro avg       0.59      0.50      0.48     14139\n",
      "weighted avg       0.87      0.92      0.88     14139\n",
      "\n",
      "Confusion_matrix\n",
      "[[13026     6]\n",
      " [ 1105     2]]\n",
      "done in 46.275115s\n",
      "0.30994371051254743\n",
      "0.26885324789147125\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     20006\n",
      "           1       0.43      0.01      0.01      1892\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19993    13]\n",
      " [ 1882    10]]\n",
      "done in 1.163730s\n",
      "0.30994371051254743\n",
      "0.2701259793797287\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19975\n",
      "           1       0.56      0.00      0.01      1923\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.74      0.50      0.48     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19968     7]\n",
      " [ 1914     9]]\n",
      "done in 1.083594s\n",
      "0.30994371051254743\n",
      "0.3009616363660132\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      7042\n",
      "           1       0.50      0.01      0.01       800\n",
      "\n",
      "    accuracy                           0.90      7842\n",
      "   macro avg       0.70      0.50      0.48      7842\n",
      "weighted avg       0.86      0.90      0.85      7842\n",
      "\n",
      "Confusion_matrix\n",
      "[[7038    4]\n",
      " [ 796    4]]\n",
      "done in 1.019664s\n",
      "0.30994371051254743\n",
      "0.3034356993654851\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.94      6943\n",
      "           1       0.50      0.00      0.01       816\n",
      "\n",
      "    accuracy                           0.89      7759\n",
      "   macro avg       0.70      0.50      0.48      7759\n",
      "weighted avg       0.85      0.89      0.85      7759\n",
      "\n",
      "Confusion_matrix\n",
      "[[6940    3]\n",
      " [ 813    3]]\n",
      "done in 1.029803s\n",
      "0.30994371051254743\n",
      "0.25093961795284314\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12964\n",
      "           1       0.40      0.01      0.01      1092\n",
      "\n",
      "    accuracy                           0.92     14056\n",
      "   macro avg       0.66      0.50      0.49     14056\n",
      "weighted avg       0.88      0.92      0.89     14056\n",
      "\n",
      "Confusion_matrix\n",
      "[[12955     9]\n",
      " [ 1086     6]]\n",
      "done in 1.037574s\n",
      "0.30994371051254743\n",
      "0.2518467434104605\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13032\n",
      "           1       0.60      0.01      0.01      1107\n",
      "\n",
      "    accuracy                           0.92     14139\n",
      "   macro avg       0.76      0.50      0.49     14139\n",
      "weighted avg       0.90      0.92      0.89     14139\n",
      "\n",
      "Confusion_matrix\n",
      "[[13028     4]\n",
      " [ 1101     6]]\n",
      "done in 1.046587s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     20006\n",
      "           1       0.30      0.01      0.02      1892\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.61      0.50      0.49     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19967    39]\n",
      " [ 1875    17]]\n",
      "done in 43.774099s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19975\n",
      "           1       0.42      0.01      0.03      1923\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19938    37]\n",
      " [ 1896    27]]\n",
      "done in 37.968555s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      7042\n",
      "           1       0.30      0.01      0.02       800\n",
      "\n",
      "    accuracy                           0.90      7842\n",
      "   macro avg       0.60      0.50      0.48      7842\n",
      "weighted avg       0.84      0.90      0.85      7842\n",
      "\n",
      "Confusion_matrix\n",
      "[[7023   19]\n",
      " [ 792    8]]\n",
      "done in 40.305776s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.94      6943\n",
      "           1       0.44      0.01      0.03       816\n",
      "\n",
      "    accuracy                           0.89      7759\n",
      "   macro avg       0.67      0.51      0.49      7759\n",
      "weighted avg       0.85      0.89      0.85      7759\n",
      "\n",
      "Confusion_matrix\n",
      "[[6928   15]\n",
      " [ 804   12]]\n",
      "done in 40.521074s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12964\n",
      "           1       0.31      0.01      0.02      1092\n",
      "\n",
      "    accuracy                           0.92     14056\n",
      "   macro avg       0.62      0.50      0.49     14056\n",
      "weighted avg       0.88      0.92      0.89     14056\n",
      "\n",
      "Confusion_matrix\n",
      "[[12944    20]\n",
      " [ 1083     9]]\n",
      "done in 38.376830s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13032\n",
      "           1       0.41      0.01      0.03      1107\n",
      "\n",
      "    accuracy                           0.92     14139\n",
      "   macro avg       0.66      0.51      0.49     14139\n",
      "weighted avg       0.88      0.92      0.89     14139\n",
      "\n",
      "Confusion_matrix\n",
      "[[13010    22]\n",
      " [ 1092    15]]\n",
      "done in 39.136694s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.2, J-value:0.292\n",
      "threshold:0.30000000000000004, J-value:0.155\n",
      "threshold:0.4, J-value:0.074\n",
      "threshold:0.5, J-value:0.031000000000000003\n",
      "threshold:0.6000000000000001, J-value:0.009\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6994448177174755\n",
      "Balanced accuracy score of test is  0.6974581851859807\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.372\n",
      "threshold:0.2, J-value:0.274\n",
      "threshold:0.30000000000000004, J-value:0.14300000000000002\n",
      "threshold:0.4, J-value:0.06\n",
      "threshold:0.5, J-value:0.024999999999999998\n",
      "threshold:0.6000000000000001, J-value:0.006999999999999999\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6856940499857995\n",
      "Balanced accuracy score of test is  0.6856006049258245\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.411\n",
      "threshold:0.2, J-value:0.304\n",
      "threshold:0.30000000000000004, J-value:0.162\n",
      "threshold:0.4, J-value:0.084\n",
      "threshold:0.5, J-value:0.035\n",
      "threshold:0.6000000000000001, J-value:0.011\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.705653327953544\n",
      "Balanced accuracy score of test is  0.70291203142234\n",
      "True positive rate of class 1 is  0.75\n",
      "True positive rate of class 2 is  0.735\n",
      "Positive prediction rate of class 1 is  0.418\n",
      "Positive prediction rate of class 2 is  0.361\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.386\n",
      "threshold:0.2, J-value:0.30800000000000005\n",
      "threshold:0.30000000000000004, J-value:0.127\n",
      "threshold:0.4, J-value:0.030999999999999996\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6930827200042947\n",
      "Balanced accuracy score of test is  0.6826852468341538\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.3479999999999999\n",
      "threshold:0.2, J-value:0.29700000000000004\n",
      "threshold:0.30000000000000004, J-value:0.14400000000000002\n",
      "threshold:0.4, J-value:0.043000000000000003\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6740295725646124\n",
      "Balanced accuracy score of test is  0.6793661905205695\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.387\n",
      "threshold:0.2, J-value:0.313\n",
      "threshold:0.30000000000000004, J-value:0.118\n",
      "threshold:0.4, J-value:0.029\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6936625289757039\n",
      "Balanced accuracy score of test is  0.6786833660233471\n",
      "True positive rate of class 1 is  0.811\n",
      "True positive rate of class 2 is  0.725\n",
      "Positive prediction rate of class 1 is  0.49\n",
      "Positive prediction rate of class 2 is  0.396\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.359\n",
      "threshold:0.2, J-value:0.261\n",
      "threshold:0.30000000000000004, J-value:0.089\n",
      "threshold:0.4, J-value:0.066\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.679483654903529\n",
      "Balanced accuracy score of test is  0.6821361335054154\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.334\n",
      "threshold:0.2, J-value:0.24100000000000002\n",
      "threshold:0.30000000000000004, J-value:0.086\n",
      "threshold:0.4, J-value:0.06\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6670931553535928\n",
      "Balanced accuracy score of test is  0.6696610247872734\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.368\n",
      "threshold:0.2, J-value:0.271\n",
      "threshold:0.30000000000000004, J-value:0.091\n",
      "threshold:0.4, J-value:0.07\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6843200895576707\n",
      "Balanced accuracy score of test is  0.6877183493289813\n",
      "True positive rate of class 1 is  0.773\n",
      "True positive rate of class 2 is  0.755\n",
      "Positive prediction rate of class 1 is  0.47\n",
      "Positive prediction rate of class 2 is  0.409\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.40700000000000003\n",
      "threshold:0.2, J-value:0.286\n",
      "threshold:0.30000000000000004, J-value:0.147\n",
      "threshold:0.4, J-value:0.05\n",
      "threshold:0.5, J-value:0.006999999999999999\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7033745848761228\n",
      "Balanced accuracy score of test is  0.6978823893881914\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.37200000000000005\n",
      "threshold:0.2, J-value:0.27299999999999996\n",
      "threshold:0.30000000000000004, J-value:0.149\n",
      "threshold:0.4, J-value:0.05700000000000001\n",
      "threshold:0.5, J-value:0.007\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6863094646407271\n",
      "Balanced accuracy score of test is  0.6907005186490555\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.42\n",
      "threshold:0.2, J-value:0.292\n",
      "threshold:0.30000000000000004, J-value:0.147\n",
      "threshold:0.4, J-value:0.044\n",
      "threshold:0.5, J-value:0.006\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7100392408167786\n",
      "Balanced accuracy score of test is  0.698124878348231\n",
      "True positive rate of class 1 is  0.795\n",
      "True positive rate of class 2 is  0.734\n",
      "Positive prediction rate of class 1 is  0.454\n",
      "Positive prediction rate of class 2 is  0.369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lifuchen/Desktop/research/CVDPrediction-master/src/lib/fairness_tests.py:125: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train ['Class'] = y_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23261, 88)\n",
      "(42433, 88)\n",
      "0.12388268831231579 0.08438322557563058\n",
      "0.12386598860238686\n",
      "(67239, 87)\n",
      "X train 67239\n",
      "Y train 67239\n",
      "21898 7814 14084\n",
      "21898 7814 14084\n",
      "21898 7778 14120\n",
      "21898 7778 14120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29212346801303013\n",
      "0.26778429401452614\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19911\n",
      "           1       0.43      0.03      0.06      1987\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19832    79]\n",
      " [ 1928    59]]\n",
      "done in 1.217708s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29212346801303013\n",
      "0.264824809758129\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19927\n",
      "           1       0.41      0.03      0.05      1971\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.66      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19856    71]\n",
      " [ 1921    50]]\n",
      "done in 1.237991s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29212346801303013\n",
      "0.29894726263646815\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6979\n",
      "           1       0.40      0.02      0.04       835\n",
      "\n",
      "    accuracy                           0.89      7814\n",
      "   macro avg       0.65      0.51      0.49      7814\n",
      "weighted avg       0.84      0.89      0.85      7814\n",
      "\n",
      "Confusion_matrix\n",
      "[[6950   29]\n",
      " [ 816   19]]\n",
      "done in 1.283253s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29212346801303013\n",
      "0.3041280615653343\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6927\n",
      "           1       0.57      0.03      0.05       851\n",
      "\n",
      "    accuracy                           0.89      7778\n",
      "   macro avg       0.73      0.51      0.50      7778\n",
      "weighted avg       0.86      0.89      0.84      7778\n",
      "\n",
      "Confusion_matrix\n",
      "[[6910   17]\n",
      " [ 828   23]]\n",
      "done in 1.314429s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29212346801303013\n",
      "0.25049464357346857\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12932\n",
      "           1       0.44      0.03      0.06      1152\n",
      "\n",
      "    accuracy                           0.92     14084\n",
      "   macro avg       0.68      0.52      0.51     14084\n",
      "weighted avg       0.88      0.92      0.88     14084\n",
      "\n",
      "Confusion_matrix\n",
      "[[12882    50]\n",
      " [ 1112    40]]\n",
      "done in 1.632533s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29212346801303013\n",
      "0.24317461906716273\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13000\n",
      "           1       0.33      0.02      0.04      1120\n",
      "\n",
      "    accuracy                           0.92     14120\n",
      "   macro avg       0.63      0.51      0.50     14120\n",
      "weighted avg       0.88      0.92      0.89     14120\n",
      "\n",
      "Confusion_matrix\n",
      "[[12946    54]\n",
      " [ 1093    27]]\n",
      "done in 1.256119s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19911\n",
      "           1       0.33      0.00      0.00      1987\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.62      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19901    10]\n",
      " [ 1982     5]]\n",
      "done in 23.037232s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19927\n",
      "           1       0.17      0.00      0.00      1971\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.54      0.50      0.48     21898\n",
      "weighted avg       0.84      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19922     5]\n",
      " [ 1970     1]]\n",
      "done in 22.683226s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6979\n",
      "           1       0.40      0.00      0.00       835\n",
      "\n",
      "    accuracy                           0.89      7814\n",
      "   macro avg       0.65      0.50      0.47      7814\n",
      "weighted avg       0.84      0.89      0.84      7814\n",
      "\n",
      "Confusion_matrix\n",
      "[[6976    3]\n",
      " [ 833    2]]\n",
      "done in 22.139923s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6927\n",
      "           1       0.00      0.00      0.00       851\n",
      "\n",
      "    accuracy                           0.89      7778\n",
      "   macro avg       0.45      0.50      0.47      7778\n",
      "weighted avg       0.79      0.89      0.84      7778\n",
      "\n",
      "Confusion_matrix\n",
      "[[6924    3]\n",
      " [ 851    0]]\n",
      "done in 21.290839s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12932\n",
      "           1       0.00      0.00      0.00      1152\n",
      "\n",
      "    accuracy                           0.92     14084\n",
      "   macro avg       0.46      0.50      0.48     14084\n",
      "weighted avg       0.84      0.92      0.88     14084\n",
      "\n",
      "Confusion_matrix\n",
      "[[12930     2]\n",
      " [ 1152     0]]\n",
      "done in 21.811669s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13000\n",
      "           1       0.33      0.00      0.00      1120\n",
      "\n",
      "    accuracy                           0.92     14120\n",
      "   macro avg       0.63      0.50      0.48     14120\n",
      "weighted avg       0.87      0.92      0.88     14120\n",
      "\n",
      "Confusion_matrix\n",
      "[[12998     2]\n",
      " [ 1119     1]]\n",
      "done in 22.200796s\n",
      "0.3067383553410903\n",
      "0.2818175274148366\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19911\n",
      "           1       0.00      0.00      0.00      1987\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.45      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19908     3]\n",
      " [ 1987     0]]\n",
      "done in 0.718600s\n",
      "0.3067383553410903\n",
      "0.2755380741156512\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19927\n",
      "           1       0.50      0.00      0.00      1971\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.71      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19926     1]\n",
      " [ 1970     1]]\n",
      "done in 0.725940s\n",
      "0.3067383553410903\n",
      "0.30708273783907236\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6979\n",
      "           1       0.00      0.00      0.00       835\n",
      "\n",
      "    accuracy                           0.89      7814\n",
      "   macro avg       0.45      0.50      0.47      7814\n",
      "weighted avg       0.80      0.89      0.84      7814\n",
      "\n",
      "Confusion_matrix\n",
      "[[6979    0]\n",
      " [ 835    0]]\n",
      "done in 0.682188s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3067383553410903\n",
      "0.31257113448875634\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6927\n",
      "           1       0.00      0.00      0.00       851\n",
      "\n",
      "    accuracy                           0.89      7778\n",
      "   macro avg       0.45      0.50      0.47      7778\n",
      "weighted avg       0.79      0.89      0.84      7778\n",
      "\n",
      "Confusion_matrix\n",
      "[[6927    0]\n",
      " [ 851    0]]\n",
      "done in 0.682873s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3067383553410903\n",
      "0.26780003563302895\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12932\n",
      "           1       0.00      0.00      0.00      1152\n",
      "\n",
      "    accuracy                           0.92     14084\n",
      "   macro avg       0.46      0.50      0.48     14084\n",
      "weighted avg       0.84      0.92      0.88     14084\n",
      "\n",
      "Confusion_matrix\n",
      "[[12929     3]\n",
      " [ 1152     0]]\n",
      "done in 0.688694s\n",
      "0.3067383553410903\n",
      "0.2551384180546021\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13000\n",
      "           1       0.50      0.00      0.00      1120\n",
      "\n",
      "    accuracy                           0.92     14120\n",
      "   macro avg       0.71      0.50      0.48     14120\n",
      "weighted avg       0.89      0.92      0.88     14120\n",
      "\n",
      "Confusion_matrix\n",
      "[[12999     1]\n",
      " [ 1119     1]]\n",
      "done in 0.707193s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19911\n",
      "           1       0.52      0.01      0.02      1987\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.72      0.51      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19888    23]\n",
      " [ 1962    25]]\n",
      "done in 38.295866s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19927\n",
      "           1       0.47      0.01      0.02      1971\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.69      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19908    19]\n",
      " [ 1954    17]]\n",
      "done in 38.436780s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6979\n",
      "           1       0.62      0.02      0.03       835\n",
      "\n",
      "    accuracy                           0.89      7814\n",
      "   macro avg       0.76      0.51      0.49      7814\n",
      "weighted avg       0.87      0.89      0.85      7814\n",
      "\n",
      "Confusion_matrix\n",
      "[[6971    8]\n",
      " [ 822   13]]\n",
      "done in 38.019390s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6927\n",
      "           1       0.42      0.01      0.01       851\n",
      "\n",
      "    accuracy                           0.89      7778\n",
      "   macro avg       0.65      0.50      0.48      7778\n",
      "weighted avg       0.84      0.89      0.84      7778\n",
      "\n",
      "Confusion_matrix\n",
      "[[6920    7]\n",
      " [ 846    5]]\n",
      "done in 37.727339s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12932\n",
      "           1       0.44      0.01      0.02      1152\n",
      "\n",
      "    accuracy                           0.92     14084\n",
      "   macro avg       0.68      0.50      0.49     14084\n",
      "weighted avg       0.88      0.92      0.88     14084\n",
      "\n",
      "Confusion_matrix\n",
      "[[12917    15]\n",
      " [ 1140    12]]\n",
      "done in 37.897036s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13000\n",
      "           1       0.50      0.01      0.02      1120\n",
      "\n",
      "    accuracy                           0.92     14120\n",
      "   macro avg       0.71      0.50      0.49     14120\n",
      "weighted avg       0.89      0.92      0.88     14120\n",
      "\n",
      "Confusion_matrix\n",
      "[[12988    12]\n",
      " [ 1108    12]]\n",
      "done in 38.505172s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.38099999999999995\n",
      "threshold:0.2, J-value:0.273\n",
      "threshold:0.30000000000000004, J-value:0.143\n",
      "threshold:0.4, J-value:0.065\n",
      "threshold:0.5, J-value:0.026\n",
      "threshold:0.6000000000000001, J-value:0.011\n",
      "threshold:0.7000000000000001, J-value:0.005\n",
      "threshold:0.8, J-value:0.002\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6906605936427166\n",
      "Balanced accuracy score of test is  0.6970802892760504\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.376\n",
      "threshold:0.2, J-value:0.277\n",
      "threshold:0.30000000000000004, J-value:0.13199999999999998\n",
      "threshold:0.4, J-value:0.05500000000000001\n",
      "threshold:0.5, J-value:0.019\n",
      "threshold:0.6000000000000001, J-value:0.008\n",
      "threshold:0.7000000000000001, J-value:0.005\n",
      "threshold:0.8, J-value:0.004\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6877997551250844\n",
      "Balanced accuracy score of test is  0.6840677931023836\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.37799999999999995\n",
      "threshold:0.2, J-value:0.268\n",
      "threshold:0.30000000000000004, J-value:0.149\n",
      "threshold:0.4, J-value:0.07100000000000001\n",
      "threshold:0.5, J-value:0.031000000000000003\n",
      "threshold:0.6000000000000001, J-value:0.013000000000000001\n",
      "threshold:0.7000000000000001, J-value:0.005\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6887132103395539\n",
      "Balanced accuracy score of test is  0.7014024725274726\n",
      "True positive rate of class 1 is  0.749\n",
      "True positive rate of class 2 is  0.708\n",
      "Positive prediction rate of class 1 is  0.421\n",
      "Positive prediction rate of class 2 is  0.337\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.374\n",
      "threshold:0.2, J-value:0.295\n",
      "threshold:0.30000000000000004, J-value:0.127\n",
      "threshold:0.4, J-value:0.027\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.686644306469274\n",
      "Balanced accuracy score of test is  0.6965059580609763\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.3539999999999999\n",
      "threshold:0.2, J-value:0.29800000000000004\n",
      "threshold:0.30000000000000004, J-value:0.141\n",
      "threshold:0.4, J-value:0.026000000000000002\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6771126896515036\n",
      "Balanced accuracy score of test is  0.6791472493828116\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.372\n",
      "threshold:0.2, J-value:0.278\n",
      "threshold:0.30000000000000004, J-value:0.119\n",
      "threshold:0.4, J-value:0.022\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.685896795631852\n",
      "Balanced accuracy score of test is  0.6933804945054945\n",
      "True positive rate of class 1 is  0.814\n",
      "True positive rate of class 2 is  0.737\n",
      "Positive prediction rate of class 1 is  0.495\n",
      "Positive prediction rate of class 2 is  0.381\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.34\n",
      "threshold:0.2, J-value:0.19799999999999998\n",
      "threshold:0.30000000000000004, J-value:0.11099999999999999\n",
      "threshold:0.4, J-value:0.063\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6700581174550858\n",
      "Balanced accuracy score of test is  0.6749587287358371\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.329\n",
      "threshold:0.2, J-value:0.191\n",
      "threshold:0.30000000000000004, J-value:0.14300000000000002\n",
      "threshold:0.4, J-value:0.065\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6648685148688152\n",
      "Balanced accuracy score of test is  0.6620827711926813\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.34600000000000003\n",
      "threshold:0.2, J-value:0.20600000000000002\n",
      "threshold:0.30000000000000004, J-value:0.08399999999999999\n",
      "threshold:0.4, J-value:0.061\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6732411202185793\n",
      "Balanced accuracy score of test is  0.683184065934066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positive rate of class 1 is  0.752\n",
      "True positive rate of class 2 is  0.773\n",
      "Positive prediction rate of class 1 is  0.463\n",
      "Positive prediction rate of class 2 is  0.436\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.399\n",
      "threshold:0.2, J-value:0.29000000000000004\n",
      "threshold:0.30000000000000004, J-value:0.143\n",
      "threshold:0.4, J-value:0.044\n",
      "threshold:0.5, J-value:0.012\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6996115350450925\n",
      "Balanced accuracy score of test is  0.702913745266621\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.38800000000000007\n",
      "threshold:0.2, J-value:0.294\n",
      "threshold:0.30000000000000004, J-value:0.146\n",
      "threshold:0.4, J-value:0.049\n",
      "threshold:0.5, J-value:0.015\n",
      "threshold:0.6000000000000001, J-value:0.002\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6938303361753353\n",
      "Balanced accuracy score of test is  0.6895040388459335\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.39699999999999996\n",
      "threshold:0.2, J-value:0.28400000000000003\n",
      "threshold:0.30000000000000004, J-value:0.139\n",
      "threshold:0.4, J-value:0.039\n",
      "threshold:0.5, J-value:0.009000000000000001\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6987319622727429\n",
      "Balanced accuracy score of test is  0.7062953296703297\n",
      "True positive rate of class 1 is  0.793\n",
      "True positive rate of class 2 is  0.735\n",
      "Positive prediction rate of class 1 is  0.456\n",
      "Positive prediction rate of class 2 is  0.355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lifuchen/Desktop/research/CVDPrediction-master/src/lib/fairness_tests.py:125: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train ['Class'] = y_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23328, 88)\n",
      "(42366, 88)\n",
      "0.12332065295902152 0.08630769230769231\n",
      "0.12330769230769231\n",
      "(67137, 87)\n",
      "X train 67137\n",
      "Y train 67137\n",
      "21898 7644 14254\n",
      "21898 7644 14254\n",
      "21898 7881 14017\n",
      "21898 7881 14017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2936208542149569\n",
      "0.2622171291799545\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19944\n",
      "           1       0.44      0.03      0.05      1954\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19873    71]\n",
      " [ 1898    56]]\n",
      "done in 1.177526s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2936208542149569\n",
      "0.26348341692549476\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19955\n",
      "           1       0.45      0.03      0.06      1943\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.51      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19877    78]\n",
      " [ 1880    63]]\n",
      "done in 1.681103s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2936208542149569\n",
      "0.3033688888987729\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6814\n",
      "           1       0.37      0.02      0.03       830\n",
      "\n",
      "    accuracy                           0.89      7644\n",
      "   macro avg       0.63      0.51      0.49      7644\n",
      "weighted avg       0.84      0.89      0.84      7644\n",
      "\n",
      "Confusion_matrix\n",
      "[[6790   24]\n",
      " [ 816   14]]\n",
      "done in 1.275739s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2936208542149569\n",
      "0.29922138790523106\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      7022\n",
      "           1       0.42      0.02      0.05       859\n",
      "\n",
      "    accuracy                           0.89      7881\n",
      "   macro avg       0.66      0.51      0.49      7881\n",
      "weighted avg       0.84      0.89      0.84      7881\n",
      "\n",
      "Confusion_matrix\n",
      "[[6993   29]\n",
      " [ 838   21]]\n",
      "done in 1.128017s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2936208542149569\n",
      "0.2401486535737634\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13130\n",
      "           1       0.47      0.04      0.07      1124\n",
      "\n",
      "    accuracy                           0.92     14254\n",
      "   macro avg       0.70      0.52      0.51     14254\n",
      "weighted avg       0.89      0.92      0.89     14254\n",
      "\n",
      "Confusion_matrix\n",
      "[[13083    47]\n",
      " [ 1082    42]]\n",
      "done in 1.266763s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2936208542149569\n",
      "0.2433898912572846\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96     12933\n",
      "           1       0.46      0.04      0.07      1084\n",
      "\n",
      "    accuracy                           0.92     14017\n",
      "   macro avg       0.69      0.52      0.52     14017\n",
      "weighted avg       0.89      0.92      0.89     14017\n",
      "\n",
      "Confusion_matrix\n",
      "[[12884    49]\n",
      " [ 1042    42]]\n",
      "done in 1.130090s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19944\n",
      "           1       0.29      0.00      0.00      1954\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.60      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19939     5]\n",
      " [ 1952     2]]\n",
      "done in 22.011870s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19955\n",
      "           1       0.53      0.00      0.01      1943\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.72      0.50      0.48     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19948     7]\n",
      " [ 1935     8]]\n",
      "done in 22.496916s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6814\n",
      "           1       0.50      0.00      0.01       830\n",
      "\n",
      "    accuracy                           0.89      7644\n",
      "   macro avg       0.70      0.50      0.47      7644\n",
      "weighted avg       0.85      0.89      0.84      7644\n",
      "\n",
      "Confusion_matrix\n",
      "[[6811    3]\n",
      " [ 827    3]]\n",
      "done in 21.930023s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      7022\n",
      "           1       0.50      0.00      0.00       859\n",
      "\n",
      "    accuracy                           0.89      7881\n",
      "   macro avg       0.70      0.50      0.47      7881\n",
      "weighted avg       0.85      0.89      0.84      7881\n",
      "\n",
      "Confusion_matrix\n",
      "[[7021    1]\n",
      " [ 858    1]]\n",
      "done in 21.611612s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13130\n",
      "           1       0.00      0.00      0.00      1124\n",
      "\n",
      "    accuracy                           0.92     14254\n",
      "   macro avg       0.46      0.50      0.48     14254\n",
      "weighted avg       0.85      0.92      0.88     14254\n",
      "\n",
      "Confusion_matrix\n",
      "[[13127     3]\n",
      " [ 1124     0]]\n",
      "done in 20.891110s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12933\n",
      "           1       0.00      0.00      0.00      1084\n",
      "\n",
      "    accuracy                           0.92     14017\n",
      "   macro avg       0.46      0.50      0.48     14017\n",
      "weighted avg       0.85      0.92      0.89     14017\n",
      "\n",
      "Confusion_matrix\n",
      "[[12928     5]\n",
      " [ 1084     0]]\n",
      "done in 19.856579s\n",
      "0.30380841025286837\n",
      "0.2695132341898859\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19944\n",
      "           1       0.14      0.00      0.00      1954\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.53      0.50      0.48     21898\n",
      "weighted avg       0.84      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19932    12]\n",
      " [ 1952     2]]\n",
      "done in 0.660962s\n",
      "0.30380841025286837\n",
      "0.27224809824363994\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19955\n",
      "           1       0.19      0.00      0.01      1943\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.55      0.50      0.48     21898\n",
      "weighted avg       0.85      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19930    25]\n",
      " [ 1937     6]]\n",
      "done in 0.657581s\n",
      "0.30380841025286837\n",
      "0.3075486026809833\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6814\n",
      "           1       0.20      0.00      0.00       830\n",
      "\n",
      "    accuracy                           0.89      7644\n",
      "   macro avg       0.55      0.50      0.47      7644\n",
      "weighted avg       0.82      0.89      0.84      7644\n",
      "\n",
      "Confusion_matrix\n",
      "[[6810    4]\n",
      " [ 829    1]]\n",
      "done in 0.641206s\n",
      "0.30380841025286837\n",
      "0.30826456708204986\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      7022\n",
      "           1       0.31      0.00      0.01       859\n",
      "\n",
      "    accuracy                           0.89      7881\n",
      "   macro avg       0.60      0.50      0.48      7881\n",
      "weighted avg       0.83      0.89      0.84      7881\n",
      "\n",
      "Confusion_matrix\n",
      "[[7013    9]\n",
      " [ 855    4]]\n",
      "done in 0.637940s\n",
      "0.30380841025286837\n",
      "0.24911598732963974\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13130\n",
      "           1       0.11      0.00      0.00      1124\n",
      "\n",
      "    accuracy                           0.92     14254\n",
      "   macro avg       0.52      0.50      0.48     14254\n",
      "weighted avg       0.86      0.92      0.88     14254\n",
      "\n",
      "Confusion_matrix\n",
      "[[13122     8]\n",
      " [ 1123     1]]\n",
      "done in 0.620701s\n",
      "0.30380841025286837\n",
      "0.25199798831173514\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12933\n",
      "           1       0.11      0.00      0.00      1084\n",
      "\n",
      "    accuracy                           0.92     14017\n",
      "   macro avg       0.52      0.50      0.48     14017\n",
      "weighted avg       0.86      0.92      0.89     14017\n",
      "\n",
      "Confusion_matrix\n",
      "[[12917    16]\n",
      " [ 1082     2]]\n",
      "done in 0.636685s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19944\n",
      "           1       0.49      0.01      0.02      1954\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.70      0.51      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19919    25]\n",
      " [ 1930    24]]\n",
      "done in 35.226489s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19955\n",
      "           1       0.40      0.01      0.02      1943\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.66      0.51      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19921    34]\n",
      " [ 1920    23]]\n",
      "done in 35.458329s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6814\n",
      "           1       0.60      0.01      0.02       830\n",
      "\n",
      "    accuracy                           0.89      7644\n",
      "   macro avg       0.75      0.50      0.48      7644\n",
      "weighted avg       0.86      0.89      0.84      7644\n",
      "\n",
      "Confusion_matrix\n",
      "[[6808    6]\n",
      " [ 821    9]]\n",
      "done in 34.866487s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      7022\n",
      "           1       0.48      0.02      0.03       859\n",
      "\n",
      "    accuracy                           0.89      7881\n",
      "   macro avg       0.69      0.51      0.49      7881\n",
      "weighted avg       0.85      0.89      0.84      7881\n",
      "\n",
      "Confusion_matrix\n",
      "[[7008   14]\n",
      " [ 846   13]]\n",
      "done in 34.244145s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13130\n",
      "           1       0.44      0.01      0.03      1124\n",
      "\n",
      "    accuracy                           0.92     14254\n",
      "   macro avg       0.68      0.51      0.49     14254\n",
      "weighted avg       0.88      0.92      0.89     14254\n",
      "\n",
      "Confusion_matrix\n",
      "[[13111    19]\n",
      " [ 1109    15]]\n",
      "done in 35.186572s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12933\n",
      "           1       0.34      0.01      0.02      1084\n",
      "\n",
      "    accuracy                           0.92     14017\n",
      "   macro avg       0.63      0.50      0.49     14017\n",
      "weighted avg       0.88      0.92      0.89     14017\n",
      "\n",
      "Confusion_matrix\n",
      "[[12914    19]\n",
      " [ 1074    10]]\n",
      "done in 35.252779s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.39599999999999996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.2, J-value:0.301\n",
      "threshold:0.30000000000000004, J-value:0.156\n",
      "threshold:0.4, J-value:0.064\n",
      "threshold:0.5, J-value:0.025\n",
      "threshold:0.6000000000000001, J-value:0.009999999999999998\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.698151497683791\n",
      "Balanced accuracy score of test is  0.6934598600840569\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.353\n",
      "threshold:0.2, J-value:0.272\n",
      "threshold:0.30000000000000004, J-value:0.131\n",
      "threshold:0.4, J-value:0.046\n",
      "threshold:0.5, J-value:0.013000000000000001\n",
      "threshold:0.6000000000000001, J-value:0.006\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6763773025769058\n",
      "Balanced accuracy score of test is  0.6948341135742017\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.418\n",
      "threshold:0.2, J-value:0.32\n",
      "threshold:0.30000000000000004, J-value:0.175\n",
      "threshold:0.4, J-value:0.076\n",
      "threshold:0.5, J-value:0.033\n",
      "threshold:0.6000000000000001, J-value:0.013000000000000001\n",
      "threshold:0.7000000000000001, J-value:0.003\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7092988808872676\n",
      "Balanced accuracy score of test is  0.6873930586905034\n",
      "True positive rate of class 1 is  0.768\n",
      "True positive rate of class 2 is  0.692\n",
      "Positive prediction rate of class 1 is  0.421\n",
      "Positive prediction rate of class 2 is  0.346\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.385\n",
      "threshold:0.2, J-value:0.307\n",
      "threshold:0.30000000000000004, J-value:0.121\n",
      "threshold:0.4, J-value:0.025\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6929063352822908\n",
      "Balanced accuracy score of test is  0.6912398367247563\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.35600000000000004\n",
      "threshold:0.2, J-value:0.28300000000000003\n",
      "threshold:0.30000000000000004, J-value:0.127\n",
      "threshold:0.4, J-value:0.025\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6784317192456353\n",
      "Balanced accuracy score of test is  0.6875645112036046\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.389\n",
      "threshold:0.2, J-value:0.311\n",
      "threshold:0.30000000000000004, J-value:0.139\n",
      "threshold:0.4, J-value:0.024\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6947207367876125\n",
      "Balanced accuracy score of test is  0.6881565379676065\n",
      "True positive rate of class 1 is  0.828\n",
      "True positive rate of class 2 is  0.735\n",
      "Positive prediction rate of class 1 is  0.493\n",
      "Positive prediction rate of class 2 is  0.388\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.36900000000000005\n",
      "threshold:0.2, J-value:0.29200000000000004\n",
      "threshold:0.30000000000000004, J-value:0.101\n",
      "threshold:0.4, J-value:0.001\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6844005590268925\n",
      "Balanced accuracy score of test is  0.6754888669346483\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.3350000000000001\n",
      "threshold:0.2, J-value:0.24699999999999997\n",
      "threshold:0.30000000000000004, J-value:0.10500000000000001\n",
      "threshold:0.4, J-value:0.001\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.667629720525778\n",
      "Balanced accuracy score of test is  0.6646478438461658\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.382\n",
      "threshold:0.2, J-value:0.32100000000000006\n",
      "threshold:0.30000000000000004, J-value:0.098\n",
      "threshold:0.4, J-value:0.002\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6907270709277333\n",
      "Balanced accuracy score of test is  0.6774927222132348\n",
      "True positive rate of class 1 is  0.802\n",
      "True positive rate of class 2 is  0.746\n",
      "Positive prediction rate of class 1 is  0.509\n",
      "Positive prediction rate of class 2 is  0.419\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41900000000000004\n",
      "threshold:0.2, J-value:0.304\n",
      "threshold:0.30000000000000004, J-value:0.138\n",
      "threshold:0.4, J-value:0.044\n",
      "threshold:0.5, J-value:0.011\n",
      "threshold:0.6000000000000001, J-value:0.004\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7096913065898743\n",
      "Balanced accuracy score of test is  0.7026080296725274\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.391\n",
      "threshold:0.2, J-value:0.274\n",
      "threshold:0.30000000000000004, J-value:0.132\n",
      "threshold:0.4, J-value:0.044\n",
      "threshold:0.5, J-value:0.009999999999999998\n",
      "threshold:0.6000000000000001, J-value:0.002\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6955217995551328\n",
      "Balanced accuracy score of test is  0.703052090734956\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.429\n",
      "threshold:0.2, J-value:0.323\n",
      "threshold:0.30000000000000004, J-value:0.143\n",
      "threshold:0.4, J-value:0.044\n",
      "threshold:0.5, J-value:0.012\n",
      "threshold:0.6000000000000001, J-value:0.004\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7142110241683901\n",
      "Balanced accuracy score of test is  0.6969233001307048\n",
      "True positive rate of class 1 is  0.804\n",
      "True positive rate of class 2 is  0.725\n",
      "Positive prediction rate of class 1 is  0.443\n",
      "Positive prediction rate of class 2 is  0.362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lifuchen/Desktop/research/CVDPrediction-master/src/lib/fairness_tests.py:125: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train ['Class'] = y_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23296, 88)\n",
      "(42398, 88)\n",
      "0.12005384874272802 0.085263777612819\n",
      "0.1200501702203906\n",
      "(67053, 87)\n",
      "X train 67053\n",
      "Y train 67053\n",
      "21898 7795 14103\n",
      "21898 7795 14103\n",
      "21898 7762 14136\n",
      "21898 7762 14136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2893516284526322\n",
      "0.26737253166772684\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19893\n",
      "           1       0.41      0.03      0.06      2005\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.66      0.51      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19800    93]\n",
      " [ 1940    65]]\n",
      "done in 1.108242s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2893516284526322\n",
      "0.2652406161306274\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19907\n",
      "           1       0.47      0.03      0.05      1991\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.69      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19841    66]\n",
      " [ 1933    58]]\n",
      "done in 1.315756s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2893516284526322\n",
      "0.3080404169380725\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94      6922\n",
      "           1       0.39      0.03      0.05       873\n",
      "\n",
      "    accuracy                           0.89      7795\n",
      "   macro avg       0.64      0.51      0.49      7795\n",
      "weighted avg       0.83      0.89      0.84      7795\n",
      "\n",
      "Confusion_matrix\n",
      "[[6887   35]\n",
      " [ 851   22]]\n",
      "done in 1.109610s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2893516284526322\n",
      "0.30744909433743156\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6882\n",
      "           1       0.59      0.03      0.06       880\n",
      "\n",
      "    accuracy                           0.89      7762\n",
      "   macro avg       0.74      0.51      0.50      7762\n",
      "weighted avg       0.86      0.89      0.84      7762\n",
      "\n",
      "Confusion_matrix\n",
      "[[6863   19]\n",
      " [ 853   27]]\n",
      "done in 1.116498s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2893516284526322\n",
      "0.24489460741881924\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12971\n",
      "           1       0.43      0.04      0.07      1132\n",
      "\n",
      "    accuracy                           0.92     14103\n",
      "   macro avg       0.67      0.52      0.51     14103\n",
      "weighted avg       0.88      0.92      0.89     14103\n",
      "\n",
      "Confusion_matrix\n",
      "[[12913    58]\n",
      " [ 1089    43]]\n",
      "done in 1.059821s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2893516284526322\n",
      "0.24206417245199024\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13025\n",
      "           1       0.40      0.03      0.05      1111\n",
      "\n",
      "    accuracy                           0.92     14136\n",
      "   macro avg       0.66      0.51      0.51     14136\n",
      "weighted avg       0.88      0.92      0.89     14136\n",
      "\n",
      "Confusion_matrix\n",
      "[[12978    47]\n",
      " [ 1080    31]]\n",
      "done in 1.063808s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19893\n",
      "           1       0.44      0.00      0.01      2005\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19884     9]\n",
      " [ 1998     7]]\n",
      "done in 20.256716s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19907\n",
      "           1       0.29      0.00      0.00      1991\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.60      0.50      0.48     21898\n",
      "weighted avg       0.85      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19895    12]\n",
      " [ 1986     5]]\n",
      "done in 20.147004s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6922\n",
      "           1       0.25      0.00      0.00       873\n",
      "\n",
      "    accuracy                           0.89      7795\n",
      "   macro avg       0.57      0.50      0.47      7795\n",
      "weighted avg       0.82      0.89      0.84      7795\n",
      "\n",
      "Confusion_matrix\n",
      "[[6919    3]\n",
      " [ 872    1]]\n",
      "done in 19.793460s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6882\n",
      "           1       0.60      0.00      0.01       880\n",
      "\n",
      "    accuracy                           0.89      7762\n",
      "   macro avg       0.74      0.50      0.47      7762\n",
      "weighted avg       0.85      0.89      0.83      7762\n",
      "\n",
      "Confusion_matrix\n",
      "[[6880    2]\n",
      " [ 877    3]]\n",
      "done in 19.552494s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12971\n",
      "           1       0.50      0.01      0.02      1132\n",
      "\n",
      "    accuracy                           0.92     14103\n",
      "   macro avg       0.71      0.50      0.49     14103\n",
      "weighted avg       0.89      0.92      0.88     14103\n",
      "\n",
      "Confusion_matrix\n",
      "[[12962     9]\n",
      " [ 1123     9]]\n",
      "done in 19.785801s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13025\n",
      "           1       0.17      0.00      0.00      1111\n",
      "\n",
      "    accuracy                           0.92     14136\n",
      "   macro avg       0.54      0.50      0.48     14136\n",
      "weighted avg       0.86      0.92      0.88     14136\n",
      "\n",
      "Confusion_matrix\n",
      "[[13020     5]\n",
      " [ 1110     1]]\n",
      "done in 21.216534s\n",
      "0.3007290323804545\n",
      "0.27685813347141525\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19893\n",
      "           1       0.06      0.00      0.00      2005\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.48      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.86     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19876    17]\n",
      " [ 2004     1]]\n",
      "done in 0.651585s\n",
      "0.3007290323804545\n",
      "0.2763046087026022\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19907\n",
      "           1       0.42      0.00      0.00      1991\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.66      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19900     7]\n",
      " [ 1986     5]]\n",
      "done in 0.657374s\n",
      "0.3007290323804545\n",
      "0.31501297660353494\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6922\n",
      "           1       0.09      0.00      0.00       873\n",
      "\n",
      "    accuracy                           0.89      7795\n",
      "   macro avg       0.49      0.50      0.47      7795\n",
      "weighted avg       0.80      0.89      0.83      7795\n",
      "\n",
      "Confusion_matrix\n",
      "[[6912   10]\n",
      " [ 872    1]]\n",
      "done in 0.632234s\n",
      "0.3007290323804545\n",
      "0.3169029149166512\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6882\n",
      "           1       0.33      0.00      0.00       880\n",
      "\n",
      "    accuracy                           0.89      7762\n",
      "   macro avg       0.61      0.50      0.47      7762\n",
      "weighted avg       0.82      0.89      0.83      7762\n",
      "\n",
      "Confusion_matrix\n",
      "[[6878    4]\n",
      " [ 878    2]]\n",
      "done in 0.664816s\n",
      "0.3007290323804545\n",
      "0.2557692160627169\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12971\n",
      "           1       0.00      0.00      0.00      1132\n",
      "\n",
      "    accuracy                           0.92     14103\n",
      "   macro avg       0.46      0.50      0.48     14103\n",
      "weighted avg       0.85      0.92      0.88     14103\n",
      "\n",
      "Confusion_matrix\n",
      "[[12964     7]\n",
      " [ 1132     0]]\n",
      "done in 0.642769s\n",
      "0.3007290323804545\n",
      "0.2540123016260991\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13025\n",
      "           1       0.50      0.00      0.01      1111\n",
      "\n",
      "    accuracy                           0.92     14136\n",
      "   macro avg       0.71      0.50      0.48     14136\n",
      "weighted avg       0.89      0.92      0.88     14136\n",
      "\n",
      "Confusion_matrix\n",
      "[[13022     3]\n",
      " [ 1108     3]]\n",
      "done in 0.623550s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19893\n",
      "           1       0.48      0.02      0.03      2005\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.70      0.51      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19860    33]\n",
      " [ 1974    31]]\n",
      "done in 35.119310s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19907\n",
      "           1       0.32      0.01      0.01      1991\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.62      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19886    21]\n",
      " [ 1981    10]]\n",
      "done in 35.202525s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6922\n",
      "           1       0.38      0.01      0.02       873\n",
      "\n",
      "    accuracy                           0.89      7795\n",
      "   macro avg       0.64      0.50      0.48      7795\n",
      "weighted avg       0.83      0.89      0.84      7795\n",
      "\n",
      "Confusion_matrix\n",
      "[[6906   16]\n",
      " [ 863   10]]\n",
      "done in 34.729190s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6882\n",
      "           1       0.36      0.01      0.01       880\n",
      "\n",
      "    accuracy                           0.89      7762\n",
      "   macro avg       0.62      0.50      0.48      7762\n",
      "weighted avg       0.83      0.89      0.83      7762\n",
      "\n",
      "Confusion_matrix\n",
      "[[6873    9]\n",
      " [ 875    5]]\n",
      "done in 34.559925s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12971\n",
      "           1       0.54      0.02      0.04      1132\n",
      "\n",
      "    accuracy                           0.92     14103\n",
      "   macro avg       0.73      0.51      0.50     14103\n",
      "weighted avg       0.89      0.92      0.88     14103\n",
      "\n",
      "Confusion_matrix\n",
      "[[12953    18]\n",
      " [ 1111    21]]\n",
      "done in 35.330103s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13025\n",
      "           1       0.33      0.01      0.01      1111\n",
      "\n",
      "    accuracy                           0.92     14136\n",
      "   macro avg       0.63      0.50      0.48     14136\n",
      "weighted avg       0.88      0.92      0.88     14136\n",
      "\n",
      "Confusion_matrix\n",
      "[[13013    12]\n",
      " [ 1105     6]]\n",
      "done in 36.118156s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.40299999999999997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.2, J-value:0.29000000000000004\n",
      "threshold:0.30000000000000004, J-value:0.161\n",
      "threshold:0.4, J-value:0.068\n",
      "threshold:0.5, J-value:0.027\n",
      "threshold:0.6000000000000001, J-value:0.006\n",
      "threshold:0.7000000000000001, J-value:0.003\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7018310304267481\n",
      "Balanced accuracy score of test is  0.6990966684182403\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.382\n",
      "threshold:0.2, J-value:0.265\n",
      "threshold:0.30000000000000004, J-value:0.13999999999999999\n",
      "threshold:0.4, J-value:0.051000000000000004\n",
      "threshold:0.5, J-value:0.02\n",
      "threshold:0.6000000000000001, J-value:0.002\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6912060190908149\n",
      "Balanced accuracy score of test is  0.6926793545745158\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.409\n",
      "threshold:0.2, J-value:0.30600000000000005\n",
      "threshold:0.30000000000000004, J-value:0.177\n",
      "threshold:0.4, J-value:0.082\n",
      "threshold:0.5, J-value:0.034\n",
      "threshold:0.6000000000000001, J-value:0.01\n",
      "threshold:0.7000000000000001, J-value:0.004\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7045329510544451\n",
      "Balanced accuracy score of test is  0.6992116870036332\n",
      "True positive rate of class 1 is  0.747\n",
      "True positive rate of class 2 is  0.702\n",
      "Positive prediction rate of class 1 is  0.405\n",
      "Positive prediction rate of class 2 is  0.335\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.384\n",
      "threshold:0.2, J-value:0.303\n",
      "threshold:0.30000000000000004, J-value:0.129\n",
      "threshold:0.4, J-value:0.026\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6918361613685586\n",
      "Balanced accuracy score of test is  0.6902521890023163\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.343\n",
      "threshold:0.2, J-value:0.29000000000000004\n",
      "threshold:0.30000000000000004, J-value:0.11299999999999999\n",
      "threshold:0.4, J-value:0.025\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6714409424869425\n",
      "Balanced accuracy score of test is  0.6775412142347627\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.4\n",
      "threshold:0.2, J-value:0.299\n",
      "threshold:0.30000000000000004, J-value:0.135\n",
      "threshold:0.4, J-value:0.030000000000000002\n",
      "threshold:0.5, J-value:0.007\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6999203237556572\n",
      "Balanced accuracy score of test is  0.6934833137824339\n",
      "True positive rate of class 1 is  0.793\n",
      "True positive rate of class 2 is  0.735\n",
      "Positive prediction rate of class 1 is  0.478\n",
      "Positive prediction rate of class 2 is  0.379\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.34800000000000003\n",
      "threshold:0.2, J-value:0.277\n",
      "threshold:0.30000000000000004, J-value:0.094\n",
      "threshold:0.4, J-value:0.036\n",
      "threshold:0.5, J-value:-0.001\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6736827187548146\n",
      "Balanced accuracy score of test is  0.6713638686088201\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.33599999999999997\n",
      "threshold:0.2, J-value:0.255\n",
      "threshold:0.30000000000000004, J-value:0.07700000000000001\n",
      "threshold:0.4, J-value:0.037\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6675770730175183\n",
      "Balanced accuracy score of test is  0.6565574555493909\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.34400000000000003\n",
      "threshold:0.2, J-value:0.292\n",
      "threshold:0.30000000000000004, J-value:0.10800000000000001\n",
      "threshold:0.4, J-value:0.035\n",
      "threshold:0.5, J-value:-0.001\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6720649325636177\n",
      "Balanced accuracy score of test is  0.6766730185494557\n",
      "True positive rate of class 1 is  0.792\n",
      "True positive rate of class 2 is  0.758\n",
      "Positive prediction rate of class 1 is  0.514\n",
      "Positive prediction rate of class 2 is  0.432\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.406\n",
      "threshold:0.2, J-value:0.305\n",
      "threshold:0.30000000000000004, J-value:0.15\n",
      "threshold:0.4, J-value:0.05\n",
      "threshold:0.5, J-value:0.013\n",
      "threshold:0.6000000000000001, J-value:0.002\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7031016938125204\n",
      "Balanced accuracy score of test is  0.7043941924120944\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.381\n",
      "threshold:0.2, J-value:0.267\n",
      "threshold:0.30000000000000004, J-value:0.137\n",
      "threshold:0.4, J-value:0.042\n",
      "threshold:0.5, J-value:0.009\n",
      "threshold:0.6000000000000001, J-value:0.002\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.690386214844315\n",
      "Balanced accuracy score of test is  0.7012187590816623\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.414\n",
      "threshold:0.2, J-value:0.332\n",
      "threshold:0.30000000000000004, J-value:0.161\n",
      "threshold:0.4, J-value:0.056\n",
      "threshold:0.5, J-value:0.018\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7069407073621422\n",
      "Balanced accuracy score of test is  0.7006608146419249\n",
      "True positive rate of class 1 is  0.788\n",
      "True positive rate of class 2 is  0.719\n",
      "Positive prediction rate of class 1 is  0.431\n",
      "Positive prediction rate of class 2 is  0.349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lifuchen/Desktop/research/CVDPrediction-master/src/lib/fairness_tests.py:125: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train ['Class'] = y_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23200, 88)\n",
      "(42494, 88)\n",
      "0.12305160228482913 0.08621967741110913\n",
      "0.12302855243986606\n",
      "(67134, 87)\n",
      "X train 67134\n",
      "Y train 67134\n",
      "21898 7804 14094\n",
      "21898 7804 14094\n",
      "21898 7849 14049\n",
      "21898 7849 14049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2917814908515603\n",
      "0.2655435449827048\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19931\n",
      "           1       0.51      0.04      0.07      1967\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.71      0.52      0.51     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19863    68]\n",
      " [ 1897    70]]\n",
      "done in 1.090642s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2917814908515603\n",
      "0.2624492604731559\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19956\n",
      "           1       0.40      0.03      0.05      1942\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.66      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19870    86]\n",
      " [ 1885    57]]\n",
      "done in 1.010807s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2917814908515603\n",
      "0.30742604684835406\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6937\n",
      "           1       0.56      0.04      0.07       867\n",
      "\n",
      "    accuracy                           0.89      7804\n",
      "   macro avg       0.73      0.52      0.51      7804\n",
      "weighted avg       0.86      0.89      0.84      7804\n",
      "\n",
      "Confusion_matrix\n",
      "[[6912   25]\n",
      " [ 835   32]]\n",
      "done in 1.279743s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2917814908515603\n",
      "0.2979995736923605\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.94      7008\n",
      "           1       0.49      0.03      0.06       841\n",
      "\n",
      "    accuracy                           0.89      7849\n",
      "   macro avg       0.69      0.51      0.50      7849\n",
      "weighted avg       0.85      0.89      0.85      7849\n",
      "\n",
      "Confusion_matrix\n",
      "[[6982   26]\n",
      " [ 816   25]]\n",
      "done in 1.051145s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2917814908515603\n",
      "0.2423527514138438\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12994\n",
      "           1       0.47      0.03      0.06      1100\n",
      "\n",
      "    accuracy                           0.92     14094\n",
      "   macro avg       0.70      0.52      0.51     14094\n",
      "weighted avg       0.89      0.92      0.89     14094\n",
      "\n",
      "Confusion_matrix\n",
      "[[12951    43]\n",
      " [ 1062    38]]\n",
      "done in 1.015228s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2917814908515603\n",
      "0.242587746596187\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12948\n",
      "           1       0.35      0.03      0.05      1101\n",
      "\n",
      "    accuracy                           0.92     14049\n",
      "   macro avg       0.64      0.51      0.51     14049\n",
      "weighted avg       0.88      0.92      0.89     14049\n",
      "\n",
      "Confusion_matrix\n",
      "[[12888    60]\n",
      " [ 1069    32]]\n",
      "done in 1.066867s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19931\n",
      "           1       0.50      0.01      0.01      1967\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.71      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19921    10]\n",
      " [ 1957    10]]\n",
      "done in 20.530080s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19956\n",
      "           1       0.50      0.00      0.01      1942\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.71      0.50      0.48     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19951     5]\n",
      " [ 1937     5]]\n",
      "done in 19.993128s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6937\n",
      "           1       0.43      0.01      0.01       867\n",
      "\n",
      "    accuracy                           0.89      7804\n",
      "   macro avg       0.66      0.50      0.48      7804\n",
      "weighted avg       0.84      0.89      0.84      7804\n",
      "\n",
      "Confusion_matrix\n",
      "[[6929    8]\n",
      " [ 861    6]]\n",
      "done in 19.568152s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      7008\n",
      "           1       0.29      0.00      0.00       841\n",
      "\n",
      "    accuracy                           0.89      7849\n",
      "   macro avg       0.59      0.50      0.47      7849\n",
      "weighted avg       0.83      0.89      0.84      7849\n",
      "\n",
      "Confusion_matrix\n",
      "[[7003    5]\n",
      " [ 839    2]]\n",
      "done in 19.693161s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12994\n",
      "           1       0.33      0.00      0.00      1100\n",
      "\n",
      "    accuracy                           0.92     14094\n",
      "   macro avg       0.63      0.50      0.48     14094\n",
      "weighted avg       0.88      0.92      0.88     14094\n",
      "\n",
      "Confusion_matrix\n",
      "[[12990     4]\n",
      " [ 1098     2]]\n",
      "done in 19.592729s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12948\n",
      "           1       0.36      0.00      0.01      1101\n",
      "\n",
      "    accuracy                           0.92     14049\n",
      "   macro avg       0.64      0.50      0.48     14049\n",
      "weighted avg       0.88      0.92      0.88     14049\n",
      "\n",
      "Confusion_matrix\n",
      "[[12941     7]\n",
      " [ 1097     4]]\n",
      "done in 19.658987s\n",
      "0.3038767264248238\n",
      "0.2727769927641789\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19931\n",
      "           1       0.00      0.00      0.00      1967\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.46      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19931     0]\n",
      " [ 1967     0]]\n",
      "done in 0.659678s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3038767264248238\n",
      "0.27001446251680694\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19956\n",
      "           1       0.00      0.00      0.00      1942\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.46      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19954     2]\n",
      " [ 1942     0]]\n",
      "done in 0.653052s\n",
      "0.3038767264248238\n",
      "0.3176885420397966\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6937\n",
      "           1       0.00      0.00      0.00       867\n",
      "\n",
      "    accuracy                           0.89      7804\n",
      "   macro avg       0.44      0.50      0.47      7804\n",
      "weighted avg       0.79      0.89      0.84      7804\n",
      "\n",
      "Confusion_matrix\n",
      "[[6937    0]\n",
      " [ 867    0]]\n",
      "done in 0.625426s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3038767264248238\n",
      "0.30461267578132667\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      7008\n",
      "           1       0.00      0.00      0.00       841\n",
      "\n",
      "    accuracy                           0.89      7849\n",
      "   macro avg       0.45      0.50      0.47      7849\n",
      "weighted avg       0.80      0.89      0.84      7849\n",
      "\n",
      "Confusion_matrix\n",
      "[[7007    1]\n",
      " [ 841    0]]\n",
      "done in 0.641834s\n",
      "0.3038767264248238\n",
      "0.24790898293397307\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12994\n",
      "           1       0.00      0.00      0.00      1100\n",
      "\n",
      "    accuracy                           0.92     14094\n",
      "   macro avg       0.46      0.50      0.48     14094\n",
      "weighted avg       0.85      0.92      0.88     14094\n",
      "\n",
      "Confusion_matrix\n",
      "[[12994     0]\n",
      " [ 1100     0]]\n",
      "done in 0.642334s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3038767264248238\n",
      "0.2506848749366792\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12948\n",
      "           1       0.00      0.00      0.00      1101\n",
      "\n",
      "    accuracy                           0.92     14049\n",
      "   macro avg       0.46      0.50      0.48     14049\n",
      "weighted avg       0.85      0.92      0.88     14049\n",
      "\n",
      "Confusion_matrix\n",
      "[[12947     1]\n",
      " [ 1101     0]]\n",
      "done in 0.639994s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19931\n",
      "           1       0.35      0.01      0.02      1967\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.63      0.50      0.49     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19896    35]\n",
      " [ 1948    19]]\n",
      "done in 34.763367s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19956\n",
      "           1       0.34      0.01      0.02      1942\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.63      0.50      0.49     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19921    35]\n",
      " [ 1924    18]]\n",
      "done in 34.945834s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6937\n",
      "           1       0.38      0.01      0.02       867\n",
      "\n",
      "    accuracy                           0.89      7804\n",
      "   macro avg       0.63      0.50      0.48      7804\n",
      "weighted avg       0.83      0.89      0.84      7804\n",
      "\n",
      "Confusion_matrix\n",
      "[[6922   15]\n",
      " [ 858    9]]\n",
      "done in 34.357045s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      7008\n",
      "           1       0.25      0.01      0.02       841\n",
      "\n",
      "    accuracy                           0.89      7849\n",
      "   macro avg       0.57      0.50      0.48      7849\n",
      "weighted avg       0.82      0.89      0.84      7849\n",
      "\n",
      "Confusion_matrix\n",
      "[[6987   21]\n",
      " [ 834    7]]\n",
      "done in 34.623642s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12994\n",
      "           1       0.33      0.01      0.02      1100\n",
      "\n",
      "    accuracy                           0.92     14094\n",
      "   macro avg       0.63      0.50      0.49     14094\n",
      "weighted avg       0.88      0.92      0.89     14094\n",
      "\n",
      "Confusion_matrix\n",
      "[[12974    20]\n",
      " [ 1090    10]]\n",
      "done in 35.284374s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12948\n",
      "           1       0.44      0.01      0.02      1101\n",
      "\n",
      "    accuracy                           0.92     14049\n",
      "   macro avg       0.68      0.50      0.49     14049\n",
      "weighted avg       0.88      0.92      0.89     14049\n",
      "\n",
      "Confusion_matrix\n",
      "[[12934    14]\n",
      " [ 1090    11]]\n",
      "done in 35.537014s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.39199999999999996\n",
      "threshold:0.2, J-value:0.279\n",
      "threshold:0.30000000000000004, J-value:0.149\n",
      "threshold:0.4, J-value:0.07100000000000001\n",
      "threshold:0.5, J-value:0.032999999999999995\n",
      "threshold:0.6000000000000001, J-value:0.009999999999999998\n",
      "threshold:0.7000000000000001, J-value:0.004\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6964430564552944\n",
      "Balanced accuracy score of test is  0.6992321572959997\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.367\n",
      "threshold:0.2, J-value:0.275\n",
      "threshold:0.30000000000000004, J-value:0.14600000000000002\n",
      "threshold:0.4, J-value:0.068\n",
      "threshold:0.5, J-value:0.033\n",
      "threshold:0.6000000000000001, J-value:0.011\n",
      "threshold:0.7000000000000001, J-value:0.003\n",
      "threshold:0.8, J-value:0.002\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6839229785818286\n",
      "Balanced accuracy score of test is  0.6875296925816733\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.40099999999999997\n",
      "threshold:0.2, J-value:0.278\n",
      "threshold:0.30000000000000004, J-value:0.151\n",
      "threshold:0.4, J-value:0.074\n",
      "threshold:0.5, J-value:0.032\n",
      "threshold:0.6000000000000001, J-value:0.009999999999999998\n",
      "threshold:0.7000000000000001, J-value:0.004\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7004671386793905\n",
      "Balanced accuracy score of test is  0.703480553949186\n",
      "True positive rate of class 1 is  0.751\n",
      "True positive rate of class 2 is  0.718\n",
      "Positive prediction rate of class 1 is  0.417\n",
      "Positive prediction rate of class 2 is  0.343\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.378\n",
      "threshold:0.2, J-value:0.29100000000000004\n",
      "threshold:0.30000000000000004, J-value:0.13499999999999998\n",
      "threshold:0.4, J-value:0.034\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6888539355030066\n",
      "Balanced accuracy score of test is  0.6916804508538765\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.34500000000000003\n",
      "threshold:0.2, J-value:0.28900000000000003\n",
      "threshold:0.30000000000000004, J-value:0.15000000000000002\n",
      "threshold:0.4, J-value:0.034999999999999996\n",
      "threshold:0.5, J-value:0.006\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6721783745254497\n",
      "Balanced accuracy score of test is  0.6780628491847605\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.39\n",
      "threshold:0.2, J-value:0.289\n",
      "threshold:0.30000000000000004, J-value:0.125\n",
      "threshold:0.4, J-value:0.031000000000000003\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6950683532259645\n",
      "Balanced accuracy score of test is  0.6958950873710731\n",
      "True positive rate of class 1 is  0.813\n",
      "True positive rate of class 2 is  0.747\n",
      "Positive prediction rate of class 1 is  0.495\n",
      "Positive prediction rate of class 2 is  0.386\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.359\n",
      "threshold:0.2, J-value:0.279\n",
      "threshold:0.30000000000000004, J-value:0.071\n",
      "threshold:0.4, J-value:0.067\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6796425425725872\n",
      "Balanced accuracy score of test is  0.6861890701252333\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.323\n",
      "threshold:0.2, J-value:0.255\n",
      "threshold:0.30000000000000004, J-value:0.07\n",
      "threshold:0.4, J-value:0.062\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.661510107693579\n",
      "Balanced accuracy score of test is  0.6738294505616819\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.369\n",
      "threshold:0.2, J-value:0.293\n",
      "threshold:0.30000000000000004, J-value:0.071\n",
      "threshold:0.4, J-value:0.07200000000000001\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6846450809464508\n",
      "Balanced accuracy score of test is  0.6874905827459913\n",
      "True positive rate of class 1 is  0.819\n",
      "True positive rate of class 2 is  0.734\n",
      "Positive prediction rate of class 1 is  0.509\n",
      "Positive prediction rate of class 2 is  0.388\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.397\n",
      "threshold:0.2, J-value:0.299\n",
      "threshold:0.30000000000000004, J-value:0.159\n",
      "threshold:0.4, J-value:0.057\n",
      "threshold:0.5, J-value:0.008\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6984525820996521\n",
      "Balanced accuracy score of test is  0.7060931577792462\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.369\n",
      "threshold:0.2, J-value:0.284\n",
      "threshold:0.30000000000000004, J-value:0.162\n",
      "threshold:0.4, J-value:0.061\n",
      "threshold:0.5, J-value:0.008\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6849337229994984\n",
      "Balanced accuracy score of test is  0.698563710439301\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.40599999999999997\n",
      "threshold:0.2, J-value:0.306\n",
      "threshold:0.30000000000000004, J-value:0.154\n",
      "threshold:0.4, J-value:0.052\n",
      "threshold:0.5, J-value:0.006999999999999999\n",
      "threshold:0.6000000000000001, J-value:0.002\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7030118096464102\n",
      "Balanced accuracy score of test is  0.7069855611925799\n",
      "True positive rate of class 1 is  0.793\n",
      "True positive rate of class 2 is  0.742\n",
      "Positive prediction rate of class 1 is  0.439\n",
      "Positive prediction rate of class 2 is  0.361\n",
      "(23317, 88)\n",
      "(42377, 88)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lifuchen/Desktop/research/CVDPrediction-master/src/lib/fairness_tests.py:125: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train ['Class'] = y_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12501206214416674 0.08378302345208563\n",
      "0.12500959054755634\n",
      "(67306, 87)\n",
      "X train 67306\n",
      "Y train 67306\n",
      "21898 7696 14202\n",
      "21898 7696 14202\n",
      "21898 7840 14058\n",
      "21898 7840 14058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29642168180406603\n",
      "0.2608409079271489\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19973\n",
      "           1       0.44      0.03      0.06      1925\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.51      0.51     21898\n",
      "weighted avg       0.87      0.91      0.88     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19894    79]\n",
      " [ 1862    63]]\n",
      "done in 1.105365s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29642168180406603\n",
      "0.2689222288081113\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19866\n",
      "           1       0.50      0.04      0.07      2032\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.71      0.52      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19795    71]\n",
      " [ 1960    72]]\n",
      "done in 1.076083s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29642168180406603\n",
      "0.28946064211583633\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      6911\n",
      "           1       0.47      0.03      0.06       785\n",
      "\n",
      "    accuracy                           0.90      7696\n",
      "   macro avg       0.69      0.51      0.50      7696\n",
      "weighted avg       0.86      0.90      0.86      7696\n",
      "\n",
      "Confusion_matrix\n",
      "[[6883   28]\n",
      " [ 760   25]]\n",
      "done in 1.044929s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29642168180406603\n",
      "0.3063051575712244\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6966\n",
      "           1       0.44      0.03      0.05       874\n",
      "\n",
      "    accuracy                           0.89      7840\n",
      "   macro avg       0.66      0.51      0.50      7840\n",
      "weighted avg       0.84      0.89      0.84      7840\n",
      "\n",
      "Confusion_matrix\n",
      "[[6935   31]\n",
      " [ 850   24]]\n",
      "done in 1.095885s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29642168180406603\n",
      "0.2453320025394473\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13062\n",
      "           1       0.43      0.03      0.06      1140\n",
      "\n",
      "    accuracy                           0.92     14202\n",
      "   macro avg       0.67      0.51      0.51     14202\n",
      "weighted avg       0.88      0.92      0.89     14202\n",
      "\n",
      "Confusion_matrix\n",
      "[[13011    51]\n",
      " [ 1102    38]]\n",
      "done in 1.089433s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29642168180406603\n",
      "0.24807415927454987\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12900\n",
      "           1       0.55      0.04      0.08      1158\n",
      "\n",
      "    accuracy                           0.92     14058\n",
      "   macro avg       0.73      0.52      0.52     14058\n",
      "weighted avg       0.89      0.92      0.88     14058\n",
      "\n",
      "Confusion_matrix\n",
      "[[12860    40]\n",
      " [ 1110    48]]\n",
      "done in 1.415921s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19973\n",
      "           1       0.43      0.00      0.01      1925\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19965     8]\n",
      " [ 1919     6]]\n",
      "done in 20.054927s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19866\n",
      "           1       0.42      0.00      0.00      2032\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.66      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.86     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19859     7]\n",
      " [ 2027     5]]\n",
      "done in 20.129451s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      6911\n",
      "           1       0.14      0.00      0.00       785\n",
      "\n",
      "    accuracy                           0.90      7696\n",
      "   macro avg       0.52      0.50      0.47      7696\n",
      "weighted avg       0.82      0.90      0.85      7696\n",
      "\n",
      "Confusion_matrix\n",
      "[[6905    6]\n",
      " [ 784    1]]\n",
      "done in 19.771706s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6966\n",
      "           1       0.36      0.00      0.01       874\n",
      "\n",
      "    accuracy                           0.89      7840\n",
      "   macro avg       0.63      0.50      0.47      7840\n",
      "weighted avg       0.83      0.89      0.84      7840\n",
      "\n",
      "Confusion_matrix\n",
      "[[6959    7]\n",
      " [ 870    4]]\n",
      "done in 19.641485s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13062\n",
      "           1       0.60      0.00      0.01      1140\n",
      "\n",
      "    accuracy                           0.92     14202\n",
      "   macro avg       0.76      0.50      0.48     14202\n",
      "weighted avg       0.89      0.92      0.88     14202\n",
      "\n",
      "Confusion_matrix\n",
      "[[13060     2]\n",
      " [ 1137     3]]\n",
      "done in 19.748386s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12900\n",
      "           1       0.33      0.00      0.00      1158\n",
      "\n",
      "    accuracy                           0.92     14058\n",
      "   macro avg       0.63      0.50      0.48     14058\n",
      "weighted avg       0.87      0.92      0.88     14058\n",
      "\n",
      "Confusion_matrix\n",
      "[[12896     4]\n",
      " [ 1156     2]]\n",
      "done in 20.107622s\n",
      "0.3071988111029656\n",
      "0.2702525245375026\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19973\n",
      "           1       0.24      0.00      0.01      1925\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.58      0.50      0.48     21898\n",
      "weighted avg       0.85      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19951    22]\n",
      " [ 1918     7]]\n",
      "done in 0.663741s\n",
      "0.3071988111029656\n",
      "0.278320351446515\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19866\n",
      "           1       0.32      0.00      0.01      2032\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.62      0.50      0.48     21898\n",
      "weighted avg       0.85      0.91      0.86     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19845    21]\n",
      " [ 2022    10]]\n",
      "done in 0.681745s\n",
      "0.3071988111029656\n",
      "0.2995226562981816\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      6911\n",
      "           1       0.12      0.00      0.00       785\n",
      "\n",
      "    accuracy                           0.90      7696\n",
      "   macro avg       0.51      0.50      0.47      7696\n",
      "weighted avg       0.82      0.90      0.85      7696\n",
      "\n",
      "Confusion_matrix\n",
      "[[6904    7]\n",
      " [ 784    1]]\n",
      "done in 0.635737s\n",
      "0.3071988111029656\n",
      "0.3146256987837641\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6966\n",
      "           1       0.47      0.01      0.02       874\n",
      "\n",
      "    accuracy                           0.89      7840\n",
      "   macro avg       0.68      0.50      0.48      7840\n",
      "weighted avg       0.84      0.89      0.84      7840\n",
      "\n",
      "Confusion_matrix\n",
      "[[6958    8]\n",
      " [ 867    7]]\n",
      "done in 0.695288s\n",
      "0.3071988111029656\n",
      "0.2546079726844966\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13062\n",
      "           1       0.25      0.00      0.01      1140\n",
      "\n",
      "    accuracy                           0.92     14202\n",
      "   macro avg       0.58      0.50      0.48     14202\n",
      "weighted avg       0.87      0.92      0.88     14202\n",
      "\n",
      "Confusion_matrix\n",
      "[[13047    15]\n",
      " [ 1135     5]]\n",
      "done in 0.647448s\n",
      "0.3071988111029656\n",
      "0.2580732378368954\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12900\n",
      "           1       0.19      0.00      0.01      1158\n",
      "\n",
      "    accuracy                           0.92     14058\n",
      "   macro avg       0.55      0.50      0.48     14058\n",
      "weighted avg       0.86      0.92      0.88     14058\n",
      "\n",
      "Confusion_matrix\n",
      "[[12887    13]\n",
      " [ 1155     3]]\n",
      "done in 0.662856s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19973\n",
      "           1       0.38      0.01      0.01      1925\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.65      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19955    18]\n",
      " [ 1914    11]]\n",
      "done in 35.397096s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19866\n",
      "           1       0.53      0.01      0.02      2032\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.72      0.51      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19844    22]\n",
      " [ 2007    25]]\n",
      "done in 35.218935s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      6911\n",
      "           1       0.31      0.01      0.01       785\n",
      "\n",
      "    accuracy                           0.90      7696\n",
      "   macro avg       0.60      0.50      0.48      7696\n",
      "weighted avg       0.84      0.90      0.85      7696\n",
      "\n",
      "Confusion_matrix\n",
      "[[6902    9]\n",
      " [ 781    4]]\n",
      "done in 32.936600s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6966\n",
      "           1       0.65      0.02      0.03       874\n",
      "\n",
      "    accuracy                           0.89      7840\n",
      "   macro avg       0.77      0.51      0.49      7840\n",
      "weighted avg       0.86      0.89      0.84      7840\n",
      "\n",
      "Confusion_matrix\n",
      "[[6958    8]\n",
      " [ 859   15]]\n",
      "done in 31.820934s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13062\n",
      "           1       0.44      0.01      0.01      1140\n",
      "\n",
      "    accuracy                           0.92     14202\n",
      "   macro avg       0.68      0.50      0.49     14202\n",
      "weighted avg       0.88      0.92      0.88     14202\n",
      "\n",
      "Confusion_matrix\n",
      "[[13053     9]\n",
      " [ 1133     7]]\n",
      "done in 31.920991s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12900\n",
      "           1       0.42      0.01      0.02      1158\n",
      "\n",
      "    accuracy                           0.92     14058\n",
      "   macro avg       0.67      0.50      0.49     14058\n",
      "weighted avg       0.88      0.92      0.88     14058\n",
      "\n",
      "Confusion_matrix\n",
      "[[12886    14]\n",
      " [ 1148    10]]\n",
      "done in 31.957781s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.395\n",
      "threshold:0.2, J-value:0.29600000000000004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.30000000000000004, J-value:0.16999999999999998\n",
      "threshold:0.4, J-value:0.07200000000000001\n",
      "threshold:0.5, J-value:0.029\n",
      "threshold:0.6000000000000001, J-value:0.009000000000000001\n",
      "threshold:0.7000000000000001, J-value:0.003\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6978284840378667\n",
      "Balanced accuracy score of test is  0.7025362497631771\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.385\n",
      "threshold:0.2, J-value:0.294\n",
      "threshold:0.30000000000000004, J-value:0.16499999999999998\n",
      "threshold:0.4, J-value:0.07\n",
      "threshold:0.5, J-value:0.028\n",
      "threshold:0.6000000000000001, J-value:0.009999999999999998\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6923260895811809\n",
      "Balanced accuracy score of test is  0.6926314541174492\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.39499999999999996\n",
      "threshold:0.2, J-value:0.29500000000000004\n",
      "threshold:0.30000000000000004, J-value:0.173\n",
      "threshold:0.4, J-value:0.07300000000000001\n",
      "threshold:0.5, J-value:0.029\n",
      "threshold:0.6000000000000001, J-value:0.008\n",
      "threshold:0.7000000000000001, J-value:0.004\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6977211920476432\n",
      "Balanced accuracy score of test is  0.7045935253243363\n",
      "True positive rate of class 1 is  0.779\n",
      "True positive rate of class 2 is  0.725\n",
      "Positive prediction rate of class 1 is  0.437\n",
      "Positive prediction rate of class 2 is  0.35\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.374\n",
      "threshold:0.2, J-value:0.30400000000000005\n",
      "threshold:0.30000000000000004, J-value:0.125\n",
      "threshold:0.4, J-value:0.028\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6871054364951126\n",
      "Balanced accuracy score of test is  0.6974500065795158\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.35699999999999993\n",
      "threshold:0.2, J-value:0.317\n",
      "threshold:0.30000000000000004, J-value:0.14100000000000001\n",
      "threshold:0.4, J-value:0.025\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6784306749970277\n",
      "Balanced accuracy score of test is  0.6726829760241145\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.379\n",
      "threshold:0.2, J-value:0.293\n",
      "threshold:0.30000000000000004, J-value:0.135\n",
      "threshold:0.4, J-value:0.020999999999999998\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6896614526670373\n",
      "Balanced accuracy score of test is  0.7053034502148854\n",
      "True positive rate of class 1 is  0.815\n",
      "True positive rate of class 2 is  0.758\n",
      "Positive prediction rate of class 1 is  0.508\n",
      "Positive prediction rate of class 2 is  0.381\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.357\n",
      "threshold:0.2, J-value:0.24300000000000002\n",
      "threshold:0.30000000000000004, J-value:0.124\n",
      "threshold:0.4, J-value:0.004\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.001\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6783959124038231\n",
      "Balanced accuracy score of test is  0.6834166623067466\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.342\n",
      "threshold:0.2, J-value:0.233\n",
      "threshold:0.30000000000000004, J-value:0.11099999999999999\n",
      "threshold:0.4, J-value:0.002\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6713761961683903\n",
      "Balanced accuracy score of test is  0.6688014225354797\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.355\n",
      "threshold:0.2, J-value:0.241\n",
      "threshold:0.30000000000000004, J-value:0.133\n",
      "threshold:0.4, J-value:0.005\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6775914867554739\n",
      "Balanced accuracy score of test is  0.6877005261678114\n",
      "True positive rate of class 1 is  0.779\n",
      "True positive rate of class 2 is  0.72\n",
      "Positive prediction rate of class 1 is  0.479\n",
      "Positive prediction rate of class 2 is  0.376\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.402\n",
      "threshold:0.2, J-value:0.296\n",
      "threshold:0.30000000000000004, J-value:0.147\n",
      "threshold:0.4, J-value:0.051000000000000004\n",
      "threshold:0.5, J-value:0.005\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7009271477533632\n",
      "Balanced accuracy score of test is  0.7027616774515236\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.38399999999999995\n",
      "threshold:0.2, J-value:0.297\n",
      "threshold:0.30000000000000004, J-value:0.159\n",
      "threshold:0.4, J-value:0.057\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6921613010551811\n",
      "Balanced accuracy score of test is  0.6934287231016161\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.40299999999999997\n",
      "threshold:0.2, J-value:0.29000000000000004\n",
      "threshold:0.30000000000000004, J-value:0.138\n",
      "threshold:0.4, J-value:0.048\n",
      "threshold:0.5, J-value:0.005\n",
      "threshold:0.6000000000000001, J-value:0.004\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7013669624221326\n",
      "Balanced accuracy score of test is  0.7027655942483031\n",
      "True positive rate of class 1 is  0.814\n",
      "True positive rate of class 2 is  0.731\n",
      "Positive prediction rate of class 1 is  0.47\n",
      "Positive prediction rate of class 2 is  0.358\n"
     ]
    }
   ],
   "source": [
    "records_lr = []\n",
    "records_rf = []\n",
    "records_dt = []\n",
    "records_gbt = []\n",
    "for random_state in range(10):\n",
    "    fairness_metrics (X, y, \"GENDER\", random_state)\n",
    "\n",
    "result_lr = pd.DataFrame(records_lr)\n",
    "result_rf = pd.DataFrame(records_rf)\n",
    "result_dt = pd.DataFrame(records_dt)\n",
    "result_gbt = pd.DataFrame(records_gbt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_mean_sd(records, result_table, overall_records, type):\n",
    "    records.append({\n",
    "        'auroc': result_table[\"auroc\"].mean(),\n",
    "        'overall threshold': result_table[\"overall threshold\"].mean(),\n",
    "        'male threshold': result_table[\"male threshold\"].mean(),\n",
    "        'female threshold': result_table[\"female threshold\"].mean(),\n",
    "        'overall ba validation': result_table[\"overall ba validation\"].mean(),\n",
    "        'overall ba test': result_table[\"overall ba test\"].mean(),\n",
    "        'male ba validation': result_table[\"male ba validation\"].mean(),\n",
    "        'male ba test': result_table[\"male ba test\"].mean(),\n",
    "        'female ba validation': result_table[\"female ba validation\"].mean(),\n",
    "        'female ba test': result_table[\"female ba test\"].mean(),\n",
    "        'overall precision':result_table[\"overall precision\"].mean(),\n",
    "        'overall recall':result_table[\"overall recall\"].mean(),\n",
    "        'overall tpr':result_table[\"overall tpr\"].mean(),\n",
    "        'overall tnr':result_table[\"overall tnr\"].mean(),\n",
    "        'overall pd':result_table[\"overall pd\"].mean(),\n",
    "        'male precision':result_table[\"male precision\"].mean(),\n",
    "        'male recall':result_table[\"male recall\"].mean(),\n",
    "        'male tpr':result_table[\"male tpr\"].mean(),\n",
    "        'male tnr':result_table[\"male tnr\"].mean(),\n",
    "        'male pd':result_table[\"male pd\"].mean(),\n",
    "        'female precision':result_table[\"female precision\"].mean(),\n",
    "        'female recall':result_table[\"female recall\"].mean(),\n",
    "        'female tpr':result_table[\"female tpr\"].mean(),\n",
    "        'female tnr':result_table[\"female tnr\"].mean(),\n",
    "        'female pd':result_table[\"female pd\"].mean(),\n",
    "        'eod': result_table[\"eod\"].mean(),\n",
    "        'di': result_table[\"di\"].mean(),\n",
    "        })\n",
    "    records.append({\n",
    "        'auroc': result_table[\"auroc\"].std(),\n",
    "        'overall threshold': result_table[\"overall threshold\"].std(),\n",
    "        'male threshold': result_table[\"male threshold\"].std(),\n",
    "        'female threshold': result_table[\"female threshold\"].std(),\n",
    "        'overall ba validation': result_table[\"overall ba validation\"].std(),\n",
    "        'overall ba test': result_table[\"overall ba test\"].std(),\n",
    "        'male ba validation': result_table[\"male ba validation\"].std(),\n",
    "        'male ba test': result_table[\"male ba test\"].std(),\n",
    "        'female ba validation': result_table[\"female ba validation\"].std(),\n",
    "        'female ba test': result_table[\"female ba test\"].std(),\n",
    "        'overall precision':result_table[\"overall precision\"].std(),\n",
    "        'overall recall':result_table[\"overall recall\"].std(),\n",
    "        'overall tpr':result_table[\"overall tpr\"].std(),\n",
    "        'overall tnr':result_table[\"overall tnr\"].std(),\n",
    "        'overall pd':result_table[\"overall pd\"].std(),\n",
    "        'male precision':result_table[\"male precision\"].std(),\n",
    "        'male recall':result_table[\"male recall\"].std(),\n",
    "        'male tpr':result_table[\"male tpr\"].std(),\n",
    "        'male tnr':result_table[\"male tnr\"].std(),\n",
    "        'male pd':result_table[\"male pd\"].std(),\n",
    "        'female precision':result_table[\"female precision\"].std(),\n",
    "        'female recall':result_table[\"female recall\"].std(),\n",
    "        'female tpr':result_table[\"female tpr\"].std(),\n",
    "        'female tnr':result_table[\"female tnr\"].std(),\n",
    "        'female pd':result_table[\"female pd\"].std(),\n",
    "        'eod': result_table[\"eod\"].std(),\n",
    "        'di': result_table[\"di\"].std(),\n",
    "        })\n",
    "    overall_records.append({\n",
    "        'type': type,\n",
    "        'auroc': result_table[\"auroc\"].mean(),\n",
    "        'overall threshold': result_table[\"overall threshold\"].mean(),\n",
    "        'male threshold': result_table[\"male threshold\"].mean(),\n",
    "        'female threshold': result_table[\"female threshold\"].mean(),\n",
    "        'overall ba test': result_table[\"overall ba test\"].mean(),\n",
    "        'male ba test': result_table[\"male ba test\"].mean(),\n",
    "        'female ba test': result_table[\"female ba test\"].mean(),\n",
    "        'overall tpr':result_table[\"overall tpr\"].mean(),\n",
    "        'overall pd':result_table[\"overall pd\"].mean(),\n",
    "        'male tpr':result_table[\"male tpr\"].mean(),\n",
    "        'male pd':result_table[\"male pd\"].mean(),\n",
    "        'female tpr':result_table[\"female tpr\"].mean(),\n",
    "        'female pd':result_table[\"female pd\"].mean(),\n",
    "        'eod': result_table[\"eod\"].mean(),\n",
    "        'di': result_table[\"di\"].mean(),\n",
    "        })\n",
    "    pd_result = pd.DataFrame(records)\n",
    "    return pd_result, overall_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_table = []\n",
    "result_lr, overall_records = add_mean_sd (records_lr, result_lr, overall_table, 'lr')\n",
    "result_rf, overall_records = add_mean_sd (records_rf, result_rf, overall_records, 'rf')\n",
    "result_dt, overall_records = add_mean_sd (records_dt, result_dt, overall_records, 'dt')\n",
    "result_gbt, overall_records = add_mean_sd (records_gbt, result_gbt, overall_records, 'gbt')\n",
    "\n",
    "result_path='/Users/lifuchen/Desktop/research/resample_data/'\n",
    "result_lr.to_csv(path.join(result_path,'gender-lr-resample-proportion-result.csv'), index=False)\n",
    "result_rf.to_csv(path.join(result_path,'gender-rf-resample-proportion-result.csv'), index=False)\n",
    "result_dt.to_csv(path.join(result_path,'gender-dt-resample-proportion-result.csv'), index=False)\n",
    "result_gbt.to_csv(path.join(result_path,'gender-gbt-resample-proportion-result.csv'), index=False)\n",
    "\n",
    "overall_result = pd.DataFrame(overall_table)\n",
    "result_path='/Users/lifuchen/Desktop/research/resample_result/'\n",
    "overall_result.to_csv(path.join(result_path,'gender-resample-proportion.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
