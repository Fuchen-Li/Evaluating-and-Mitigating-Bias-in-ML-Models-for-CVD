{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from os import path\n",
    "import imblearn\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score\n",
    "import sklearn.preprocessing\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import src.lib.utility_classfier as uclf\n",
    "import src.lib.optimal_threhold_related as thres\n",
    "import src.lib.fairness_tests as fair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_path='/Users/lifuchen/Desktop/research/data.csv'\n",
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109490, 86)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df.Class.values\n",
    "X = df.drop(['GRID','Class','Race_B'], axis=1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def save_prediction(classifier, characteristic, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_white_scaled, y_val_white, X_test_white_scaled, y_test_white, X_val_black_scaled, y_val_black, X_test_black_scaled, y_test_black):\n",
    "    method_to_call = getattr(uclf, classifier)\n",
    "    y_val_score = method_to_call(X_train_scaled, y_train,X_val_scaled, y_val)\n",
    "    y_test_score = method_to_call(X_train_scaled, y_train,X_test_scaled, y_test)\n",
    "\n",
    "    y_val_score_white = method_to_call(X_train_scaled, y_train, X_val_white_scaled, y_val_white)\n",
    "    y_test_score_white = method_to_call(X_train_scaled, y_train,X_test_white_scaled, y_test_white)\n",
    "\n",
    "    y_val_score_black = method_to_call(X_train_scaled, y_train, X_val_black_scaled, y_val_black)\n",
    "    y_test_score_black = method_to_call(X_train_scaled, y_train,X_test_black_scaled, y_test_black)\n",
    "\n",
    "    my_dict = dict(val_score = y_val_score, test_score = y_test_score, val_1_score = y_val_score_white, test_1_score = y_test_score_white, val_2_score = y_val_score_black, test_2_score = y_test_score_black)\n",
    "    overall_prediction = pd.DataFrame.from_dict(my_dict, orient='index')\n",
    "    overall_prediction = overall_prediction.transpose()\n",
    "\n",
    "    result_path='/Users/lifuchen/Desktop/research/predictions/'\n",
    "    filename = str(classifier) + str(characteristic) + \"prediction.csv\"\n",
    "    overall_prediction.to_csv(path.join(result_path, filename), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_result (classifier, characteristic, records, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_white_scaled, y_val_white, X_test_white_scaled, y_test_white, X_val_black_scaled, y_val_black, X_test_black_scaled, y_test_black):\n",
    "    result_path='/Users/lifuchen/Desktop/research/predictions/'\n",
    "    filename = str(classifier) + characteristic + \"prediction.csv\"\n",
    "    prediction = pd.read_csv(path.join(result_path, filename))\n",
    "    \n",
    "    y_val_score = prediction['val_score'][prediction['val_score'].notna()]\n",
    "    y_test_score = prediction['test_score'][prediction['test_score'].notna()]\n",
    "    \n",
    "    y_val_score_white = prediction['val_1_score'][prediction['val_1_score'].notna()]\n",
    "    y_test_score_white = prediction['test_1_score'][prediction['test_1_score'].notna()]\n",
    "    \n",
    "    y_val_score_black = prediction['val_2_score'][prediction['val_2_score'].notna()]\n",
    "    y_test_score_black = prediction['test_2_score'][prediction['test_2_score'].notna()]\n",
    "    \n",
    "    threshold, ba_val, ba_test = balance_accuracy (y_val, y_val_score,y_test, y_test_score)\n",
    "    auroc = roc_auc_score(y_test, y_test_score)\n",
    "    precision, recall, tpr, tnr, pd_overall = thres.calculate_precision_metrics(y_test, y_test_score,threshold)\n",
    "    \n",
    "    threshold_white, ba_val_white, ba_test_white = balance_accuracy (y_val_white, y_val_score_white,y_test_white, y_test_score_white)\n",
    "    precision_white, recall_white, tpr_white, tnr_white, pd_white = thres.calculate_precision_metrics(y_test_white, y_test_score_white,threshold_white)\n",
    "    \n",
    "    threshold_black, ba_val_black, ba_test_black = balance_accuracy (y_val_black, y_val_score_black, y_test_black, y_test_score_black)\n",
    "    precision_black, recall_black, tpr_black, tnr_black, pd_black = thres.calculate_precision_metrics(y_test_black, y_test_score_black,threshold_black)\n",
    "\n",
    "    eod = fair.get_EOD(y_test_white, y_test_score_white,threshold_white, y_test_black, y_test_score_black, threshold_black)\n",
    "    sp = fair.get_SP(y_test_white, y_test_score_white,threshold_white, y_test_black, y_test_score_black, threshold_black)\n",
    "\n",
    "    records.append({\n",
    "        'auroc': auroc,\n",
    "        'overall threshold': threshold,\n",
    "        'white threshold': threshold_white,\n",
    "        'black threshold': threshold_black,\n",
    "        'overall ba validation': ba_val,\n",
    "        'overall ba test': ba_test,\n",
    "        'white ba validation': ba_val_white,\n",
    "        'white ba test': ba_test_white,\n",
    "        'black ba validation': ba_val_black,\n",
    "        'black ba test': ba_test_black,\n",
    "        'overall precision':precision,\n",
    "        'overall recall':recall,\n",
    "        'overall tpr':tpr,\n",
    "        'overall tnr':tnr,\n",
    "        'overall pd':pd_overall,\n",
    "        'white precision':precision_white,\n",
    "        'white recall':recall_white,\n",
    "        'white tpr':tpr_white,\n",
    "        'white tnr':tnr_white,\n",
    "        'white pd':pd_white,\n",
    "        'black precision':precision_black,\n",
    "        'black recall':recall_black,\n",
    "        'black tpr':tpr_black,\n",
    "        'black tnr':tnr_black,\n",
    "        'black pd':pd_black,\n",
    "        'eod': eod,\n",
    "        'di': sp,\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def balance_accuracy (y_val, y_val_score,y_test, y_test_score):\n",
    "    \n",
    "    threshold, _ = thres.get_optimal_threshold_Jvalue (y_val, y_val_score)\n",
    "    print (\"Optimal threshold by J value is \",threshold)\n",
    "\n",
    "    ba_val = thres.calculate_balanced_accuracy(y_val, y_val_score, threshold)\n",
    "    print (\"Balanced accuracy score of val is \", ba_val)\n",
    "\n",
    "    ba_test = thres.calculate_balanced_accuracy(y_test, y_test_score, threshold)\n",
    "    print (\"Balanced accuracy score of test is \",ba_test)\n",
    "\n",
    "    return threshold, ba_val, ba_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def fairness_metrics (X, y, attribute, random_state):\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, X_val_white, X_val_black, y_val_white, y_val_black, X_test_white, X_test_black, y_test_white, y_test_black \\\n",
    "        = fair.split_by_trait_balance_proportion_no_protected_trait(X, y, attribute, random_state)\n",
    "    \n",
    "    print(\"X train\", X_train.shape[0])\n",
    "    print(\"Y train\", y_train.shape[0])\n",
    "    print(X_val.shape[0], X_val_white.shape[0], X_val_black.shape[0])\n",
    "    print(y_val.shape[0], y_val_white.shape[0], y_val_black.shape[0])\n",
    "    print(X_test.shape[0], X_test_white.shape[0], X_test_black.shape[0])\n",
    "    print(y_test.shape[0], y_test_white.shape[0], y_test_black.shape[0])\n",
    "\n",
    "    max_abs_scaler = preprocessing.MaxAbsScaler()\n",
    "    X_train_scaled = max_abs_scaler.fit_transform(X_train)\n",
    "    X_test_scaled = max_abs_scaler.transform(X_test)\n",
    "    X_test_white_scaled = max_abs_scaler.transform(X_test_white)\n",
    "    X_test_black_scaled = max_abs_scaler.transform(X_test_black)\n",
    "    X_val_scaled = max_abs_scaler.transform(X_val)\n",
    "    X_val_white_scaled = max_abs_scaler.transform(X_val_white)\n",
    "    X_val_black_scaled = max_abs_scaler.transform(X_val_black)\n",
    "\n",
    "    characteristic = attribute + \"resample-by-proportion\" + str(random_state)\n",
    "    save_prediction (\"logic_regression\", characteristic, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_white_scaled, y_val_white, X_test_white_scaled, y_test_white, X_val_black_scaled, y_val_black, X_test_black_scaled, y_test_black)\n",
    "    save_prediction (\"random_forest\", characteristic, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_white_scaled, y_val_white, X_test_white_scaled, y_test_white, X_val_black_scaled, y_val_black, X_test_black_scaled, y_test_black)\n",
    "    save_prediction (\"decision_tree\", characteristic, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_white_scaled, y_val_white, X_test_white_scaled, y_test_white, X_val_black_scaled, y_val_black, X_test_black_scaled, y_test_black)\n",
    "    save_prediction (\"gradiant_boosting\", characteristic, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_white_scaled, y_val_white, X_test_white_scaled, y_test_white, X_val_black_scaled, y_val_black, X_test_black_scaled, y_test_black)\n",
    "\n",
    "    get_result (\"logic_regression\", characteristic, records_lr, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_white_scaled, y_val_white, X_test_white_scaled, y_test_white, X_val_black_scaled, y_val_black, X_test_black_scaled, y_test_black)\n",
    "    get_result (\"random_forest\", characteristic, records_rf, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_white_scaled, y_val_white, X_test_white_scaled, y_test_white, X_val_black_scaled, y_val_black, X_test_black_scaled, y_test_black)\n",
    "    get_result (\"decision_tree\", characteristic, records_dt, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_white_scaled, y_val_white, X_test_white_scaled, y_test_white, X_val_black_scaled, y_val_black, X_test_black_scaled, y_test_black)\n",
    "    get_result (\"gradiant_boosting\", characteristic, records_gbt, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_white_scaled, y_val_white, X_test_white_scaled, y_test_white, X_val_black_scaled, y_val_black, X_test_black_scaled, y_test_black)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lifuchen/Desktop/research/CVDPrediction-master/src/lib/fairness_tests.py:273: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train ['Class'] = y_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9055, 87)\n",
      "(56639, 87)\n",
      "0.09307098020280058 0.0988475865280149\n",
      "0.0987445678416224\n",
      "(65741, 86)\n",
      "X train 65741\n",
      "Y train 65741\n",
      "21898 18899 2999\n",
      "21898 18899 2999\n",
      "21898 18968 2930\n",
      "21898 18968 2930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26052423943952174\n",
      "0.2619197793527146\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19904\n",
      "           1       0.46      0.03      0.06      1994\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.51      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19826    78]\n",
      " [ 1928    66]]\n",
      "done in 0.633689s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26052423943952174\n",
      "0.2624419486803707\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19934\n",
      "           1       0.42      0.03      0.06      1964\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19846    88]\n",
      " [ 1900    64]]\n",
      "done in 0.633162s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26052423943952174\n",
      "0.26280953220326864\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17180\n",
      "           1       0.47      0.03      0.06      1719\n",
      "\n",
      "    accuracy                           0.91     18899\n",
      "   macro avg       0.69      0.51      0.50     18899\n",
      "weighted avg       0.87      0.91      0.87     18899\n",
      "\n",
      "Confusion_matrix\n",
      "[[17120    60]\n",
      " [ 1666    53]]\n",
      "done in 0.600093s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26052423943952174\n",
      "0.2629030196799557\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17260\n",
      "           1       0.41      0.03      0.05      1708\n",
      "\n",
      "    accuracy                           0.91     18968\n",
      "   macro avg       0.66      0.51      0.50     18968\n",
      "weighted avg       0.87      0.91      0.87     18968\n",
      "\n",
      "Confusion_matrix\n",
      "[[17188    72]\n",
      " [ 1658    50]]\n",
      "done in 0.618986s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26052423943952174\n",
      "0.25631276397338126\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95      2724\n",
      "           1       0.42      0.05      0.08       275\n",
      "\n",
      "    accuracy                           0.91      2999\n",
      "   macro avg       0.67      0.52      0.52      2999\n",
      "weighted avg       0.87      0.91      0.87      2999\n",
      "\n",
      "Confusion_matrix\n",
      "[[2706   18]\n",
      " [ 262   13]]\n",
      "done in 0.594428s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26052423943952174\n",
      "0.25945710406599304\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95      2674\n",
      "           1       0.47      0.05      0.10       256\n",
      "\n",
      "    accuracy                           0.91      2930\n",
      "   macro avg       0.69      0.52      0.53      2930\n",
      "weighted avg       0.88      0.91      0.88      2930\n",
      "\n",
      "Confusion_matrix\n",
      "[[2658   16]\n",
      " [ 242   14]]\n",
      "done in 0.610357s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19904\n",
      "           1       0.25      0.00      0.00      1994\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.58      0.50      0.48     21898\n",
      "weighted avg       0.85      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19892    12]\n",
      " [ 1990     4]]\n",
      "done in 18.857104s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19934\n",
      "           1       0.57      0.00      0.01      1964\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.74      0.50      0.48     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19928     6]\n",
      " [ 1956     8]]\n",
      "done in 19.650094s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17180\n",
      "           1       0.38      0.00      0.01      1719\n",
      "\n",
      "    accuracy                           0.91     18899\n",
      "   macro avg       0.64      0.50      0.48     18899\n",
      "weighted avg       0.86      0.91      0.87     18899\n",
      "\n",
      "Confusion_matrix\n",
      "[[17170    10]\n",
      " [ 1713     6]]\n",
      "done in 19.067592s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17260\n",
      "           1       0.50      0.00      0.01      1708\n",
      "\n",
      "    accuracy                           0.91     18968\n",
      "   macro avg       0.71      0.50      0.48     18968\n",
      "weighted avg       0.87      0.91      0.87     18968\n",
      "\n",
      "Confusion_matrix\n",
      "[[17254     6]\n",
      " [ 1702     6]]\n",
      "done in 18.906513s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2724\n",
      "           1       0.00      0.00      0.00       275\n",
      "\n",
      "    accuracy                           0.91      2999\n",
      "   macro avg       0.45      0.50      0.48      2999\n",
      "weighted avg       0.82      0.91      0.86      2999\n",
      "\n",
      "Confusion_matrix\n",
      "[[2722    2]\n",
      " [ 275    0]]\n",
      "done in 18.421366s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2674\n",
      "           1       0.00      0.00      0.00       256\n",
      "\n",
      "    accuracy                           0.91      2930\n",
      "   macro avg       0.46      0.50      0.48      2930\n",
      "weighted avg       0.83      0.91      0.87      2930\n",
      "\n",
      "Confusion_matrix\n",
      "[[2671    3]\n",
      " [ 256    0]]\n",
      "done in 18.281790s\n",
      "0.2659754894839782\n",
      "0.2726565563516711\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19904\n",
      "           1       0.00      0.00      0.00      1994\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.45      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19903     1]\n",
      " [ 1994     0]]\n",
      "done in 0.604187s\n",
      "0.2659754894839782\n",
      "0.2771072731769899\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19934\n",
      "           1       0.00      0.00      0.00      1964\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.46      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19931     3]\n",
      " [ 1964     0]]\n",
      "done in 0.600967s\n",
      "0.2659754894839782\n",
      "0.2717203149276728\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17180\n",
      "           1       0.00      0.00      0.00      1719\n",
      "\n",
      "    accuracy                           0.91     18899\n",
      "   macro avg       0.45      0.50      0.48     18899\n",
      "weighted avg       0.83      0.91      0.87     18899\n",
      "\n",
      "Confusion_matrix\n",
      "[[17180     0]\n",
      " [ 1719     0]]\n",
      "done in 0.597977s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2659754894839782\n",
      "0.2783021940103029\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17260\n",
      "           1       0.00      0.00      0.00      1708\n",
      "\n",
      "    accuracy                           0.91     18968\n",
      "   macro avg       0.45      0.50      0.48     18968\n",
      "weighted avg       0.83      0.91      0.87     18968\n",
      "\n",
      "Confusion_matrix\n",
      "[[17257     3]\n",
      " [ 1708     0]]\n",
      "done in 0.592916s\n",
      "0.2659754894839782\n",
      "0.278556531900902\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2724\n",
      "           1       0.00      0.00      0.00       275\n",
      "\n",
      "    accuracy                           0.91      2999\n",
      "   macro avg       0.45      0.50      0.48      2999\n",
      "weighted avg       0.82      0.91      0.86      2999\n",
      "\n",
      "Confusion_matrix\n",
      "[[2723    1]\n",
      " [ 275    0]]\n",
      "done in 0.561499s\n",
      "0.2659754894839782\n",
      "0.26937169011682616\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2674\n",
      "           1       0.00      0.00      0.00       256\n",
      "\n",
      "    accuracy                           0.91      2930\n",
      "   macro avg       0.46      0.50      0.48      2930\n",
      "weighted avg       0.83      0.91      0.87      2930\n",
      "\n",
      "Confusion_matrix\n",
      "[[2674    0]\n",
      " [ 256    0]]\n",
      "done in 0.570286s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19904\n",
      "           1       0.41      0.02      0.03      1994\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.66      0.51      0.49     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19860    44]\n",
      " [ 1963    31]]\n",
      "done in 32.414456s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19934\n",
      "           1       0.44      0.02      0.04      1964\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19880    54]\n",
      " [ 1921    43]]\n",
      "done in 32.726181s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17180\n",
      "           1       0.45      0.02      0.03      1719\n",
      "\n",
      "    accuracy                           0.91     18899\n",
      "   macro avg       0.68      0.51      0.49     18899\n",
      "weighted avg       0.87      0.91      0.87     18899\n",
      "\n",
      "Confusion_matrix\n",
      "[[17144    36]\n",
      " [ 1690    29]]\n",
      "done in 32.752441s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17260\n",
      "           1       0.45      0.02      0.04      1708\n",
      "\n",
      "    accuracy                           0.91     18968\n",
      "   macro avg       0.68      0.51      0.50     18968\n",
      "weighted avg       0.87      0.91      0.87     18968\n",
      "\n",
      "Confusion_matrix\n",
      "[[17213    47]\n",
      " [ 1670    38]]\n",
      "done in 32.311902s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2724\n",
      "           1       0.27      0.01      0.02       275\n",
      "\n",
      "    accuracy                           0.91      2999\n",
      "   macro avg       0.59      0.50      0.49      2999\n",
      "weighted avg       0.85      0.91      0.87      2999\n",
      "\n",
      "Confusion_matrix\n",
      "[[2716    8]\n",
      " [ 272    3]]\n",
      "done in 33.546701s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2674\n",
      "           1       0.50      0.02      0.04       256\n",
      "\n",
      "    accuracy                           0.91      2930\n",
      "   macro avg       0.71      0.51      0.50      2930\n",
      "weighted avg       0.88      0.91      0.87      2930\n",
      "\n",
      "Confusion_matrix\n",
      "[[2669    5]\n",
      " [ 251    5]]\n",
      "done in 33.372712s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41400000000000003\n",
      "threshold:0.2, J-value:0.269\n",
      "threshold:0.30000000000000004, J-value:0.153\n",
      "threshold:0.4, J-value:0.07100000000000001\n",
      "threshold:0.5, J-value:0.029\n",
      "threshold:0.6000000000000001, J-value:0.009999999999999998\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7067092303840783\n",
      "Balanced accuracy score of test is  0.6985490254295387\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.40700000000000003\n",
      "threshold:0.2, J-value:0.26\n",
      "threshold:0.30000000000000004, J-value:0.151\n",
      "threshold:0.4, J-value:0.068\n",
      "threshold:0.5, J-value:0.028\n",
      "threshold:0.6000000000000001, J-value:0.009000000000000001\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7036173635618077\n",
      "Balanced accuracy score of test is  0.6991166916779059\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.45199999999999996\n",
      "threshold:0.2, J-value:0.32499999999999996\n",
      "threshold:0.30000000000000004, J-value:0.161\n",
      "threshold:0.4, J-value:0.087\n",
      "threshold:0.5, J-value:0.04\n",
      "threshold:0.6000000000000001, J-value:0.009999999999999998\n",
      "threshold:0.7000000000000001, J-value:-0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7260752903484181\n",
      "Balanced accuracy score of test is  0.6947208652767389\n",
      "True positive rate of class 1 is  0.664\n",
      "True positive rate of class 2 is  0.652\n",
      "Positive prediction rate of class 1 is  0.302\n",
      "Positive prediction rate of class 2 is  0.297\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.398\n",
      "threshold:0.2, J-value:0.28300000000000003\n",
      "threshold:0.30000000000000004, J-value:0.1\n",
      "threshold:0.4, J-value:0.026\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6986313643502856\n",
      "Balanced accuracy score of test is  0.6903421310691882\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.395\n",
      "threshold:0.2, J-value:0.272\n",
      "threshold:0.30000000000000004, J-value:0.095\n",
      "threshold:0.4, J-value:0.024\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.697659233479681\n",
      "Balanced accuracy score of test is  0.6928736285654584\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.44100000000000006\n",
      "threshold:0.2, J-value:0.31\n",
      "threshold:0.30000000000000004, J-value:0.11100000000000002\n",
      "threshold:0.4, J-value:0.032\n",
      "threshold:0.5, J-value:-0.001\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7205019356561206\n",
      "Balanced accuracy score of test is  0.6900710545998504\n",
      "True positive rate of class 1 is  0.739\n",
      "True positive rate of class 2 is  0.75\n",
      "Positive prediction rate of class 1 is  0.388\n",
      "Positive prediction rate of class 2 is  0.403\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.37699999999999995\n",
      "threshold:0.2, J-value:0.182\n",
      "threshold:0.30000000000000004, J-value:0.08499999999999999\n",
      "threshold:0.4, J-value:0.028999999999999998\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6884413036134126\n",
      "Balanced accuracy score of test is  0.6756029367380789\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.36999999999999994\n",
      "threshold:0.2, J-value:0.176\n",
      "threshold:0.30000000000000004, J-value:0.088\n",
      "threshold:0.4, J-value:0.032\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6852700693001115\n",
      "Balanced accuracy score of test is  0.6741885368017997\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.4169999999999999\n",
      "threshold:0.2, J-value:0.21999999999999997\n",
      "threshold:0.30000000000000004, J-value:0.063\n",
      "threshold:0.4, J-value:0.015\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.708523561607262\n",
      "Balanced accuracy score of test is  0.6839165926514585\n",
      "True positive rate of class 1 is  0.694\n",
      "True positive rate of class 2 is  0.637\n",
      "Positive prediction rate of class 1 is  0.377\n",
      "Positive prediction rate of class 2 is  0.301\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.43099999999999994\n",
      "threshold:0.2, J-value:0.26799999999999996\n",
      "threshold:0.30000000000000004, J-value:0.14100000000000001\n",
      "threshold:0.4, J-value:0.052\n",
      "threshold:0.5, J-value:0.014\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7157985209648237\n",
      "Balanced accuracy score of test is  0.6982277513758743\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.42799999999999994\n",
      "threshold:0.2, J-value:0.258\n",
      "threshold:0.30000000000000004, J-value:0.136\n",
      "threshold:0.4, J-value:0.052\n",
      "threshold:0.5, J-value:0.015000000000000001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.714171645940292\n",
      "Balanced accuracy score of test is  0.698445933660967\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.45199999999999996\n",
      "threshold:0.2, J-value:0.32599999999999996\n",
      "threshold:0.30000000000000004, J-value:0.167\n",
      "threshold:0.4, J-value:0.059000000000000004\n",
      "threshold:0.5, J-value:0.008\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.004\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7260058737151248\n",
      "Balanced accuracy score of test is  0.6966739902767389\n",
      "True positive rate of class 1 is  0.68\n",
      "True positive rate of class 2 is  0.656\n",
      "Positive prediction rate of class 1 is  0.319\n",
      "Positive prediction rate of class 2 is  0.297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lifuchen/Desktop/research/CVDPrediction-master/src/lib/fairness_tests.py:273: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train ['Class'] = y_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8896, 87)\n",
      "(56798, 87)\n",
      "0.09772951628825272 0.10052315442743655\n",
      "0.10044422507403751\n",
      "(65716, 86)\n",
      "X train 65716\n",
      "Y train 65716\n",
      "21898 18825 3073\n",
      "21898 18825 3073\n",
      "21898 18883 3015\n",
      "21898 18883 3015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2628977766867542\n",
      "0.25605708671099653\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.95     19980\n",
      "           1       0.47      0.04      0.07      1918\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.69      0.52      0.51     21898\n",
      "weighted avg       0.88      0.91      0.88     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19901    79]\n",
      " [ 1847    71]]\n",
      "done in 0.564627s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2628977766867542\n",
      "0.2579563507090466\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19972\n",
      "           1       0.43      0.03      0.06      1926\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.51     21898\n",
      "weighted avg       0.87      0.91      0.88     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19886    86]\n",
      " [ 1860    66]]\n",
      "done in 0.547873s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2628977766867542\n",
      "0.2555714900540008\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17178\n",
      "           1       0.45      0.03      0.06      1647\n",
      "\n",
      "    accuracy                           0.91     18825\n",
      "   macro avg       0.68      0.51      0.51     18825\n",
      "weighted avg       0.87      0.91      0.88     18825\n",
      "\n",
      "Confusion_matrix\n",
      "[[17112    66]\n",
      " [ 1592    55]]\n",
      "done in 0.529280s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2628977766867542\n",
      "0.26084811991730744\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17196\n",
      "           1       0.44      0.03      0.06      1687\n",
      "\n",
      "    accuracy                           0.91     18883\n",
      "   macro avg       0.68      0.51      0.51     18883\n",
      "weighted avg       0.87      0.91      0.87     18883\n",
      "\n",
      "Confusion_matrix\n",
      "[[17124    72]\n",
      " [ 1630    57]]\n",
      "done in 0.579354s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2628977766867542\n",
      "0.25903182054371543\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.95      2802\n",
      "           1       0.55      0.06      0.11       271\n",
      "\n",
      "    accuracy                           0.91      3073\n",
      "   macro avg       0.73      0.53      0.53      3073\n",
      "weighted avg       0.88      0.91      0.88      3073\n",
      "\n",
      "Confusion_matrix\n",
      "[[2789   13]\n",
      " [ 255   16]]\n",
      "done in 0.607253s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2628977766867542\n",
      "0.23984514740570043\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96      2776\n",
      "           1       0.39      0.04      0.07       239\n",
      "\n",
      "    accuracy                           0.92      3015\n",
      "   macro avg       0.66      0.52      0.51      3015\n",
      "weighted avg       0.88      0.92      0.89      3015\n",
      "\n",
      "Confusion_matrix\n",
      "[[2762   14]\n",
      " [ 230    9]]\n",
      "done in 0.556355s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19980\n",
      "           1       0.67      0.00      0.00      1918\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.79      0.50      0.48     21898\n",
      "weighted avg       0.89      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19978     2]\n",
      " [ 1914     4]]\n",
      "done in 18.950767s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19972\n",
      "           1       0.50      0.00      0.01      1926\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.71      0.50      0.48     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19966     6]\n",
      " [ 1920     6]]\n",
      "done in 19.145994s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17178\n",
      "           1       0.71      0.00      0.01      1647\n",
      "\n",
      "    accuracy                           0.91     18825\n",
      "   macro avg       0.81      0.50      0.48     18825\n",
      "weighted avg       0.90      0.91      0.87     18825\n",
      "\n",
      "Confusion_matrix\n",
      "[[17176     2]\n",
      " [ 1642     5]]\n",
      "done in 18.995309s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17196\n",
      "           1       0.10      0.00      0.00      1687\n",
      "\n",
      "    accuracy                           0.91     18883\n",
      "   macro avg       0.51      0.50      0.48     18883\n",
      "weighted avg       0.84      0.91      0.87     18883\n",
      "\n",
      "Confusion_matrix\n",
      "[[17187     9]\n",
      " [ 1686     1]]\n",
      "done in 18.961820s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2802\n",
      "           1       0.50      0.01      0.01       271\n",
      "\n",
      "    accuracy                           0.91      3073\n",
      "   macro avg       0.71      0.50      0.48      3073\n",
      "weighted avg       0.88      0.91      0.87      3073\n",
      "\n",
      "Confusion_matrix\n",
      "[[2800    2]\n",
      " [ 269    2]]\n",
      "done in 18.926140s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2776\n",
      "           1       0.00      0.00      0.00       239\n",
      "\n",
      "    accuracy                           0.92      3015\n",
      "   macro avg       0.46      0.50      0.48      3015\n",
      "weighted avg       0.85      0.92      0.88      3015\n",
      "\n",
      "Confusion_matrix\n",
      "[[2776    0]\n",
      " [ 239    0]]\n",
      "done in 18.702343s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26792162888937726\n",
      "0.2685942867524345\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19980\n",
      "           1       0.40      0.00      0.00      1918\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.66      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19977     3]\n",
      " [ 1916     2]]\n",
      "done in 0.630462s\n",
      "0.26792162888937726\n",
      "0.26931751906249957\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19972\n",
      "           1       0.14      0.00      0.00      1926\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.53      0.50      0.48     21898\n",
      "weighted avg       0.84      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19966     6]\n",
      " [ 1925     1]]\n",
      "done in 0.624156s\n",
      "0.26792162888937726\n",
      "0.2654946532081715\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17178\n",
      "           1       0.67      0.00      0.00      1647\n",
      "\n",
      "    accuracy                           0.91     18825\n",
      "   macro avg       0.79      0.50      0.48     18825\n",
      "weighted avg       0.89      0.91      0.87     18825\n",
      "\n",
      "Confusion_matrix\n",
      "[[17177     1]\n",
      " [ 1645     2]]\n",
      "done in 0.615265s\n",
      "0.26792162888937726\n",
      "0.2738622111721778\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17196\n",
      "           1       0.17      0.00      0.00      1687\n",
      "\n",
      "    accuracy                           0.91     18883\n",
      "   macro avg       0.54      0.50      0.48     18883\n",
      "weighted avg       0.84      0.91      0.87     18883\n",
      "\n",
      "Confusion_matrix\n",
      "[[17191     5]\n",
      " [ 1686     1]]\n",
      "done in 0.610564s\n",
      "0.26792162888937726\n",
      "0.2875824421285337\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2802\n",
      "           1       0.00      0.00      0.00       271\n",
      "\n",
      "    accuracy                           0.91      3073\n",
      "   macro avg       0.46      0.50      0.48      3073\n",
      "weighted avg       0.83      0.91      0.87      3073\n",
      "\n",
      "Confusion_matrix\n",
      "[[2800    2]\n",
      " [ 271    0]]\n",
      "done in 0.590953s\n",
      "0.26792162888937726\n",
      "0.24085402947475337\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2776\n",
      "           1       0.00      0.00      0.00       239\n",
      "\n",
      "    accuracy                           0.92      3015\n",
      "   macro avg       0.46      0.50      0.48      3015\n",
      "weighted avg       0.85      0.92      0.88      3015\n",
      "\n",
      "Confusion_matrix\n",
      "[[2775    1]\n",
      " [ 239    0]]\n",
      "done in 0.585256s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19980\n",
      "           1       0.39      0.01      0.03      1918\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.65      0.51      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19937    43]\n",
      " [ 1891    27]]\n",
      "done in 32.902517s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19972\n",
      "           1       0.40      0.02      0.03      1926\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.66      0.51      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19920    52]\n",
      " [ 1891    35]]\n",
      "done in 32.935061s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17178\n",
      "           1       0.42      0.01      0.03      1647\n",
      "\n",
      "    accuracy                           0.91     18825\n",
      "   macro avg       0.67      0.51      0.49     18825\n",
      "weighted avg       0.87      0.91      0.87     18825\n",
      "\n",
      "Confusion_matrix\n",
      "[[17145    33]\n",
      " [ 1623    24]]\n",
      "done in 32.763873s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17196\n",
      "           1       0.39      0.02      0.03      1687\n",
      "\n",
      "    accuracy                           0.91     18883\n",
      "   macro avg       0.65      0.51      0.49     18883\n",
      "weighted avg       0.87      0.91      0.87     18883\n",
      "\n",
      "Confusion_matrix\n",
      "[[17152    44]\n",
      " [ 1659    28]]\n",
      "done in 32.992891s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2802\n",
      "           1       0.23      0.01      0.02       271\n",
      "\n",
      "    accuracy                           0.91      3073\n",
      "   macro avg       0.57      0.50      0.49      3073\n",
      "weighted avg       0.85      0.91      0.87      3073\n",
      "\n",
      "Confusion_matrix\n",
      "[[2792   10]\n",
      " [ 268    3]]\n",
      "done in 33.418106s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2776\n",
      "           1       0.44      0.03      0.05       239\n",
      "\n",
      "    accuracy                           0.92      3015\n",
      "   macro avg       0.68      0.51      0.51      3015\n",
      "weighted avg       0.88      0.92      0.89      3015\n",
      "\n",
      "Confusion_matrix\n",
      "[[2767    9]\n",
      " [ 232    7]]\n",
      "done in 33.501459s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.404\n",
      "threshold:0.2, J-value:0.27599999999999997\n",
      "threshold:0.30000000000000004, J-value:0.151\n",
      "threshold:0.4, J-value:0.067\n",
      "threshold:0.5, J-value:0.033\n",
      "threshold:0.6000000000000001, J-value:0.012\n",
      "threshold:0.7000000000000001, J-value:0.004\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7023663131327365\n",
      "Balanced accuracy score of test is  0.6982604566434545\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.405\n",
      "threshold:0.2, J-value:0.282\n",
      "threshold:0.30000000000000004, J-value:0.15\n",
      "threshold:0.4, J-value:0.063\n",
      "threshold:0.5, J-value:0.029\n",
      "threshold:0.6000000000000001, J-value:0.009999999999999998\n",
      "threshold:0.7000000000000001, J-value:0.003\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7022441123807912\n",
      "Balanced accuracy score of test is  0.7001416631954083\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.406\n",
      "threshold:0.2, J-value:0.24\n",
      "threshold:0.30000000000000004, J-value:0.158\n",
      "threshold:0.4, J-value:0.09\n",
      "threshold:0.5, J-value:0.054\n",
      "threshold:0.6000000000000001, J-value:0.019999999999999997\n",
      "threshold:0.7000000000000001, J-value:0.006\n",
      "threshold:0.8, J-value:-0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7032029046200526\n",
      "Balanced accuracy score of test is  0.6830581614074012\n",
      "True positive rate of class 1 is  0.66\n",
      "True positive rate of class 2 is  0.594\n",
      "Positive prediction rate of class 1 is  0.296\n",
      "Positive prediction rate of class 2 is  0.257\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.392\n",
      "threshold:0.2, J-value:0.29300000000000004\n",
      "threshold:0.30000000000000004, J-value:0.122\n",
      "threshold:0.4, J-value:0.02\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6958675307215454\n",
      "Balanced accuracy score of test is  0.6959506289074694\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.395\n",
      "threshold:0.2, J-value:0.304\n",
      "threshold:0.30000000000000004, J-value:0.128\n",
      "threshold:0.4, J-value:0.023\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6974416168772656\n",
      "Balanced accuracy score of test is  0.6946262747309069\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41300000000000003\n",
      "threshold:0.2, J-value:0.332\n",
      "threshold:0.30000000000000004, J-value:0.096\n",
      "threshold:0.4, J-value:0.018\n",
      "threshold:0.5, J-value:0.006\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7062120888874841\n",
      "Balanced accuracy score of test is  0.7175408160804504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positive rate of class 1 is  0.738\n",
      "True positive rate of class 2 is  0.774\n",
      "Positive prediction rate of class 1 is  0.384\n",
      "Positive prediction rate of class 2 is  0.373\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.35800000000000004\n",
      "threshold:0.2, J-value:0.20999999999999996\n",
      "threshold:0.30000000000000004, J-value:0.10700000000000001\n",
      "threshold:0.4, J-value:0.001\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.001\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6794684152348386\n",
      "Balanced accuracy score of test is  0.6874879244233724\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.35100000000000003\n",
      "threshold:0.2, J-value:0.21699999999999997\n",
      "threshold:0.30000000000000004, J-value:0.11500000000000002\n",
      "threshold:0.4, J-value:0.001\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.001\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.675344899361894\n",
      "Balanced accuracy score of test is  0.6838631673347891\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41000000000000003\n",
      "threshold:0.2, J-value:0.169\n",
      "threshold:0.30000000000000004, J-value:0.064\n",
      "threshold:0.4, J-value:-0.001\n",
      "threshold:0.5, J-value:-0.001\n",
      "threshold:0.6000000000000001, J-value:-0.001\n",
      "threshold:0.7000000000000001, J-value:-0.001\n",
      "threshold:0.8, J-value:-0.001\n",
      "threshold:0.9, J-value:-0.001\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7047549062214391\n",
      "Balanced accuracy score of test is  0.7094785851229306\n",
      "True positive rate of class 1 is  0.682\n",
      "True positive rate of class 2 is  0.674\n",
      "Positive prediction rate of class 1 is  0.347\n",
      "Positive prediction rate of class 2 is  0.288\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.42099999999999993\n",
      "threshold:0.2, J-value:0.277\n",
      "threshold:0.30000000000000004, J-value:0.149\n",
      "threshold:0.4, J-value:0.059000000000000004\n",
      "threshold:0.5, J-value:0.012\n",
      "threshold:0.6000000000000001, J-value:0.006\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7105188347889078\n",
      "Balanced accuracy score of test is  0.7031255751822021\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.422\n",
      "threshold:0.2, J-value:0.28200000000000003\n",
      "threshold:0.30000000000000004, J-value:0.151\n",
      "threshold:0.4, J-value:0.058\n",
      "threshold:0.5, J-value:0.013\n",
      "threshold:0.6000000000000001, J-value:0.007\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.711061305804582\n",
      "Balanced accuracy score of test is  0.702041617045251\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41500000000000004\n",
      "threshold:0.2, J-value:0.25\n",
      "threshold:0.30000000000000004, J-value:0.137\n",
      "threshold:0.4, J-value:0.067\n",
      "threshold:0.5, J-value:0.006999999999999999\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:-0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7073137005459991\n",
      "Balanced accuracy score of test is  0.7088967901800248\n",
      "True positive rate of class 1 is  0.683\n",
      "True positive rate of class 2 is  0.665\n",
      "Positive prediction rate of class 1 is  0.315\n",
      "Positive prediction rate of class 2 is  0.281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lifuchen/Desktop/research/CVDPrediction-master/src/lib/fairness_tests.py:273: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train ['Class'] = y_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8953, 87)\n",
      "(56741, 87)\n",
      "0.09624096975633648 0.09822707389772771\n",
      "0.09820007346638912\n",
      "(65710, 86)\n",
      "X train 65710\n",
      "Y train 65710\n",
      "21898 18936 2962\n",
      "21898 18936 2962\n",
      "21898 18829 3069\n",
      "21898 18829 3069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.259968929643947\n",
      "0.2601665091026239\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19950\n",
      "           1       0.46      0.03      0.06      1948\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.69      0.52      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19872    78]\n",
      " [ 1881    67]]\n",
      "done in 0.613166s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.259968929643947\n",
      "0.2624529489116322\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19883\n",
      "           1       0.50      0.03      0.05      2015\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.71      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19826    57]\n",
      " [ 1957    58]]\n",
      "done in 0.573044s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.259968929643947\n",
      "0.26291187565653557\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17239\n",
      "           1       0.44      0.03      0.06      1697\n",
      "\n",
      "    accuracy                           0.91     18936\n",
      "   macro avg       0.68      0.51      0.50     18936\n",
      "weighted avg       0.87      0.91      0.87     18936\n",
      "\n",
      "Confusion_matrix\n",
      "[[17174    65]\n",
      " [ 1646    51]]\n",
      "done in 0.577484s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.259968929643947\n",
      "0.2632969628273859\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17079\n",
      "           1       0.53      0.03      0.05      1750\n",
      "\n",
      "    accuracy                           0.91     18829\n",
      "   macro avg       0.72      0.51      0.50     18829\n",
      "weighted avg       0.87      0.91      0.87     18829\n",
      "\n",
      "Confusion_matrix\n",
      "[[17039    40]\n",
      " [ 1705    45]]\n",
      "done in 0.714199s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.259968929643947\n",
      "0.24261544189638803\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2711\n",
      "           1       0.55      0.06      0.11       251\n",
      "\n",
      "    accuracy                           0.92      2962\n",
      "   macro avg       0.74      0.53      0.54      2962\n",
      "weighted avg       0.89      0.92      0.88      2962\n",
      "\n",
      "Confusion_matrix\n",
      "[[2698   13]\n",
      " [ 235   16]]\n",
      "done in 0.558590s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.259968929643947\n",
      "0.2572747351547967\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95      2804\n",
      "           1       0.43      0.05      0.09       265\n",
      "\n",
      "    accuracy                           0.91      3069\n",
      "   macro avg       0.68      0.52      0.52      3069\n",
      "weighted avg       0.88      0.91      0.88      3069\n",
      "\n",
      "Confusion_matrix\n",
      "[[2787   17]\n",
      " [ 252   13]]\n",
      "done in 0.612691s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19950\n",
      "           1       0.33      0.00      0.01      1948\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.62      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19938    12]\n",
      " [ 1942     6]]\n",
      "done in 19.591834s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19883\n",
      "           1       0.57      0.00      0.00      2015\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.74      0.50      0.48     21898\n",
      "weighted avg       0.88      0.91      0.86     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19880     3]\n",
      " [ 2011     4]]\n",
      "done in 19.652634s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17239\n",
      "           1       0.25      0.00      0.00      1697\n",
      "\n",
      "    accuracy                           0.91     18936\n",
      "   macro avg       0.58      0.50      0.48     18936\n",
      "weighted avg       0.85      0.91      0.87     18936\n",
      "\n",
      "Confusion_matrix\n",
      "[[17230     9]\n",
      " [ 1694     3]]\n",
      "done in 19.263775s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17079\n",
      "           1       0.50      0.00      0.01      1750\n",
      "\n",
      "    accuracy                           0.91     18829\n",
      "   macro avg       0.70      0.50      0.48     18829\n",
      "weighted avg       0.87      0.91      0.86     18829\n",
      "\n",
      "Confusion_matrix\n",
      "[[17074     5]\n",
      " [ 1745     5]]\n",
      "done in 20.021424s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2711\n",
      "           1       1.00      0.00      0.01       251\n",
      "\n",
      "    accuracy                           0.92      2962\n",
      "   macro avg       0.96      0.50      0.48      2962\n",
      "weighted avg       0.92      0.92      0.88      2962\n",
      "\n",
      "Confusion_matrix\n",
      "[[2711    0]\n",
      " [ 250    1]]\n",
      "done in 19.180611s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2804\n",
      "           1       0.00      0.00      0.00       265\n",
      "\n",
      "    accuracy                           0.91      3069\n",
      "   macro avg       0.46      0.50      0.48      3069\n",
      "weighted avg       0.83      0.91      0.87      3069\n",
      "\n",
      "Confusion_matrix\n",
      "[[2803    1]\n",
      " [ 265    0]]\n",
      "done in 19.206615s\n",
      "0.26451451233769135\n",
      "0.26847785802966473\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19950\n",
      "           1       0.00      0.00      0.00      1948\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.46      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19950     0]\n",
      " [ 1948     0]]\n",
      "done in 0.640579s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26451451233769135\n",
      "0.2812937742410675\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19883\n",
      "           1       0.00      0.00      0.00      2015\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.45      0.50      0.48     21898\n",
      "weighted avg       0.82      0.91      0.86     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19878     5]\n",
      " [ 2015     0]]\n",
      "done in 0.628619s\n",
      "0.26451451233769135\n",
      "0.271372572295425\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17239\n",
      "           1       0.00      0.00      0.00      1697\n",
      "\n",
      "    accuracy                           0.91     18936\n",
      "   macro avg       0.46      0.50      0.48     18936\n",
      "weighted avg       0.83      0.91      0.87     18936\n",
      "\n",
      "Confusion_matrix\n",
      "[[17239     0]\n",
      " [ 1697     0]]\n",
      "done in 0.611576s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26451451233769135\n",
      "0.27511831675186643\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17079\n",
      "           1       0.00      0.00      0.00      1750\n",
      "\n",
      "    accuracy                           0.91     18829\n",
      "   macro avg       0.45      0.50      0.48     18829\n",
      "weighted avg       0.82      0.91      0.86     18829\n",
      "\n",
      "Confusion_matrix\n",
      "[[17079     0]\n",
      " [ 1750     0]]\n",
      "done in 0.754245s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26451451233769135\n",
      "0.24997201422938214\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2711\n",
      "           1       0.00      0.00      0.00       251\n",
      "\n",
      "    accuracy                           0.92      2962\n",
      "   macro avg       0.46      0.50      0.48      2962\n",
      "weighted avg       0.84      0.92      0.87      2962\n",
      "\n",
      "Confusion_matrix\n",
      "[[2711    0]\n",
      " [ 251    0]]\n",
      "done in 0.606412s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26451451233769135\n",
      "0.31918158429781796\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2804\n",
      "           1       0.00      0.00      0.00       265\n",
      "\n",
      "    accuracy                           0.91      3069\n",
      "   macro avg       0.46      0.50      0.48      3069\n",
      "weighted avg       0.83      0.91      0.87      3069\n",
      "\n",
      "Confusion_matrix\n",
      "[[2799    5]\n",
      " [ 265    0]]\n",
      "done in 0.578845s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19950\n",
      "           1       0.46      0.02      0.04      1948\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.51      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19906    44]\n",
      " [ 1911    37]]\n",
      "done in 33.556010s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19883\n",
      "           1       0.37      0.01      0.02      2015\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.64      0.51      0.49     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19841    42]\n",
      " [ 1990    25]]\n",
      "done in 33.559508s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17239\n",
      "           1       0.41      0.02      0.03      1697\n",
      "\n",
      "    accuracy                           0.91     18936\n",
      "   macro avg       0.66      0.51      0.49     18936\n",
      "weighted avg       0.87      0.91      0.87     18936\n",
      "\n",
      "Confusion_matrix\n",
      "[[17201    38]\n",
      " [ 1671    26]]\n",
      "done in 33.043642s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17079\n",
      "           1       0.40      0.01      0.02      1750\n",
      "\n",
      "    accuracy                           0.91     18829\n",
      "   macro avg       0.65      0.50      0.49     18829\n",
      "weighted avg       0.86      0.91      0.86     18829\n",
      "\n",
      "Confusion_matrix\n",
      "[[17049    30]\n",
      " [ 1730    20]]\n",
      "done in 33.125615s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2711\n",
      "           1       0.65      0.04      0.08       251\n",
      "\n",
      "    accuracy                           0.92      2962\n",
      "   macro avg       0.78      0.52      0.52      2962\n",
      "weighted avg       0.90      0.92      0.88      2962\n",
      "\n",
      "Confusion_matrix\n",
      "[[2705    6]\n",
      " [ 240   11]]\n",
      "done in 32.994157s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2804\n",
      "           1       0.31      0.02      0.04       265\n",
      "\n",
      "    accuracy                           0.91      3069\n",
      "   macro avg       0.61      0.51      0.49      3069\n",
      "weighted avg       0.86      0.91      0.87      3069\n",
      "\n",
      "Confusion_matrix\n",
      "[[2793   11]\n",
      " [ 260    5]]\n",
      "done in 32.697553s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.396\n",
      "threshold:0.2, J-value:0.256\n",
      "threshold:0.30000000000000004, J-value:0.14200000000000002\n",
      "threshold:0.4, J-value:0.07\n",
      "threshold:0.5, J-value:0.030000000000000002\n",
      "threshold:0.6000000000000001, J-value:0.009999999999999998\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6981929670171322\n",
      "Balanced accuracy score of test is  0.7076559535815539\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.387\n",
      "threshold:0.2, J-value:0.248\n",
      "threshold:0.30000000000000004, J-value:0.139\n",
      "threshold:0.4, J-value:0.065\n",
      "threshold:0.5, J-value:0.026\n",
      "threshold:0.6000000000000001, J-value:0.009000000000000001\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.693786371865222\n",
      "Balanced accuracy score of test is  0.7111916723126981\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.45400000000000007\n",
      "threshold:0.2, J-value:0.308\n",
      "threshold:0.30000000000000004, J-value:0.164\n",
      "threshold:0.4, J-value:0.095\n",
      "threshold:0.5, J-value:0.059000000000000004\n",
      "threshold:0.6000000000000001, J-value:0.017\n",
      "threshold:0.7000000000000001, J-value:0.004\n",
      "threshold:0.8, J-value:0.004\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7271739306146863\n",
      "Balanced accuracy score of test is  0.6843592711221167\n",
      "True positive rate of class 1 is  0.675\n",
      "True positive rate of class 2 is  0.623\n",
      "Positive prediction rate of class 1 is  0.292\n",
      "Positive prediction rate of class 2 is  0.286\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.38399999999999995\n",
      "threshold:0.2, J-value:0.27\n",
      "threshold:0.30000000000000004, J-value:0.101\n",
      "threshold:0.4, J-value:0.024\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6923028567311502\n",
      "Balanced accuracy score of test is  0.697085468601742\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.368\n",
      "threshold:0.2, J-value:0.273\n",
      "threshold:0.30000000000000004, J-value:0.098\n",
      "threshold:0.4, J-value:0.023\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6841880979810924\n",
      "Balanced accuracy score of test is  0.6960132995407895\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.449\n",
      "threshold:0.2, J-value:0.35600000000000004\n",
      "threshold:0.30000000000000004, J-value:0.10800000000000001\n",
      "threshold:0.4, J-value:0.019\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7245587917602919\n",
      "Balanced accuracy score of test is  0.6804100610987\n",
      "True positive rate of class 1 is  0.738\n",
      "True positive rate of class 2 is  0.732\n",
      "Positive prediction rate of class 1 is  0.382\n",
      "Positive prediction rate of class 2 is  0.402\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.358\n",
      "threshold:0.2, J-value:0.20799999999999996\n",
      "threshold:0.30000000000000004, J-value:0.071\n",
      "threshold:0.4, J-value:0.001\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6791722375754581\n",
      "Balanced accuracy score of test is  0.6812920473105134\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.34900000000000003\n",
      "threshold:0.2, J-value:0.201\n",
      "threshold:0.30000000000000004, J-value:0.073\n",
      "threshold:0.4, J-value:0.002\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6746097867811003\n",
      "Balanced accuracy score of test is  0.6811837929621172\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.416\n",
      "threshold:0.2, J-value:0.257\n",
      "threshold:0.30000000000000004, J-value:0.05\n",
      "threshold:0.4, J-value:0.003\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7076952242670778\n",
      "Balanced accuracy score of test is  0.6798313729712271\n",
      "True positive rate of class 1 is  0.644\n",
      "True positive rate of class 2 is  0.581\n",
      "Positive prediction rate of class 1 is  0.315\n",
      "Positive prediction rate of class 2 is  0.253\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.4119999999999999\n",
      "threshold:0.2, J-value:0.26\n",
      "threshold:0.30000000000000004, J-value:0.132\n",
      "threshold:0.4, J-value:0.047\n",
      "threshold:0.5, J-value:0.017\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7063035669255273\n",
      "Balanced accuracy score of test is  0.7148662479475153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.3990000000000001\n",
      "threshold:0.2, J-value:0.256\n",
      "threshold:0.30000000000000004, J-value:0.129\n",
      "threshold:0.4, J-value:0.043\n",
      "threshold:0.5, J-value:0.013\n",
      "threshold:0.6000000000000001, J-value:0.002\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6995637914237232\n",
      "Balanced accuracy score of test is  0.7175458750512325\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.502\n",
      "threshold:0.2, J-value:0.285\n",
      "threshold:0.30000000000000004, J-value:0.156\n",
      "threshold:0.4, J-value:0.07100000000000001\n",
      "threshold:0.5, J-value:0.041999999999999996\n",
      "threshold:0.6000000000000001, J-value:0.012\n",
      "threshold:0.7000000000000001, J-value:0.004\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7507836599011553\n",
      "Balanced accuracy score of test is  0.6971933625817566\n",
      "True positive rate of class 1 is  0.708\n",
      "True positive rate of class 2 is  0.668\n",
      "Positive prediction rate of class 1 is  0.313\n",
      "Positive prediction rate of class 2 is  0.308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lifuchen/Desktop/research/CVDPrediction-master/src/lib/fairness_tests.py:273: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train ['Class'] = y_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9002, 87)\n",
      "(56692, 87)\n",
      "0.09566699123661149 0.09817139315047264\n",
      "0.0981012658227848\n",
      "(65714, 86)\n",
      "X train 65714\n",
      "Y train 65714\n",
      "21898 18932 2966\n",
      "21898 18932 2966\n",
      "21898 18882 3016\n",
      "21898 18882 3016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25950205031724244\n",
      "0.2629677218436161\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19908\n",
      "           1       0.46      0.04      0.07      1990\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.69      0.52      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19822    86]\n",
      " [ 1916    74]]\n",
      "done in 0.688490s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25950205031724244\n",
      "0.2608569571200985\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19918\n",
      "           1       0.44      0.03      0.06      1980\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.52      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19831    87]\n",
      " [ 1911    69]]\n",
      "done in 0.769708s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25950205031724244\n",
      "0.2631295050127756\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17204\n",
      "           1       0.48      0.04      0.07      1728\n",
      "\n",
      "    accuracy                           0.91     18932\n",
      "   macro avg       0.69      0.52      0.51     18932\n",
      "weighted avg       0.87      0.91      0.87     18932\n",
      "\n",
      "Confusion_matrix\n",
      "[[17137    67]\n",
      " [ 1667    61]]\n",
      "done in 0.694592s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25950205031724244\n",
      "0.26319439247262666\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17156\n",
      "           1       0.41      0.03      0.05      1726\n",
      "\n",
      "    accuracy                           0.91     18882\n",
      "   macro avg       0.66      0.51      0.50     18882\n",
      "weighted avg       0.87      0.91      0.87     18882\n",
      "\n",
      "Confusion_matrix\n",
      "[[17085    71]\n",
      " [ 1676    50]]\n",
      "done in 0.693827s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25950205031724244\n",
      "0.26193505867486067\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95      2704\n",
      "           1       0.41      0.05      0.09       262\n",
      "\n",
      "    accuracy                           0.91      2966\n",
      "   macro avg       0.66      0.52      0.52      2966\n",
      "weighted avg       0.87      0.91      0.88      2966\n",
      "\n",
      "Confusion_matrix\n",
      "[[2685   19]\n",
      " [ 249   13]]\n",
      "done in 0.678557s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25950205031724244\n",
      "0.2462231857917041\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96      2762\n",
      "           1       0.54      0.07      0.13       254\n",
      "\n",
      "    accuracy                           0.92      3016\n",
      "   macro avg       0.73      0.53      0.54      3016\n",
      "weighted avg       0.89      0.92      0.89      3016\n",
      "\n",
      "Confusion_matrix\n",
      "[[2746   16]\n",
      " [ 235   19]]\n",
      "done in 0.665298s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19908\n",
      "           1       0.44      0.00      0.01      1990\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19899     9]\n",
      " [ 1983     7]]\n",
      "done in 20.794431s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19918\n",
      "           1       0.50      0.00      0.00      1980\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.70      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19914     4]\n",
      " [ 1976     4]]\n",
      "done in 19.126836s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17204\n",
      "           1       0.38      0.00      0.01      1728\n",
      "\n",
      "    accuracy                           0.91     18932\n",
      "   macro avg       0.65      0.50      0.48     18932\n",
      "weighted avg       0.86      0.91      0.87     18932\n",
      "\n",
      "Confusion_matrix\n",
      "[[17196     8]\n",
      " [ 1723     5]]\n",
      "done in 20.561653s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17156\n",
      "           1       0.33      0.00      0.00      1726\n",
      "\n",
      "    accuracy                           0.91     18882\n",
      "   macro avg       0.62      0.50      0.48     18882\n",
      "weighted avg       0.86      0.91      0.87     18882\n",
      "\n",
      "Confusion_matrix\n",
      "[[17154     2]\n",
      " [ 1725     1]]\n",
      "done in 19.218690s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2704\n",
      "           1       0.00      0.00      0.00       262\n",
      "\n",
      "    accuracy                           0.91      2966\n",
      "   macro avg       0.46      0.50      0.48      2966\n",
      "weighted avg       0.83      0.91      0.87      2966\n",
      "\n",
      "Confusion_matrix\n",
      "[[2703    1]\n",
      " [ 262    0]]\n",
      "done in 19.850642s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2762\n",
      "           1       0.00      0.00      0.00       254\n",
      "\n",
      "    accuracy                           0.92      3016\n",
      "   macro avg       0.46      0.50      0.48      3016\n",
      "weighted avg       0.84      0.92      0.88      3016\n",
      "\n",
      "Confusion_matrix\n",
      "[[2761    1]\n",
      " [ 254    0]]\n",
      "done in 18.762242s\n",
      "0.2648899142682214\n",
      "0.27086859042682465\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19908\n",
      "           1       0.00      0.00      0.00      1990\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.45      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19907     1]\n",
      " [ 1990     0]]\n",
      "done in 0.617835s\n",
      "0.2648899142682214\n",
      "0.270593739503088\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19918\n",
      "           1       0.00      0.00      0.00      1980\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.45      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19915     3]\n",
      " [ 1980     0]]\n",
      "done in 0.611672s\n",
      "0.26488991426822145\n",
      "0.2716954850904344\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17204\n",
      "           1       0.00      0.00      0.00      1728\n",
      "\n",
      "    accuracy                           0.91     18932\n",
      "   macro avg       0.45      0.50      0.48     18932\n",
      "weighted avg       0.83      0.91      0.87     18932\n",
      "\n",
      "Confusion_matrix\n",
      "[[17203     1]\n",
      " [ 1728     0]]\n",
      "done in 0.605279s\n",
      "0.26488991426822145\n",
      "0.27235667161947485\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17156\n",
      "           1       0.00      0.00      0.00      1726\n",
      "\n",
      "    accuracy                           0.91     18882\n",
      "   macro avg       0.45      0.50      0.48     18882\n",
      "weighted avg       0.83      0.91      0.87     18882\n",
      "\n",
      "Confusion_matrix\n",
      "[[17155     1]\n",
      " [ 1726     0]]\n",
      "done in 0.607138s\n",
      "0.2648899142682214\n",
      "0.26536279313514954\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2704\n",
      "           1       0.00      0.00      0.00       262\n",
      "\n",
      "    accuracy                           0.91      2966\n",
      "   macro avg       0.46      0.50      0.48      2966\n",
      "weighted avg       0.83      0.91      0.87      2966\n",
      "\n",
      "Confusion_matrix\n",
      "[[2704    0]\n",
      " [ 262    0]]\n",
      "done in 0.578230s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26488991426822145\n",
      "0.2593327616459042\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2762\n",
      "           1       0.00      0.00      0.00       254\n",
      "\n",
      "    accuracy                           0.92      3016\n",
      "   macro avg       0.46      0.50      0.48      3016\n",
      "weighted avg       0.84      0.92      0.88      3016\n",
      "\n",
      "Confusion_matrix\n",
      "[[2760    2]\n",
      " [ 254    0]]\n",
      "done in 0.577392s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19908\n",
      "           1       0.51      0.02      0.04      1990\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.71      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19865    43]\n",
      " [ 1946    44]]\n",
      "done in 33.302562s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19918\n",
      "           1       0.38      0.02      0.03      1980\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.64      0.51      0.49     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19867    51]\n",
      " [ 1949    31]]\n",
      "done in 33.046897s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17204\n",
      "           1       0.47      0.02      0.04      1728\n",
      "\n",
      "    accuracy                           0.91     18932\n",
      "   macro avg       0.69      0.51      0.49     18932\n",
      "weighted avg       0.87      0.91      0.87     18932\n",
      "\n",
      "Confusion_matrix\n",
      "[[17167    37]\n",
      " [ 1695    33]]\n",
      "done in 33.868952s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17156\n",
      "           1       0.42      0.02      0.03      1726\n",
      "\n",
      "    accuracy                           0.91     18882\n",
      "   macro avg       0.66      0.51      0.49     18882\n",
      "weighted avg       0.86      0.91      0.87     18882\n",
      "\n",
      "Confusion_matrix\n",
      "[[17117    39]\n",
      " [ 1698    28]]\n",
      "done in 33.617169s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2704\n",
      "           1       0.59      0.04      0.07       262\n",
      "\n",
      "    accuracy                           0.91      2966\n",
      "   macro avg       0.75      0.52      0.51      2966\n",
      "weighted avg       0.89      0.91      0.88      2966\n",
      "\n",
      "Confusion_matrix\n",
      "[[2697    7]\n",
      " [ 252   10]]\n",
      "done in 32.825160s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.95      2762\n",
      "           1       0.20      0.01      0.02       254\n",
      "\n",
      "    accuracy                           0.91      3016\n",
      "   macro avg       0.56      0.50      0.49      3016\n",
      "weighted avg       0.86      0.91      0.88      3016\n",
      "\n",
      "Confusion_matrix\n",
      "[[2750   12]\n",
      " [ 251    3]]\n",
      "done in 32.943785s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.395\n",
      "threshold:0.2, J-value:0.26499999999999996\n",
      "threshold:0.30000000000000004, J-value:0.157\n",
      "threshold:0.4, J-value:0.077\n",
      "threshold:0.5, J-value:0.033\n",
      "threshold:0.6000000000000001, J-value:0.013000000000000001\n",
      "threshold:0.7000000000000001, J-value:0.004\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6978644225750008\n",
      "Balanced accuracy score of test is  0.7096572208681858\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.396\n",
      "threshold:0.2, J-value:0.263\n",
      "threshold:0.30000000000000004, J-value:0.157\n",
      "threshold:0.4, J-value:0.07400000000000001\n",
      "threshold:0.5, J-value:0.031000000000000003\n",
      "threshold:0.6000000000000001, J-value:0.011\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6981188294927105\n",
      "Balanced accuracy score of test is  0.7097255854327827\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.392\n",
      "threshold:0.2, J-value:0.278\n",
      "threshold:0.30000000000000004, J-value:0.157\n",
      "threshold:0.4, J-value:0.096\n",
      "threshold:0.5, J-value:0.043000000000000003\n",
      "threshold:0.6000000000000001, J-value:0.026\n",
      "threshold:0.7000000000000001, J-value:0.011\n",
      "threshold:0.8, J-value:0.004\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6962247052712408\n",
      "Balanced accuracy score of test is  0.7082437694926078\n",
      "True positive rate of class 1 is  0.672\n",
      "True positive rate of class 2 is  0.646\n",
      "Positive prediction rate of class 1 is  0.291\n",
      "Positive prediction rate of class 2 is  0.264\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.38699999999999996\n",
      "threshold:0.2, J-value:0.28\n",
      "threshold:0.30000000000000004, J-value:0.10500000000000001\n",
      "threshold:0.4, J-value:0.026\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6933352718989765\n",
      "Balanced accuracy score of test is  0.6946700918209101\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.378\n",
      "threshold:0.2, J-value:0.277\n",
      "threshold:0.30000000000000004, J-value:0.11000000000000001\n",
      "threshold:0.4, J-value:0.021\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6890303154089918\n",
      "Balanced accuracy score of test is  0.693808530107605\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.385\n",
      "threshold:0.2, J-value:0.307\n",
      "threshold:0.30000000000000004, J-value:0.124\n",
      "threshold:0.4, J-value:0.013999999999999999\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6926478725326347\n",
      "Balanced accuracy score of test is  0.7052746212661143\n",
      "True positive rate of class 1 is  0.731\n",
      "True positive rate of class 2 is  0.752\n",
      "Positive prediction rate of class 1 is  0.379\n",
      "Positive prediction rate of class 2 is  0.376\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.35600000000000004\n",
      "threshold:0.2, J-value:0.228\n",
      "threshold:0.30000000000000004, J-value:0.10200000000000001\n",
      "threshold:0.4, J-value:0.003\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6781724323849507\n",
      "Balanced accuracy score of test is  0.680777729093323\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.35300000000000004\n",
      "threshold:0.2, J-value:0.233\n",
      "threshold:0.30000000000000004, J-value:0.10800000000000001\n",
      "threshold:0.4, J-value:0.003\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6765429093793864\n",
      "Balanced accuracy score of test is  0.6804934920693672\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.378\n",
      "threshold:0.2, J-value:0.19199999999999998\n",
      "threshold:0.30000000000000004, J-value:0.064\n",
      "threshold:0.4, J-value:0.005\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6888282555670988\n",
      "Balanced accuracy score of test is  0.6812719870914036\n",
      "True positive rate of class 1 is  0.653\n",
      "True positive rate of class 2 is  0.614\n",
      "Positive prediction rate of class 1 is  0.325\n",
      "Positive prediction rate of class 2 is  0.282\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.405\n",
      "threshold:0.2, J-value:0.27099999999999996\n",
      "threshold:0.30000000000000004, J-value:0.145\n",
      "threshold:0.4, J-value:0.063\n",
      "threshold:0.5, J-value:0.019999999999999997\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.702490425807963\n",
      "Balanced accuracy score of test is  0.7109545855177947\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.406\n",
      "threshold:0.2, J-value:0.27099999999999996\n",
      "threshold:0.30000000000000004, J-value:0.14400000000000002\n",
      "threshold:0.4, J-value:0.061000000000000006\n",
      "threshold:0.5, J-value:0.017\n",
      "threshold:0.6000000000000001, J-value:0.002\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7032687004314242\n",
      "Balanced accuracy score of test is  0.7093143904466599\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.395\n",
      "threshold:0.2, J-value:0.271\n",
      "threshold:0.30000000000000004, J-value:0.152\n",
      "threshold:0.4, J-value:0.068\n",
      "threshold:0.5, J-value:0.034999999999999996\n",
      "threshold:0.6000000000000001, J-value:0.008\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6975049686074348\n",
      "Balanced accuracy score of test is  0.7208687074868718\n",
      "True positive rate of class 1 is  0.692\n",
      "True positive rate of class 2 is  0.685\n",
      "Positive prediction rate of class 1 is  0.312\n",
      "Positive prediction rate of class 2 is  0.281\n",
      "(9072, 87)\n",
      "(56622, 87)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lifuchen/Desktop/research/CVDPrediction-master/src/lib/fairness_tests.py:273: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train ['Class'] = y_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09936984973339796 0.10088853459840959\n",
      "0.10082404265632573\n",
      "(65706, 86)\n",
      "X train 65706\n",
      "Y train 65706\n",
      "21898 18875 3023\n",
      "21898 18875 3023\n",
      "21898 19009 2889\n",
      "21898 19009 2889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.263464598857356\n",
      "0.25485150505345416\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95     20006\n",
      "           1       0.40      0.04      0.07      1892\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.66      0.52      0.51     21898\n",
      "weighted avg       0.87      0.91      0.88     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19904   102]\n",
      " [ 1825    67]]\n",
      "done in 0.563977s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.263464598857356\n",
      "0.25643792329866016\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.95     19975\n",
      "           1       0.47      0.04      0.08      1923\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.69      0.52      0.52     21898\n",
      "weighted avg       0.88      0.91      0.88     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19880    95]\n",
      " [ 1839    84]]\n",
      "done in 0.647398s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.263464598857356\n",
      "0.2557917755637069\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.95     17241\n",
      "           1       0.39      0.03      0.06      1634\n",
      "\n",
      "    accuracy                           0.91     18875\n",
      "   macro avg       0.65      0.51      0.51     18875\n",
      "weighted avg       0.87      0.91      0.88     18875\n",
      "\n",
      "Confusion_matrix\n",
      "[[17162    79]\n",
      " [ 1583    51]]\n",
      "done in 0.615009s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.263464598857356\n",
      "0.25990447202063816\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17310\n",
      "           1       0.46      0.04      0.07      1699\n",
      "\n",
      "    accuracy                           0.91     19009\n",
      "   macro avg       0.69      0.52      0.51     19009\n",
      "weighted avg       0.87      0.91      0.87     19009\n",
      "\n",
      "Confusion_matrix\n",
      "[[17238    72]\n",
      " [ 1637    62]]\n",
      "done in 0.695251s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.263464598857356\n",
      "0.24898064634322484\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95      2765\n",
      "           1       0.41      0.06      0.11       258\n",
      "\n",
      "    accuracy                           0.91      3023\n",
      "   macro avg       0.66      0.53      0.53      3023\n",
      "weighted avg       0.88      0.91      0.88      3023\n",
      "\n",
      "Confusion_matrix\n",
      "[[2742   23]\n",
      " [ 242   16]]\n",
      "done in 0.769689s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.263464598857356\n",
      "0.23362877665411882\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      2665\n",
      "           1       0.49      0.10      0.16       224\n",
      "\n",
      "    accuracy                           0.92      2889\n",
      "   macro avg       0.71      0.54      0.56      2889\n",
      "weighted avg       0.89      0.92      0.90      2889\n",
      "\n",
      "Confusion_matrix\n",
      "[[2642   23]\n",
      " [ 202   22]]\n",
      "done in 0.771905s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     20006\n",
      "           1       0.50      0.00      0.01      1892\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.71      0.50      0.48     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19999     7]\n",
      " [ 1885     7]]\n",
      "done in 19.481995s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19975\n",
      "           1       0.33      0.00      0.00      1923\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.62      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19967     8]\n",
      " [ 1919     4]]\n",
      "done in 19.027215s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17241\n",
      "           1       0.44      0.00      0.00      1634\n",
      "\n",
      "    accuracy                           0.91     18875\n",
      "   macro avg       0.68      0.50      0.48     18875\n",
      "weighted avg       0.87      0.91      0.87     18875\n",
      "\n",
      "Confusion_matrix\n",
      "[[17236     5]\n",
      " [ 1630     4]]\n",
      "done in 19.011953s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17310\n",
      "           1       0.29      0.00      0.00      1699\n",
      "\n",
      "    accuracy                           0.91     19009\n",
      "   macro avg       0.60      0.50      0.48     19009\n",
      "weighted avg       0.85      0.91      0.87     19009\n",
      "\n",
      "Confusion_matrix\n",
      "[[17300    10]\n",
      " [ 1695     4]]\n",
      "done in 19.639488s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.96      2765\n",
      "           1       1.00      0.00      0.01       258\n",
      "\n",
      "    accuracy                           0.91      3023\n",
      "   macro avg       0.96      0.50      0.48      3023\n",
      "weighted avg       0.92      0.91      0.87      3023\n",
      "\n",
      "Confusion_matrix\n",
      "[[2765    0]\n",
      " [ 257    1]]\n",
      "done in 18.745468s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2665\n",
      "           1       0.50      0.00      0.01       224\n",
      "\n",
      "    accuracy                           0.92      2889\n",
      "   macro avg       0.71      0.50      0.48      2889\n",
      "weighted avg       0.89      0.92      0.89      2889\n",
      "\n",
      "Confusion_matrix\n",
      "[[2664    1]\n",
      " [ 223    1]]\n",
      "done in 18.937655s\n",
      "0.2687397351290156\n",
      "0.26676797321638085\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     20006\n",
      "           1       0.50      0.00      0.01      1892\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.71      0.50      0.48     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19997     9]\n",
      " [ 1883     9]]\n",
      "done in 0.650125s\n",
      "0.2687397351290156\n",
      "0.26685311724722177\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19975\n",
      "           1       0.56      0.00      0.01      1923\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.74      0.50      0.48     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19968     7]\n",
      " [ 1914     9]]\n",
      "done in 0.618950s\n",
      "0.2687397351290156\n",
      "0.26800827418668616\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17241\n",
      "           1       0.44      0.00      0.01      1634\n",
      "\n",
      "    accuracy                           0.91     18875\n",
      "   macro avg       0.68      0.50      0.48     18875\n",
      "weighted avg       0.87      0.91      0.87     18875\n",
      "\n",
      "Confusion_matrix\n",
      "[[17232     9]\n",
      " [ 1627     7]]\n",
      "done in 0.615470s\n",
      "0.2687397351290156\n",
      "0.26920603899739975\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17310\n",
      "           1       0.55      0.00      0.01      1699\n",
      "\n",
      "    accuracy                           0.91     19009\n",
      "   macro avg       0.73      0.50      0.48     19009\n",
      "weighted avg       0.88      0.91      0.87     19009\n",
      "\n",
      "Confusion_matrix\n",
      "[[17305     5]\n",
      " [ 1693     6]]\n",
      "done in 0.673370s\n",
      "0.2687397351290156\n",
      "0.2590237850541203\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2765\n",
      "           1       1.00      0.01      0.02       258\n",
      "\n",
      "    accuracy                           0.92      3023\n",
      "   macro avg       0.96      0.50      0.49      3023\n",
      "weighted avg       0.92      0.92      0.88      3023\n",
      "\n",
      "Confusion_matrix\n",
      "[[2765    0]\n",
      " [ 256    2]]\n",
      "done in 0.579376s\n",
      "0.2687397351290156\n",
      "0.25137139708483586\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2665\n",
      "           1       0.60      0.01      0.03       224\n",
      "\n",
      "    accuracy                           0.92      2889\n",
      "   macro avg       0.76      0.51      0.49      2889\n",
      "weighted avg       0.90      0.92      0.89      2889\n",
      "\n",
      "Confusion_matrix\n",
      "[[2663    2]\n",
      " [ 221    3]]\n",
      "done in 0.569694s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     20006\n",
      "           1       0.34      0.02      0.03      1892\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.63      0.51      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19943    63]\n",
      " [ 1859    33]]\n",
      "done in 32.547943s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19975\n",
      "           1       0.51      0.02      0.05      1923\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.71      0.51      0.50     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19930    45]\n",
      " [ 1877    46]]\n",
      "done in 33.746898s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17241\n",
      "           1       0.35      0.02      0.03      1634\n",
      "\n",
      "    accuracy                           0.91     18875\n",
      "   macro avg       0.63      0.51      0.49     18875\n",
      "weighted avg       0.87      0.91      0.87     18875\n",
      "\n",
      "Confusion_matrix\n",
      "[[17187    54]\n",
      " [ 1605    29]]\n",
      "done in 33.094332s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17310\n",
      "           1       0.50      0.02      0.04      1699\n",
      "\n",
      "    accuracy                           0.91     19009\n",
      "   macro avg       0.71      0.51      0.50     19009\n",
      "weighted avg       0.88      0.91      0.87     19009\n",
      "\n",
      "Confusion_matrix\n",
      "[[17273    37]\n",
      " [ 1662    37]]\n",
      "done in 32.291677s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.95      2765\n",
      "           1       0.36      0.02      0.04       258\n",
      "\n",
      "    accuracy                           0.91      3023\n",
      "   macro avg       0.64      0.51      0.50      3023\n",
      "weighted avg       0.87      0.91      0.88      3023\n",
      "\n",
      "Confusion_matrix\n",
      "[[2756    9]\n",
      " [ 253    5]]\n",
      "done in 32.625106s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96      2665\n",
      "           1       0.53      0.04      0.07       224\n",
      "\n",
      "    accuracy                           0.92      2889\n",
      "   macro avg       0.73      0.52      0.52      2889\n",
      "weighted avg       0.89      0.92      0.89      2889\n",
      "\n",
      "Confusion_matrix\n",
      "[[2657    8]\n",
      " [ 215    9]]\n",
      "done in 32.638253s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.2, J-value:0.266\n",
      "threshold:0.30000000000000004, J-value:0.152\n",
      "threshold:0.4, J-value:0.07100000000000001\n",
      "threshold:0.5, J-value:0.030000000000000002\n",
      "threshold:0.6000000000000001, J-value:0.012\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7015204106844057\n",
      "Balanced accuracy score of test is  0.7060154105788763\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.399\n",
      "threshold:0.2, J-value:0.263\n",
      "threshold:0.30000000000000004, J-value:0.148\n",
      "threshold:0.4, J-value:0.066\n",
      "threshold:0.5, J-value:0.026\n",
      "threshold:0.6000000000000001, J-value:0.01\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6994874376832374\n",
      "Balanced accuracy score of test is  0.703331538006691\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.42800000000000005\n",
      "threshold:0.2, J-value:0.28200000000000003\n",
      "threshold:0.30000000000000004, J-value:0.183\n",
      "threshold:0.4, J-value:0.098\n",
      "threshold:0.5, J-value:0.054\n",
      "threshold:0.6000000000000001, J-value:0.023\n",
      "threshold:0.7000000000000001, J-value:0.003\n",
      "threshold:0.8, J-value:-0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7143221610104153\n",
      "Balanced accuracy score of test is  0.7251373626373626\n",
      "True positive rate of class 1 is  0.67\n",
      "True positive rate of class 2 is  0.696\n",
      "Positive prediction rate of class 1 is  0.299\n",
      "Positive prediction rate of class 2 is  0.281\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.388\n",
      "threshold:0.2, J-value:0.28400000000000003\n",
      "threshold:0.30000000000000004, J-value:0.10800000000000001\n",
      "threshold:0.4, J-value:0.027\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6943135082730995\n",
      "Balanced accuracy score of test is  0.6984547116552997\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.383\n",
      "threshold:0.2, J-value:0.292\n",
      "threshold:0.30000000000000004, J-value:0.10400000000000001\n",
      "threshold:0.4, J-value:0.027\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6915561891443619\n",
      "Balanced accuracy score of test is  0.696858977432268\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.413\n",
      "threshold:0.2, J-value:0.289\n",
      "threshold:0.30000000000000004, J-value:0.10400000000000001\n",
      "threshold:0.4, J-value:0.034\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7062975734892132\n",
      "Balanced accuracy score of test is  0.7226304945054945\n",
      "True positive rate of class 1 is  0.745\n",
      "True positive rate of class 2 is  0.799\n",
      "Positive prediction rate of class 1 is  0.386\n",
      "Positive prediction rate of class 2 is  0.388\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.35500000000000004\n",
      "threshold:0.2, J-value:0.216\n",
      "threshold:0.30000000000000004, J-value:0.053000000000000005\n",
      "threshold:0.4, J-value:0.049999999999999996\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.005\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.001\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6775105681826108\n",
      "Balanced accuracy score of test is  0.6876722007553644\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.35600000000000004\n",
      "threshold:0.2, J-value:0.215\n",
      "threshold:0.30000000000000004, J-value:0.051000000000000004\n",
      "threshold:0.4, J-value:0.049999999999999996\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6776041490293447\n",
      "Balanced accuracy score of test is  0.6872136870534847\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.353\n",
      "threshold:0.2, J-value:0.221\n",
      "threshold:0.30000000000000004, J-value:0.064\n",
      "threshold:0.4, J-value:0.05\n",
      "threshold:0.5, J-value:0.007\n",
      "threshold:0.6000000000000001, J-value:0.008\n",
      "threshold:0.7000000000000001, J-value:0.004\n",
      "threshold:0.8, J-value:0.004\n",
      "threshold:0.9, J-value:0.004\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6765689614085257\n",
      "Balanced accuracy score of test is  0.688090491825248\n",
      "True positive rate of class 1 is  0.67\n",
      "True positive rate of class 2 is  0.629\n",
      "Positive prediction rate of class 1 is  0.329\n",
      "Positive prediction rate of class 2 is  0.282\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.4109999999999999\n",
      "threshold:0.2, J-value:0.271\n",
      "threshold:0.30000000000000004, J-value:0.148\n",
      "threshold:0.4, J-value:0.06099999999999999\n",
      "threshold:0.5, J-value:0.014000000000000002\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7055256044751057\n",
      "Balanced accuracy score of test is  0.7092399690981381\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.40599999999999997\n",
      "threshold:0.2, J-value:0.273\n",
      "threshold:0.30000000000000004, J-value:0.148\n",
      "threshold:0.4, J-value:0.059000000000000004\n",
      "threshold:0.5, J-value:0.015\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7031461326176104\n",
      "Balanced accuracy score of test is  0.707799011142246\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.43999999999999995\n",
      "threshold:0.2, J-value:0.261\n",
      "threshold:0.30000000000000004, J-value:0.147\n",
      "threshold:0.4, J-value:0.08\n",
      "threshold:0.5, J-value:0.016\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.004\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7201872800930793\n",
      "Balanced accuracy score of test is  0.7185707585097829\n",
      "True positive rate of class 1 is  0.697\n",
      "True positive rate of class 2 is  0.696\n",
      "Positive prediction rate of class 1 is  0.318\n",
      "Positive prediction rate of class 2 is  0.293\n",
      "(9050, 87)\n",
      "(56644, 87)\n",
      "0.09418450006045219 0.09866749422968753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lifuchen/Desktop/research/CVDPrediction-master/src/lib/fairness_tests.py:273: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train ['Class'] = y_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09865796155241205\n",
      "(65731, 86)\n",
      "X train 65731\n",
      "Y train 65731\n",
      "21898 18970 2928\n",
      "21898 18970 2928\n",
      "21898 18892 3006\n",
      "21898 18892 3006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2597885829565758\n",
      "0.26394558318736044\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19911\n",
      "           1       0.43      0.03      0.06      1987\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.52      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19820    91]\n",
      " [ 1918    69]]\n",
      "done in 0.661306s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2597885829565758\n",
      "0.2608880096839597\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19927\n",
      "           1       0.44      0.03      0.06      1971\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19852    75]\n",
      " [ 1911    60]]\n",
      "done in 0.670689s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2597885829565758\n",
      "0.265881722628289\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17229\n",
      "           1       0.42      0.03      0.06      1741\n",
      "\n",
      "    accuracy                           0.91     18970\n",
      "   macro avg       0.67      0.51      0.51     18970\n",
      "weighted avg       0.87      0.91      0.87     18970\n",
      "\n",
      "Confusion_matrix\n",
      "[[17152    77]\n",
      " [ 1685    56]]\n",
      "done in 0.615333s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2597885829565758\n",
      "0.2605472600309407\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17198\n",
      "           1       0.44      0.03      0.05      1694\n",
      "\n",
      "    accuracy                           0.91     18892\n",
      "   macro avg       0.68      0.51      0.50     18892\n",
      "weighted avg       0.87      0.91      0.87     18892\n",
      "\n",
      "Confusion_matrix\n",
      "[[17143    55]\n",
      " [ 1651    43]]\n",
      "done in 0.547099s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2597885829565758\n",
      "0.25140167430948684\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96      2682\n",
      "           1       0.48      0.05      0.10       246\n",
      "\n",
      "    accuracy                           0.92      2928\n",
      "   macro avg       0.70      0.52      0.53      2928\n",
      "weighted avg       0.88      0.92      0.88      2928\n",
      "\n",
      "Confusion_matrix\n",
      "[[2668   14]\n",
      " [ 233   13]]\n",
      "done in 0.552607s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2597885829565758\n",
      "0.26302954077006585\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95      2729\n",
      "           1       0.46      0.06      0.11       277\n",
      "\n",
      "    accuracy                           0.91      3006\n",
      "   macro avg       0.69      0.53      0.53      3006\n",
      "weighted avg       0.87      0.91      0.87      3006\n",
      "\n",
      "Confusion_matrix\n",
      "[[2709   20]\n",
      " [ 260   17]]\n",
      "done in 0.622625s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19911\n",
      "           1       0.50      0.00      0.00      1987\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.70      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19907     4]\n",
      " [ 1983     4]]\n",
      "done in 19.127515s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19927\n",
      "           1       0.73      0.00      0.01      1971\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.82      0.50      0.48     21898\n",
      "weighted avg       0.89      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19924     3]\n",
      " [ 1963     8]]\n",
      "done in 18.865599s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17229\n",
      "           1       0.80      0.00      0.00      1741\n",
      "\n",
      "    accuracy                           0.91     18970\n",
      "   macro avg       0.85      0.50      0.48     18970\n",
      "weighted avg       0.90      0.91      0.87     18970\n",
      "\n",
      "Confusion_matrix\n",
      "[[17228     1]\n",
      " [ 1737     4]]\n",
      "done in 19.173763s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17198\n",
      "           1       0.80      0.00      0.00      1694\n",
      "\n",
      "    accuracy                           0.91     18892\n",
      "   macro avg       0.86      0.50      0.48     18892\n",
      "weighted avg       0.90      0.91      0.87     18892\n",
      "\n",
      "Confusion_matrix\n",
      "[[17197     1]\n",
      " [ 1690     4]]\n",
      "done in 19.247076s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2682\n",
      "           1       0.00      0.00      0.00       246\n",
      "\n",
      "    accuracy                           0.92      2928\n",
      "   macro avg       0.46      0.50      0.48      2928\n",
      "weighted avg       0.84      0.92      0.88      2928\n",
      "\n",
      "Confusion_matrix\n",
      "[[2681    1]\n",
      " [ 246    0]]\n",
      "done in 19.168234s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2729\n",
      "           1       0.00      0.00      0.00       277\n",
      "\n",
      "    accuracy                           0.91      3006\n",
      "   macro avg       0.45      0.50      0.48      3006\n",
      "weighted avg       0.82      0.91      0.86      3006\n",
      "\n",
      "Confusion_matrix\n",
      "[[2729    0]\n",
      " [ 277    0]]\n",
      "done in 18.697122s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2656621451580536\n",
      "0.27092013518165314\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19911\n",
      "           1       0.32      0.00      0.01      1987\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.61      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19898    13]\n",
      " [ 1981     6]]\n",
      "done in 0.648963s\n",
      "0.2656621451580536\n",
      "0.26946899774235417\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19927\n",
      "           1       0.32      0.00      0.01      1971\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.61      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19914    13]\n",
      " [ 1965     6]]\n",
      "done in 0.652368s\n",
      "0.2656621451580536\n",
      "0.27309495825452984\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17229\n",
      "           1       0.31      0.00      0.00      1741\n",
      "\n",
      "    accuracy                           0.91     18970\n",
      "   macro avg       0.61      0.50      0.48     18970\n",
      "weighted avg       0.85      0.91      0.86     18970\n",
      "\n",
      "Confusion_matrix\n",
      "[[17220     9]\n",
      " [ 1737     4]]\n",
      "done in 0.649542s\n",
      "0.2656621451580536\n",
      "0.2692110649412957\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17198\n",
      "           1       0.27      0.00      0.00      1694\n",
      "\n",
      "    accuracy                           0.91     18892\n",
      "   macro avg       0.59      0.50      0.48     18892\n",
      "weighted avg       0.85      0.91      0.87     18892\n",
      "\n",
      "Confusion_matrix\n",
      "[[17190     8]\n",
      " [ 1691     3]]\n",
      "done in 0.646812s\n",
      "0.2656621451580536\n",
      "0.2568298367894156\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2682\n",
      "           1       0.33      0.01      0.02       246\n",
      "\n",
      "    accuracy                           0.92      2928\n",
      "   macro avg       0.62      0.50      0.49      2928\n",
      "weighted avg       0.87      0.92      0.88      2928\n",
      "\n",
      "Confusion_matrix\n",
      "[[2678    4]\n",
      " [ 244    2]]\n",
      "done in 0.644566s\n",
      "0.2656621451580536\n",
      "0.2710900444747551\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2729\n",
      "           1       0.38      0.01      0.02       277\n",
      "\n",
      "    accuracy                           0.91      3006\n",
      "   macro avg       0.64      0.50      0.49      3006\n",
      "weighted avg       0.86      0.91      0.87      3006\n",
      "\n",
      "Confusion_matrix\n",
      "[[2724    5]\n",
      " [ 274    3]]\n",
      "done in 0.591498s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19911\n",
      "           1       0.43      0.02      0.04      1987\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19856    55]\n",
      " [ 1945    42]]\n",
      "done in 32.700364s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19927\n",
      "           1       0.40      0.01      0.03      1971\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.66      0.51      0.49     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19885    42]\n",
      " [ 1943    28]]\n",
      "done in 33.201492s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17229\n",
      "           1       0.40      0.02      0.03      1741\n",
      "\n",
      "    accuracy                           0.91     18970\n",
      "   macro avg       0.65      0.51      0.49     18970\n",
      "weighted avg       0.86      0.91      0.87     18970\n",
      "\n",
      "Confusion_matrix\n",
      "[[17182    47]\n",
      " [ 1710    31]]\n",
      "done in 33.176134s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17198\n",
      "           1       0.41      0.01      0.03      1694\n",
      "\n",
      "    accuracy                           0.91     18892\n",
      "   macro avg       0.66      0.51      0.49     18892\n",
      "weighted avg       0.87      0.91      0.87     18892\n",
      "\n",
      "Confusion_matrix\n",
      "[[17165    33]\n",
      " [ 1671    23]]\n",
      "done in 33.283902s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2682\n",
      "           1       0.58      0.04      0.08       246\n",
      "\n",
      "    accuracy                           0.92      2928\n",
      "   macro avg       0.75      0.52      0.52      2928\n",
      "weighted avg       0.89      0.92      0.88      2928\n",
      "\n",
      "Confusion_matrix\n",
      "[[2674    8]\n",
      " [ 235   11]]\n",
      "done in 33.449121s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2729\n",
      "           1       0.36      0.02      0.03       277\n",
      "\n",
      "    accuracy                           0.91      3006\n",
      "   macro avg       0.63      0.51      0.49      3006\n",
      "weighted avg       0.86      0.91      0.87      3006\n",
      "\n",
      "Confusion_matrix\n",
      "[[2720    9]\n",
      " [ 272    5]]\n",
      "done in 33.366273s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.39\n",
      "threshold:0.2, J-value:0.255\n",
      "threshold:0.30000000000000004, J-value:0.144\n",
      "threshold:0.4, J-value:0.07100000000000001\n",
      "threshold:0.5, J-value:0.030000000000000002\n",
      "threshold:0.6000000000000001, J-value:0.013000000000000001\n",
      "threshold:0.7000000000000001, J-value:0.006\n",
      "threshold:0.8, J-value:0.002\n",
      "threshold:0.9, J-value:0.001\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6947294170685114\n",
      "Balanced accuracy score of test is  0.7048089427984952\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.389\n",
      "threshold:0.2, J-value:0.253\n",
      "threshold:0.30000000000000004, J-value:0.14\n",
      "threshold:0.4, J-value:0.065\n",
      "threshold:0.5, J-value:0.028\n",
      "threshold:0.6000000000000001, J-value:0.011\n",
      "threshold:0.7000000000000001, J-value:0.005\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6946639232057646\n",
      "Balanced accuracy score of test is  0.70430940255127\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.389\n",
      "threshold:0.2, J-value:0.268\n",
      "threshold:0.30000000000000004, J-value:0.16899999999999998\n",
      "threshold:0.4, J-value:0.111\n",
      "threshold:0.5, J-value:0.048\n",
      "threshold:0.6000000000000001, J-value:0.022\n",
      "threshold:0.7000000000000001, J-value:0.015\n",
      "threshold:0.8, J-value:0.007\n",
      "threshold:0.9, J-value:0.004\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6947581891926302\n",
      "Balanced accuracy score of test is  0.707908637405696\n",
      "True positive rate of class 1 is  0.661\n",
      "True positive rate of class 2 is  0.664\n",
      "Positive prediction rate of class 1 is  0.289\n",
      "Positive prediction rate of class 2 is  0.287\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.395\n",
      "threshold:0.2, J-value:0.28400000000000003\n",
      "threshold:0.30000000000000004, J-value:0.10300000000000001\n",
      "threshold:0.4, J-value:0.026\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6977188271401091\n",
      "Balanced accuracy score of test is  0.7032348691699843\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.389\n",
      "threshold:0.2, J-value:0.279\n",
      "threshold:0.30000000000000004, J-value:0.11100000000000002\n",
      "threshold:0.4, J-value:0.018\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6946545718619765\n",
      "Balanced accuracy score of test is  0.6973013665546623\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.377\n",
      "threshold:0.2, J-value:0.307\n",
      "threshold:0.30000000000000004, J-value:0.124\n",
      "threshold:0.4, J-value:0.039\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6883559775195067\n",
      "Balanced accuracy score of test is  0.6986465731751359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positive rate of class 1 is  0.738\n",
      "True positive rate of class 2 is  0.751\n",
      "Positive prediction rate of class 1 is  0.379\n",
      "Positive prediction rate of class 2 is  0.39\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.346\n",
      "threshold:0.2, J-value:0.20400000000000001\n",
      "threshold:0.30000000000000004, J-value:0.10600000000000001\n",
      "threshold:0.4, J-value:0.004\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.002\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.672955143594835\n",
      "Balanced accuracy score of test is  0.6669901456908278\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.346\n",
      "threshold:0.2, J-value:0.20899999999999996\n",
      "threshold:0.30000000000000004, J-value:0.10700000000000001\n",
      "threshold:0.4, J-value:0.003\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6727651263486563\n",
      "Balanced accuracy score of test is  0.6642952085392538\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.3470000000000001\n",
      "threshold:0.2, J-value:0.164\n",
      "threshold:0.30000000000000004, J-value:0.09699999999999999\n",
      "threshold:0.4, J-value:0.006\n",
      "threshold:0.5, J-value:0.007\n",
      "threshold:0.6000000000000001, J-value:0.007\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6733280587839435\n",
      "Balanced accuracy score of test is  0.6836690553263318\n",
      "True positive rate of class 1 is  0.551\n",
      "True positive rate of class 2 is  0.574\n",
      "Positive prediction rate of class 1 is  0.252\n",
      "Positive prediction rate of class 2 is  0.241\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.406\n",
      "threshold:0.2, J-value:0.25999999999999995\n",
      "threshold:0.30000000000000004, J-value:0.14300000000000002\n",
      "threshold:0.4, J-value:0.051\n",
      "threshold:0.5, J-value:0.018000000000000002\n",
      "threshold:0.6000000000000001, J-value:0.008\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7034025747743033\n",
      "Balanced accuracy score of test is  0.7130120576838082\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.40800000000000003\n",
      "threshold:0.2, J-value:0.26\n",
      "threshold:0.30000000000000004, J-value:0.14100000000000001\n",
      "threshold:0.4, J-value:0.048\n",
      "threshold:0.5, J-value:0.015\n",
      "threshold:0.6000000000000001, J-value:0.006\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7038765970669985\n",
      "Balanced accuracy score of test is  0.7115324150840966\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.398\n",
      "threshold:0.2, J-value:0.261\n",
      "threshold:0.30000000000000004, J-value:0.158\n",
      "threshold:0.4, J-value:0.068\n",
      "threshold:0.5, J-value:0.041999999999999996\n",
      "threshold:0.6000000000000001, J-value:0.015\n",
      "threshold:0.7000000000000001, J-value:0.004\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6991597097179025\n",
      "Balanced accuracy score of test is  0.7221116157119745\n",
      "True positive rate of class 1 is  0.697\n",
      "True positive rate of class 2 is  0.7\n",
      "Positive prediction rate of class 1 is  0.312\n",
      "Positive prediction rate of class 2 is  0.297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lifuchen/Desktop/research/CVDPrediction-master/src/lib/fairness_tests.py:273: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train ['Class'] = y_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8944, 87)\n",
      "(56750, 87)\n",
      "0.09594412449454724 0.09967833197690192\n",
      "0.09962014459012376\n",
      "(65724, 86)\n",
      "X train 65724\n",
      "Y train 65724\n",
      "21898 18842 3056\n",
      "21898 18842 3056\n",
      "21898 18914 2984\n",
      "21898 18914 2984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26260772139083455\n",
      "0.25769002306734395\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19944\n",
      "           1       0.42      0.03      0.06      1954\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19860    84]\n",
      " [ 1893    61]]\n",
      "done in 0.673687s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26260772139083455\n",
      "0.25838909838441804\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19955\n",
      "           1       0.47      0.04      0.07      1943\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.69      0.52      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19874    81]\n",
      " [ 1871    72]]\n",
      "done in 0.730400s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26260772139083455\n",
      "0.2584035388263612\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17147\n",
      "           1       0.42      0.03      0.06      1695\n",
      "\n",
      "    accuracy                           0.91     18842\n",
      "   macro avg       0.67      0.51      0.50     18842\n",
      "weighted avg       0.87      0.91      0.87     18842\n",
      "\n",
      "Confusion_matrix\n",
      "[[17078    69]\n",
      " [ 1644    51]]\n",
      "done in 0.540645s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26260772139083455\n",
      "0.2599797563647646\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17231\n",
      "           1       0.43      0.03      0.06      1683\n",
      "\n",
      "    accuracy                           0.91     18914\n",
      "   macro avg       0.67      0.51      0.51     18914\n",
      "weighted avg       0.87      0.91      0.87     18914\n",
      "\n",
      "Confusion_matrix\n",
      "[[17163    68]\n",
      " [ 1631    52]]\n",
      "done in 0.530653s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26260772139083455\n",
      "0.2532907874876963\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95      2797\n",
      "           1       0.40      0.04      0.07       259\n",
      "\n",
      "    accuracy                           0.91      3056\n",
      "   macro avg       0.66      0.52      0.51      3056\n",
      "weighted avg       0.87      0.91      0.88      3056\n",
      "\n",
      "Confusion_matrix\n",
      "[[2782   15]\n",
      " [ 249   10]]\n",
      "done in 0.529196s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26260772139083455\n",
      "0.24830675755322662\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2724\n",
      "           1       0.61      0.08      0.14       260\n",
      "\n",
      "    accuracy                           0.92      2984\n",
      "   macro avg       0.76      0.54      0.55      2984\n",
      "weighted avg       0.89      0.92      0.88      2984\n",
      "\n",
      "Confusion_matrix\n",
      "[[2711   13]\n",
      " [ 240   20]]\n",
      "done in 0.519074s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19944\n",
      "           1       0.43      0.00      0.00      1954\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19940     4]\n",
      " [ 1951     3]]\n",
      "done in 19.385488s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19955\n",
      "           1       0.44      0.00      0.00      1943\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19950     5]\n",
      " [ 1939     4]]\n",
      "done in 20.319008s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17147\n",
      "           1       0.44      0.00      0.00      1695\n",
      "\n",
      "    accuracy                           0.91     18842\n",
      "   macro avg       0.68      0.50      0.48     18842\n",
      "weighted avg       0.87      0.91      0.87     18842\n",
      "\n",
      "Confusion_matrix\n",
      "[[17142     5]\n",
      " [ 1691     4]]\n",
      "done in 20.077627s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17231\n",
      "           1       0.40      0.00      0.00      1683\n",
      "\n",
      "    accuracy                           0.91     18914\n",
      "   macro avg       0.66      0.50      0.48     18914\n",
      "weighted avg       0.87      0.91      0.87     18914\n",
      "\n",
      "Confusion_matrix\n",
      "[[17225     6]\n",
      " [ 1679     4]]\n",
      "done in 80.091527s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2797\n",
      "           1       0.00      0.00      0.00       259\n",
      "\n",
      "    accuracy                           0.91      3056\n",
      "   macro avg       0.46      0.50      0.48      3056\n",
      "weighted avg       0.84      0.91      0.87      3056\n",
      "\n",
      "Confusion_matrix\n",
      "[[2796    1]\n",
      " [ 259    0]]\n",
      "done in 17.095472s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2724\n",
      "           1       1.00      0.00      0.01       260\n",
      "\n",
      "    accuracy                           0.91      2984\n",
      "   macro avg       0.96      0.50      0.48      2984\n",
      "weighted avg       0.92      0.91      0.87      2984\n",
      "\n",
      "Confusion_matrix\n",
      "[[2724    0]\n",
      " [ 259    1]]\n",
      "done in 17.177582s\n",
      "0.26791748199233967\n",
      "0.27255152375081904\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19944\n",
      "           1       0.29      0.01      0.01      1954\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.60      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19917    27]\n",
      " [ 1943    11]]\n",
      "done in 0.555408s\n",
      "0.26791748199233967\n",
      "0.2730712089174907\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19955\n",
      "           1       0.27      0.01      0.01      1943\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.59      0.50      0.48     21898\n",
      "weighted avg       0.85      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19923    32]\n",
      " [ 1931    12]]\n",
      "done in 0.556671s\n",
      "0.26791748199233967\n",
      "0.27144672788871377\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17147\n",
      "           1       0.26      0.00      0.01      1695\n",
      "\n",
      "    accuracy                           0.91     18842\n",
      "   macro avg       0.58      0.50      0.48     18842\n",
      "weighted avg       0.85      0.91      0.87     18842\n",
      "\n",
      "Confusion_matrix\n",
      "[[17127    20]\n",
      " [ 1688     7]]\n",
      "done in 0.551085s\n",
      "0.26791748199233967\n",
      "0.2764730297811071\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17231\n",
      "           1       0.28      0.01      0.01      1683\n",
      "\n",
      "    accuracy                           0.91     18914\n",
      "   macro avg       0.60      0.50      0.48     18914\n",
      "weighted avg       0.86      0.91      0.87     18914\n",
      "\n",
      "Confusion_matrix\n",
      "[[17203    28]\n",
      " [ 1672    11]]\n",
      "done in 0.548408s\n",
      "0.26791748199233967\n",
      "0.2793632265105661\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2797\n",
      "           1       0.36      0.02      0.03       259\n",
      "\n",
      "    accuracy                           0.91      3056\n",
      "   macro avg       0.64      0.51      0.49      3056\n",
      "weighted avg       0.87      0.91      0.88      3056\n",
      "\n",
      "Confusion_matrix\n",
      "[[2790    7]\n",
      " [ 255    4]]\n",
      "done in 0.528288s\n",
      "0.26791748199233967\n",
      "0.26303860754413466\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2724\n",
      "           1       0.17      0.00      0.01       260\n",
      "\n",
      "    accuracy                           0.91      2984\n",
      "   macro avg       0.54      0.50      0.48      2984\n",
      "weighted avg       0.85      0.91      0.87      2984\n",
      "\n",
      "Confusion_matrix\n",
      "[[2719    5]\n",
      " [ 259    1]]\n",
      "done in 0.523489s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19944\n",
      "           1       0.43      0.01      0.03      1954\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19905    39]\n",
      " [ 1925    29]]\n",
      "done in 54.227899s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19955\n",
      "           1       0.50      0.02      0.04      1943\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.71      0.51      0.50     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19918    37]\n",
      " [ 1906    37]]\n",
      "done in 262.272635s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17147\n",
      "           1       0.45      0.02      0.03      1695\n",
      "\n",
      "    accuracy                           0.91     18842\n",
      "   macro avg       0.68      0.51      0.49     18842\n",
      "weighted avg       0.87      0.91      0.87     18842\n",
      "\n",
      "Confusion_matrix\n",
      "[[17113    34]\n",
      " [ 1667    28]]\n",
      "done in 30.125133s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17231\n",
      "           1       0.52      0.02      0.03      1683\n",
      "\n",
      "    accuracy                           0.91     18914\n",
      "   macro avg       0.71      0.51      0.49     18914\n",
      "weighted avg       0.88      0.91      0.87     18914\n",
      "\n",
      "Confusion_matrix\n",
      "[[17203    28]\n",
      " [ 1653    30]]\n",
      "done in 261.651393s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2797\n",
      "           1       0.25      0.00      0.01       259\n",
      "\n",
      "    accuracy                           0.91      3056\n",
      "   macro avg       0.58      0.50      0.48      3056\n",
      "weighted avg       0.86      0.91      0.88      3056\n",
      "\n",
      "Confusion_matrix\n",
      "[[2794    3]\n",
      " [ 258    1]]\n",
      "done in 261.540312s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2724\n",
      "           1       0.44      0.03      0.05       260\n",
      "\n",
      "    accuracy                           0.91      2984\n",
      "   macro avg       0.68      0.51      0.50      2984\n",
      "weighted avg       0.87      0.91      0.88      2984\n",
      "\n",
      "Confusion_matrix\n",
      "[[2715    9]\n",
      " [ 253    7]]\n",
      "done in 30.034260s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41200000000000003\n",
      "threshold:0.2, J-value:0.26999999999999996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.30000000000000004, J-value:0.147\n",
      "threshold:0.4, J-value:0.07400000000000001\n",
      "threshold:0.5, J-value:0.027\n",
      "threshold:0.6000000000000001, J-value:0.012\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7060576933735853\n",
      "Balanced accuracy score of test is  0.70496770074407\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41500000000000004\n",
      "threshold:0.2, J-value:0.27099999999999996\n",
      "threshold:0.30000000000000004, J-value:0.148\n",
      "threshold:0.4, J-value:0.076\n",
      "threshold:0.5, J-value:0.026\n",
      "threshold:0.6000000000000001, J-value:0.013000000000000001\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7074112227204876\n",
      "Balanced accuracy score of test is  0.70107307391682\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.393\n",
      "threshold:0.2, J-value:0.259\n",
      "threshold:0.30000000000000004, J-value:0.144\n",
      "threshold:0.4, J-value:0.057999999999999996\n",
      "threshold:0.5, J-value:0.034\n",
      "threshold:0.6000000000000001, J-value:0.006\n",
      "threshold:0.7000000000000001, J-value:-0.001\n",
      "threshold:0.8, J-value:-0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.696509497903849\n",
      "Balanced accuracy score of test is  0.7299559471365639\n",
      "True positive rate of class 1 is  0.664\n",
      "True positive rate of class 2 is  0.7\n",
      "Positive prediction rate of class 1 is  0.298\n",
      "Positive prediction rate of class 2 is  0.28\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.392\n",
      "threshold:0.2, J-value:0.28600000000000003\n",
      "threshold:0.30000000000000004, J-value:0.11700000000000002\n",
      "threshold:0.4, J-value:0.019\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6958138365724951\n",
      "Balanced accuracy score of test is  0.7003563731210458\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.394\n",
      "threshold:0.2, J-value:0.28900000000000003\n",
      "threshold:0.30000000000000004, J-value:0.10300000000000001\n",
      "threshold:0.4, J-value:0.025\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6968728845297981\n",
      "Balanced accuracy score of test is  0.6962457947515659\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41200000000000003\n",
      "threshold:0.2, J-value:0.328\n",
      "threshold:0.30000000000000004, J-value:0.082\n",
      "threshold:0.4, J-value:0.012\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7056933587144527\n",
      "Balanced accuracy score of test is  0.714898904326217\n",
      "True positive rate of class 1 is  0.746\n",
      "True positive rate of class 2 is  0.788\n",
      "Positive prediction rate of class 1 is  0.388\n",
      "Positive prediction rate of class 2 is  0.396\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.368\n",
      "threshold:0.2, J-value:0.234\n",
      "threshold:0.30000000000000004, J-value:0.10600000000000001\n",
      "threshold:0.4, J-value:0.013000000000000001\n",
      "threshold:0.5, J-value:0.005\n",
      "threshold:0.6000000000000001, J-value:0.004\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6838966916988858\n",
      "Balanced accuracy score of test is  0.6779069427054929\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.36800000000000005\n",
      "threshold:0.2, J-value:0.23900000000000002\n",
      "threshold:0.30000000000000004, J-value:0.11000000000000001\n",
      "threshold:0.4, J-value:0.012\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.683798777635621\n",
      "Balanced accuracy score of test is  0.6767645043290511\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.365\n",
      "threshold:0.2, J-value:0.20399999999999996\n",
      "threshold:0.30000000000000004, J-value:0.077\n",
      "threshold:0.4, J-value:0.015\n",
      "threshold:0.5, J-value:0.012\n",
      "threshold:0.6000000000000001, J-value:0.011\n",
      "threshold:0.7000000000000001, J-value:-0.001\n",
      "threshold:0.8, J-value:-0.001\n",
      "threshold:0.9, J-value:-0.001\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6826391486741862\n",
      "Balanced accuracy score of test is  0.6846492714334125\n",
      "True positive rate of class 1 is  0.638\n",
      "True positive rate of class 2 is  0.588\n",
      "Positive prediction rate of class 1 is  0.315\n",
      "Positive prediction rate of class 2 is  0.251\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.42999999999999994\n",
      "threshold:0.2, J-value:0.27799999999999997\n",
      "threshold:0.30000000000000004, J-value:0.14400000000000002\n",
      "threshold:0.4, J-value:0.049\n",
      "threshold:0.5, J-value:0.013\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7148743708586704\n",
      "Balanced accuracy score of test is  0.7101190622802489\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.42999999999999994\n",
      "threshold:0.2, J-value:0.283\n",
      "threshold:0.30000000000000004, J-value:0.14600000000000002\n",
      "threshold:0.4, J-value:0.052\n",
      "threshold:0.5, J-value:0.015000000000000001\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7150177202751222\n",
      "Balanced accuracy score of test is  0.7081204394255085\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.42600000000000005\n",
      "threshold:0.2, J-value:0.244\n",
      "threshold:0.30000000000000004, J-value:0.129\n",
      "threshold:0.4, J-value:0.027\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.004\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7130612915382311\n",
      "Balanced accuracy score of test is  0.7226138032305434\n",
      "True positive rate of class 1 is  0.696\n",
      "True positive rate of class 2 is  0.7\n",
      "Positive prediction rate of class 1 is  0.317\n",
      "Positive prediction rate of class 2 is  0.294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lifuchen/Desktop/research/CVDPrediction-master/src/lib/fairness_tests.py:273: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train ['Class'] = y_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8973, 87)\n",
      "(56721, 87)\n",
      "0.09320175438596491 0.0980099887723102\n",
      "0.097953216374269\n",
      "(65733, 86)\n",
      "X train 65733\n",
      "Y train 65733\n",
      "21898 18920 2978\n",
      "21898 18920 2978\n",
      "21898 18865 3033\n",
      "21898 18865 3033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25956929144131974\n",
      "0.2633176829237143\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19893\n",
      "           1       0.42      0.03      0.06      2005\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19803    90]\n",
      " [ 1939    66]]\n",
      "done in 0.609400s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25956929144131974\n",
      "0.26230421956300937\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19907\n",
      "           1       0.49      0.03      0.06      1991\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.70      0.52      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19837    70]\n",
      " [ 1924    67]]\n",
      "done in 0.622782s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25956929144131974\n",
      "0.261926883185371\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17191\n",
      "           1       0.42      0.03      0.06      1729\n",
      "\n",
      "    accuracy                           0.91     18920\n",
      "   macro avg       0.66      0.51      0.50     18920\n",
      "weighted avg       0.87      0.91      0.87     18920\n",
      "\n",
      "Confusion_matrix\n",
      "[[17116    75]\n",
      " [ 1675    54]]\n",
      "done in 0.663796s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25956929144131974\n",
      "0.26440701415101514\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17135\n",
      "           1       0.47      0.03      0.05      1730\n",
      "\n",
      "    accuracy                           0.91     18865\n",
      "   macro avg       0.69      0.51      0.50     18865\n",
      "weighted avg       0.87      0.91      0.87     18865\n",
      "\n",
      "Confusion_matrix\n",
      "[[17082    53]\n",
      " [ 1683    47]]\n",
      "done in 0.640148s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25956929144131974\n",
      "0.2721537914023766\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95      2702\n",
      "           1       0.44      0.04      0.08       276\n",
      "\n",
      "    accuracy                           0.91      2978\n",
      "   macro avg       0.68      0.52      0.51      2978\n",
      "weighted avg       0.87      0.91      0.87      2978\n",
      "\n",
      "Confusion_matrix\n",
      "[[2687   15]\n",
      " [ 264   12]]\n",
      "done in 0.634659s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25956929144131974\n",
      "0.24922501748495804\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96      2772\n",
      "           1       0.54      0.08      0.13       261\n",
      "\n",
      "    accuracy                           0.91      3033\n",
      "   macro avg       0.73      0.54      0.54      3033\n",
      "weighted avg       0.89      0.91      0.88      3033\n",
      "\n",
      "Confusion_matrix\n",
      "[[2755   17]\n",
      " [ 241   20]]\n",
      "done in 0.645759s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19893\n",
      "           1       0.63      0.01      0.01      2005\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.77      0.50      0.48     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19886     7]\n",
      " [ 1993    12]]\n",
      "done in 17.746685s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19907\n",
      "           1       0.43      0.00      0.00      1991\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19903     4]\n",
      " [ 1988     3]]\n",
      "done in 17.585054s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17191\n",
      "           1       0.67      0.00      0.01      1729\n",
      "\n",
      "    accuracy                           0.91     18920\n",
      "   macro avg       0.79      0.50      0.48     18920\n",
      "weighted avg       0.89      0.91      0.87     18920\n",
      "\n",
      "Confusion_matrix\n",
      "[[17188     3]\n",
      " [ 1723     6]]\n",
      "done in 17.276554s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17135\n",
      "           1       0.29      0.00      0.00      1730\n",
      "\n",
      "    accuracy                           0.91     18865\n",
      "   macro avg       0.60      0.50      0.48     18865\n",
      "weighted avg       0.85      0.91      0.86     18865\n",
      "\n",
      "Confusion_matrix\n",
      "[[17130     5]\n",
      " [ 1728     2]]\n",
      "done in 17.388193s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2702\n",
      "           1       1.00      0.00      0.01       276\n",
      "\n",
      "    accuracy                           0.91      2978\n",
      "   macro avg       0.95      0.50      0.48      2978\n",
      "weighted avg       0.92      0.91      0.86      2978\n",
      "\n",
      "Confusion_matrix\n",
      "[[2702    0]\n",
      " [ 275    1]]\n",
      "done in 17.541075s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.96      2772\n",
      "           1       0.00      0.00      0.00       261\n",
      "\n",
      "    accuracy                           0.91      3033\n",
      "   macro avg       0.46      0.50      0.48      3033\n",
      "weighted avg       0.84      0.91      0.87      3033\n",
      "\n",
      "Confusion_matrix\n",
      "[[2772    0]\n",
      " [ 261    0]]\n",
      "done in 17.486514s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2651559464007411\n",
      "0.2709021114332017\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19893\n",
      "           1       0.08      0.00      0.00      2005\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.50      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.86     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19882    11]\n",
      " [ 2004     1]]\n",
      "done in 0.609815s\n",
      "0.2651559464007411\n",
      "0.27202870881314756\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19907\n",
      "           1       0.33      0.00      0.00      1991\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.62      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19903     4]\n",
      " [ 1989     2]]\n",
      "done in 0.599353s\n",
      "0.2651559464007411\n",
      "0.2696438972228694\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17191\n",
      "           1       0.10      0.00      0.00      1729\n",
      "\n",
      "    accuracy                           0.91     18920\n",
      "   macro avg       0.50      0.50      0.48     18920\n",
      "weighted avg       0.83      0.91      0.87     18920\n",
      "\n",
      "Confusion_matrix\n",
      "[[17182     9]\n",
      " [ 1728     1]]\n",
      "done in 0.571238s\n",
      "0.2651559464007411\n",
      "0.27272496293090426\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17135\n",
      "           1       0.33      0.00      0.00      1730\n",
      "\n",
      "    accuracy                           0.91     18865\n",
      "   macro avg       0.62      0.50      0.48     18865\n",
      "weighted avg       0.86      0.91      0.86     18865\n",
      "\n",
      "Confusion_matrix\n",
      "[[17133     2]\n",
      " [ 1729     1]]\n",
      "done in 0.567333s\n",
      "0.2651559464007411\n",
      "0.2788958699488121\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2702\n",
      "           1       0.00      0.00      0.00       276\n",
      "\n",
      "    accuracy                           0.91      2978\n",
      "   macro avg       0.45      0.50      0.48      2978\n",
      "weighted avg       0.82      0.91      0.86      2978\n",
      "\n",
      "Confusion_matrix\n",
      "[[2700    2]\n",
      " [ 276    0]]\n",
      "done in 0.547150s\n",
      "0.2651559464007411\n",
      "0.2676980678861841\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2772\n",
      "           1       0.33      0.00      0.01       261\n",
      "\n",
      "    accuracy                           0.91      3033\n",
      "   macro avg       0.62      0.50      0.48      3033\n",
      "weighted avg       0.86      0.91      0.87      3033\n",
      "\n",
      "Confusion_matrix\n",
      "[[2770    2]\n",
      " [ 260    1]]\n",
      "done in 0.538067s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19893\n",
      "           1       0.44      0.02      0.04      2005\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19835    58]\n",
      " [ 1959    46]]\n",
      "done in 31.840431s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19907\n",
      "           1       0.41      0.02      0.03      1991\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.66      0.51      0.49     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19863    44]\n",
      " [ 1961    30]]\n",
      "done in 31.971098s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17191\n",
      "           1       0.47      0.02      0.05      1729\n",
      "\n",
      "    accuracy                           0.91     18920\n",
      "   macro avg       0.69      0.51      0.50     18920\n",
      "weighted avg       0.87      0.91      0.87     18920\n",
      "\n",
      "Confusion_matrix\n",
      "[[17145    46]\n",
      " [ 1688    41]]\n",
      "done in 32.167047s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17135\n",
      "           1       0.38      0.01      0.03      1730\n",
      "\n",
      "    accuracy                           0.91     18865\n",
      "   macro avg       0.65      0.51      0.49     18865\n",
      "weighted avg       0.86      0.91      0.87     18865\n",
      "\n",
      "Confusion_matrix\n",
      "[[17098    37]\n",
      " [ 1707    23]]\n",
      "done in 34.503960s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2702\n",
      "           1       0.29      0.02      0.03       276\n",
      "\n",
      "    accuracy                           0.90      2978\n",
      "   macro avg       0.60      0.51      0.49      2978\n",
      "weighted avg       0.85      0.90      0.87      2978\n",
      "\n",
      "Confusion_matrix\n",
      "[[2690   12]\n",
      " [ 271    5]]\n",
      "done in 51.033990s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.95      2772\n",
      "           1       0.50      0.03      0.05       261\n",
      "\n",
      "    accuracy                           0.91      3033\n",
      "   macro avg       0.71      0.51      0.50      3033\n",
      "weighted avg       0.88      0.91      0.88      3033\n",
      "\n",
      "Confusion_matrix\n",
      "[[2765    7]\n",
      " [ 254    7]]\n",
      "done in 56.521474s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41300000000000003\n",
      "threshold:0.2, J-value:0.26499999999999996\n",
      "threshold:0.30000000000000004, J-value:0.144\n",
      "threshold:0.4, J-value:0.069\n",
      "threshold:0.5, J-value:0.028\n",
      "threshold:0.6000000000000001, J-value:0.008\n",
      "threshold:0.7000000000000001, J-value:0.005\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7064080486462925\n",
      "Balanced accuracy score of test is  0.697746000570155\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41600000000000004\n",
      "threshold:0.2, J-value:0.26899999999999996\n",
      "threshold:0.30000000000000004, J-value:0.147\n",
      "threshold:0.4, J-value:0.068\n",
      "threshold:0.5, J-value:0.027\n",
      "threshold:0.6000000000000001, J-value:0.009\n",
      "threshold:0.7000000000000001, J-value:0.006\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7081132880571999\n",
      "Balanced accuracy score of test is  0.6966342593920094\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.392\n",
      "threshold:0.2, J-value:0.23900000000000002\n",
      "threshold:0.30000000000000004, J-value:0.129\n",
      "threshold:0.4, J-value:0.079\n",
      "threshold:0.5, J-value:0.037\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:-0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6958224718136861\n",
      "Balanced accuracy score of test is  0.7051549982584466\n",
      "True positive rate of class 1 is  0.645\n",
      "True positive rate of class 2 is  0.663\n",
      "Positive prediction rate of class 1 is  0.287\n",
      "Positive prediction rate of class 2 is  0.288\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.407\n",
      "threshold:0.2, J-value:0.296\n",
      "threshold:0.30000000000000004, J-value:0.11000000000000001\n",
      "threshold:0.4, J-value:0.025\n",
      "threshold:0.5, J-value:0.006\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7033939180601254\n",
      "Balanced accuracy score of test is  0.6928171673823208\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.40800000000000003\n",
      "threshold:0.2, J-value:0.28800000000000003\n",
      "threshold:0.30000000000000004, J-value:0.11300000000000002\n",
      "threshold:0.4, J-value:0.021\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7040168300635068\n",
      "Balanced accuracy score of test is  0.6973145085524507\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.384\n",
      "threshold:0.2, J-value:0.28400000000000003\n",
      "threshold:0.30000000000000004, J-value:0.10699999999999998\n",
      "threshold:0.4, J-value:0.025\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6922207382615132\n",
      "Balanced accuracy score of test is  0.7041411653480618\n",
      "True positive rate of class 1 is  0.734\n",
      "True positive rate of class 2 is  0.77\n",
      "Positive prediction rate of class 1 is  0.375\n",
      "Positive prediction rate of class 2 is  0.397\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.37400000000000005\n",
      "threshold:0.2, J-value:0.21000000000000002\n",
      "threshold:0.30000000000000004, J-value:0.098\n",
      "threshold:0.4, J-value:0.008\n",
      "threshold:0.5, J-value:-0.001\n",
      "threshold:0.6000000000000001, J-value:-0.001\n",
      "threshold:0.7000000000000001, J-value:-0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.687285719246347\n",
      "Balanced accuracy score of test is  0.6872702163503284\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.38099999999999995\n",
      "threshold:0.2, J-value:0.21500000000000002\n",
      "threshold:0.30000000000000004, J-value:0.10400000000000001\n",
      "threshold:0.4, J-value:0.008\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6902225729840546\n",
      "Balanced accuracy score of test is  0.6843686906595194\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.33799999999999997\n",
      "threshold:0.2, J-value:0.182\n",
      "threshold:0.30000000000000004, J-value:0.05499999999999999\n",
      "threshold:0.4, J-value:0.005\n",
      "threshold:0.5, J-value:-0.001\n",
      "threshold:0.6000000000000001, J-value:-0.001\n",
      "threshold:0.7000000000000001, J-value:-0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6693498642980509\n",
      "Balanced accuracy score of test is  0.7046822908891874\n",
      "True positive rate of class 1 is  0.677\n",
      "True positive rate of class 2 is  0.659\n",
      "Positive prediction rate of class 1 is  0.342\n",
      "Positive prediction rate of class 2 is  0.285\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.42199999999999993\n",
      "threshold:0.2, J-value:0.285\n",
      "threshold:0.30000000000000004, J-value:0.14100000000000001\n",
      "threshold:0.4, J-value:0.065\n",
      "threshold:0.5, J-value:0.02\n",
      "threshold:0.6000000000000001, J-value:0.006\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7113651552012745\n",
      "Balanced accuracy score of test is  0.7073628560652337\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.42999999999999994\n",
      "threshold:0.2, J-value:0.286\n",
      "threshold:0.30000000000000004, J-value:0.146\n",
      "threshold:0.4, J-value:0.065\n",
      "threshold:0.5, J-value:0.021\n",
      "threshold:0.6000000000000001, J-value:0.008\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7149920975974389\n",
      "Balanced accuracy score of test is  0.7049475349612311\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.377\n",
      "threshold:0.2, J-value:0.26999999999999996\n",
      "threshold:0.30000000000000004, J-value:0.10499999999999998\n",
      "threshold:0.4, J-value:0.068\n",
      "threshold:0.5, J-value:0.013999999999999999\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:-0.001\n",
      "threshold:0.8, J-value:-0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6886055954258252\n",
      "Balanced accuracy score of test is  0.7230929989550678\n",
      "True positive rate of class 1 is  0.682\n",
      "True positive rate of class 2 is  0.709\n",
      "Positive prediction rate of class 1 is  0.309\n",
      "Positive prediction rate of class 2 is  0.301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lifuchen/Desktop/research/CVDPrediction-master/src/lib/fairness_tests.py:273: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train ['Class'] = y_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9011, 87)\n",
      "(56683, 87)\n",
      "0.09316996239233288 0.09987193418193108\n",
      "0.09984229042824215\n",
      "(65749, 86)\n",
      "X train 65749\n",
      "Y train 65749\n",
      "21898 18905 2993\n",
      "21898 18905 2993\n",
      "21898 18918 2980\n",
      "21898 18918 2980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2616645787273284\n",
      "0.2622271780959184\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19931\n",
      "           1       0.50      0.04      0.08      1967\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.71      0.52      0.52     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19847    84]\n",
      " [ 1882    85]]\n",
      "done in 0.811297s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2616645787273284\n",
      "0.2594175931917696\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19956\n",
      "           1       0.44      0.03      0.06      1942\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.52      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19871    85]\n",
      " [ 1875    67]]\n",
      "done in 1.181156s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2616645787273284\n",
      "0.2606922108291378\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17217\n",
      "           1       0.52      0.04      0.07      1688\n",
      "\n",
      "    accuracy                           0.91     18905\n",
      "   macro avg       0.72      0.52      0.51     18905\n",
      "weighted avg       0.88      0.91      0.87     18905\n",
      "\n",
      "Confusion_matrix\n",
      "[[17154    63]\n",
      " [ 1620    68]]\n",
      "done in 0.882652s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2616645787273284\n",
      "0.2604733500510281\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17231\n",
      "           1       0.42      0.03      0.05      1687\n",
      "\n",
      "    accuracy                           0.91     18918\n",
      "   macro avg       0.67      0.51      0.50     18918\n",
      "weighted avg       0.87      0.91      0.87     18918\n",
      "\n",
      "Confusion_matrix\n",
      "[[17163    68]\n",
      " [ 1638    49]]\n",
      "done in 0.826409s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2616645787273284\n",
      "0.2719226529300268\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95      2714\n",
      "           1       0.45      0.06      0.11       279\n",
      "\n",
      "    accuracy                           0.91      2993\n",
      "   macro avg       0.68      0.53      0.53      2993\n",
      "weighted avg       0.87      0.91      0.87      2993\n",
      "\n",
      "Confusion_matrix\n",
      "[[2693   21]\n",
      " [ 262   17]]\n",
      "done in 0.798110s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2616645787273284\n",
      "0.25271530853960406\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96      2725\n",
      "           1       0.51      0.07      0.12       255\n",
      "\n",
      "    accuracy                           0.91      2980\n",
      "   macro avg       0.72      0.53      0.54      2980\n",
      "weighted avg       0.88      0.91      0.88      2980\n",
      "\n",
      "Confusion_matrix\n",
      "[[2708   17]\n",
      " [ 237   18]]\n",
      "done in 0.801922s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19931\n",
      "           1       0.47      0.00      0.01      1967\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.69      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19923     8]\n",
      " [ 1960     7]]\n",
      "done in 24.858357s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19956\n",
      "           1       0.50      0.00      0.01      1942\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.71      0.50      0.48     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19949     7]\n",
      " [ 1935     7]]\n",
      "done in 23.611502s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17217\n",
      "           1       0.23      0.00      0.00      1688\n",
      "\n",
      "    accuracy                           0.91     18905\n",
      "   macro avg       0.57      0.50      0.48     18905\n",
      "weighted avg       0.85      0.91      0.87     18905\n",
      "\n",
      "Confusion_matrix\n",
      "[[17207    10]\n",
      " [ 1685     3]]\n",
      "done in 22.761187s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17231\n",
      "           1       0.60      0.00      0.00      1687\n",
      "\n",
      "    accuracy                           0.91     18918\n",
      "   macro avg       0.76      0.50      0.48     18918\n",
      "weighted avg       0.88      0.91      0.87     18918\n",
      "\n",
      "Confusion_matrix\n",
      "[[17229     2]\n",
      " [ 1684     3]]\n",
      "done in 22.534924s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2714\n",
      "           1       0.50      0.00      0.01       279\n",
      "\n",
      "    accuracy                           0.91      2993\n",
      "   macro avg       0.70      0.50      0.48      2993\n",
      "weighted avg       0.87      0.91      0.86      2993\n",
      "\n",
      "Confusion_matrix\n",
      "[[2713    1]\n",
      " [ 278    1]]\n",
      "done in 22.343950s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.96      2725\n",
      "           1       0.50      0.00      0.01       255\n",
      "\n",
      "    accuracy                           0.91      2980\n",
      "   macro avg       0.71      0.50      0.48      2980\n",
      "weighted avg       0.88      0.91      0.87      2980\n",
      "\n",
      "Confusion_matrix\n",
      "[[2724    1]\n",
      " [ 254    1]]\n",
      "done in 22.643075s\n",
      "0.2671673652917732\n",
      "0.270119975155797\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19931\n",
      "           1       0.35      0.00      0.01      1967\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.63      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19920    11]\n",
      " [ 1961     6]]\n",
      "done in 0.766385s\n",
      "0.2671673652917732\n",
      "0.26832493575982996\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19956\n",
      "           1       0.30      0.00      0.01      1942\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.61      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19942    14]\n",
      " [ 1936     6]]\n",
      "done in 0.743304s\n",
      "0.2671673652917732\n",
      "0.26943176405853075\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17217\n",
      "           1       0.33      0.00      0.00      1688\n",
      "\n",
      "    accuracy                           0.91     18905\n",
      "   macro avg       0.62      0.50      0.48     18905\n",
      "weighted avg       0.86      0.91      0.87     18905\n",
      "\n",
      "Confusion_matrix\n",
      "[[17213     4]\n",
      " [ 1686     2]]\n",
      "done in 0.722881s\n",
      "0.2671673652917732\n",
      "0.269815655362959\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17231\n",
      "           1       0.40      0.00      0.00      1687\n",
      "\n",
      "    accuracy                           0.91     18918\n",
      "   macro avg       0.66      0.50      0.48     18918\n",
      "weighted avg       0.87      0.91      0.87     18918\n",
      "\n",
      "Confusion_matrix\n",
      "[[17225     6]\n",
      " [ 1683     4]]\n",
      "done in 0.811424s\n",
      "0.2671673652917732\n",
      "0.27412648456993194\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2714\n",
      "           1       0.40      0.01      0.03       279\n",
      "\n",
      "    accuracy                           0.91      2993\n",
      "   macro avg       0.65      0.51      0.49      2993\n",
      "weighted avg       0.86      0.91      0.86      2993\n",
      "\n",
      "Confusion_matrix\n",
      "[[2708    6]\n",
      " [ 275    4]]\n",
      "done in 0.754909s\n",
      "0.2671673652917732\n",
      "0.2588613674873484\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2725\n",
      "           1       0.20      0.01      0.02       255\n",
      "\n",
      "    accuracy                           0.91      2980\n",
      "   macro avg       0.56      0.50      0.48      2980\n",
      "weighted avg       0.85      0.91      0.87      2980\n",
      "\n",
      "Confusion_matrix\n",
      "[[2717    8]\n",
      " [ 253    2]]\n",
      "done in 0.788709s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19931\n",
      "           1       0.41      0.02      0.04      1967\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.66      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19869    62]\n",
      " [ 1924    43]]\n",
      "done in 40.480518s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19956\n",
      "           1       0.39      0.02      0.03      1942\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.65      0.51      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19906    50]\n",
      " [ 1910    32]]\n",
      "done in 40.963774s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17217\n",
      "           1       0.39      0.02      0.04      1688\n",
      "\n",
      "    accuracy                           0.91     18905\n",
      "   macro avg       0.65      0.51      0.49     18905\n",
      "weighted avg       0.87      0.91      0.87     18905\n",
      "\n",
      "Confusion_matrix\n",
      "[[17167    50]\n",
      " [ 1656    32]]\n",
      "done in 34.585573s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17231\n",
      "           1       0.37      0.01      0.03      1687\n",
      "\n",
      "    accuracy                           0.91     18918\n",
      "   macro avg       0.64      0.51      0.49     18918\n",
      "weighted avg       0.86      0.91      0.87     18918\n",
      "\n",
      "Confusion_matrix\n",
      "[[17188    43]\n",
      " [ 1662    25]]\n",
      "done in 33.459024s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2714\n",
      "           1       0.52      0.04      0.07       279\n",
      "\n",
      "    accuracy                           0.91      2993\n",
      "   macro avg       0.72      0.52      0.51      2993\n",
      "weighted avg       0.87      0.91      0.87      2993\n",
      "\n",
      "Confusion_matrix\n",
      "[[2704   10]\n",
      " [ 268   11]]\n",
      "done in 32.510832s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2725\n",
      "           1       0.50      0.03      0.05       255\n",
      "\n",
      "    accuracy                           0.91      2980\n",
      "   macro avg       0.71      0.51      0.50      2980\n",
      "weighted avg       0.88      0.91      0.88      2980\n",
      "\n",
      "Confusion_matrix\n",
      "[[2718    7]\n",
      " [ 248    7]]\n",
      "done in 32.544116s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.2, J-value:0.26\n",
      "threshold:0.30000000000000004, J-value:0.154\n",
      "threshold:0.4, J-value:0.07200000000000001\n",
      "threshold:0.5, J-value:0.03899999999999999\n",
      "threshold:0.6000000000000001, J-value:0.009999999999999998\n",
      "threshold:0.7000000000000001, J-value:0.003\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6952195674976993\n",
      "Balanced accuracy score of test is  0.7013302592170334\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.386\n",
      "threshold:0.2, J-value:0.254\n",
      "threshold:0.30000000000000004, J-value:0.155\n",
      "threshold:0.4, J-value:0.07100000000000001\n",
      "threshold:0.5, J-value:0.036000000000000004\n",
      "threshold:0.6000000000000001, J-value:0.009999999999999998\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6930072042484186\n",
      "Balanced accuracy score of test is  0.7013550005354556\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41800000000000004\n",
      "threshold:0.2, J-value:0.29800000000000004\n",
      "threshold:0.30000000000000004, J-value:0.149\n",
      "threshold:0.4, J-value:0.073\n",
      "threshold:0.5, J-value:0.053\n",
      "threshold:0.6000000000000001, J-value:0.011\n",
      "threshold:0.7000000000000001, J-value:0.009999999999999998\n",
      "threshold:0.8, J-value:0.003\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7091286915317628\n",
      "Balanced accuracy score of test is  0.7009030401151286\n",
      "True positive rate of class 1 is  0.665\n",
      "True positive rate of class 2 is  0.651\n",
      "Positive prediction rate of class 1 is  0.298\n",
      "Positive prediction rate of class 2 is  0.284\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.381\n",
      "threshold:0.2, J-value:0.28\n",
      "threshold:0.30000000000000004, J-value:0.123\n",
      "threshold:0.4, J-value:0.028\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6902113639284816\n",
      "Balanced accuracy score of test is  0.7019641718474774\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.383\n",
      "threshold:0.2, J-value:0.279\n",
      "threshold:0.30000000000000004, J-value:0.125\n",
      "threshold:0.4, J-value:0.026\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6916117363886184\n",
      "Balanced accuracy score of test is  0.6967545879335424\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.42700000000000005\n",
      "threshold:0.2, J-value:0.337\n",
      "threshold:0.30000000000000004, J-value:0.136\n",
      "threshold:0.4, J-value:0.024\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7132339152093353\n",
      "Balanced accuracy score of test is  0.6931570426335671\n",
      "True positive rate of class 1 is  0.744\n",
      "True positive rate of class 2 is  0.741\n",
      "Positive prediction rate of class 1 is  0.386\n",
      "Positive prediction rate of class 2 is  0.388\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.35500000000000004\n",
      "threshold:0.2, J-value:0.208\n",
      "threshold:0.30000000000000004, J-value:0.094\n",
      "threshold:0.4, J-value:0.013000000000000001\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6774639792489987\n",
      "Balanced accuracy score of test is  0.6802763453438967\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.3539999999999999\n",
      "threshold:0.2, J-value:0.21\n",
      "threshold:0.30000000000000004, J-value:0.097\n",
      "threshold:0.4, J-value:0.012\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6770571396010832\n",
      "Balanced accuracy score of test is  0.6786712180459964\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.363\n",
      "threshold:0.2, J-value:0.198\n",
      "threshold:0.30000000000000004, J-value:0.07899999999999999\n",
      "threshold:0.4, J-value:0.017\n",
      "threshold:0.5, J-value:0.012\n",
      "threshold:0.6000000000000001, J-value:0.004\n",
      "threshold:0.7000000000000001, J-value:0.004\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6812928053924558\n",
      "Balanced accuracy score of test is  0.6894585357078611\n",
      "True positive rate of class 1 is  0.694\n",
      "True positive rate of class 2 is  0.643\n",
      "Positive prediction rate of class 1 is  0.368\n",
      "Positive prediction rate of class 2 is  0.297\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.395\n",
      "threshold:0.2, J-value:0.267\n",
      "threshold:0.30000000000000004, J-value:0.14\n",
      "threshold:0.4, J-value:0.063\n",
      "threshold:0.5, J-value:0.019\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6976806510167246\n",
      "Balanced accuracy score of test is  0.7074352968910593\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.38900000000000007\n",
      "threshold:0.2, J-value:0.266\n",
      "threshold:0.30000000000000004, J-value:0.14400000000000002\n",
      "threshold:0.4, J-value:0.063\n",
      "threshold:0.5, J-value:0.016\n",
      "threshold:0.6000000000000001, J-value:0.002\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6946447383234966\n",
      "Balanced accuracy score of test is  0.7071289951524142\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.43299999999999994\n",
      "threshold:0.2, J-value:0.274\n",
      "threshold:0.30000000000000004, J-value:0.11099999999999999\n",
      "threshold:0.4, J-value:0.068\n",
      "threshold:0.5, J-value:0.035\n",
      "threshold:0.6000000000000001, J-value:0.006\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7167831475186409\n",
      "Balanced accuracy score of test is  0.7086994063680518\n",
      "True positive rate of class 1 is  0.698\n",
      "True positive rate of class 2 is  0.682\n",
      "Positive prediction rate of class 1 is  0.321\n",
      "Positive prediction rate of class 2 is  0.301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lifuchen/Desktop/research/CVDPrediction-master/src/lib/fairness_tests.py:273: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train ['Class'] = y_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8852, 87)\n",
      "(56842, 87)\n",
      "0.09297444128904803 0.09886328487472935\n",
      "0.09877762686751451\n",
      "(65741, 86)\n",
      "X train 65741\n",
      "Y train 65741\n",
      "21898 18847 3051\n",
      "21898 18847 3051\n",
      "21898 18817 3081\n",
      "21898 18817 3081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2615714069393591\n",
      "0.25524203471459056\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19973\n",
      "           1       0.50      0.04      0.07      1925\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.71      0.52      0.51     21898\n",
      "weighted avg       0.88      0.91      0.88     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19901    72]\n",
      " [ 1852    73]]\n",
      "done in 0.594829s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2615714069393591\n",
      "0.26498524637218457\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19866\n",
      "           1       0.44      0.04      0.07      2032\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.52      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19775    91]\n",
      " [ 1960    72]]\n",
      "done in 0.553952s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2615714069393591\n",
      "0.2551367281798623\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17189\n",
      "           1       0.49      0.03      0.06      1658\n",
      "\n",
      "    accuracy                           0.91     18847\n",
      "   macro avg       0.70      0.51      0.51     18847\n",
      "weighted avg       0.88      0.91      0.88     18847\n",
      "\n",
      "Confusion_matrix\n",
      "[[17131    58]\n",
      " [ 1603    55]]\n",
      "done in 0.533497s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2615714069393591\n",
      "0.2658462786043097\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17067\n",
      "           1       0.44      0.03      0.06      1750\n",
      "\n",
      "    accuracy                           0.91     18817\n",
      "   macro avg       0.67      0.51      0.50     18817\n",
      "weighted avg       0.87      0.91      0.87     18817\n",
      "\n",
      "Confusion_matrix\n",
      "[[17000    67]\n",
      " [ 1698    52]]\n",
      "done in 0.565340s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2615714069393591\n",
      "0.2558925467631066\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95      2784\n",
      "           1       0.56      0.07      0.12       267\n",
      "\n",
      "    accuracy                           0.91      3051\n",
      "   macro avg       0.74      0.53      0.54      3051\n",
      "weighted avg       0.89      0.91      0.88      3051\n",
      "\n",
      "Confusion_matrix\n",
      "[[2770   14]\n",
      " [ 249   18]]\n",
      "done in 0.578154s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2615714069393591\n",
      "0.2597265500035059\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95      2799\n",
      "           1       0.45      0.07      0.12       282\n",
      "\n",
      "    accuracy                           0.91      3081\n",
      "   macro avg       0.68      0.53      0.54      3081\n",
      "weighted avg       0.87      0.91      0.88      3081\n",
      "\n",
      "Confusion_matrix\n",
      "[[2775   24]\n",
      " [ 262   20]]\n",
      "done in 0.525899s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19973\n",
      "           1       0.38      0.00      0.01      1925\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.65      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19965     8]\n",
      " [ 1920     5]]\n",
      "done in 19.015445s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19866\n",
      "           1       0.77      0.00      0.01      2032\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.84      0.50      0.48     21898\n",
      "weighted avg       0.89      0.91      0.86     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19863     3]\n",
      " [ 2022    10]]\n",
      "done in 18.653084s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17189\n",
      "           1       0.55      0.00      0.01      1658\n",
      "\n",
      "    accuracy                           0.91     18847\n",
      "   macro avg       0.73      0.50      0.48     18847\n",
      "weighted avg       0.88      0.91      0.87     18847\n",
      "\n",
      "Confusion_matrix\n",
      "[[17184     5]\n",
      " [ 1652     6]]\n",
      "done in 18.685979s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17067\n",
      "           1       0.50      0.00      0.01      1750\n",
      "\n",
      "    accuracy                           0.91     18817\n",
      "   macro avg       0.70      0.50      0.48     18817\n",
      "weighted avg       0.87      0.91      0.86     18817\n",
      "\n",
      "Confusion_matrix\n",
      "[[17061     6]\n",
      " [ 1744     6]]\n",
      "done in 18.652258s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2784\n",
      "           1       0.50      0.00      0.01       267\n",
      "\n",
      "    accuracy                           0.91      3051\n",
      "   macro avg       0.71      0.50      0.48      3051\n",
      "weighted avg       0.88      0.91      0.87      3051\n",
      "\n",
      "Confusion_matrix\n",
      "[[2783    1]\n",
      " [ 266    1]]\n",
      "done in 18.570741s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2799\n",
      "           1       1.00      0.00      0.01       282\n",
      "\n",
      "    accuracy                           0.91      3081\n",
      "   macro avg       0.95      0.50      0.48      3081\n",
      "weighted avg       0.92      0.91      0.87      3081\n",
      "\n",
      "Confusion_matrix\n",
      "[[2799    0]\n",
      " [ 281    1]]\n",
      "done in 18.281090s\n",
      "0.26679099373980447\n",
      "0.26982445686404216\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19973\n",
      "           1       0.00      0.00      0.00      1925\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.46      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19960    13]\n",
      " [ 1925     0]]\n",
      "done in 0.600053s\n",
      "0.26679099373980447\n",
      "0.2780127324258221\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19866\n",
      "           1       0.08      0.00      0.00      2032\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.49      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.86     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19854    12]\n",
      " [ 2031     1]]\n",
      "done in 0.600646s\n",
      "0.26679099373980447\n",
      "0.2693652831341641\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17189\n",
      "           1       0.00      0.00      0.00      1658\n",
      "\n",
      "    accuracy                           0.91     18847\n",
      "   macro avg       0.46      0.50      0.48     18847\n",
      "weighted avg       0.83      0.91      0.87     18847\n",
      "\n",
      "Confusion_matrix\n",
      "[[17180     9]\n",
      " [ 1658     0]]\n",
      "done in 0.595242s\n",
      "0.26679099373980447\n",
      "0.27981782081011625\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17067\n",
      "           1       0.09      0.00      0.00      1750\n",
      "\n",
      "    accuracy                           0.91     18817\n",
      "   macro avg       0.50      0.50      0.48     18817\n",
      "weighted avg       0.83      0.91      0.86     18817\n",
      "\n",
      "Confusion_matrix\n",
      "[[17057    10]\n",
      " [ 1749     1]]\n",
      "done in 0.592852s\n",
      "0.26679099373980447\n",
      "0.27266091942943455\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2784\n",
      "           1       0.00      0.00      0.00       267\n",
      "\n",
      "    accuracy                           0.91      3051\n",
      "   macro avg       0.46      0.50      0.48      3051\n",
      "weighted avg       0.83      0.91      0.87      3051\n",
      "\n",
      "Confusion_matrix\n",
      "[[2780    4]\n",
      " [ 267    0]]\n",
      "done in 0.567644s\n",
      "0.26679099373980447\n",
      "0.26761986063802357\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2799\n",
      "           1       0.00      0.00      0.00       282\n",
      "\n",
      "    accuracy                           0.91      3081\n",
      "   macro avg       0.45      0.50      0.48      3081\n",
      "weighted avg       0.83      0.91      0.86      3081\n",
      "\n",
      "Confusion_matrix\n",
      "[[2796    3]\n",
      " [ 282    0]]\n",
      "done in 0.570646s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19973\n",
      "           1       0.54      0.02      0.04      1925\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.73      0.51      0.50     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19942    31]\n",
      " [ 1888    37]]\n",
      "done in 32.296140s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19866\n",
      "           1       0.45      0.02      0.03      2032\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.51      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19822    44]\n",
      " [ 1996    36]]\n",
      "done in 32.291229s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17189\n",
      "           1       0.54      0.02      0.03      1658\n",
      "\n",
      "    accuracy                           0.91     18847\n",
      "   macro avg       0.73      0.51      0.49     18847\n",
      "weighted avg       0.88      0.91      0.87     18847\n",
      "\n",
      "Confusion_matrix\n",
      "[[17164    25]\n",
      " [ 1629    29]]\n",
      "done in 32.242990s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17067\n",
      "           1       0.46      0.02      0.03      1750\n",
      "\n",
      "    accuracy                           0.91     18817\n",
      "   macro avg       0.68      0.51      0.49     18817\n",
      "weighted avg       0.87      0.91      0.87     18817\n",
      "\n",
      "Confusion_matrix\n",
      "[[17033    34]\n",
      " [ 1721    29]]\n",
      "done in 30.826463s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2784\n",
      "           1       0.62      0.03      0.06       267\n",
      "\n",
      "    accuracy                           0.91      3051\n",
      "   macro avg       0.77      0.51      0.51      3051\n",
      "weighted avg       0.89      0.91      0.88      3051\n",
      "\n",
      "Confusion_matrix\n",
      "[[2779    5]\n",
      " [ 259    8]]\n",
      "done in 29.668876s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2799\n",
      "           1       0.41      0.02      0.05       282\n",
      "\n",
      "    accuracy                           0.91      3081\n",
      "   macro avg       0.66      0.51      0.50      3081\n",
      "weighted avg       0.86      0.91      0.87      3081\n",
      "\n",
      "Confusion_matrix\n",
      "[[2789   10]\n",
      " [ 275    7]]\n",
      "done in 29.744445s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.404\n",
      "threshold:0.2, J-value:0.26399999999999996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.30000000000000004, J-value:0.16\n",
      "threshold:0.4, J-value:0.079\n",
      "threshold:0.5, J-value:0.034\n",
      "threshold:0.6000000000000001, J-value:0.012\n",
      "threshold:0.7000000000000001, J-value:0.004\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.70201313331439\n",
      "Balanced accuracy score of test is  0.7067917052123242\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.403\n",
      "threshold:0.2, J-value:0.26\n",
      "threshold:0.30000000000000004, J-value:0.155\n",
      "threshold:0.4, J-value:0.076\n",
      "threshold:0.5, J-value:0.030000000000000002\n",
      "threshold:0.6000000000000001, J-value:0.013000000000000001\n",
      "threshold:0.7000000000000001, J-value:0.004\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7017581305855198\n",
      "Balanced accuracy score of test is  0.7062684210966861\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.40700000000000003\n",
      "threshold:0.2, J-value:0.28800000000000003\n",
      "threshold:0.30000000000000004, J-value:0.19\n",
      "threshold:0.4, J-value:0.106\n",
      "threshold:0.5, J-value:0.062000000000000006\n",
      "threshold:0.6000000000000001, J-value:0.006\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7035124467260752\n",
      "Balanced accuracy score of test is  0.7100351189254521\n",
      "True positive rate of class 1 is  0.67\n",
      "True positive rate of class 2 is  0.677\n",
      "Positive prediction rate of class 1 is  0.296\n",
      "Positive prediction rate of class 2 is  0.296\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.406\n",
      "threshold:0.2, J-value:0.28900000000000003\n",
      "threshold:0.30000000000000004, J-value:0.11400000000000002\n",
      "threshold:0.4, J-value:0.024\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7031705529737873\n",
      "Balanced accuracy score of test is  0.6993149376412515\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.401\n",
      "threshold:0.2, J-value:0.28700000000000003\n",
      "threshold:0.30000000000000004, J-value:0.10700000000000001\n",
      "threshold:0.4, J-value:0.019\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7005469455772377\n",
      "Balanced accuracy score of test is  0.7000530514191966\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.418\n",
      "threshold:0.2, J-value:0.293\n",
      "threshold:0.30000000000000004, J-value:0.10200000000000001\n",
      "threshold:0.4, J-value:0.016999999999999998\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7088398392096087\n",
      "Balanced accuracy score of test is  0.7162322409979248\n",
      "True positive rate of class 1 is  0.747\n",
      "True positive rate of class 2 is  0.787\n",
      "Positive prediction rate of class 1 is  0.384\n",
      "Positive prediction rate of class 2 is  0.394\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.36899999999999994\n",
      "threshold:0.2, J-value:0.192\n",
      "threshold:0.30000000000000004, J-value:0.08\n",
      "threshold:0.4, J-value:-0.001\n",
      "threshold:0.5, J-value:-0.001\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6844875907149977\n",
      "Balanced accuracy score of test is  0.6794513149519101\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.373\n",
      "threshold:0.2, J-value:0.194\n",
      "threshold:0.30000000000000004, J-value:0.086\n",
      "threshold:0.4, J-value:-0.001\n",
      "threshold:0.5, J-value:-0.001\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6865020697656319\n",
      "Balanced accuracy score of test is  0.6777896860273376\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.34299999999999997\n",
      "threshold:0.2, J-value:0.177\n",
      "threshold:0.30000000000000004, J-value:0.047\n",
      "threshold:0.4, J-value:-0.001\n",
      "threshold:0.5, J-value:-0.001\n",
      "threshold:0.6000000000000001, J-value:-0.001\n",
      "threshold:0.7000000000000001, J-value:-0.001\n",
      "threshold:0.8, J-value:-0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6717519049464031\n",
      "Balanced accuracy score of test is  0.689035977894841\n",
      "True positive rate of class 1 is  0.705\n",
      "True positive rate of class 2 is  0.656\n",
      "Positive prediction rate of class 1 is  0.383\n",
      "Positive prediction rate of class 2 is  0.313\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.4139999999999999\n",
      "threshold:0.2, J-value:0.26699999999999996\n",
      "threshold:0.30000000000000004, J-value:0.14\n",
      "threshold:0.4, J-value:0.052\n",
      "threshold:0.5, J-value:0.017\n",
      "threshold:0.6000000000000001, J-value:0.004\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7072022945261818\n",
      "Balanced accuracy score of test is  0.708347849885572\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.415\n",
      "threshold:0.2, J-value:0.26599999999999996\n",
      "threshold:0.30000000000000004, J-value:0.14\n",
      "threshold:0.4, J-value:0.049\n",
      "threshold:0.5, J-value:0.016\n",
      "threshold:0.6000000000000001, J-value:0.004\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7074576090510377\n",
      "Balanced accuracy score of test is  0.7082276406431793\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41100000000000003\n",
      "threshold:0.2, J-value:0.27399999999999997\n",
      "threshold:0.30000000000000004, J-value:0.143\n",
      "threshold:0.4, J-value:0.065\n",
      "threshold:0.5, J-value:0.027999999999999997\n",
      "threshold:0.6000000000000001, J-value:0.004\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7055122368590986\n",
      "Balanced accuracy score of test is  0.7091286401678412\n",
      "True positive rate of class 1 is  0.698\n",
      "True positive rate of class 2 is  0.681\n",
      "Positive prediction rate of class 1 is  0.321\n",
      "Positive prediction rate of class 2 is  0.301\n"
     ]
    }
   ],
   "source": [
    "records_lr = []\n",
    "records_rf = []\n",
    "records_dt = []\n",
    "records_gbt = []\n",
    "for random_state in range(10):\n",
    "    fairness_metrics (X, y, \"Race_W\", random_state)\n",
    "\n",
    "result_lr = pd.DataFrame(records_lr)\n",
    "result_rf = pd.DataFrame(records_rf)\n",
    "result_dt = pd.DataFrame(records_dt)\n",
    "result_gbt = pd.DataFrame(records_gbt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def add_mean_sd(records, result_table, overall_records, type):\n",
    "    records.append({\n",
    "        'auroc': result_table[\"auroc\"].mean(),\n",
    "        'overall threshold': result_table[\"overall threshold\"].mean(),\n",
    "        'white threshold': result_table[\"white threshold\"].mean(),\n",
    "        'black threshold': result_table[\"black threshold\"].mean(),\n",
    "        'overall ba validation': result_table[\"overall ba validation\"].mean(),\n",
    "        'overall ba test': result_table[\"overall ba test\"].mean(),\n",
    "        'white ba validation': result_table[\"white ba validation\"].mean(),\n",
    "        'white ba test': result_table[\"white ba test\"].mean(),\n",
    "        'black ba validation': result_table[\"black ba validation\"].mean(),\n",
    "        'black ba test': result_table[\"black ba test\"].mean(),\n",
    "        'overall precision':result_table[\"overall precision\"].mean(),\n",
    "        'overall recall':result_table[\"overall recall\"].mean(),\n",
    "        'overall tpr':result_table[\"overall tpr\"].mean(),\n",
    "        'overall tnr':result_table[\"overall tnr\"].mean(),\n",
    "        'overall pd':result_table[\"overall pd\"].mean(),\n",
    "        'white precision':result_table[\"white precision\"].mean(),\n",
    "        'white recall':result_table[\"white recall\"].mean(),\n",
    "        'white tpr':result_table[\"white tpr\"].mean(),\n",
    "        'white tnr':result_table[\"white tnr\"].mean(),\n",
    "        'white pd':result_table[\"white pd\"].mean(),\n",
    "        'black precision':result_table[\"black precision\"].mean(),\n",
    "        'black recall':result_table[\"black recall\"].mean(),\n",
    "        'black tpr':result_table[\"black tpr\"].mean(),\n",
    "        'black tnr':result_table[\"black tnr\"].mean(),\n",
    "        'black pd':result_table[\"black pd\"].mean(),\n",
    "        'eod': result_table[\"eod\"].mean(),\n",
    "        'di': result_table[\"di\"].mean(),\n",
    "        })\n",
    "    records.append({\n",
    "        'auroc': result_table[\"auroc\"].std(),\n",
    "        'overall threshold': result_table[\"overall threshold\"].std(),\n",
    "        'white threshold': result_table[\"white threshold\"].std(),\n",
    "        'black threshold': result_table[\"black threshold\"].std(),\n",
    "        'overall ba validation': result_table[\"overall ba validation\"].std(),\n",
    "        'overall ba test': result_table[\"overall ba test\"].std(),\n",
    "        'white ba validation': result_table[\"white ba validation\"].std(),\n",
    "        'white ba test': result_table[\"white ba test\"].std(),\n",
    "        'black ba validation': result_table[\"black ba validation\"].std(),\n",
    "        'black ba test': result_table[\"black ba test\"].std(),\n",
    "        'overall precision':result_table[\"overall precision\"].std(),\n",
    "        'overall recall':result_table[\"overall recall\"].std(),\n",
    "        'overall tpr':result_table[\"overall tpr\"].std(),\n",
    "        'overall tnr':result_table[\"overall tnr\"].std(),\n",
    "        'overall pd':result_table[\"overall pd\"].std(),\n",
    "        'white precision':result_table[\"white precision\"].std(),\n",
    "        'white recall':result_table[\"white recall\"].std(),\n",
    "        'white tpr':result_table[\"white tpr\"].std(),\n",
    "        'white tnr':result_table[\"white tnr\"].std(),\n",
    "        'white pd':result_table[\"white pd\"].std(),\n",
    "        'black precision':result_table[\"black precision\"].std(),\n",
    "        'black recall':result_table[\"black recall\"].std(),\n",
    "        'black tpr':result_table[\"black tpr\"].std(),\n",
    "        'black tnr':result_table[\"black tnr\"].std(),\n",
    "        'black pd':result_table[\"black pd\"].std(),\n",
    "        'eod': result_table[\"eod\"].std(),\n",
    "        'di': result_table[\"di\"].std(),\n",
    "        })\n",
    "    overall_records.append({\n",
    "        'type': type,\n",
    "        'auroc': result_table[\"auroc\"].mean(),\n",
    "        'overall threshold': result_table[\"overall threshold\"].mean(),\n",
    "        'white threshold': result_table[\"white threshold\"].mean(),\n",
    "        'black threshold': result_table[\"black threshold\"].mean(),\n",
    "        'overall ba test': result_table[\"overall ba test\"].mean(),\n",
    "        'white ba test': result_table[\"white ba test\"].mean(),\n",
    "        'black ba test': result_table[\"black ba test\"].mean(),\n",
    "        'overall tpr':result_table[\"overall tpr\"].mean(),\n",
    "        'overall pd':result_table[\"overall pd\"].mean(),\n",
    "        'white tpr':result_table[\"white tpr\"].mean(),\n",
    "        'white pd':result_table[\"white pd\"].mean(),\n",
    "        'black tpr':result_table[\"black tpr\"].mean(),\n",
    "        'black pd':result_table[\"black pd\"].mean(),\n",
    "        'eod': result_table[\"eod\"].mean(),\n",
    "        'di': result_table[\"di\"].mean(),\n",
    "        })\n",
    "    pd_result = pd.DataFrame(records)\n",
    "    return pd_result, overall_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "overall_table = []\n",
    "result_lr, overall_records = add_mean_sd (records_lr, result_lr, overall_table, 'lr')\n",
    "result_rf, overall_records = add_mean_sd (records_rf, result_rf, overall_records, 'rf')\n",
    "result_dt, overall_records = add_mean_sd (records_dt, result_dt, overall_records, 'dt')\n",
    "result_gbt, overall_records = add_mean_sd (records_gbt, result_gbt, overall_records, 'gbt')\n",
    "\n",
    "result_path='/Users/lifuchen/Desktop/research/resample_data/'\n",
    "result_lr.to_csv(path.join(result_path,'race-lr-resample-proportion-result.csv'), index=False)\n",
    "result_rf.to_csv(path.join(result_path,'race-rf-resample-proportion-result.csv'), index=False)\n",
    "result_dt.to_csv(path.join(result_path,'race-dt-resample-proportion-result.csv'), index=False)\n",
    "result_gbt.to_csv(path.join(result_path,'race-gbt-resample-proportion-result.csv'), index=False)\n",
    "\n",
    "overall_result = pd.DataFrame(overall_table)\n",
    "result_path='/Users/lifuchen/Desktop/research/resample_result/'\n",
    "overall_result.to_csv(path.join(result_path,'race-resample-proportion.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
