{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from os import path\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score\n",
    "import sklearn.preprocessing\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import src.lib.utility_classfier as uclf\n",
    "import src.lib.optimal_threhold_related as thres\n",
    "import src.lib.fairness_tests as fair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_path='/Users/lifuchen/Desktop/research/data.csv'\n",
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109490, 87)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df.Class.values\n",
    "X = df.drop(['GRID','Class'], axis=1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def save_prediction(classifier, characteristic, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_male_scaled, y_val_male, X_test_male_scaled, y_test_male, X_val_female_scaled, y_val_female, X_test_female_scaled, y_test_female):\n",
    "    method_to_call = getattr(uclf, classifier)\n",
    "    y_val_score = method_to_call(X_train_scaled, y_train,X_val_scaled, y_val)\n",
    "    y_test_score = method_to_call(X_train_scaled, y_train,X_test_scaled, y_test)\n",
    "\n",
    "    y_val_score_male = method_to_call(X_train_scaled, y_train, X_val_male_scaled, y_val_male)\n",
    "    y_test_score_male = method_to_call(X_train_scaled, y_train,X_test_male_scaled, y_test_male)\n",
    "\n",
    "    y_val_score_female = method_to_call(X_train_scaled, y_train, X_val_female_scaled, y_val_female)\n",
    "    y_test_score_female = method_to_call(X_train_scaled, y_train,X_test_female_scaled, y_test_female)\n",
    "\n",
    "    my_dict = dict(val_score = y_val_score, test_score = y_test_score, val_1_score = y_val_score_male, test_1_score = y_test_score_male, val_2_score = y_val_score_female, test_2_score = y_test_score_female)\n",
    "    overall_prediction = pd.DataFrame.from_dict(my_dict, orient='index')\n",
    "    overall_prediction = overall_prediction.transpose()\n",
    "\n",
    "    result_path='/Users/lifuchen/Desktop/research/predictions/'\n",
    "    filename = str(classifier) + str(characteristic) + \"prediction.csv\"\n",
    "    overall_prediction.to_csv(path.join(result_path, filename), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_result (classifier,characteristic, records, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_male_scaled, y_val_male, X_test_male_scaled, y_test_male, X_val_female_scaled, y_val_female, X_test_female_scaled, y_test_female):\n",
    "    result_path='/Users/lifuchen/Desktop/research/predictions/'\n",
    "    filename = str(classifier) + characteristic + \"prediction.csv\"\n",
    "    prediction = pd.read_csv(path.join(result_path, filename))\n",
    "    \n",
    "    y_val_score = prediction['val_score'][prediction['val_score'].notna()]\n",
    "    y_test_score = prediction['test_score'][prediction['test_score'].notna()]\n",
    "    \n",
    "    y_val_score_male = prediction['val_1_score'][prediction['val_1_score'].notna()]\n",
    "    y_test_score_male = prediction['test_1_score'][prediction['test_1_score'].notna()]\n",
    "    \n",
    "    y_val_score_female = prediction['val_2_score'][prediction['val_2_score'].notna()]\n",
    "    y_test_score_female = prediction['test_2_score'][prediction['test_2_score'].notna()]\n",
    "    \n",
    "    threshold, ba_val, ba_test = balance_accuracy (y_val, y_val_score,y_test, y_test_score)\n",
    "    auroc = roc_auc_score(y_test, y_test_score)\n",
    "    precision, recall, tpr, tnr, pd_overall = thres.calculate_precision_metrics(y_test, y_test_score,threshold)\n",
    "    \n",
    "    threshold_male, ba_val_male, ba_test_male = balance_accuracy (y_val_male, y_val_score_male,y_test_male, y_test_score_male)\n",
    "    precision_male, recall_male, tpr_male, tnr_male, pd_male = thres.calculate_precision_metrics(y_test_male, y_test_score_male,threshold_male)\n",
    "    \n",
    "    threshold_female, ba_val_female, ba_test_female = balance_accuracy (y_val_female, y_val_score_female, y_test_female, y_test_score_female)\n",
    "    precision_female, recall_female, tpr_female, tnr_female, pd_female = thres.calculate_precision_metrics(y_test_female, y_test_score_female,threshold_female)\n",
    "\n",
    "    eod = fair.get_EOD(y_test_male, y_test_score_male,threshold_male, y_test_female, y_test_score_female, threshold_female)\n",
    "    sp = fair.get_SP(y_test_male, y_test_score_male,threshold_male, y_test_female, y_test_score_female, threshold_female)\n",
    "\n",
    "    records.append({\n",
    "        'auroc': auroc,\n",
    "        'overall threshold': threshold,\n",
    "        'male threshold': threshold_male,\n",
    "        'female threshold': threshold_female,\n",
    "        'overall ba validation': ba_val,\n",
    "        'overall ba test': ba_test,\n",
    "        'male ba validation': ba_val_male,\n",
    "        'male ba test': ba_test_male,\n",
    "        'female ba validation': ba_val_female,\n",
    "        'female ba test': ba_test_female,\n",
    "        'overall precision':precision,\n",
    "        'overall recall':recall,\n",
    "        'overall tpr':tpr,\n",
    "        'overall tnr':tnr,\n",
    "        'overall pd':pd_overall,\n",
    "        'male precision':precision_male,\n",
    "        'male recall':recall_male,\n",
    "        'male tpr':tpr_male,\n",
    "        'male tnr':tnr_male,\n",
    "        'male pd':pd_male,\n",
    "        'female precision':precision_female,\n",
    "        'female recall':recall_female,\n",
    "        'female tpr':tpr_female,\n",
    "        'female tnr':tnr_female,\n",
    "        'female pd':pd_female,\n",
    "        'eod': eod,\n",
    "        'di': sp,\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def balance_accuracy (y_val, y_val_score,y_test, y_test_score):\n",
    "    \n",
    "    threshold, _ = thres.get_optimal_threshold_Jvalue (y_val, y_val_score)\n",
    "    print (\"Optimal threshold by J value is \",threshold)\n",
    "\n",
    "    ba_val = thres.calculate_balanced_accuracy(y_val, y_val_score, threshold)\n",
    "    print (\"Balanced accuracy score of val is \", ba_val)\n",
    "\n",
    "    ba_test = thres.calculate_balanced_accuracy(y_test, y_test_score, threshold)\n",
    "    print (\"Balanced accuracy score of test is \",ba_test)\n",
    "\n",
    "    return threshold, ba_val, ba_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def fairness_metrics (X, y, attribute, random_state):\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, X_val_female, X_val_male, y_val_female, y_val_male, X_test_female, X_test_male, y_test_female, y_test_male \\\n",
    "        = fair.split_by_trait_no_protected_trait(X, y, attribute, random_state)\n",
    "    print(\"X train\", X_train.shape[0])\n",
    "    print(\"Y train\", y_train.shape[0])\n",
    "    print(X_val.shape[0], X_val_male.shape[0], X_val_female.shape[0])\n",
    "    print(y_val.shape[0], y_val_male.shape[0], y_val_female.shape[0])\n",
    "    print(X_test.shape[0], X_test_male.shape[0], X_test_female.shape[0])\n",
    "    print(y_test.shape[0], y_test_male.shape[0], y_test_female.shape[0])\n",
    "\n",
    "    max_abs_scaler = preprocessing.MaxAbsScaler()\n",
    "    X_train_scaled = max_abs_scaler.fit_transform(X_train)\n",
    "    X_test_scaled = max_abs_scaler.transform(X_test)\n",
    "    X_test_male_scaled = max_abs_scaler.transform(X_test_male)\n",
    "    X_test_female_scaled = max_abs_scaler.transform(X_test_female)\n",
    "    X_val_scaled = max_abs_scaler.transform(X_val)\n",
    "    X_val_male_scaled = max_abs_scaler.transform(X_val_male)\n",
    "    X_val_female_scaled = max_abs_scaler.transform(X_val_female)\n",
    "\n",
    "    characteristic = attribute + str(random_state)\n",
    "    save_prediction (\"logic_regression\", characteristic, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_male_scaled, y_val_male, X_test_male_scaled, y_test_male, X_val_female_scaled, y_val_female, X_test_female_scaled, y_test_female)\n",
    "    save_prediction (\"random_forest\", characteristic, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_male_scaled, y_val_male, X_test_male_scaled, y_test_male, X_val_female_scaled, y_val_female, X_test_female_scaled, y_test_female)\n",
    "    save_prediction (\"decision_tree\", characteristic, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_male_scaled, y_val_male, X_test_male_scaled, y_test_male, X_val_female_scaled, y_val_female, X_test_female_scaled, y_test_female)\n",
    "    save_prediction (\"gradiant_boosting\", characteristic, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_male_scaled, y_val_male, X_test_male_scaled, y_test_male, X_val_female_scaled, y_val_female, X_test_female_scaled, y_test_female)\n",
    "\n",
    "    get_result (\"logic_regression\", characteristic, records_lr, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_male_scaled, y_val_male, X_test_male_scaled, y_test_male, X_val_female_scaled, y_val_female, X_test_female_scaled, y_test_female)\n",
    "    get_result (\"random_forest\", characteristic, records_rf, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_male_scaled, y_val_male, X_test_male_scaled, y_test_male, X_val_female_scaled, y_val_female, X_test_female_scaled, y_test_female)\n",
    "    get_result (\"decision_tree\", characteristic, records_dt, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_male_scaled, y_val_male, X_test_male_scaled, y_test_male, X_val_female_scaled, y_val_female, X_test_female_scaled, y_test_female)\n",
    "    get_result (\"gradiant_boosting\", characteristic, records_gbt, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_male_scaled, y_val_male, X_test_male_scaled, y_test_male, X_val_female_scaled, y_val_female, X_test_female_scaled, y_test_female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train 65694\n",
      "Y train 65694\n",
      "21898 7708 14190\n",
      "21898 7708 14190\n",
      "21898 7848 14050\n",
      "21898 7848 14050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25979173317983345\n",
      "0.2582836446542785\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.95     19981\n",
      "           1       0.45      0.04      0.07      1917\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.52      0.51     21898\n",
      "weighted avg       0.87      0.91      0.88     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19886    95]\n",
      " [ 1840    77]]\n",
      "done in 0.494612s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25979173317983345\n",
      "0.2628890215802185\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95     19906\n",
      "           1       0.37      0.03      0.06      1992\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.64      0.51      0.50     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19804   102]\n",
      " [ 1931    61]]\n",
      "done in 0.502770s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25979173317983345\n",
      "0.30391815106978515\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94      6872\n",
      "           1       0.44      0.04      0.08       836\n",
      "\n",
      "    accuracy                           0.89      7708\n",
      "   macro avg       0.67      0.52      0.51      7708\n",
      "weighted avg       0.85      0.89      0.85      7708\n",
      "\n",
      "Confusion_matrix\n",
      "[[6825   47]\n",
      " [ 799   37]]\n",
      "done in 0.512443s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25979173317983345\n",
      "0.31056735187449014\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94      6955\n",
      "           1       0.31      0.02      0.05       893\n",
      "\n",
      "    accuracy                           0.88      7848\n",
      "   macro avg       0.60      0.51      0.49      7848\n",
      "weighted avg       0.82      0.88      0.84      7848\n",
      "\n",
      "Confusion_matrix\n",
      "[[6907   48]\n",
      " [ 871   22]]\n",
      "done in 0.488048s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25979173317983345\n",
      "0.2334950064970745\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96     13109\n",
      "           1       0.45      0.04      0.07      1081\n",
      "\n",
      "    accuracy                           0.92     14190\n",
      "   macro avg       0.69      0.52      0.51     14190\n",
      "weighted avg       0.89      0.92      0.89     14190\n",
      "\n",
      "Confusion_matrix\n",
      "[[13061    48]\n",
      " [ 1041    40]]\n",
      "done in 0.497878s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25979173317983345\n",
      "0.23625702612474198\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12951\n",
      "           1       0.42      0.04      0.07      1099\n",
      "\n",
      "    accuracy                           0.92     14050\n",
      "   macro avg       0.67      0.52      0.51     14050\n",
      "weighted avg       0.88      0.92      0.89     14050\n",
      "\n",
      "Confusion_matrix\n",
      "[[12897    54]\n",
      " [ 1060    39]]\n",
      "done in 0.481361s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19981\n",
      "           1       0.43      0.00      0.01      1917\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19969    12]\n",
      " [ 1908     9]]\n",
      "done in 18.560004s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19906\n",
      "           1       0.32      0.00      0.01      1992\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.61      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19891    15]\n",
      " [ 1985     7]]\n",
      "done in 32.150481s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6872\n",
      "           1       0.40      0.00      0.01       836\n",
      "\n",
      "    accuracy                           0.89      7708\n",
      "   macro avg       0.65      0.50      0.48      7708\n",
      "weighted avg       0.84      0.89      0.84      7708\n",
      "\n",
      "Confusion_matrix\n",
      "[[6866    6]\n",
      " [ 832    4]]\n",
      "done in 16.780455s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6955\n",
      "           1       0.11      0.00      0.00       893\n",
      "\n",
      "    accuracy                           0.89      7848\n",
      "   macro avg       0.50      0.50      0.47      7848\n",
      "weighted avg       0.80      0.89      0.83      7848\n",
      "\n",
      "Confusion_matrix\n",
      "[[6947    8]\n",
      " [ 892    1]]\n",
      "done in 16.372259s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13109\n",
      "           1       0.33      0.00      0.01      1081\n",
      "\n",
      "    accuracy                           0.92     14190\n",
      "   macro avg       0.63      0.50      0.48     14190\n",
      "weighted avg       0.88      0.92      0.89     14190\n",
      "\n",
      "Confusion_matrix\n",
      "[[13101     8]\n",
      " [ 1077     4]]\n",
      "done in 17.023232s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12951\n",
      "           1       0.57      0.01      0.01      1099\n",
      "\n",
      "    accuracy                           0.92     14050\n",
      "   macro avg       0.75      0.50      0.49     14050\n",
      "weighted avg       0.89      0.92      0.89     14050\n",
      "\n",
      "Confusion_matrix\n",
      "[[12945     6]\n",
      " [ 1091     8]]\n",
      "done in 16.844939s\n",
      "0.2654152750506658\n",
      "0.2658912800375855\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19981\n",
      "           1       0.37      0.01      0.02      1917\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.64      0.50      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19943    38]\n",
      " [ 1895    22]]\n",
      "done in 0.551571s\n",
      "0.2654152750506658\n",
      "0.2762132573993715\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19906\n",
      "           1       0.38      0.01      0.02      1992\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.65      0.50      0.49     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19869    37]\n",
      " [ 1969    23]]\n",
      "done in 0.553097s\n",
      "0.2654152750506658\n",
      "0.31154855624478395\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6872\n",
      "           1       0.48      0.01      0.03       836\n",
      "\n",
      "    accuracy                           0.89      7708\n",
      "   macro avg       0.69      0.51      0.48      7708\n",
      "weighted avg       0.85      0.89      0.84      7708\n",
      "\n",
      "Confusion_matrix\n",
      "[[6860   12]\n",
      " [ 825   11]]\n",
      "done in 0.526044s\n",
      "0.2654152750506658\n",
      "0.32744607078778254\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6955\n",
      "           1       0.43      0.01      0.02       893\n",
      "\n",
      "    accuracy                           0.89      7848\n",
      "   macro avg       0.66      0.50      0.48      7848\n",
      "weighted avg       0.84      0.89      0.83      7848\n",
      "\n",
      "Confusion_matrix\n",
      "[[6942   13]\n",
      " [ 883   10]]\n",
      "done in 0.523886s\n",
      "0.2654152750506658\n",
      "0.2410902733423716\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13109\n",
      "           1       0.30      0.01      0.02      1081\n",
      "\n",
      "    accuracy                           0.92     14190\n",
      "   macro avg       0.61      0.50      0.49     14190\n",
      "weighted avg       0.88      0.92      0.89     14190\n",
      "\n",
      "Confusion_matrix\n",
      "[[13083    26]\n",
      " [ 1070    11]]\n",
      "done in 0.528134s\n",
      "0.2654152750506658\n",
      "0.2475958111735886\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12951\n",
      "           1       0.35      0.01      0.02      1099\n",
      "\n",
      "    accuracy                           0.92     14050\n",
      "   macro avg       0.64      0.50      0.49     14050\n",
      "weighted avg       0.88      0.92      0.89     14050\n",
      "\n",
      "Confusion_matrix\n",
      "[[12927    24]\n",
      " [ 1086    13]]\n",
      "done in 0.532399s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19981\n",
      "           1       0.46      0.03      0.05      1917\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.69      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.88     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19916    65]\n",
      " [ 1862    55]]\n",
      "done in 29.438819s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19906\n",
      "           1       0.37      0.02      0.04      1992\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.64      0.51      0.49     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19837    69]\n",
      " [ 1952    40]]\n",
      "done in 30.522562s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6872\n",
      "           1       0.52      0.04      0.07       836\n",
      "\n",
      "    accuracy                           0.89      7708\n",
      "   macro avg       0.71      0.52      0.51      7708\n",
      "weighted avg       0.85      0.89      0.85      7708\n",
      "\n",
      "Confusion_matrix\n",
      "[[6843   29]\n",
      " [ 805   31]]\n",
      "done in 30.502047s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6955\n",
      "           1       0.19      0.01      0.02       893\n",
      "\n",
      "    accuracy                           0.88      7848\n",
      "   macro avg       0.54      0.50      0.48      7848\n",
      "weighted avg       0.81      0.88      0.83      7848\n",
      "\n",
      "Confusion_matrix\n",
      "[[6921   34]\n",
      " [ 885    8]]\n",
      "done in 30.403601s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96     13109\n",
      "           1       0.41      0.02      0.04      1081\n",
      "\n",
      "    accuracy                           0.92     14190\n",
      "   macro avg       0.67      0.51      0.50     14190\n",
      "weighted avg       0.89      0.92      0.89     14190\n",
      "\n",
      "Confusion_matrix\n",
      "[[13073    36]\n",
      " [ 1056    25]]\n",
      "done in 30.332785s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12951\n",
      "           1       0.48      0.03      0.05      1099\n",
      "\n",
      "    accuracy                           0.92     14050\n",
      "   macro avg       0.70      0.51      0.51     14050\n",
      "weighted avg       0.89      0.92      0.89     14050\n",
      "\n",
      "Confusion_matrix\n",
      "[[12916    35]\n",
      " [ 1067    32]]\n",
      "done in 30.669731s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.39\n",
      "threshold:0.2, J-value:0.256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.30000000000000004, J-value:0.138\n",
      "threshold:0.4, J-value:0.077\n",
      "threshold:0.5, J-value:0.035\n",
      "threshold:0.6000000000000001, J-value:0.009999999999999998\n",
      "threshold:0.7000000000000001, J-value:0.004\n",
      "threshold:0.8, J-value:0.002\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6946727847375715\n",
      "Balanced accuracy score of test is  0.7054334337248522\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.37099999999999994\n",
      "threshold:0.2, J-value:0.261\n",
      "threshold:0.30000000000000004, J-value:0.15300000000000002\n",
      "threshold:0.4, J-value:0.082\n",
      "threshold:0.5, J-value:0.037\n",
      "threshold:0.6000000000000001, J-value:0.009\n",
      "threshold:0.7000000000000001, J-value:0.006\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6855337657563318\n",
      "Balanced accuracy score of test is  0.693209667330294\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.384\n",
      "threshold:0.2, J-value:0.244\n",
      "threshold:0.30000000000000004, J-value:0.122\n",
      "threshold:0.4, J-value:0.07\n",
      "threshold:0.5, J-value:0.033\n",
      "threshold:0.6000000000000001, J-value:0.009999999999999998\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.002\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.691943075454513\n",
      "Balanced accuracy score of test is  0.7046228842261119\n",
      "True positive rate of class 1 is  0.717\n",
      "True positive rate of class 2 is  0.62\n",
      "Positive prediction rate of class 1 is  0.374\n",
      "Positive prediction rate of class 2 is  0.242\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.38\n",
      "threshold:0.2, J-value:0.266\n",
      "threshold:0.30000000000000004, J-value:0.11100000000000002\n",
      "threshold:0.4, J-value:0.028\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6902665905066777\n",
      "Balanced accuracy score of test is  0.7043728768182345\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.35700000000000004\n",
      "threshold:0.2, J-value:0.278\n",
      "threshold:0.30000000000000004, J-value:0.13999999999999999\n",
      "threshold:0.4, J-value:0.03\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6785610841581677\n",
      "Balanced accuracy score of test is  0.6892039128520171\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.38200000000000006\n",
      "threshold:0.2, J-value:0.26\n",
      "threshold:0.30000000000000004, J-value:0.10800000000000001\n",
      "threshold:0.4, J-value:0.027\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6907718666282685\n",
      "Balanced accuracy score of test is  0.7099894057175963\n",
      "True positive rate of class 1 is  0.805\n",
      "True positive rate of class 2 is  0.712\n",
      "Positive prediction rate of class 1 is  0.47\n",
      "Positive prediction rate of class 2 is  0.325\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.33999999999999997\n",
      "threshold:0.2, J-value:0.223\n",
      "threshold:0.30000000000000004, J-value:0.126\n",
      "threshold:0.4, J-value:0.014\n",
      "threshold:0.5, J-value:0.009\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6699300694553931\n",
      "Balanced accuracy score of test is  0.677715105372762\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.323\n",
      "threshold:0.2, J-value:0.215\n",
      "threshold:0.30000000000000004, J-value:0.125\n",
      "threshold:0.4, J-value:0.014\n",
      "threshold:0.5, J-value:0.011\n",
      "threshold:0.6000000000000001, J-value:0.002\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.661910060101041\n",
      "Balanced accuracy score of test is  0.6714838551784266\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.34099999999999997\n",
      "threshold:0.2, J-value:0.22799999999999998\n",
      "threshold:0.30000000000000004, J-value:0.126\n",
      "threshold:0.4, J-value:0.015000000000000001\n",
      "threshold:0.5, J-value:0.008\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6704408048392934\n",
      "Balanced accuracy score of test is  0.6768515175383887\n",
      "True positive rate of class 1 is  0.66\n",
      "True positive rate of class 2 is  0.604\n",
      "Positive prediction rate of class 1 is  0.356\n",
      "Positive prediction rate of class 2 is  0.278\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.401\n",
      "threshold:0.2, J-value:0.258\n",
      "threshold:0.30000000000000004, J-value:0.142\n",
      "threshold:0.4, J-value:0.06099999999999999\n",
      "threshold:0.5, J-value:0.026000000000000002\n",
      "threshold:0.6000000000000001, J-value:0.007\n",
      "threshold:0.7000000000000001, J-value:0.003\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7005735521776465\n",
      "Balanced accuracy score of test is  0.7136353865174352\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.381\n",
      "threshold:0.2, J-value:0.264\n",
      "threshold:0.30000000000000004, J-value:0.15\n",
      "threshold:0.4, J-value:0.071\n",
      "threshold:0.5, J-value:0.033\n",
      "threshold:0.6000000000000001, J-value:0.007\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6906227197531345\n",
      "Balanced accuracy score of test is  0.7052165456546363\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.396\n",
      "threshold:0.2, J-value:0.247\n",
      "threshold:0.30000000000000004, J-value:0.133\n",
      "threshold:0.4, J-value:0.051\n",
      "threshold:0.5, J-value:0.02\n",
      "threshold:0.6000000000000001, J-value:0.007\n",
      "threshold:0.7000000000000001, J-value:0.004\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6981338212464493\n",
      "Balanced accuracy score of test is  0.7102936251141613\n",
      "True positive rate of class 1 is  0.754\n",
      "True positive rate of class 2 is  0.65\n",
      "Positive prediction rate of class 1 is  0.39\n",
      "Positive prediction rate of class 2 is  0.262\n"
     ]
    }
   ],
   "source": [
    "records_lr = []\n",
    "records_rf = []\n",
    "records_dt = []\n",
    "records_gbt = []\n",
    "\n",
    "fairness_metrics (X, y, \"GENDER\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train 65694\n",
      "Y train 65694\n",
      "21898 7782 14116\n",
      "21898 7782 14116\n",
      "21898 7707 14191\n",
      "21898 7707 14191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2588873633479377\n",
      "0.26198310268376185\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19904\n",
      "           1       0.46      0.03      0.06      1994\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.69      0.51      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19825    79]\n",
      " [ 1927    67]]\n",
      "done in 0.526235s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2588873633479377\n",
      "0.2622422310280552\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19934\n",
      "           1       0.42      0.03      0.06      1964\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19848    86]\n",
      " [ 1901    63]]\n",
      "done in 0.531567s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2588873633479377\n",
      "0.30535300485622074\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94      6915\n",
      "           1       0.42      0.03      0.06       867\n",
      "\n",
      "    accuracy                           0.89      7782\n",
      "   macro avg       0.65      0.51      0.50      7782\n",
      "weighted avg       0.84      0.89      0.84      7782\n",
      "\n",
      "Confusion_matrix\n",
      "[[6873   42]\n",
      " [ 837   30]]\n",
      "done in 0.514383s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2588873633479377\n",
      "0.3017063055148335\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6860\n",
      "           1       0.48      0.04      0.07       847\n",
      "\n",
      "    accuracy                           0.89      7707\n",
      "   macro avg       0.69      0.52      0.50      7707\n",
      "weighted avg       0.85      0.89      0.85      7707\n",
      "\n",
      "Confusion_matrix\n",
      "[[6828   32]\n",
      " [ 817   30]]\n",
      "done in 0.502179s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2588873633479377\n",
      "0.2380737389329772\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12989\n",
      "           1       0.50      0.03      0.06      1127\n",
      "\n",
      "    accuracy                           0.92     14116\n",
      "   macro avg       0.71      0.51      0.51     14116\n",
      "weighted avg       0.89      0.92      0.89     14116\n",
      "\n",
      "Confusion_matrix\n",
      "[[12952    37]\n",
      " [ 1090    37]]\n",
      "done in 0.510987s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2588873633479377\n",
      "0.24080965953417877\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13074\n",
      "           1       0.38      0.03      0.05      1117\n",
      "\n",
      "    accuracy                           0.92     14191\n",
      "   macro avg       0.65      0.51      0.51     14191\n",
      "weighted avg       0.88      0.92      0.89     14191\n",
      "\n",
      "Confusion_matrix\n",
      "[[13020    54]\n",
      " [ 1084    33]]\n",
      "done in 0.525647s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19904\n",
      "           1       0.46      0.00      0.01      1994\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.69      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19897     7]\n",
      " [ 1988     6]]\n",
      "done in 16.981195s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19934\n",
      "           1       0.67      0.00      0.01      1964\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.79      0.50      0.48     21898\n",
      "weighted avg       0.89      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19930     4]\n",
      " [ 1956     8]]\n",
      "done in 17.477237s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6915\n",
      "           1       0.50      0.01      0.01       867\n",
      "\n",
      "    accuracy                           0.89      7782\n",
      "   macro avg       0.69      0.50      0.48      7782\n",
      "weighted avg       0.85      0.89      0.84      7782\n",
      "\n",
      "Confusion_matrix\n",
      "[[6910    5]\n",
      " [ 862    5]]\n",
      "done in 17.408931s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6860\n",
      "           1       0.40      0.00      0.00       847\n",
      "\n",
      "    accuracy                           0.89      7707\n",
      "   macro avg       0.65      0.50      0.47      7707\n",
      "weighted avg       0.84      0.89      0.84      7707\n",
      "\n",
      "Confusion_matrix\n",
      "[[6857    3]\n",
      " [ 845    2]]\n",
      "done in 17.418351s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12989\n",
      "           1       0.40      0.00      0.01      1127\n",
      "\n",
      "    accuracy                           0.92     14116\n",
      "   macro avg       0.66      0.50      0.48     14116\n",
      "weighted avg       0.88      0.92      0.88     14116\n",
      "\n",
      "Confusion_matrix\n",
      "[[12983     6]\n",
      " [ 1123     4]]\n",
      "done in 17.309837s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13074\n",
      "           1       0.33      0.00      0.00      1117\n",
      "\n",
      "    accuracy                           0.92     14191\n",
      "   macro avg       0.63      0.50      0.48     14191\n",
      "weighted avg       0.88      0.92      0.88     14191\n",
      "\n",
      "Confusion_matrix\n",
      "[[13070     4]\n",
      " [ 1115     2]]\n",
      "done in 16.757327s\n",
      "0.26448598669059525\n",
      "0.2722330649120758\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19904\n",
      "           1       0.00      0.00      0.00      1994\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.45      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19903     1]\n",
      " [ 1994     0]]\n",
      "done in 0.549176s\n",
      "0.26448598669059525\n",
      "0.2769244924266795\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19934\n",
      "           1       0.00      0.00      0.00      1964\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.46      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19931     3]\n",
      " [ 1964     0]]\n",
      "done in 0.544595s\n",
      "0.26448598669059525\n",
      "0.3197072152180041\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6915\n",
      "           1       0.00      0.00      0.00       867\n",
      "\n",
      "    accuracy                           0.89      7782\n",
      "   macro avg       0.44      0.50      0.47      7782\n",
      "weighted avg       0.79      0.89      0.84      7782\n",
      "\n",
      "Confusion_matrix\n",
      "[[6914    1]\n",
      " [ 867    0]]\n",
      "done in 0.527571s\n",
      "0.26448598669059525\n",
      "0.32281195865362033\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6860\n",
      "           1       0.00      0.00      0.00       847\n",
      "\n",
      "    accuracy                           0.89      7707\n",
      "   macro avg       0.45      0.50      0.47      7707\n",
      "weighted avg       0.79      0.89      0.84      7707\n",
      "\n",
      "Confusion_matrix\n",
      "[[6858    2]\n",
      " [ 847    0]]\n",
      "done in 0.526622s\n",
      "0.26448598669059525\n",
      "0.24606107301063523\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12989\n",
      "           1       0.00      0.00      0.00      1127\n",
      "\n",
      "    accuracy                           0.92     14116\n",
      "   macro avg       0.46      0.50      0.48     14116\n",
      "weighted avg       0.85      0.92      0.88     14116\n",
      "\n",
      "Confusion_matrix\n",
      "[[12989     0]\n",
      " [ 1127     0]]\n",
      "done in 0.536511s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26448598669059525\n",
      "0.2520034366722554\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13074\n",
      "           1       0.00      0.00      0.00      1117\n",
      "\n",
      "    accuracy                           0.92     14191\n",
      "   macro avg       0.46      0.50      0.48     14191\n",
      "weighted avg       0.85      0.92      0.88     14191\n",
      "\n",
      "Confusion_matrix\n",
      "[[13073     1]\n",
      " [ 1117     0]]\n",
      "done in 0.534704s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19904\n",
      "           1       0.47      0.02      0.03      1994\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.69      0.51      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19865    39]\n",
      " [ 1960    34]]\n",
      "done in 30.172595s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19934\n",
      "           1       0.45      0.02      0.05      1964\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19877    57]\n",
      " [ 1917    47]]\n",
      "done in 30.253075s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6915\n",
      "           1       0.51      0.02      0.04       867\n",
      "\n",
      "    accuracy                           0.89      7782\n",
      "   macro avg       0.70      0.51      0.49      7782\n",
      "weighted avg       0.85      0.89      0.84      7782\n",
      "\n",
      "Confusion_matrix\n",
      "[[6898   17]\n",
      " [ 849   18]]\n",
      "done in 29.877646s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6860\n",
      "           1       0.53      0.03      0.06       847\n",
      "\n",
      "    accuracy                           0.89      7707\n",
      "   macro avg       0.71      0.51      0.50      7707\n",
      "weighted avg       0.85      0.89      0.84      7707\n",
      "\n",
      "Confusion_matrix\n",
      "[[6837   23]\n",
      " [ 821   26]]\n",
      "done in 30.086959s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12989\n",
      "           1       0.41      0.01      0.03      1127\n",
      "\n",
      "    accuracy                           0.92     14116\n",
      "   macro avg       0.67      0.51      0.49     14116\n",
      "weighted avg       0.88      0.92      0.88     14116\n",
      "\n",
      "Confusion_matrix\n",
      "[[12966    23]\n",
      " [ 1111    16]]\n",
      "done in 30.169090s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13074\n",
      "           1       0.38      0.02      0.04      1117\n",
      "\n",
      "    accuracy                           0.92     14191\n",
      "   macro avg       0.65      0.51      0.50     14191\n",
      "weighted avg       0.88      0.92      0.89     14191\n",
      "\n",
      "Confusion_matrix\n",
      "[[13040    34]\n",
      " [ 1096    21]]\n",
      "done in 29.630929s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41100000000000003\n",
      "threshold:0.2, J-value:0.26399999999999996\n",
      "threshold:0.30000000000000004, J-value:0.154\n",
      "threshold:0.4, J-value:0.07100000000000001\n",
      "threshold:0.5, J-value:0.030000000000000002\n",
      "threshold:0.6000000000000001, J-value:0.011\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7054833108650711\n",
      "Balanced accuracy score of test is  0.6986732387959697\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.37999999999999995\n",
      "threshold:0.2, J-value:0.266\n",
      "threshold:0.30000000000000004, J-value:0.15200000000000002\n",
      "threshold:0.4, J-value:0.064\n",
      "threshold:0.5, J-value:0.029000000000000005\n",
      "threshold:0.6000000000000001, J-value:0.012\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6899428803038378\n",
      "Balanced accuracy score of test is  0.6960557068163746\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41600000000000004\n",
      "threshold:0.2, J-value:0.256\n",
      "threshold:0.30000000000000004, J-value:0.152\n",
      "threshold:0.4, J-value:0.07500000000000001\n",
      "threshold:0.5, J-value:0.030000000000000002\n",
      "threshold:0.6000000000000001, J-value:0.011\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7080041039435252\n",
      "Balanced accuracy score of test is  0.6909537665152115\n",
      "True positive rate of class 1 is  0.737\n",
      "True positive rate of class 2 is  0.6\n",
      "Positive prediction rate of class 1 is  0.388\n",
      "Positive prediction rate of class 2 is  0.248\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41000000000000003\n",
      "threshold:0.2, J-value:0.28600000000000003\n",
      "threshold:0.30000000000000004, J-value:0.10600000000000001\n",
      "threshold:0.4, J-value:0.021\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7048512902050201\n",
      "Balanced accuracy score of test is  0.6905491022614956\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.37700000000000006\n",
      "threshold:0.2, J-value:0.28\n",
      "threshold:0.30000000000000004, J-value:0.11499999999999999\n",
      "threshold:0.4, J-value:0.026000000000000002\n",
      "threshold:0.5, J-value:0.005\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6883653959223093\n",
      "Balanced accuracy score of test is  0.6743476375201793\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.40099999999999997\n",
      "threshold:0.2, J-value:0.275\n",
      "threshold:0.30000000000000004, J-value:0.098\n",
      "threshold:0.4, J-value:0.025\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.700867254887642\n",
      "Balanced accuracy score of test is  0.692098548185667\n",
      "True positive rate of class 1 is  0.786\n",
      "True positive rate of class 2 is  0.685\n",
      "Positive prediction rate of class 1 is  0.476\n",
      "Positive prediction rate of class 2 is  0.331\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.37899999999999995\n",
      "threshold:0.2, J-value:0.21299999999999997\n",
      "threshold:0.30000000000000004, J-value:0.08499999999999999\n",
      "threshold:0.4, J-value:0.028999999999999998\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.689387268517772\n",
      "Balanced accuracy score of test is  0.6746810298833401\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.35\n",
      "threshold:0.2, J-value:0.19599999999999998\n",
      "threshold:0.30000000000000004, J-value:0.063\n",
      "threshold:0.4, J-value:0.04\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6746861919451972\n",
      "Balanced accuracy score of test is  0.6672589933257836\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.39499999999999996\n",
      "threshold:0.2, J-value:0.22599999999999998\n",
      "threshold:0.30000000000000004, J-value:0.10200000000000001\n",
      "threshold:0.4, J-value:0.019\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6972239427491818\n",
      "Balanced accuracy score of test is  0.6751617300268193\n",
      "True positive rate of class 1 is  0.724\n",
      "True positive rate of class 2 is  0.672\n",
      "Positive prediction rate of class 1 is  0.426\n",
      "Positive prediction rate of class 2 is  0.35\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.42899999999999994\n",
      "threshold:0.2, J-value:0.27799999999999997\n",
      "threshold:0.30000000000000004, J-value:0.143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.4, J-value:0.060000000000000005\n",
      "threshold:0.5, J-value:0.015000000000000001\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7141994210122329\n",
      "Balanced accuracy score of test is  0.6986592670272183\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.40599999999999997\n",
      "threshold:0.2, J-value:0.28\n",
      "threshold:0.30000000000000004, J-value:0.13099999999999998\n",
      "threshold:0.4, J-value:0.057999999999999996\n",
      "threshold:0.5, J-value:0.019000000000000003\n",
      "threshold:0.6000000000000001, J-value:0.005\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7033498712742721\n",
      "Balanced accuracy score of test is  0.6953045562971352\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.42900000000000005\n",
      "threshold:0.2, J-value:0.269\n",
      "threshold:0.30000000000000004, J-value:0.14900000000000002\n",
      "threshold:0.4, J-value:0.061000000000000006\n",
      "threshold:0.5, J-value:0.012\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.714291520850726\n",
      "Balanced accuracy score of test is  0.6917673298018894\n",
      "True positive rate of class 1 is  0.745\n",
      "True positive rate of class 2 is  0.614\n",
      "Positive prediction rate of class 1 is  0.397\n",
      "Positive prediction rate of class 2 is  0.261\n",
      "X train 65694\n",
      "Y train 65694\n",
      "21898 7665 14233\n",
      "21898 7665 14233\n",
      "21898 7807 14091\n",
      "21898 7807 14091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26215139120322445\n",
      "0.2559736159575194\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.95     19980\n",
      "           1       0.48      0.04      0.07      1918\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.70      0.52      0.51     21898\n",
      "weighted avg       0.88      0.91      0.88     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19899    81]\n",
      " [ 1842    76]]\n",
      "done in 0.521702s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26215139120322445\n",
      "0.25789795973082535\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19972\n",
      "           1       0.44      0.04      0.07      1926\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.52      0.51     21898\n",
      "weighted avg       0.87      0.91      0.88     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19884    88]\n",
      " [ 1858    68]]\n",
      "done in 0.511424s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26215139120322445\n",
      "0.29650901754760267\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94      6836\n",
      "           1       0.53      0.05      0.09       829\n",
      "\n",
      "    accuracy                           0.89      7665\n",
      "   macro avg       0.71      0.52      0.52      7665\n",
      "weighted avg       0.86      0.89      0.85      7665\n",
      "\n",
      "Confusion_matrix\n",
      "[[6800   36]\n",
      " [ 789   40]]\n",
      "done in 0.479392s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26215139120322445\n",
      "0.2972168201069575\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94      6982\n",
      "           1       0.40      0.04      0.07       825\n",
      "\n",
      "    accuracy                           0.89      7807\n",
      "   macro avg       0.65      0.52      0.51      7807\n",
      "weighted avg       0.84      0.89      0.85      7807\n",
      "\n",
      "Confusion_matrix\n",
      "[[6933   49]\n",
      " [ 793   32]]\n",
      "done in 0.476253s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26215139120322445\n",
      "0.23414379419204556\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96     13144\n",
      "           1       0.44      0.03      0.06      1089\n",
      "\n",
      "    accuracy                           0.92     14233\n",
      "   macro avg       0.69      0.51      0.51     14233\n",
      "weighted avg       0.89      0.92      0.89     14233\n",
      "\n",
      "Confusion_matrix\n",
      "[[13099    45]\n",
      " [ 1053    36]]\n",
      "done in 0.496017s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26215139120322445\n",
      "0.2361136759357461\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12990\n",
      "           1       0.48      0.03      0.06      1101\n",
      "\n",
      "    accuracy                           0.92     14091\n",
      "   macro avg       0.70      0.51      0.51     14091\n",
      "weighted avg       0.89      0.92      0.89     14091\n",
      "\n",
      "Confusion_matrix\n",
      "[[12951    39]\n",
      " [ 1065    36]]\n",
      "done in 0.498512s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19980\n",
      "           1       0.83      0.00      0.01      1918\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.87      0.50      0.48     21898\n",
      "weighted avg       0.91      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19979     1]\n",
      " [ 1913     5]]\n",
      "done in 16.635286s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19972\n",
      "           1       0.57      0.00      0.00      1926\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.74      0.50      0.48     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19969     3]\n",
      " [ 1922     4]]\n",
      "done in 16.802175s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6836\n",
      "           1       0.67      0.00      0.00       829\n",
      "\n",
      "    accuracy                           0.89      7665\n",
      "   macro avg       0.78      0.50      0.47      7665\n",
      "weighted avg       0.87      0.89      0.84      7665\n",
      "\n",
      "Confusion_matrix\n",
      "[[6835    1]\n",
      " [ 827    2]]\n",
      "done in 16.463622s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6982\n",
      "           1       0.22      0.00      0.00       825\n",
      "\n",
      "    accuracy                           0.89      7807\n",
      "   macro avg       0.56      0.50      0.47      7807\n",
      "weighted avg       0.82      0.89      0.84      7807\n",
      "\n",
      "Confusion_matrix\n",
      "[[6975    7]\n",
      " [ 823    2]]\n",
      "done in 16.420643s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13144\n",
      "           1       0.25      0.00      0.00      1089\n",
      "\n",
      "    accuracy                           0.92     14233\n",
      "   macro avg       0.59      0.50      0.48     14233\n",
      "weighted avg       0.87      0.92      0.89     14233\n",
      "\n",
      "Confusion_matrix\n",
      "[[13141     3]\n",
      " [ 1088     1]]\n",
      "done in 16.539631s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12990\n",
      "           1       1.00      0.00      0.01      1101\n",
      "\n",
      "    accuracy                           0.92     14091\n",
      "   macro avg       0.96      0.50      0.48     14091\n",
      "weighted avg       0.93      0.92      0.89     14091\n",
      "\n",
      "Confusion_matrix\n",
      "[[12990     0]\n",
      " [ 1097     4]]\n",
      "done in 17.027890s\n",
      "0.26732574897465733\n",
      "0.2685985620764942\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19980\n",
      "           1       0.40      0.00      0.00      1918\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.66      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19977     3]\n",
      " [ 1916     2]]\n",
      "done in 0.574687s\n",
      "0.26732574897465733\n",
      "0.26985788626648854\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19972\n",
      "           1       0.14      0.00      0.00      1926\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.53      0.50      0.48     21898\n",
      "weighted avg       0.84      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19966     6]\n",
      " [ 1925     1]]\n",
      "done in 0.574804s\n",
      "0.26732574897465733\n",
      "0.3061298532338181\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6836\n",
      "           1       1.00      0.00      0.00       829\n",
      "\n",
      "    accuracy                           0.89      7665\n",
      "   macro avg       0.95      0.50      0.47      7665\n",
      "weighted avg       0.90      0.89      0.84      7665\n",
      "\n",
      "Confusion_matrix\n",
      "[[6836    0]\n",
      " [ 828    1]]\n",
      "done in 0.561500s\n",
      "0.26732574897465733\n",
      "0.3146999065380737\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6982\n",
      "           1       0.33      0.00      0.00       825\n",
      "\n",
      "    accuracy                           0.89      7807\n",
      "   macro avg       0.61      0.50      0.47      7807\n",
      "weighted avg       0.84      0.89      0.84      7807\n",
      "\n",
      "Confusion_matrix\n",
      "[[6980    2]\n",
      " [ 824    1]]\n",
      "done in 0.548181s\n",
      "0.26732574897465733\n",
      "0.248386565538808\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13144\n",
      "           1       0.25      0.00      0.00      1089\n",
      "\n",
      "    accuracy                           0.92     14233\n",
      "   macro avg       0.59      0.50      0.48     14233\n",
      "weighted avg       0.87      0.92      0.89     14233\n",
      "\n",
      "Confusion_matrix\n",
      "[[13141     3]\n",
      " [ 1088     1]]\n",
      "done in 0.543525s\n",
      "0.26732574897465733\n",
      "0.24501354219862498\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12990\n",
      "           1       0.00      0.00      0.00      1101\n",
      "\n",
      "    accuracy                           0.92     14091\n",
      "   macro avg       0.46      0.50      0.48     14091\n",
      "weighted avg       0.85      0.92      0.88     14091\n",
      "\n",
      "Confusion_matrix\n",
      "[[12986     4]\n",
      " [ 1101     0]]\n",
      "done in 0.559595s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19980\n",
      "           1       0.44      0.02      0.04      1918\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.51      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19934    46]\n",
      " [ 1882    36]]\n",
      "done in 29.704570s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19972\n",
      "           1       0.45      0.02      0.04      1926\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19921    51]\n",
      " [ 1885    41]]\n",
      "done in 30.037905s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6836\n",
      "           1       0.50      0.02      0.04       829\n",
      "\n",
      "    accuracy                           0.89      7665\n",
      "   macro avg       0.70      0.51      0.49      7665\n",
      "weighted avg       0.85      0.89      0.85      7665\n",
      "\n",
      "Confusion_matrix\n",
      "[[6818   18]\n",
      " [ 811   18]]\n",
      "done in 29.767163s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.94      6982\n",
      "           1       0.38      0.02      0.04       825\n",
      "\n",
      "    accuracy                           0.89      7807\n",
      "   macro avg       0.64      0.51      0.49      7807\n",
      "weighted avg       0.84      0.89      0.85      7807\n",
      "\n",
      "Confusion_matrix\n",
      "[[6954   28]\n",
      " [ 808   17]]\n",
      "done in 29.783590s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13144\n",
      "           1       0.39      0.02      0.03      1089\n",
      "\n",
      "    accuracy                           0.92     14233\n",
      "   macro avg       0.66      0.51      0.50     14233\n",
      "weighted avg       0.88      0.92      0.89     14233\n",
      "\n",
      "Confusion_matrix\n",
      "[[13116    28]\n",
      " [ 1071    18]]\n",
      "done in 29.800110s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12990\n",
      "           1       0.51      0.02      0.04      1101\n",
      "\n",
      "    accuracy                           0.92     14091\n",
      "   macro avg       0.72      0.51      0.50     14091\n",
      "weighted avg       0.89      0.92      0.89     14091\n",
      "\n",
      "Confusion_matrix\n",
      "[[12967    23]\n",
      " [ 1077    24]]\n",
      "done in 29.711253s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.404\n",
      "threshold:0.2, J-value:0.27599999999999997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.30000000000000004, J-value:0.155\n",
      "threshold:0.4, J-value:0.07\n",
      "threshold:0.5, J-value:0.036000000000000004\n",
      "threshold:0.6000000000000001, J-value:0.012\n",
      "threshold:0.7000000000000001, J-value:0.004\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7021389481243496\n",
      "Balanced accuracy score of test is  0.6985516223231736\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.39799999999999996\n",
      "threshold:0.2, J-value:0.313\n",
      "threshold:0.30000000000000004, J-value:0.188\n",
      "threshold:0.4, J-value:0.077\n",
      "threshold:0.5, J-value:0.043000000000000003\n",
      "threshold:0.6000000000000001, J-value:0.012\n",
      "threshold:0.7000000000000001, J-value:0.003\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6985878352100319\n",
      "Balanced accuracy score of test is  0.6863112939767193\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.391\n",
      "threshold:0.2, J-value:0.238\n",
      "threshold:0.30000000000000004, J-value:0.127\n",
      "threshold:0.4, J-value:0.064\n",
      "threshold:0.5, J-value:0.030000000000000002\n",
      "threshold:0.6000000000000001, J-value:0.011\n",
      "threshold:0.7000000000000001, J-value:0.004\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6950855732671148\n",
      "Balanced accuracy score of test is  0.6982723033647765\n",
      "True positive rate of class 1 is  0.716\n",
      "True positive rate of class 2 is  0.603\n",
      "Positive prediction rate of class 1 is  0.383\n",
      "Positive prediction rate of class 2 is  0.238\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.392\n",
      "threshold:0.2, J-value:0.295\n",
      "threshold:0.30000000000000004, J-value:0.119\n",
      "threshold:0.4, J-value:0.022000000000000002\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6959217298633358\n",
      "Balanced accuracy score of test is  0.6946210416285812\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.35900000000000004\n",
      "threshold:0.2, J-value:0.31999999999999995\n",
      "threshold:0.30000000000000004, J-value:0.145\n",
      "threshold:0.4, J-value:0.033\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6796853880082809\n",
      "Balanced accuracy score of test is  0.672699842886036\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.39599999999999996\n",
      "threshold:0.2, J-value:0.274\n",
      "threshold:0.30000000000000004, J-value:0.094\n",
      "threshold:0.4, J-value:0.018000000000000002\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6982208657705254\n",
      "Balanced accuracy score of test is  0.7039775933279215\n",
      "True positive rate of class 1 is  0.784\n",
      "True positive rate of class 2 is  0.701\n",
      "Positive prediction rate of class 1 is  0.475\n",
      "Positive prediction rate of class 2 is  0.325\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.35300000000000004\n",
      "threshold:0.2, J-value:0.21199999999999997\n",
      "threshold:0.30000000000000004, J-value:0.10800000000000001\n",
      "threshold:0.4, J-value:0.001\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.001\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6761341894553574\n",
      "Balanced accuracy score of test is  0.6840908788399294\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.33399999999999996\n",
      "threshold:0.2, J-value:0.23800000000000002\n",
      "threshold:0.30000000000000004, J-value:0.124\n",
      "threshold:0.4, J-value:0.001\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.001\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6669769989433645\n",
      "Balanced accuracy score of test is  0.6645410275774069\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.35400000000000004\n",
      "threshold:0.2, J-value:0.189\n",
      "threshold:0.30000000000000004, J-value:0.096\n",
      "threshold:0.4, J-value:0.001\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6768581837296218\n",
      "Balanced accuracy score of test is  0.6928545957590517\n",
      "True positive rate of class 1 is  0.716\n",
      "True positive rate of class 2 is  0.688\n",
      "Positive prediction rate of class 1 is  0.422\n",
      "Positive prediction rate of class 2 is  0.332\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41899999999999993\n",
      "threshold:0.2, J-value:0.27599999999999997\n",
      "threshold:0.30000000000000004, J-value:0.151\n",
      "threshold:0.4, J-value:0.058\n",
      "threshold:0.5, J-value:0.017\n",
      "threshold:0.6000000000000001, J-value:0.006\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7097472081048724\n",
      "Balanced accuracy score of test is  0.7026313994316862\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.402\n",
      "threshold:0.2, J-value:0.304\n",
      "threshold:0.30000000000000004, J-value:0.176\n",
      "threshold:0.4, J-value:0.066\n",
      "threshold:0.5, J-value:0.019\n",
      "threshold:0.6000000000000001, J-value:0.007\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7009800876788674\n",
      "Balanced accuracy score of test is  0.69121021153963\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41600000000000004\n",
      "threshold:0.2, J-value:0.249\n",
      "threshold:0.30000000000000004, J-value:0.129\n",
      "threshold:0.4, J-value:0.052\n",
      "threshold:0.5, J-value:0.015000000000000001\n",
      "threshold:0.6000000000000001, J-value:0.005\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7076167529329704\n",
      "Balanced accuracy score of test is  0.7028272638982407\n",
      "True positive rate of class 1 is  0.736\n",
      "True positive rate of class 2 is  0.638\n",
      "Positive prediction rate of class 1 is  0.394\n",
      "Positive prediction rate of class 2 is  0.264\n",
      "X train 65694\n",
      "Y train 65694\n",
      "21898 7743 14155\n",
      "21898 7743 14155\n",
      "21898 7740 14158\n",
      "21898 7740 14158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2595091489403858\n",
      "0.26037470726594736\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19950\n",
      "           1       0.44      0.03      0.06      1948\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.51      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19871    79]\n",
      " [ 1885    63]]\n",
      "done in 0.468990s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2595091489403858\n",
      "0.2625560786274971\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19883\n",
      "           1       0.50      0.03      0.05      2015\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.70      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19824    59]\n",
      " [ 1957    58]]\n",
      "done in 0.478496s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2595091489403858\n",
      "0.3017116540814592\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94      6895\n",
      "           1       0.44      0.03      0.06       848\n",
      "\n",
      "    accuracy                           0.89      7743\n",
      "   macro avg       0.67      0.51      0.50      7743\n",
      "weighted avg       0.84      0.89      0.85      7743\n",
      "\n",
      "Confusion_matrix\n",
      "[[6858   37]\n",
      " [ 819   29]]\n",
      "done in 0.459417s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2595091489403858\n",
      "0.3051434203141274\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6860\n",
      "           1       0.43      0.03      0.06       880\n",
      "\n",
      "    accuracy                           0.89      7740\n",
      "   macro avg       0.66      0.51      0.50      7740\n",
      "weighted avg       0.84      0.89      0.84      7740\n",
      "\n",
      "Confusion_matrix\n",
      "[[6826   34]\n",
      " [ 854   26]]\n",
      "done in 0.474107s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2595091489403858\n",
      "0.23776276949183864\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13055\n",
      "           1       0.45      0.03      0.06      1100\n",
      "\n",
      "    accuracy                           0.92     14155\n",
      "   macro avg       0.69      0.51      0.51     14155\n",
      "weighted avg       0.89      0.92      0.89     14155\n",
      "\n",
      "Confusion_matrix\n",
      "[[13013    42]\n",
      " [ 1066    34]]\n",
      "done in 0.457991s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2595091489403858\n",
      "0.23927411615719624\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13023\n",
      "           1       0.56      0.03      0.05      1135\n",
      "\n",
      "    accuracy                           0.92     14158\n",
      "   macro avg       0.74      0.51      0.51     14158\n",
      "weighted avg       0.89      0.92      0.89     14158\n",
      "\n",
      "Confusion_matrix\n",
      "[[12998    25]\n",
      " [ 1103    32]]\n",
      "done in 0.492865s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19950\n",
      "           1       0.57      0.00      0.01      1948\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.74      0.50      0.48     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19944     6]\n",
      " [ 1940     8]]\n",
      "done in 16.858979s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19883\n",
      "           1       0.50      0.00      0.00      2015\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.70      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.86     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19878     5]\n",
      " [ 2010     5]]\n",
      "done in 16.902464s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6895\n",
      "           1       0.38      0.00      0.01       848\n",
      "\n",
      "    accuracy                           0.89      7743\n",
      "   macro avg       0.63      0.50      0.47      7743\n",
      "weighted avg       0.83      0.89      0.84      7743\n",
      "\n",
      "Confusion_matrix\n",
      "[[6890    5]\n",
      " [ 845    3]]\n",
      "done in 16.510476s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6860\n",
      "           1       0.67      0.00      0.00       880\n",
      "\n",
      "    accuracy                           0.89      7740\n",
      "   macro avg       0.78      0.50      0.47      7740\n",
      "weighted avg       0.86      0.89      0.83      7740\n",
      "\n",
      "Confusion_matrix\n",
      "[[6859    1]\n",
      " [ 878    2]]\n",
      "done in 16.538309s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13055\n",
      "           1       0.60      0.00      0.01      1100\n",
      "\n",
      "    accuracy                           0.92     14155\n",
      "   macro avg       0.76      0.50      0.48     14155\n",
      "weighted avg       0.90      0.92      0.89     14155\n",
      "\n",
      "Confusion_matrix\n",
      "[[13053     2]\n",
      " [ 1097     3]]\n",
      "done in 16.667831s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13023\n",
      "           1       0.67      0.00      0.00      1135\n",
      "\n",
      "    accuracy                           0.92     14158\n",
      "   macro avg       0.79      0.50      0.48     14158\n",
      "weighted avg       0.90      0.92      0.88     14158\n",
      "\n",
      "Confusion_matrix\n",
      "[[13022     1]\n",
      " [ 1133     2]]\n",
      "done in 16.693489s\n",
      "0.264372916262498\n",
      "0.27018076777808153\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19950\n",
      "           1       0.00      0.00      0.00      1948\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.46      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19949     1]\n",
      " [ 1948     0]]\n",
      "done in 0.550735s\n",
      "0.264372916262498\n",
      "0.2809860830385153\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19883\n",
      "           1       0.00      0.00      0.00      2015\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.45      0.50      0.48     21898\n",
      "weighted avg       0.82      0.91      0.86     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19878     5]\n",
      " [ 2015     0]]\n",
      "done in 0.548825s\n",
      "0.264372916262498\n",
      "0.31633604840315793\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6895\n",
      "           1       0.00      0.00      0.00       848\n",
      "\n",
      "    accuracy                           0.89      7743\n",
      "   macro avg       0.45      0.50      0.47      7743\n",
      "weighted avg       0.79      0.89      0.84      7743\n",
      "\n",
      "Confusion_matrix\n",
      "[[6894    1]\n",
      " [ 848    0]]\n",
      "done in 0.535043s\n",
      "0.264372916262498\n",
      "0.3347560673438306\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6860\n",
      "           1       0.00      0.00      0.00       880\n",
      "\n",
      "    accuracy                           0.89      7740\n",
      "   macro avg       0.44      0.50      0.47      7740\n",
      "weighted avg       0.79      0.89      0.83      7740\n",
      "\n",
      "Confusion_matrix\n",
      "[[6856    4]\n",
      " [ 880    0]]\n",
      "done in 0.533719s\n",
      "0.264372916262498\n",
      "0.24493312822456925\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13055\n",
      "           1       0.00      0.00      0.00      1100\n",
      "\n",
      "    accuracy                           0.92     14155\n",
      "   macro avg       0.46      0.50      0.48     14155\n",
      "weighted avg       0.85      0.92      0.89     14155\n",
      "\n",
      "Confusion_matrix\n",
      "[[13055     0]\n",
      " [ 1100     0]]\n",
      "done in 0.540305s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.264372916262498\n",
      "0.249151187225685\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13023\n",
      "           1       0.00      0.00      0.00      1135\n",
      "\n",
      "    accuracy                           0.92     14158\n",
      "   macro avg       0.46      0.50      0.48     14158\n",
      "weighted avg       0.85      0.92      0.88     14158\n",
      "\n",
      "Confusion_matrix\n",
      "[[13023     0]\n",
      " [ 1135     0]]\n",
      "done in 0.538592s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19950\n",
      "           1       0.44      0.02      0.03      1948\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19905    45]\n",
      " [ 1913    35]]\n",
      "done in 29.659496s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19883\n",
      "           1       0.43      0.02      0.03      2015\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19842    41]\n",
      " [ 1984    31]]\n",
      "done in 29.718322s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6895\n",
      "           1       0.47      0.02      0.03       848\n",
      "\n",
      "    accuracy                           0.89      7743\n",
      "   macro avg       0.68      0.51      0.49      7743\n",
      "weighted avg       0.85      0.89      0.84      7743\n",
      "\n",
      "Confusion_matrix\n",
      "[[6879   16]\n",
      " [ 834   14]]\n",
      "done in 29.364279s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6860\n",
      "           1       0.38      0.02      0.03       880\n",
      "\n",
      "    accuracy                           0.89      7740\n",
      "   macro avg       0.64      0.51      0.49      7740\n",
      "weighted avg       0.83      0.89      0.84      7740\n",
      "\n",
      "Confusion_matrix\n",
      "[[6836   24]\n",
      " [ 865   15]]\n",
      "done in 29.739400s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13055\n",
      "           1       0.42      0.02      0.04      1100\n",
      "\n",
      "    accuracy                           0.92     14155\n",
      "   macro avg       0.67      0.51      0.50     14155\n",
      "weighted avg       0.88      0.92      0.89     14155\n",
      "\n",
      "Confusion_matrix\n",
      "[[13026    29]\n",
      " [ 1079    21]]\n",
      "done in 29.748066s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13023\n",
      "           1       0.47      0.01      0.03      1135\n",
      "\n",
      "    accuracy                           0.92     14158\n",
      "   macro avg       0.70      0.51      0.49     14158\n",
      "weighted avg       0.88      0.92      0.88     14158\n",
      "\n",
      "Confusion_matrix\n",
      "[[13005    18]\n",
      " [ 1119    16]]\n",
      "done in 29.654175s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.397\n",
      "threshold:0.2, J-value:0.254\n",
      "threshold:0.30000000000000004, J-value:0.14100000000000001\n",
      "threshold:0.4, J-value:0.07100000000000001\n",
      "threshold:0.5, J-value:0.028\n",
      "threshold:0.6000000000000001, J-value:0.009000000000000001\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6987633611750115\n",
      "Balanced accuracy score of test is  0.7065258436793205\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.38799999999999996\n",
      "threshold:0.2, J-value:0.274\n",
      "threshold:0.30000000000000004, J-value:0.151\n",
      "threshold:0.4, J-value:0.074\n",
      "threshold:0.5, J-value:0.029\n",
      "threshold:0.6000000000000001, J-value:0.009\n",
      "threshold:0.7000000000000001, J-value:0.005\n",
      "threshold:0.8, J-value:0.002\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6937904483697511\n",
      "Balanced accuracy score of test is  0.7033146700238537\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.385\n",
      "threshold:0.2, J-value:0.23299999999999998\n",
      "threshold:0.30000000000000004, J-value:0.132\n",
      "threshold:0.4, J-value:0.067\n",
      "threshold:0.5, J-value:0.028\n",
      "threshold:0.6000000000000001, J-value:0.008\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6926999408098604\n",
      "Balanced accuracy score of test is  0.6999322784054371\n",
      "True positive rate of class 1 is  0.731\n",
      "True positive rate of class 2 is  0.612\n",
      "Positive prediction rate of class 1 is  0.37\n",
      "Positive prediction rate of class 2 is  0.245\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.383\n",
      "threshold:0.2, J-value:0.275\n",
      "threshold:0.30000000000000004, J-value:0.10400000000000001\n",
      "threshold:0.4, J-value:0.019\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.691926042004395\n",
      "Balanced accuracy score of test is  0.6920221010030265\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.35300000000000004\n",
      "threshold:0.2, J-value:0.3\n",
      "threshold:0.30000000000000004, J-value:0.122\n",
      "threshold:0.4, J-value:0.022\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6768645586766457\n",
      "Balanced accuracy score of test is  0.6852637158759607\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.38000000000000006\n",
      "threshold:0.2, J-value:0.253\n",
      "threshold:0.30000000000000004, J-value:0.095\n",
      "threshold:0.4, J-value:0.016\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6902106472615857\n",
      "Balanced accuracy score of test is  0.6979512018891687\n",
      "True positive rate of class 1 is  0.795\n",
      "True positive rate of class 2 is  0.7\n",
      "Positive prediction rate of class 1 is  0.467\n",
      "Positive prediction rate of class 2 is  0.336\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.35900000000000004\n",
      "threshold:0.2, J-value:0.226\n",
      "threshold:0.30000000000000004, J-value:0.10600000000000001\n",
      "threshold:0.4, J-value:0.003\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6796957743434562\n",
      "Balanced accuracy score of test is  0.6855552875138419\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.32899999999999996\n",
      "threshold:0.2, J-value:0.22200000000000003\n",
      "threshold:0.30000000000000004, J-value:0.10500000000000001\n",
      "threshold:0.4, J-value:0.002\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6643826022411647\n",
      "Balanced accuracy score of test is  0.6797359528226875\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.37000000000000005\n",
      "threshold:0.2, J-value:0.22399999999999998\n",
      "threshold:0.30000000000000004, J-value:0.10500000000000001\n",
      "threshold:0.4, J-value:0.003\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6850767730928589\n",
      "Balanced accuracy score of test is  0.6848380753671663\n",
      "True positive rate of class 1 is  0.706\n",
      "True positive rate of class 2 is  0.651\n",
      "Positive prediction rate of class 1 is  0.387\n",
      "Positive prediction rate of class 2 is  0.311\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.4149999999999999\n",
      "threshold:0.2, J-value:0.26\n",
      "threshold:0.30000000000000004, J-value:0.138\n",
      "threshold:0.4, J-value:0.053\n",
      "threshold:0.5, J-value:0.016\n",
      "threshold:0.6000000000000001, J-value:0.005\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7072499009330308\n",
      "Balanced accuracy score of test is  0.7106360671466541\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.401\n",
      "threshold:0.2, J-value:0.258\n",
      "threshold:0.30000000000000004, J-value:0.143\n",
      "threshold:0.4, J-value:0.05\n",
      "threshold:0.5, J-value:0.015000000000000001\n",
      "threshold:0.6000000000000001, J-value:0.004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7005006875367712\n",
      "Balanced accuracy score of test is  0.705203087728598\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.406\n",
      "threshold:0.2, J-value:0.255\n",
      "threshold:0.30000000000000004, J-value:0.132\n",
      "threshold:0.4, J-value:0.056\n",
      "threshold:0.5, J-value:0.017\n",
      "threshold:0.6000000000000001, J-value:0.005\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.702808572124926\n",
      "Balanced accuracy score of test is  0.7059039564362746\n",
      "True positive rate of class 1 is  0.753\n",
      "True positive rate of class 2 is  0.645\n",
      "Positive prediction rate of class 1 is  0.39\n",
      "Positive prediction rate of class 2 is  0.266\n",
      "X train 65694\n",
      "Y train 65694\n",
      "21898 7751 14147\n",
      "21898 7751 14147\n",
      "21898 7757 14141\n",
      "21898 7757 14141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25892930913047413\n",
      "0.26313429063096405\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19908\n",
      "           1       0.46      0.04      0.07      1990\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.69      0.52      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19819    89]\n",
      " [ 1913    77]]\n",
      "done in 0.563654s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25892930913047413\n",
      "0.2609482804053149\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19918\n",
      "           1       0.43      0.03      0.06      1980\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.52      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19825    93]\n",
      " [ 1911    69]]\n",
      "done in 0.499346s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25892930913047413\n",
      "0.3014853219155957\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94      6908\n",
      "           1       0.43      0.04      0.08       843\n",
      "\n",
      "    accuracy                           0.89      7751\n",
      "   macro avg       0.66      0.52      0.51      7751\n",
      "weighted avg       0.84      0.89      0.85      7751\n",
      "\n",
      "Confusion_matrix\n",
      "[[6860   48]\n",
      " [ 807   36]]\n",
      "done in 0.492689s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25892930913047413\n",
      "0.3027876996166047\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94      6894\n",
      "           1       0.39      0.04      0.08       863\n",
      "\n",
      "    accuracy                           0.89      7757\n",
      "   macro avg       0.64      0.52      0.51      7757\n",
      "weighted avg       0.84      0.89      0.84      7757\n",
      "\n",
      "Confusion_matrix\n",
      "[[6837   57]\n",
      " [ 827   36]]\n",
      "done in 0.505093s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25892930913047413\n",
      "0.2421221436395751\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13000\n",
      "           1       0.50      0.04      0.07      1147\n",
      "\n",
      "    accuracy                           0.92     14147\n",
      "   macro avg       0.71      0.52      0.51     14147\n",
      "weighted avg       0.89      0.92      0.89     14147\n",
      "\n",
      "Confusion_matrix\n",
      "[[12959    41]\n",
      " [ 1106    41]]\n",
      "done in 0.532629s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25892930913047413\n",
      "0.23799740176717224\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13024\n",
      "           1       0.48      0.03      0.06      1117\n",
      "\n",
      "    accuracy                           0.92     14141\n",
      "   macro avg       0.70      0.51      0.51     14141\n",
      "weighted avg       0.89      0.92      0.89     14141\n",
      "\n",
      "Confusion_matrix\n",
      "[[12988    36]\n",
      " [ 1084    33]]\n",
      "done in 0.590342s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19908\n",
      "           1       0.54      0.00      0.01      1990\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.72      0.50      0.48     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19902     6]\n",
      " [ 1983     7]]\n",
      "done in 17.162590s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19918\n",
      "           1       0.67      0.00      0.00      1980\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.79      0.50      0.48     21898\n",
      "weighted avg       0.89      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19917     1]\n",
      " [ 1978     2]]\n",
      "done in 17.024857s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6908\n",
      "           1       0.31      0.00      0.01       843\n",
      "\n",
      "    accuracy                           0.89      7751\n",
      "   macro avg       0.60      0.50      0.48      7751\n",
      "weighted avg       0.83      0.89      0.84      7751\n",
      "\n",
      "Confusion_matrix\n",
      "[[6899    9]\n",
      " [ 839    4]]\n",
      "done in 16.848352s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6894\n",
      "           1       1.00      0.00      0.01       863\n",
      "\n",
      "    accuracy                           0.89      7757\n",
      "   macro avg       0.94      0.50      0.48      7757\n",
      "weighted avg       0.90      0.89      0.84      7757\n",
      "\n",
      "Confusion_matrix\n",
      "[[6894    0]\n",
      " [ 859    4]]\n",
      "done in 16.549326s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13000\n",
      "           1       0.50      0.00      0.01      1147\n",
      "\n",
      "    accuracy                           0.92     14147\n",
      "   macro avg       0.71      0.50      0.48     14147\n",
      "weighted avg       0.89      0.92      0.88     14147\n",
      "\n",
      "Confusion_matrix\n",
      "[[12997     3]\n",
      " [ 1144     3]]\n",
      "done in 16.744030s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13024\n",
      "           1       0.00      0.00      0.00      1117\n",
      "\n",
      "    accuracy                           0.92     14141\n",
      "   macro avg       0.46      0.50      0.48     14141\n",
      "weighted avg       0.85      0.92      0.88     14141\n",
      "\n",
      "Confusion_matrix\n",
      "[[13023     1]\n",
      " [ 1117     0]]\n",
      "done in 16.655805s\n",
      "0.26428564201629917\n",
      "0.2711976984051151\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19908\n",
      "           1       0.00      0.00      0.00      1990\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.45      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19905     3]\n",
      " [ 1990     0]]\n",
      "done in 0.550716s\n",
      "0.26428564201629917\n",
      "0.27044922960654555\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19918\n",
      "           1       0.00      0.00      0.00      1980\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.45      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19915     3]\n",
      " [ 1980     0]]\n",
      "done in 0.552466s\n",
      "0.26428564201629917\n",
      "0.3098035048476032\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6908\n",
      "           1       0.00      0.00      0.00       843\n",
      "\n",
      "    accuracy                           0.89      7751\n",
      "   macro avg       0.45      0.50      0.47      7751\n",
      "weighted avg       0.79      0.89      0.84      7751\n",
      "\n",
      "Confusion_matrix\n",
      "[[6907    1]\n",
      " [ 843    0]]\n",
      "done in 0.529054s\n",
      "0.26428564201629917\n",
      "0.31005626911062445\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6894\n",
      "           1       0.00      0.00      0.00       863\n",
      "\n",
      "    accuracy                           0.89      7757\n",
      "   macro avg       0.44      0.50      0.47      7757\n",
      "weighted avg       0.79      0.89      0.84      7757\n",
      "\n",
      "Confusion_matrix\n",
      "[[6894    0]\n",
      " [ 863    0]]\n",
      "done in 0.528209s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26428564201629917\n",
      "0.25004596264942663\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13000\n",
      "           1       0.00      0.00      0.00      1147\n",
      "\n",
      "    accuracy                           0.92     14147\n",
      "   macro avg       0.46      0.50      0.48     14147\n",
      "weighted avg       0.84      0.92      0.88     14147\n",
      "\n",
      "Confusion_matrix\n",
      "[[12998     2]\n",
      " [ 1147     0]]\n",
      "done in 0.545680s\n",
      "0.26428564201629917\n",
      "0.24877068299137428\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13024\n",
      "           1       0.00      0.00      0.00      1117\n",
      "\n",
      "    accuracy                           0.92     14141\n",
      "   macro avg       0.46      0.50      0.48     14141\n",
      "weighted avg       0.85      0.92      0.88     14141\n",
      "\n",
      "Confusion_matrix\n",
      "[[13021     3]\n",
      " [ 1117     0]]\n",
      "done in 0.556460s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19908\n",
      "           1       0.45      0.02      0.04      1990\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.51      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19860    48]\n",
      " [ 1951    39]]\n",
      "done in 29.963125s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19918\n",
      "           1       0.36      0.02      0.03      1980\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.64      0.51      0.49     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19861    57]\n",
      " [ 1948    32]]\n",
      "done in 30.249180s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6908\n",
      "           1       0.44      0.03      0.05       843\n",
      "\n",
      "    accuracy                           0.89      7751\n",
      "   macro avg       0.67      0.51      0.50      7751\n",
      "weighted avg       0.84      0.89      0.84      7751\n",
      "\n",
      "Confusion_matrix\n",
      "[[6880   28]\n",
      " [ 821   22]]\n",
      "done in 29.829950s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94      6894\n",
      "           1       0.35      0.02      0.04       863\n",
      "\n",
      "    accuracy                           0.89      7757\n",
      "   macro avg       0.62      0.51      0.49      7757\n",
      "weighted avg       0.83      0.89      0.84      7757\n",
      "\n",
      "Confusion_matrix\n",
      "[[6858   36]\n",
      " [ 844   19]]\n",
      "done in 29.819361s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13000\n",
      "           1       0.46      0.01      0.03      1147\n",
      "\n",
      "    accuracy                           0.92     14147\n",
      "   macro avg       0.69      0.51      0.49     14147\n",
      "weighted avg       0.88      0.92      0.88     14147\n",
      "\n",
      "Confusion_matrix\n",
      "[[12980    20]\n",
      " [ 1130    17]]\n",
      "done in 29.980352s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13024\n",
      "           1       0.38      0.01      0.02      1117\n",
      "\n",
      "    accuracy                           0.92     14141\n",
      "   macro avg       0.65      0.51      0.49     14141\n",
      "weighted avg       0.88      0.92      0.88     14141\n",
      "\n",
      "Confusion_matrix\n",
      "[[13003    21]\n",
      " [ 1104    13]]\n",
      "done in 29.885690s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.397\n",
      "threshold:0.2, J-value:0.26\n",
      "threshold:0.30000000000000004, J-value:0.157\n",
      "threshold:0.4, J-value:0.077\n",
      "threshold:0.5, J-value:0.035\n",
      "threshold:0.6000000000000001, J-value:0.013999999999999999\n",
      "threshold:0.7000000000000001, J-value:0.004\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6984924118280775\n",
      "Balanced accuracy score of test is  0.7102360841064526\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.383\n",
      "threshold:0.2, J-value:0.276\n",
      "threshold:0.30000000000000004, J-value:0.174\n",
      "threshold:0.4, J-value:0.08499999999999999\n",
      "threshold:0.5, J-value:0.036\n",
      "threshold:0.6000000000000001, J-value:0.018000000000000002\n",
      "threshold:0.7000000000000001, J-value:0.005\n",
      "threshold:0.8, J-value:0.002\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6912018042931296\n",
      "Balanced accuracy score of test is  0.7065178513500748\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.38799999999999996\n",
      "threshold:0.2, J-value:0.241\n",
      "threshold:0.30000000000000004, J-value:0.14200000000000002\n",
      "threshold:0.4, J-value:0.07\n",
      "threshold:0.5, J-value:0.032999999999999995\n",
      "threshold:0.6000000000000001, J-value:0.009000000000000001\n",
      "threshold:0.7000000000000001, J-value:0.003\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6939380993897123\n",
      "Balanced accuracy score of test is  0.7019873715682803\n",
      "True positive rate of class 1 is  0.753\n",
      "True positive rate of class 2 is  0.604\n",
      "Positive prediction rate of class 1 is  0.386\n",
      "Positive prediction rate of class 2 is  0.232\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.38199999999999995\n",
      "threshold:0.2, J-value:0.275\n",
      "threshold:0.30000000000000004, J-value:0.11000000000000001\n",
      "threshold:0.4, J-value:0.023\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6911991391556941\n",
      "Balanced accuracy score of test is  0.6959121032597285\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.339\n",
      "threshold:0.2, J-value:0.27\n",
      "threshold:0.30000000000000004, J-value:0.10799999999999998\n",
      "threshold:0.4, J-value:0.038\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6695002132758554\n",
      "Balanced accuracy score of test is  0.688055695902965\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.39000000000000007\n",
      "threshold:0.2, J-value:0.27799999999999997\n",
      "threshold:0.30000000000000004, J-value:0.117\n",
      "threshold:0.4, J-value:0.027999999999999997\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6949917510562672\n",
      "Balanced accuracy score of test is  0.6909756095213795\n",
      "True positive rate of class 1 is  0.809\n",
      "True positive rate of class 2 is  0.67\n",
      "Positive prediction rate of class 1 is  0.475\n",
      "Positive prediction rate of class 2 is  0.318\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.35500000000000004\n",
      "threshold:0.2, J-value:0.227\n",
      "threshold:0.30000000000000004, J-value:0.101\n",
      "threshold:0.4, J-value:0.003\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6777201508850259\n",
      "Balanced accuracy score of test is  0.6807762330605989\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.3539999999999999\n",
      "threshold:0.2, J-value:0.22200000000000003\n",
      "threshold:0.30000000000000004, J-value:0.095\n",
      "threshold:0.4, J-value:0.003\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6772603977989657\n",
      "Balanced accuracy score of test is  0.6753775345313455\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.346\n",
      "threshold:0.2, J-value:0.22699999999999998\n",
      "threshold:0.30000000000000004, J-value:0.10500000000000001\n",
      "threshold:0.4, J-value:0.002\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6727718127556837\n",
      "Balanced accuracy score of test is  0.6784891235848041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positive rate of class 1 is  0.689\n",
      "True positive rate of class 2 is  0.615\n",
      "Positive prediction rate of class 1 is  0.378\n",
      "Positive prediction rate of class 2 is  0.286\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.397\n",
      "threshold:0.2, J-value:0.27299999999999996\n",
      "threshold:0.30000000000000004, J-value:0.14400000000000002\n",
      "threshold:0.4, J-value:0.058\n",
      "threshold:0.5, J-value:0.018000000000000002\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6985208592692214\n",
      "Balanced accuracy score of test is  0.7095885555017998\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.383\n",
      "threshold:0.2, J-value:0.278\n",
      "threshold:0.30000000000000004, J-value:0.158\n",
      "threshold:0.4, J-value:0.061\n",
      "threshold:0.5, J-value:0.022\n",
      "threshold:0.6000000000000001, J-value:0.005\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6917628125212503\n",
      "Balanced accuracy score of test is  0.7062910264051465\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.389\n",
      "threshold:0.2, J-value:0.261\n",
      "threshold:0.30000000000000004, J-value:0.131\n",
      "threshold:0.4, J-value:0.055\n",
      "threshold:0.5, J-value:0.013\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6942847897525317\n",
      "Balanced accuracy score of test is  0.7018013641642782\n",
      "True positive rate of class 1 is  0.766\n",
      "True positive rate of class 2 is  0.628\n",
      "Positive prediction rate of class 1 is  0.399\n",
      "Positive prediction rate of class 2 is  0.256\n",
      "X train 65694\n",
      "Y train 65694\n",
      "21898 7842 14056\n",
      "21898 7842 14056\n",
      "21898 7759 14139\n",
      "21898 7759 14139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2631517264955017\n",
      "0.25484997974541185\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.95     20006\n",
      "           1       0.39      0.03      0.06      1892\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.65      0.51      0.51     21898\n",
      "weighted avg       0.87      0.91      0.88     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19906   100]\n",
      " [ 1828    64]]\n",
      "done in 0.486123s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2631517264955017\n",
      "0.25647906239900653\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.95     19975\n",
      "           1       0.47      0.04      0.08      1923\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.69      0.52      0.51     21898\n",
      "weighted avg       0.88      0.91      0.88     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19885    90]\n",
      " [ 1844    79]]\n",
      "done in 0.478516s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2631517264955017\n",
      "0.29105907511637935\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94      7042\n",
      "           1       0.33      0.04      0.07       800\n",
      "\n",
      "    accuracy                           0.89      7842\n",
      "   macro avg       0.62      0.52      0.51      7842\n",
      "weighted avg       0.84      0.89      0.85      7842\n",
      "\n",
      "Confusion_matrix\n",
      "[[6977   65]\n",
      " [ 768   32]]\n",
      "done in 0.498561s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2631517264955017\n",
      "0.2916956708205887\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94      6943\n",
      "           1       0.46      0.05      0.10       816\n",
      "\n",
      "    accuracy                           0.89      7759\n",
      "   macro avg       0.68      0.52      0.52      7759\n",
      "weighted avg       0.85      0.89      0.85      7759\n",
      "\n",
      "Confusion_matrix\n",
      "[[6892   51]\n",
      " [ 772   44]]\n",
      "done in 0.508013s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2631517264955017\n",
      "0.23464851945093776\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12964\n",
      "           1       0.48      0.03      0.06      1092\n",
      "\n",
      "    accuracy                           0.92     14056\n",
      "   macro avg       0.70      0.51      0.51     14056\n",
      "weighted avg       0.89      0.92      0.89     14056\n",
      "\n",
      "Confusion_matrix\n",
      "[[12929    35]\n",
      " [ 1060    32]]\n",
      "done in 0.494668s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2631517264955017\n",
      "0.23715339122402557\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13032\n",
      "           1       0.47      0.03      0.06      1107\n",
      "\n",
      "    accuracy                           0.92     14139\n",
      "   macro avg       0.70      0.51      0.51     14139\n",
      "weighted avg       0.89      0.92      0.89     14139\n",
      "\n",
      "Confusion_matrix\n",
      "[[12993    39]\n",
      " [ 1072    35]]\n",
      "done in 0.510602s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     20006\n",
      "           1       0.73      0.00      0.01      1892\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.82      0.50      0.48     21898\n",
      "weighted avg       0.90      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[20003     3]\n",
      " [ 1884     8]]\n",
      "done in 17.330381s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19975\n",
      "           1       0.40      0.00      0.00      1923\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.66      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19972     3]\n",
      " [ 1921     2]]\n",
      "done in 17.155560s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      7042\n",
      "           1       0.50      0.00      0.00       800\n",
      "\n",
      "    accuracy                           0.90      7842\n",
      "   macro avg       0.70      0.50      0.48      7842\n",
      "weighted avg       0.86      0.90      0.85      7842\n",
      "\n",
      "Confusion_matrix\n",
      "[[7040    2]\n",
      " [ 798    2]]\n",
      "done in 16.766556s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.94      6943\n",
      "           1       0.43      0.00      0.01       816\n",
      "\n",
      "    accuracy                           0.89      7759\n",
      "   macro avg       0.66      0.50      0.48      7759\n",
      "weighted avg       0.85      0.89      0.85      7759\n",
      "\n",
      "Confusion_matrix\n",
      "[[6939    4]\n",
      " [ 813    3]]\n",
      "done in 17.007578s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12964\n",
      "           1       0.50      0.00      0.00      1092\n",
      "\n",
      "    accuracy                           0.92     14056\n",
      "   macro avg       0.71      0.50      0.48     14056\n",
      "weighted avg       0.89      0.92      0.89     14056\n",
      "\n",
      "Confusion_matrix\n",
      "[[12962     2]\n",
      " [ 1090     2]]\n",
      "done in 17.198463s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13032\n",
      "           1       0.40      0.00      0.00      1107\n",
      "\n",
      "    accuracy                           0.92     14139\n",
      "   macro avg       0.66      0.50      0.48     14139\n",
      "weighted avg       0.88      0.92      0.88     14139\n",
      "\n",
      "Confusion_matrix\n",
      "[[13029     3]\n",
      " [ 1105     2]]\n",
      "done in 17.078194s\n",
      "0.2682128952371694\n",
      "0.2638709963739227\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     20006\n",
      "           1       0.56      0.00      0.01      1892\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.74      0.50      0.48     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19999     7]\n",
      " [ 1883     9]]\n",
      "done in 0.559044s\n",
      "0.2682128952371694\n",
      "0.26619820202997585\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19975\n",
      "           1       0.56      0.00      0.01      1923\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.74      0.50      0.48     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19968     7]\n",
      " [ 1914     9]]\n",
      "done in 0.580517s\n",
      "0.2682128952371694\n",
      "0.29869111392486253\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      7042\n",
      "           1       0.60      0.00      0.01       800\n",
      "\n",
      "    accuracy                           0.90      7842\n",
      "   macro avg       0.75      0.50      0.48      7842\n",
      "weighted avg       0.87      0.90      0.85      7842\n",
      "\n",
      "Confusion_matrix\n",
      "[[7040    2]\n",
      " [ 797    3]]\n",
      "done in 0.556725s\n",
      "0.2682128952371694\n",
      "0.3058807672332038\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.94      6943\n",
      "           1       0.50      0.00      0.01       816\n",
      "\n",
      "    accuracy                           0.89      7759\n",
      "   macro avg       0.70      0.50      0.48      7759\n",
      "weighted avg       0.85      0.89      0.85      7759\n",
      "\n",
      "Confusion_matrix\n",
      "[[6940    3]\n",
      " [ 813    3]]\n",
      "done in 0.546515s\n",
      "0.2682128952371694\n",
      "0.24444446237886935\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12964\n",
      "           1       0.55      0.01      0.01      1092\n",
      "\n",
      "    accuracy                           0.92     14056\n",
      "   macro avg       0.73      0.50      0.49     14056\n",
      "weighted avg       0.89      0.92      0.89     14056\n",
      "\n",
      "Confusion_matrix\n",
      "[[12959     5]\n",
      " [ 1086     6]]\n",
      "done in 0.549247s\n",
      "0.2682128952371694\n",
      "0.24442176639719798\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13032\n",
      "           1       0.60      0.01      0.01      1107\n",
      "\n",
      "    accuracy                           0.92     14139\n",
      "   macro avg       0.76      0.50      0.49     14139\n",
      "weighted avg       0.90      0.92      0.89     14139\n",
      "\n",
      "Confusion_matrix\n",
      "[[13028     4]\n",
      " [ 1101     6]]\n",
      "done in 0.547757s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     20006\n",
      "           1       0.36      0.02      0.04      1892\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.64      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19943    63]\n",
      " [ 1856    36]]\n",
      "done in 30.420282s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19975\n",
      "           1       0.47      0.02      0.05      1923\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.69      0.51      0.50     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19923    52]\n",
      " [ 1876    47]]\n",
      "done in 30.542794s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94      7042\n",
      "           1       0.36      0.03      0.05       800\n",
      "\n",
      "    accuracy                           0.90      7842\n",
      "   macro avg       0.63      0.51      0.50      7842\n",
      "weighted avg       0.84      0.90      0.85      7842\n",
      "\n",
      "Confusion_matrix\n",
      "[[7004   38]\n",
      " [ 779   21]]\n",
      "done in 30.154401s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.94      6943\n",
      "           1       0.43      0.03      0.05       816\n",
      "\n",
      "    accuracy                           0.89      7759\n",
      "   macro avg       0.66      0.51      0.50      7759\n",
      "weighted avg       0.85      0.89      0.85      7759\n",
      "\n",
      "Confusion_matrix\n",
      "[[6914   29]\n",
      " [ 794   22]]\n",
      "done in 30.407280s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12964\n",
      "           1       0.38      0.01      0.03      1092\n",
      "\n",
      "    accuracy                           0.92     14056\n",
      "   macro avg       0.65      0.51      0.49     14056\n",
      "weighted avg       0.88      0.92      0.89     14056\n",
      "\n",
      "Confusion_matrix\n",
      "[[12939    25]\n",
      " [ 1077    15]]\n",
      "done in 30.123734s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13032\n",
      "           1       0.49      0.02      0.04      1107\n",
      "\n",
      "    accuracy                           0.92     14139\n",
      "   macro avg       0.71      0.51      0.50     14139\n",
      "weighted avg       0.89      0.92      0.89     14139\n",
      "\n",
      "Confusion_matrix\n",
      "[[13006    26]\n",
      " [ 1082    25]]\n",
      "done in 29.988141s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.402\n",
      "threshold:0.2, J-value:0.262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.30000000000000004, J-value:0.148\n",
      "threshold:0.4, J-value:0.069\n",
      "threshold:0.5, J-value:0.029\n",
      "threshold:0.6000000000000001, J-value:0.011\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7010668469649379\n",
      "Balanced accuracy score of test is  0.7041008488900258\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.38\n",
      "threshold:0.2, J-value:0.28099999999999997\n",
      "threshold:0.30000000000000004, J-value:0.16999999999999998\n",
      "threshold:0.4, J-value:0.08\n",
      "threshold:0.5, J-value:0.031\n",
      "threshold:0.6000000000000001, J-value:0.015\n",
      "threshold:0.7000000000000001, J-value:0.003\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6900505893212155\n",
      "Balanced accuracy score of test is  0.6991381854484556\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.401\n",
      "threshold:0.2, J-value:0.242\n",
      "threshold:0.30000000000000004, J-value:0.13\n",
      "threshold:0.4, J-value:0.060000000000000005\n",
      "threshold:0.5, J-value:0.026000000000000002\n",
      "threshold:0.6000000000000001, J-value:0.008\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7002943061258396\n",
      "Balanced accuracy score of test is  0.6986395589094012\n",
      "True positive rate of class 1 is  0.748\n",
      "True positive rate of class 2 is  0.61\n",
      "Positive prediction rate of class 1 is  0.391\n",
      "Positive prediction rate of class 2 is  0.244\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.393\n",
      "threshold:0.2, J-value:0.291\n",
      "threshold:0.30000000000000004, J-value:0.11000000000000001\n",
      "threshold:0.4, J-value:0.029\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6965169962753246\n",
      "Balanced accuracy score of test is  0.6954556820570694\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.36899999999999994\n",
      "threshold:0.2, J-value:0.30700000000000005\n",
      "threshold:0.30000000000000004, J-value:0.127\n",
      "threshold:0.4, J-value:0.027000000000000003\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.684097912524851\n",
      "Balanced accuracy score of test is  0.6935214583456888\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.40599999999999997\n",
      "threshold:0.2, J-value:0.271\n",
      "threshold:0.30000000000000004, J-value:0.107\n",
      "threshold:0.4, J-value:0.025\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7028764072500573\n",
      "Balanced accuracy score of test is  0.6941615260996072\n",
      "True positive rate of class 1 is  0.82\n",
      "True positive rate of class 2 is  0.692\n",
      "Positive prediction rate of class 1 is  0.474\n",
      "Positive prediction rate of class 2 is  0.334\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.35400000000000004\n",
      "threshold:0.2, J-value:0.215\n",
      "threshold:0.30000000000000004, J-value:0.053000000000000005\n",
      "threshold:0.4, J-value:0.049999999999999996\n",
      "threshold:0.5, J-value:0.005\n",
      "threshold:0.6000000000000001, J-value:0.005\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.001\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6772188480876455\n",
      "Balanced accuracy score of test is  0.6904182620371148\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.33399999999999996\n",
      "threshold:0.2, J-value:0.23099999999999998\n",
      "threshold:0.30000000000000004, J-value:0.059\n",
      "threshold:0.4, J-value:0.056999999999999995\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.004\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6671833285998297\n",
      "Balanced accuracy score of test is  0.6824183547825007\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.36100000000000004\n",
      "threshold:0.2, J-value:0.197\n",
      "threshold:0.30000000000000004, J-value:0.047\n",
      "threshold:0.4, J-value:0.043000000000000003\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.005\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.001\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6804246869041686\n",
      "Balanced accuracy score of test is  0.6933835786332081\n",
      "True positive rate of class 1 is  0.723\n",
      "True positive rate of class 2 is  0.701\n",
      "Positive prediction rate of class 1 is  0.397\n",
      "Positive prediction rate of class 2 is  0.345\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.4119999999999999\n",
      "threshold:0.2, J-value:0.265\n",
      "threshold:0.30000000000000004, J-value:0.149\n",
      "threshold:0.4, J-value:0.06199999999999999\n",
      "threshold:0.5, J-value:0.016\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.705811168911483\n",
      "Balanced accuracy score of test is  0.7052590829540566\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.4\n",
      "threshold:0.2, J-value:0.285\n",
      "threshold:0.30000000000000004, J-value:0.16299999999999998\n",
      "threshold:0.4, J-value:0.071\n",
      "threshold:0.5, J-value:0.020999999999999998\n",
      "threshold:0.6000000000000001, J-value:0.004\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6999234947458108\n",
      "Balanced accuracy score of test is  0.7037191677045296\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.405\n",
      "threshold:0.2, J-value:0.245\n",
      "threshold:0.30000000000000004, J-value:0.136\n",
      "threshold:0.4, J-value:0.054\n",
      "threshold:0.5, J-value:0.012\n",
      "threshold:0.6000000000000001, J-value:0.002\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.702099106796731\n",
      "Balanced accuracy score of test is  0.6986164762660518\n",
      "True positive rate of class 1 is  0.763\n",
      "True positive rate of class 2 is  0.636\n",
      "Positive prediction rate of class 1 is  0.399\n",
      "Positive prediction rate of class 2 is  0.27\n",
      "X train 65694\n",
      "Y train 65694\n",
      "21898 7814 14084\n",
      "21898 7814 14084\n",
      "21898 7778 14120\n",
      "21898 7778 14120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2586404020735353\n",
      "0.2639917869176803\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19911\n",
      "           1       0.43      0.03      0.06      1987\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19820    91]\n",
      " [ 1919    68]]\n",
      "done in 0.485461s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2586404020735353\n",
      "0.2609678507142087\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19927\n",
      "           1       0.45      0.03      0.06      1971\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.51      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19851    76]\n",
      " [ 1910    61]]\n",
      "done in 0.503640s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2586404020735353\n",
      "0.29710870079052865\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94      6979\n",
      "           1       0.39      0.03      0.06       835\n",
      "\n",
      "    accuracy                           0.89      7814\n",
      "   macro avg       0.64      0.51      0.50      7814\n",
      "weighted avg       0.84      0.89      0.85      7814\n",
      "\n",
      "Confusion_matrix\n",
      "[[6935   44]\n",
      " [ 807   28]]\n",
      "done in 0.468153s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2586404020735353\n",
      "0.3022687616568602\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94      6927\n",
      "           1       0.46      0.04      0.07       851\n",
      "\n",
      "    accuracy                           0.89      7778\n",
      "   macro avg       0.68      0.52      0.51      7778\n",
      "weighted avg       0.85      0.89      0.85      7778\n",
      "\n",
      "Confusion_matrix\n",
      "[[6889   38]\n",
      " [ 818   33]]\n",
      "done in 0.472609s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2586404020735353\n",
      "0.24561806034835085\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12932\n",
      "           1       0.46      0.03      0.06      1152\n",
      "\n",
      "    accuracy                           0.92     14084\n",
      "   macro avg       0.69      0.52      0.51     14084\n",
      "weighted avg       0.88      0.92      0.88     14084\n",
      "\n",
      "Confusion_matrix\n",
      "[[12885    47]\n",
      " [ 1112    40]]\n",
      "done in 0.499983s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2586404020735353\n",
      "0.23821724977143652\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13000\n",
      "           1       0.42      0.03      0.05      1120\n",
      "\n",
      "    accuracy                           0.92     14120\n",
      "   macro avg       0.67      0.51      0.50     14120\n",
      "weighted avg       0.88      0.92      0.89     14120\n",
      "\n",
      "Confusion_matrix\n",
      "[[12962    38]\n",
      " [ 1092    28]]\n",
      "done in 0.484457s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19911\n",
      "           1       0.56      0.00      0.01      1987\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.73      0.50      0.48     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19907     4]\n",
      " [ 1982     5]]\n",
      "done in 16.981501s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19927\n",
      "           1       0.62      0.00      0.01      1971\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.77      0.50      0.48     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19924     3]\n",
      " [ 1966     5]]\n",
      "done in 17.407263s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6979\n",
      "           1       0.50      0.00      0.00       835\n",
      "\n",
      "    accuracy                           0.89      7814\n",
      "   macro avg       0.70      0.50      0.47      7814\n",
      "weighted avg       0.85      0.89      0.84      7814\n",
      "\n",
      "Confusion_matrix\n",
      "[[6977    2]\n",
      " [ 833    2]]\n",
      "done in 17.052488s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6927\n",
      "           1       1.00      0.00      0.00       851\n",
      "\n",
      "    accuracy                           0.89      7778\n",
      "   macro avg       0.95      0.50      0.47      7778\n",
      "weighted avg       0.90      0.89      0.84      7778\n",
      "\n",
      "Confusion_matrix\n",
      "[[6927    0]\n",
      " [ 849    2]]\n",
      "done in 17.166207s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12932\n",
      "           1       0.71      0.00      0.01      1152\n",
      "\n",
      "    accuracy                           0.92     14084\n",
      "   macro avg       0.82      0.50      0.48     14084\n",
      "weighted avg       0.90      0.92      0.88     14084\n",
      "\n",
      "Confusion_matrix\n",
      "[[12930     2]\n",
      " [ 1147     5]]\n",
      "done in 17.067550s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13000\n",
      "           1       0.75      0.00      0.01      1120\n",
      "\n",
      "    accuracy                           0.92     14120\n",
      "   macro avg       0.84      0.50      0.48     14120\n",
      "weighted avg       0.91      0.92      0.88     14120\n",
      "\n",
      "Confusion_matrix\n",
      "[[12999     1]\n",
      " [ 1117     3]]\n",
      "done in 17.164748s\n",
      "0.26445464621705217\n",
      "0.2702963274846509\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19911\n",
      "           1       0.32      0.00      0.01      1987\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.61      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19898    13]\n",
      " [ 1981     6]]\n",
      "done in 0.567993s\n",
      "0.26445464621705217\n",
      "0.26900537003743663\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19927\n",
      "           1       0.30      0.00      0.01      1971\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.61      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19913    14]\n",
      " [ 1965     6]]\n",
      "done in 0.569378s\n",
      "0.26445464621705217\n",
      "0.3046069296582728\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6979\n",
      "           1       0.08      0.00      0.00       835\n",
      "\n",
      "    accuracy                           0.89      7814\n",
      "   macro avg       0.49      0.50      0.47      7814\n",
      "weighted avg       0.81      0.89      0.84      7814\n",
      "\n",
      "Confusion_matrix\n",
      "[[6968   11]\n",
      " [ 834    1]]\n",
      "done in 0.542708s\n",
      "0.26445464621705217\n",
      "0.3102037177268921\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6927\n",
      "           1       0.22      0.00      0.01       851\n",
      "\n",
      "    accuracy                           0.89      7778\n",
      "   macro avg       0.56      0.50      0.48      7778\n",
      "weighted avg       0.82      0.89      0.84      7778\n",
      "\n",
      "Confusion_matrix\n",
      "[[6913   14]\n",
      " [ 847    4]]\n",
      "done in 0.545228s\n",
      "0.26445464621705217\n",
      "0.2512603259662838\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12932\n",
      "           1       0.71      0.00      0.01      1152\n",
      "\n",
      "    accuracy                           0.92     14084\n",
      "   macro avg       0.82      0.50      0.48     14084\n",
      "weighted avg       0.90      0.92      0.88     14084\n",
      "\n",
      "Confusion_matrix\n",
      "[[12930     2]\n",
      " [ 1147     5]]\n",
      "done in 0.552872s\n",
      "0.26445464621705217\n",
      "0.24631126604816012\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13000\n",
      "           1       1.00      0.00      0.00      1120\n",
      "\n",
      "    accuracy                           0.92     14120\n",
      "   macro avg       0.96      0.50      0.48     14120\n",
      "weighted avg       0.93      0.92      0.88     14120\n",
      "\n",
      "Confusion_matrix\n",
      "[[13000     0]\n",
      " [ 1118     2]]\n",
      "done in 0.552058s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19911\n",
      "           1       0.42      0.02      0.04      1987\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19856    55]\n",
      " [ 1947    40]]\n",
      "done in 30.068857s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19927\n",
      "           1       0.43      0.02      0.04      1971\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19879    48]\n",
      " [ 1935    36]]\n",
      "done in 30.900889s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6979\n",
      "           1       0.38      0.02      0.04       835\n",
      "\n",
      "    accuracy                           0.89      7814\n",
      "   macro avg       0.63      0.51      0.49      7814\n",
      "weighted avg       0.84      0.89      0.85      7814\n",
      "\n",
      "Confusion_matrix\n",
      "[[6949   30]\n",
      " [ 817   18]]\n",
      "done in 30.236475s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6927\n",
      "           1       0.44      0.02      0.05       851\n",
      "\n",
      "    accuracy                           0.89      7778\n",
      "   macro avg       0.67      0.51      0.49      7778\n",
      "weighted avg       0.84      0.89      0.84      7778\n",
      "\n",
      "Confusion_matrix\n",
      "[[6900   27]\n",
      " [ 830   21]]\n",
      "done in 29.991462s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12932\n",
      "           1       0.45      0.02      0.04      1152\n",
      "\n",
      "    accuracy                           0.92     14084\n",
      "   macro avg       0.68      0.51      0.50     14084\n",
      "weighted avg       0.88      0.92      0.88     14084\n",
      "\n",
      "Confusion_matrix\n",
      "[[12905    27]\n",
      " [ 1130    22]]\n",
      "done in 30.838589s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13000\n",
      "           1       0.42      0.01      0.03      1120\n",
      "\n",
      "    accuracy                           0.92     14120\n",
      "   macro avg       0.67      0.51      0.49     14120\n",
      "weighted avg       0.88      0.92      0.88     14120\n",
      "\n",
      "Confusion_matrix\n",
      "[[12979    21]\n",
      " [ 1105    15]]\n",
      "done in 29.879938s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.39\n",
      "threshold:0.2, J-value:0.248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.30000000000000004, J-value:0.145\n",
      "threshold:0.4, J-value:0.07\n",
      "threshold:0.5, J-value:0.029\n",
      "threshold:0.6000000000000001, J-value:0.013000000000000001\n",
      "threshold:0.7000000000000001, J-value:0.005\n",
      "threshold:0.8, J-value:0.002\n",
      "threshold:0.9, J-value:0.001\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6950035736531339\n",
      "Balanced accuracy score of test is  0.7058600268453218\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.39399999999999996\n",
      "threshold:0.2, J-value:0.279\n",
      "threshold:0.30000000000000004, J-value:0.15799999999999997\n",
      "threshold:0.4, J-value:0.074\n",
      "threshold:0.5, J-value:0.028000000000000004\n",
      "threshold:0.6000000000000001, J-value:0.012\n",
      "threshold:0.7000000000000001, J-value:0.005\n",
      "threshold:0.8, J-value:0.004\n",
      "threshold:0.9, J-value:0.001\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.697199125177071\n",
      "Balanced accuracy score of test is  0.6982385722382334\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.371\n",
      "threshold:0.2, J-value:0.21800000000000003\n",
      "threshold:0.30000000000000004, J-value:0.132\n",
      "threshold:0.4, J-value:0.065\n",
      "threshold:0.5, J-value:0.031000000000000003\n",
      "threshold:0.6000000000000001, J-value:0.012\n",
      "threshold:0.7000000000000001, J-value:0.006\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6855383501735575\n",
      "Balanced accuracy score of test is  0.7015398351648352\n",
      "True positive rate of class 1 is  0.734\n",
      "True positive rate of class 2 is  0.604\n",
      "Positive prediction rate of class 1 is  0.381\n",
      "Positive prediction rate of class 2 is  0.233\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.393\n",
      "threshold:0.2, J-value:0.277\n",
      "threshold:0.30000000000000004, J-value:0.11400000000000002\n",
      "threshold:0.4, J-value:0.025\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6962827941157477\n",
      "Balanced accuracy score of test is  0.7017157907946959\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.37100000000000005\n",
      "threshold:0.2, J-value:0.33299999999999996\n",
      "threshold:0.30000000000000004, J-value:0.121\n",
      "threshold:0.4, J-value:0.028000000000000004\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6852030857328186\n",
      "Balanced accuracy score of test is  0.6831187487033232\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.38100000000000006\n",
      "threshold:0.2, J-value:0.266\n",
      "threshold:0.30000000000000004, J-value:0.09\n",
      "threshold:0.4, J-value:0.018000000000000002\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6906239797058116\n",
      "Balanced accuracy score of test is  0.6976730769230769\n",
      "True positive rate of class 1 is  0.806\n",
      "True positive rate of class 2 is  0.688\n",
      "Positive prediction rate of class 1 is  0.48\n",
      "Positive prediction rate of class 2 is  0.324\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.348\n",
      "threshold:0.2, J-value:0.21099999999999997\n",
      "threshold:0.30000000000000004, J-value:0.11000000000000001\n",
      "threshold:0.4, J-value:0.007\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.002\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6740769195946623\n",
      "Balanced accuracy score of test is  0.6700628399696437\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.327\n",
      "threshold:0.2, J-value:0.216\n",
      "threshold:0.30000000000000004, J-value:0.10600000000000001\n",
      "threshold:0.4, J-value:0.008\n",
      "threshold:0.5, J-value:-0.001\n",
      "threshold:0.6000000000000001, J-value:-0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6637412665713136\n",
      "Balanced accuracy score of test is  0.6609305843022679\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.355\n",
      "threshold:0.2, J-value:0.20500000000000002\n",
      "threshold:0.30000000000000004, J-value:0.11200000000000002\n",
      "threshold:0.4, J-value:0.008\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.004\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6773265929477266\n",
      "Balanced accuracy score of test is  0.6721950549450549\n",
      "True positive rate of class 1 is  0.626\n",
      "True positive rate of class 2 is  0.584\n",
      "Positive prediction rate of class 1 is  0.34\n",
      "Positive prediction rate of class 2 is  0.267\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.405\n",
      "threshold:0.2, J-value:0.26399999999999996\n",
      "threshold:0.30000000000000004, J-value:0.138\n",
      "threshold:0.4, J-value:0.052\n",
      "threshold:0.5, J-value:0.017\n",
      "threshold:0.6000000000000001, J-value:0.008\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7026707069913556\n",
      "Balanced accuracy score of test is  0.7129174454796536\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.404\n",
      "threshold:0.2, J-value:0.279\n",
      "threshold:0.30000000000000004, J-value:0.149\n",
      "threshold:0.4, J-value:0.057999999999999996\n",
      "threshold:0.5, J-value:0.018\n",
      "threshold:0.6000000000000001, J-value:0.009999999999999998\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7017445836225529\n",
      "Balanced accuracy score of test is  0.7046061351237694\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.392\n",
      "threshold:0.2, J-value:0.248\n",
      "threshold:0.30000000000000004, J-value:0.127\n",
      "threshold:0.4, J-value:0.048\n",
      "threshold:0.5, J-value:0.017\n",
      "threshold:0.6000000000000001, J-value:0.007\n",
      "threshold:0.7000000000000001, J-value:0.003\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6957990192287864\n",
      "Balanced accuracy score of test is  0.7101442307692307\n",
      "True positive rate of class 1 is  0.761\n",
      "True positive rate of class 2 is  0.644\n",
      "Positive prediction rate of class 1 is  0.397\n",
      "Positive prediction rate of class 2 is  0.257\n",
      "X train 65694\n",
      "Y train 65694\n",
      "21898 7644 14254\n",
      "21898 7644 14254\n",
      "21898 7881 14017\n",
      "21898 7881 14017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2615249031494391\n",
      "0.2575706140794245\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19944\n",
      "           1       0.43      0.03      0.06      1954\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19861    83]\n",
      " [ 1891    63]]\n",
      "done in 0.521507s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2615249031494391\n",
      "0.25832616083809007\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19955\n",
      "           1       0.47      0.04      0.07      1943\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.69      0.52      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19876    79]\n",
      " [ 1873    70]]\n",
      "done in 0.513711s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2615249031494391\n",
      "0.30092177683801535\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94      6814\n",
      "           1       0.37      0.03      0.05       830\n",
      "\n",
      "    accuracy                           0.89      7644\n",
      "   macro avg       0.63      0.51      0.50      7644\n",
      "weighted avg       0.84      0.89      0.84      7644\n",
      "\n",
      "Confusion_matrix\n",
      "[[6774   40]\n",
      " [ 807   23]]\n",
      "done in 0.491605s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2615249031494391\n",
      "0.2959564312090811\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94      7022\n",
      "           1       0.45      0.04      0.08       859\n",
      "\n",
      "    accuracy                           0.89      7881\n",
      "   macro avg       0.67      0.52      0.51      7881\n",
      "weighted avg       0.85      0.89      0.85      7881\n",
      "\n",
      "Confusion_matrix\n",
      "[[6976   46]\n",
      " [ 821   38]]\n",
      "done in 0.527936s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2615249031494391\n",
      "0.234322663460183\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13130\n",
      "           1       0.48      0.04      0.07      1124\n",
      "\n",
      "    accuracy                           0.92     14254\n",
      "   macro avg       0.70      0.52      0.51     14254\n",
      "weighted avg       0.89      0.92      0.89     14254\n",
      "\n",
      "Confusion_matrix\n",
      "[[13087    43]\n",
      " [ 1084    40]]\n",
      "done in 0.555139s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2615249031494391\n",
      "0.23716869770091514\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12933\n",
      "           1       0.49      0.03      0.06      1084\n",
      "\n",
      "    accuracy                           0.92     14017\n",
      "   macro avg       0.71      0.51      0.51     14017\n",
      "weighted avg       0.89      0.92      0.89     14017\n",
      "\n",
      "Confusion_matrix\n",
      "[[12900    33]\n",
      " [ 1052    32]]\n",
      "done in 0.540990s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19944\n",
      "           1       0.56      0.00      0.01      1954\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.73      0.50      0.48     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19940     4]\n",
      " [ 1949     5]]\n",
      "done in 17.771721s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19955\n",
      "           1       0.42      0.00      0.01      1943\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.66      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19948     7]\n",
      " [ 1938     5]]\n",
      "done in 17.433125s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6814\n",
      "           1       0.57      0.00      0.01       830\n",
      "\n",
      "    accuracy                           0.89      7644\n",
      "   macro avg       0.73      0.50      0.48      7644\n",
      "weighted avg       0.86      0.89      0.84      7644\n",
      "\n",
      "Confusion_matrix\n",
      "[[6811    3]\n",
      " [ 826    4]]\n",
      "done in 16.610286s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      7022\n",
      "           1       0.50      0.01      0.01       859\n",
      "\n",
      "    accuracy                           0.89      7881\n",
      "   macro avg       0.70      0.50      0.48      7881\n",
      "weighted avg       0.85      0.89      0.84      7881\n",
      "\n",
      "Confusion_matrix\n",
      "[[7017    5]\n",
      " [ 854    5]]\n",
      "done in 16.985205s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13130\n",
      "           1       0.75      0.00      0.01      1124\n",
      "\n",
      "    accuracy                           0.92     14254\n",
      "   macro avg       0.84      0.50      0.48     14254\n",
      "weighted avg       0.91      0.92      0.88     14254\n",
      "\n",
      "Confusion_matrix\n",
      "[[13129     1]\n",
      " [ 1121     3]]\n",
      "done in 17.283087s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12933\n",
      "           1       0.40      0.00      0.00      1084\n",
      "\n",
      "    accuracy                           0.92     14017\n",
      "   macro avg       0.66      0.50      0.48     14017\n",
      "weighted avg       0.88      0.92      0.89     14017\n",
      "\n",
      "Confusion_matrix\n",
      "[[12930     3]\n",
      " [ 1082     2]]\n",
      "done in 17.424994s\n",
      "0.26691180010608717\n",
      "0.26804236350549815\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19944\n",
      "           1       0.34      0.01      0.03      1954\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.63      0.51      0.49     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19890    54]\n",
      " [ 1926    28]]\n",
      "done in 0.568786s\n",
      "0.26691180010608717\n",
      "0.2720697371491411\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19955\n",
      "           1       0.38      0.01      0.03      1943\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.65      0.51      0.49     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19909    46]\n",
      " [ 1915    28]]\n",
      "done in 0.568297s\n",
      "0.26691180010608717\n",
      "0.31258487389502215\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6814\n",
      "           1       0.35      0.01      0.03       830\n",
      "\n",
      "    accuracy                           0.89      7644\n",
      "   macro avg       0.62      0.51      0.48      7644\n",
      "weighted avg       0.83      0.89      0.84      7644\n",
      "\n",
      "Confusion_matrix\n",
      "[[6794   20]\n",
      " [ 819   11]]\n",
      "done in 0.548969s\n",
      "0.26691180010608717\n",
      "0.3138185118268663\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      7022\n",
      "           1       0.37      0.01      0.02       859\n",
      "\n",
      "    accuracy                           0.89      7881\n",
      "   macro avg       0.63      0.51      0.48      7881\n",
      "weighted avg       0.83      0.89      0.84      7881\n",
      "\n",
      "Confusion_matrix\n",
      "[[7003   19]\n",
      " [ 848   11]]\n",
      "done in 0.545070s\n",
      "0.26691180010608717\n",
      "0.2441555282720534\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13130\n",
      "           1       0.33      0.02      0.03      1124\n",
      "\n",
      "    accuracy                           0.92     14254\n",
      "   macro avg       0.63      0.51      0.49     14254\n",
      "weighted avg       0.88      0.92      0.88     14254\n",
      "\n",
      "Confusion_matrix\n",
      "[[13096    34]\n",
      " [ 1107    17]]\n",
      "done in 0.558471s\n",
      "0.26691180010608717\n",
      "0.24859666208064193\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12933\n",
      "           1       0.39      0.02      0.03      1084\n",
      "\n",
      "    accuracy                           0.92     14017\n",
      "   macro avg       0.66      0.51      0.49     14017\n",
      "weighted avg       0.88      0.92      0.89     14017\n",
      "\n",
      "Confusion_matrix\n",
      "[[12906    27]\n",
      " [ 1067    17]]\n",
      "done in 0.597516s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19944\n",
      "           1       0.44      0.01      0.03      1954\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19909    35]\n",
      " [ 1927    27]]\n",
      "done in 30.457657s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19955\n",
      "           1       0.54      0.02      0.03      1943\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.73      0.51      0.49     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19925    30]\n",
      " [ 1908    35]]\n",
      "done in 30.997172s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6814\n",
      "           1       0.42      0.01      0.03       830\n",
      "\n",
      "    accuracy                           0.89      7644\n",
      "   macro avg       0.66      0.51      0.48      7644\n",
      "weighted avg       0.84      0.89      0.84      7644\n",
      "\n",
      "Confusion_matrix\n",
      "[[6799   15]\n",
      " [ 819   11]]\n",
      "done in 30.630745s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      7022\n",
      "           1       0.53      0.02      0.04       859\n",
      "\n",
      "    accuracy                           0.89      7881\n",
      "   macro avg       0.71      0.51      0.49      7881\n",
      "weighted avg       0.85      0.89      0.84      7881\n",
      "\n",
      "Confusion_matrix\n",
      "[[7007   15]\n",
      " [ 842   17]]\n",
      "done in 30.380851s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13130\n",
      "           1       0.44      0.01      0.03      1124\n",
      "\n",
      "    accuracy                           0.92     14254\n",
      "   macro avg       0.68      0.51      0.49     14254\n",
      "weighted avg       0.88      0.92      0.89     14254\n",
      "\n",
      "Confusion_matrix\n",
      "[[13110    20]\n",
      " [ 1108    16]]\n",
      "done in 30.084567s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12933\n",
      "           1       0.56      0.02      0.03      1084\n",
      "\n",
      "    accuracy                           0.92     14017\n",
      "   macro avg       0.74      0.51      0.50     14017\n",
      "weighted avg       0.90      0.92      0.89     14017\n",
      "\n",
      "Confusion_matrix\n",
      "[[12919    14]\n",
      " [ 1066    18]]\n",
      "done in 30.139381s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41400000000000003\n",
      "threshold:0.2, J-value:0.26599999999999996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.30000000000000004, J-value:0.143\n",
      "threshold:0.4, J-value:0.07\n",
      "threshold:0.5, J-value:0.028\n",
      "threshold:0.6000000000000001, J-value:0.011\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.707055317837745\n",
      "Balanced accuracy score of test is  0.7037223485214352\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.37999999999999995\n",
      "threshold:0.2, J-value:0.273\n",
      "threshold:0.30000000000000004, J-value:0.15\n",
      "threshold:0.4, J-value:0.072\n",
      "threshold:0.5, J-value:0.022\n",
      "threshold:0.6000000000000001, J-value:0.005\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6896481729677737\n",
      "Balanced accuracy score of test is  0.7129755012435555\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.42100000000000004\n",
      "threshold:0.2, J-value:0.253\n",
      "threshold:0.30000000000000004, J-value:0.135\n",
      "threshold:0.4, J-value:0.068\n",
      "threshold:0.5, J-value:0.032999999999999995\n",
      "threshold:0.6000000000000001, J-value:0.015\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7108996267817309\n",
      "Balanced accuracy score of test is  0.6866901384741056\n",
      "True positive rate of class 1 is  0.76\n",
      "True positive rate of class 2 is  0.588\n",
      "Positive prediction rate of class 1 is  0.381\n",
      "Positive prediction rate of class 2 is  0.243\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.398\n",
      "threshold:0.2, J-value:0.277\n",
      "threshold:0.30000000000000004, J-value:0.10300000000000001\n",
      "threshold:0.4, J-value:0.02\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6987833333538617\n",
      "Balanced accuracy score of test is  0.6920715717415136\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.36300000000000004\n",
      "threshold:0.2, J-value:0.275\n",
      "threshold:0.30000000000000004, J-value:0.11299999999999999\n",
      "threshold:0.4, J-value:0.018\n",
      "threshold:0.5, J-value:0.005\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6817882035921791\n",
      "Balanced accuracy score of test is  0.6965577833046912\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.40599999999999997\n",
      "threshold:0.2, J-value:0.269\n",
      "threshold:0.30000000000000004, J-value:0.093\n",
      "threshold:0.4, J-value:0.014\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7025797323778367\n",
      "Balanced accuracy score of test is  0.6916151094357151\n",
      "True positive rate of class 1 is  0.823\n",
      "True positive rate of class 2 is  0.689\n",
      "Positive prediction rate of class 1 is  0.473\n",
      "Positive prediction rate of class 2 is  0.336\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.364\n",
      "threshold:0.2, J-value:0.23500000000000001\n",
      "threshold:0.30000000000000004, J-value:0.143\n",
      "threshold:0.4, J-value:0.011\n",
      "threshold:0.5, J-value:0.011\n",
      "threshold:0.6000000000000001, J-value:0.002\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6823207591286309\n",
      "Balanced accuracy score of test is  0.6769141788788026\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.336\n",
      "threshold:0.2, J-value:0.21800000000000003\n",
      "threshold:0.30000000000000004, J-value:0.141\n",
      "threshold:0.4, J-value:0.009999999999999998\n",
      "threshold:0.5, J-value:0.009999999999999998\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6678703661137063\n",
      "Balanced accuracy score of test is  0.6804924420141056\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.378\n",
      "threshold:0.2, J-value:0.245\n",
      "threshold:0.30000000000000004, J-value:0.144\n",
      "threshold:0.4, J-value:0.012\n",
      "threshold:0.5, J-value:0.012\n",
      "threshold:0.6000000000000001, J-value:0.004\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6892697714885094\n",
      "Balanced accuracy score of test is  0.6711030280100991\n",
      "True positive rate of class 1 is  0.659\n",
      "True positive rate of class 2 is  0.603\n",
      "Positive prediction rate of class 1 is  0.337\n",
      "Positive prediction rate of class 2 is  0.288\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.42799999999999994\n",
      "threshold:0.2, J-value:0.27299999999999996\n",
      "threshold:0.30000000000000004, J-value:0.138\n",
      "threshold:0.4, J-value:0.044\n",
      "threshold:0.5, J-value:0.012\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7139303766000277\n",
      "Balanced accuracy score of test is  0.7088256219313838\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.393\n",
      "threshold:0.2, J-value:0.271\n",
      "threshold:0.30000000000000004, J-value:0.154\n",
      "threshold:0.4, J-value:0.043\n",
      "threshold:0.5, J-value:0.011\n",
      "threshold:0.6000000000000001, J-value:0.004\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.696740940869436\n",
      "Balanced accuracy score of test is  0.7156914788678457\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.43500000000000005\n",
      "threshold:0.2, J-value:0.268\n",
      "threshold:0.30000000000000004, J-value:0.12499999999999999\n",
      "threshold:0.4, J-value:0.044\n",
      "threshold:0.5, J-value:0.012\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7176861958027174\n",
      "Balanced accuracy score of test is  0.6941993193418364\n",
      "True positive rate of class 1 is  0.781\n",
      "True positive rate of class 2 is  0.625\n",
      "Positive prediction rate of class 1 is  0.397\n",
      "Positive prediction rate of class 2 is  0.266\n",
      "X train 65694\n",
      "Y train 65694\n",
      "21898 7795 14103\n",
      "21898 7795 14103\n",
      "21898 7762 14136\n",
      "21898 7762 14136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25825949338863036\n",
      "0.2633059221721374\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19893\n",
      "           1       0.41      0.03      0.06      2005\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.66      0.51      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19795    98]\n",
      " [ 1936    69]]\n",
      "done in 0.506978s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25825949338863036\n",
      "0.2622847363281984\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19907\n",
      "           1       0.48      0.03      0.06      1991\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.70      0.52      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19833    74]\n",
      " [ 1922    69]]\n",
      "done in 0.497473s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25825949338863036\n",
      "0.305337048163835\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94      6922\n",
      "           1       0.36      0.03      0.06       873\n",
      "\n",
      "    accuracy                           0.89      7795\n",
      "   macro avg       0.62      0.51      0.50      7795\n",
      "weighted avg       0.83      0.89      0.84      7795\n",
      "\n",
      "Confusion_matrix\n",
      "[[6873   49]\n",
      " [ 846   27]]\n",
      "done in 0.502500s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25825949338863036\n",
      "0.3055214423807388\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94      6882\n",
      "           1       0.50      0.04      0.07       880\n",
      "\n",
      "    accuracy                           0.89      7762\n",
      "   macro avg       0.70      0.52      0.51      7762\n",
      "weighted avg       0.85      0.89      0.84      7762\n",
      "\n",
      "Confusion_matrix\n",
      "[[6847   35]\n",
      " [ 845   35]]\n",
      "done in 0.506315s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25825949338863036\n",
      "0.24007450849382184\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12971\n",
      "           1       0.46      0.04      0.07      1132\n",
      "\n",
      "    accuracy                           0.92     14103\n",
      "   macro avg       0.69      0.52      0.51     14103\n",
      "weighted avg       0.89      0.92      0.89     14103\n",
      "\n",
      "Confusion_matrix\n",
      "[[12922    49]\n",
      " [ 1090    42]]\n",
      "done in 0.477336s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25825949338863036\n",
      "0.2385436983839553\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13025\n",
      "           1       0.47      0.03      0.06      1111\n",
      "\n",
      "    accuracy                           0.92     14136\n",
      "   macro avg       0.69      0.51      0.51     14136\n",
      "weighted avg       0.89      0.92      0.89     14136\n",
      "\n",
      "Confusion_matrix\n",
      "[[12986    39]\n",
      " [ 1077    34]]\n",
      "done in 0.477304s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19893\n",
      "           1       0.79      0.01      0.01      2005\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.85      0.50      0.48     21898\n",
      "weighted avg       0.90      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19890     3]\n",
      " [ 1994    11]]\n",
      "done in 17.024088s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19907\n",
      "           1       0.20      0.00      0.00      1991\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.55      0.50      0.48     21898\n",
      "weighted avg       0.84      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19899     8]\n",
      " [ 1989     2]]\n",
      "done in 16.974108s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6922\n",
      "           1       0.40      0.00      0.00       873\n",
      "\n",
      "    accuracy                           0.89      7795\n",
      "   macro avg       0.64      0.50      0.47      7795\n",
      "weighted avg       0.83      0.89      0.84      7795\n",
      "\n",
      "Confusion_matrix\n",
      "[[6919    3]\n",
      " [ 871    2]]\n",
      "done in 16.686738s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6882\n",
      "           1       0.50      0.00      0.00       880\n",
      "\n",
      "    accuracy                           0.89      7762\n",
      "   macro avg       0.69      0.50      0.47      7762\n",
      "weighted avg       0.84      0.89      0.83      7762\n",
      "\n",
      "Confusion_matrix\n",
      "[[6881    1]\n",
      " [ 879    1]]\n",
      "done in 16.604954s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12971\n",
      "           1       0.50      0.00      0.01      1132\n",
      "\n",
      "    accuracy                           0.92     14103\n",
      "   macro avg       0.71      0.50      0.48     14103\n",
      "weighted avg       0.89      0.92      0.88     14103\n",
      "\n",
      "Confusion_matrix\n",
      "[[12966     5]\n",
      " [ 1127     5]]\n",
      "done in 16.811359s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13025\n",
      "           1       0.29      0.00      0.00      1111\n",
      "\n",
      "    accuracy                           0.92     14136\n",
      "   macro avg       0.60      0.50      0.48     14136\n",
      "weighted avg       0.87      0.92      0.88     14136\n",
      "\n",
      "Confusion_matrix\n",
      "[[13020     5]\n",
      " [ 1109     2]]\n",
      "done in 16.686277s\n",
      "0.2638844630577774\n",
      "0.27072063991639456\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19893\n",
      "           1       0.08      0.00      0.00      2005\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.50      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.86     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19882    11]\n",
      " [ 2004     1]]\n",
      "done in 0.550704s\n",
      "0.2638844630577774\n",
      "0.27224900833516935\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19907\n",
      "           1       0.33      0.00      0.00      1991\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.62      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19903     4]\n",
      " [ 1989     2]]\n",
      "done in 0.549271s\n",
      "0.2638844630577774\n",
      "0.3143419511293864\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6922\n",
      "           1       0.00      0.00      0.00       873\n",
      "\n",
      "    accuracy                           0.89      7795\n",
      "   macro avg       0.44      0.50      0.47      7795\n",
      "weighted avg       0.79      0.89      0.84      7795\n",
      "\n",
      "Confusion_matrix\n",
      "[[6918    4]\n",
      " [ 873    0]]\n",
      "done in 0.533958s\n",
      "0.2638844630577774\n",
      "0.3212229532607184\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6882\n",
      "           1       0.00      0.00      0.00       880\n",
      "\n",
      "    accuracy                           0.89      7762\n",
      "   macro avg       0.44      0.50      0.47      7762\n",
      "weighted avg       0.79      0.89      0.83      7762\n",
      "\n",
      "Confusion_matrix\n",
      "[[6880    2]\n",
      " [ 880    0]]\n",
      "done in 0.535290s\n",
      "0.2638844630577774\n",
      "0.2466103002081572\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12971\n",
      "           1       0.12      0.00      0.00      1132\n",
      "\n",
      "    accuracy                           0.92     14103\n",
      "   macro avg       0.52      0.50      0.48     14103\n",
      "weighted avg       0.86      0.92      0.88     14103\n",
      "\n",
      "Confusion_matrix\n",
      "[[12964     7]\n",
      " [ 1131     1]]\n",
      "done in 0.539524s\n",
      "0.2638844630577774\n",
      "0.2477867512488837\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13025\n",
      "           1       0.40      0.00      0.00      1111\n",
      "\n",
      "    accuracy                           0.92     14136\n",
      "   macro avg       0.66      0.50      0.48     14136\n",
      "weighted avg       0.88      0.92      0.88     14136\n",
      "\n",
      "Confusion_matrix\n",
      "[[13022     3]\n",
      " [ 1109     2]]\n",
      "done in 0.540021s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19893\n",
      "           1       0.46      0.02      0.04      2005\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.51      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19846    47]\n",
      " [ 1965    40]]\n",
      "done in 29.744303s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19907\n",
      "           1       0.51      0.02      0.03      1991\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.71      0.51      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19874    33]\n",
      " [ 1957    34]]\n",
      "done in 30.077979s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6922\n",
      "           1       0.50      0.02      0.04       873\n",
      "\n",
      "    accuracy                           0.89      7795\n",
      "   macro avg       0.69      0.51      0.49      7795\n",
      "weighted avg       0.85      0.89      0.84      7795\n",
      "\n",
      "Confusion_matrix\n",
      "[[6906   16]\n",
      " [ 857   16]]\n",
      "done in 29.760007s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6882\n",
      "           1       0.49      0.02      0.04       880\n",
      "\n",
      "    accuracy                           0.89      7762\n",
      "   macro avg       0.69      0.51      0.49      7762\n",
      "weighted avg       0.84      0.89      0.84      7762\n",
      "\n",
      "Confusion_matrix\n",
      "[[6863   19]\n",
      " [ 862   18]]\n",
      "done in 29.804198s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12971\n",
      "           1       0.44      0.02      0.04      1132\n",
      "\n",
      "    accuracy                           0.92     14103\n",
      "   macro avg       0.68      0.51      0.50     14103\n",
      "weighted avg       0.88      0.92      0.88     14103\n",
      "\n",
      "Confusion_matrix\n",
      "[[12940    31]\n",
      " [ 1108    24]]\n",
      "done in 29.823202s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13025\n",
      "           1       0.53      0.01      0.03      1111\n",
      "\n",
      "    accuracy                           0.92     14136\n",
      "   macro avg       0.73      0.51      0.49     14136\n",
      "weighted avg       0.89      0.92      0.89     14136\n",
      "\n",
      "Confusion_matrix\n",
      "[[13011    14]\n",
      " [ 1095    16]]\n",
      "done in 29.698870s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41000000000000003\n",
      "threshold:0.2, J-value:0.26899999999999996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.30000000000000004, J-value:0.147\n",
      "threshold:0.4, J-value:0.07100000000000001\n",
      "threshold:0.5, J-value:0.029\n",
      "threshold:0.6000000000000001, J-value:0.008\n",
      "threshold:0.7000000000000001, J-value:0.005\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7048403221574576\n",
      "Balanced accuracy score of test is  0.6978716980720774\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.39099999999999996\n",
      "threshold:0.2, J-value:0.272\n",
      "threshold:0.30000000000000004, J-value:0.15500000000000003\n",
      "threshold:0.4, J-value:0.075\n",
      "threshold:0.5, J-value:0.024\n",
      "threshold:0.6000000000000001, J-value:0.008\n",
      "threshold:0.7000000000000001, J-value:0.005\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6953793423230479\n",
      "Balanced accuracy score of test is  0.7020554278618795\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.404\n",
      "threshold:0.2, J-value:0.258\n",
      "threshold:0.30000000000000004, J-value:0.139\n",
      "threshold:0.4, J-value:0.068\n",
      "threshold:0.5, J-value:0.033\n",
      "threshold:0.6000000000000001, J-value:0.009999999999999998\n",
      "threshold:0.7000000000000001, J-value:0.006\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7022066144835735\n",
      "Balanced accuracy score of test is  0.684866359956533\n",
      "True positive rate of class 1 is  0.727\n",
      "True positive rate of class 2 is  0.581\n",
      "Positive prediction rate of class 1 is  0.369\n",
      "Positive prediction rate of class 2 is  0.24\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.408\n",
      "threshold:0.2, J-value:0.299\n",
      "threshold:0.30000000000000004, J-value:0.10600000000000001\n",
      "threshold:0.4, J-value:0.023\n",
      "threshold:0.5, J-value:0.005\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7040321204729593\n",
      "Balanced accuracy score of test is  0.7041433272451707\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.34700000000000003\n",
      "threshold:0.2, J-value:0.29800000000000004\n",
      "threshold:0.30000000000000004, J-value:0.11599999999999999\n",
      "threshold:0.4, J-value:0.035\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6732463652421534\n",
      "Balanced accuracy score of test is  0.6876865868801352\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.417\n",
      "threshold:0.2, J-value:0.281\n",
      "threshold:0.30000000000000004, J-value:0.097\n",
      "threshold:0.4, J-value:0.021\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7084439247868239\n",
      "Balanced accuracy score of test is  0.6973428168152708\n",
      "True positive rate of class 1 is  0.795\n",
      "True positive rate of class 2 is  0.691\n",
      "Positive prediction rate of class 1 is  0.463\n",
      "Positive prediction rate of class 2 is  0.328\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.37400000000000005\n",
      "threshold:0.2, J-value:0.21000000000000002\n",
      "threshold:0.30000000000000004, J-value:0.093\n",
      "threshold:0.4, J-value:0.008\n",
      "threshold:0.5, J-value:-0.001\n",
      "threshold:0.6000000000000001, J-value:-0.001\n",
      "threshold:0.7000000000000001, J-value:-0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.687285719246347\n",
      "Balanced accuracy score of test is  0.6872702163503284\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.356\n",
      "threshold:0.2, J-value:0.2\n",
      "threshold:0.30000000000000004, J-value:0.08199999999999999\n",
      "threshold:0.4, J-value:0.009999999999999998\n",
      "threshold:0.5, J-value:-0.001\n",
      "threshold:0.6000000000000001, J-value:-0.001\n",
      "threshold:0.7000000000000001, J-value:-0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6777800283505981\n",
      "Balanced accuracy score of test is  0.6815914705027608\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.375\n",
      "threshold:0.2, J-value:0.21700000000000003\n",
      "threshold:0.30000000000000004, J-value:0.10099999999999999\n",
      "threshold:0.4, J-value:0.006999999999999999\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6871925562133305\n",
      "Balanced accuracy score of test is  0.6852648527808636\n",
      "True positive rate of class 1 is  0.712\n",
      "True positive rate of class 2 is  0.644\n",
      "Positive prediction rate of class 1 is  0.39\n",
      "Positive prediction rate of class 2 is  0.303\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.42399999999999993\n",
      "threshold:0.2, J-value:0.285\n",
      "threshold:0.30000000000000004, J-value:0.14\n",
      "threshold:0.4, J-value:0.060000000000000005\n",
      "threshold:0.5, J-value:0.018000000000000002\n",
      "threshold:0.6000000000000001, J-value:0.006\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7122527341727118\n",
      "Balanced accuracy score of test is  0.7062079755746189\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.4\n",
      "threshold:0.2, J-value:0.274\n",
      "threshold:0.30000000000000004, J-value:0.13699999999999998\n",
      "threshold:0.4, J-value:0.061\n",
      "threshold:0.5, J-value:0.016\n",
      "threshold:0.6000000000000001, J-value:0.006\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7000492809254355\n",
      "Balanced accuracy score of test is  0.7056116417003514\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.42500000000000004\n",
      "threshold:0.2, J-value:0.287\n",
      "threshold:0.30000000000000004, J-value:0.14100000000000001\n",
      "threshold:0.4, J-value:0.060000000000000005\n",
      "threshold:0.5, J-value:0.019000000000000003\n",
      "threshold:0.6000000000000001, J-value:0.006\n",
      "threshold:0.7000000000000001, J-value:0.003\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7123480880016934\n",
      "Balanced accuracy score of test is  0.697551962489915\n",
      "True positive rate of class 1 is  0.747\n",
      "True positive rate of class 2 is  0.625\n",
      "Positive prediction rate of class 1 is  0.382\n",
      "Positive prediction rate of class 2 is  0.261\n",
      "X train 65694\n",
      "Y train 65694\n",
      "21898 7804 14094\n",
      "21898 7804 14094\n",
      "21898 7849 14049\n",
      "21898 7849 14049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.259703992793075\n",
      "0.2622894173060706\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19931\n",
      "           1       0.50      0.04      0.08      1967\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.71      0.52      0.51     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19851    80]\n",
      " [ 1886    81]]\n",
      "done in 0.486030s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.259703992793075\n",
      "0.25915565572607974\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19956\n",
      "           1       0.47      0.04      0.07      1942\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.69      0.52      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19877    79]\n",
      " [ 1873    69]]\n",
      "done in 0.470511s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.259703992793075\n",
      "0.30680142174138497\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94      6937\n",
      "           1       0.51      0.05      0.10       867\n",
      "\n",
      "    accuracy                           0.89      7804\n",
      "   macro avg       0.70      0.52      0.52      7804\n",
      "weighted avg       0.85      0.89      0.85      7804\n",
      "\n",
      "Confusion_matrix\n",
      "[[6891   46]\n",
      " [ 820   47]]\n",
      "done in 0.453625s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.259703992793075\n",
      "0.29676212964722404\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94      7008\n",
      "           1       0.48      0.04      0.08       841\n",
      "\n",
      "    accuracy                           0.89      7849\n",
      "   macro avg       0.69      0.52      0.51      7849\n",
      "weighted avg       0.85      0.89      0.85      7849\n",
      "\n",
      "Confusion_matrix\n",
      "[[6970   38]\n",
      " [ 806   35]]\n",
      "done in 0.448326s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.259703992793075\n",
      "0.23764263976859407\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12994\n",
      "           1       0.50      0.03      0.06      1100\n",
      "\n",
      "    accuracy                           0.92     14094\n",
      "   macro avg       0.71      0.51      0.51     14094\n",
      "weighted avg       0.89      0.92      0.89     14094\n",
      "\n",
      "Confusion_matrix\n",
      "[[12960    34]\n",
      " [ 1066    34]]\n",
      "done in 0.457358s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.259703992793075\n",
      "0.23814539066756585\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12948\n",
      "           1       0.45      0.03      0.06      1101\n",
      "\n",
      "    accuracy                           0.92     14049\n",
      "   macro avg       0.69      0.51      0.51     14049\n",
      "weighted avg       0.89      0.92      0.89     14049\n",
      "\n",
      "Confusion_matrix\n",
      "[[12907    41]\n",
      " [ 1067    34]]\n",
      "done in 0.475744s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19931\n",
      "           1       0.53      0.00      0.01      1967\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.72      0.50      0.48     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19924     7]\n",
      " [ 1959     8]]\n",
      "done in 16.876383s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19956\n",
      "           1       0.45      0.00      0.01      1942\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19950     6]\n",
      " [ 1937     5]]\n",
      "done in 16.730622s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6937\n",
      "           1       0.50      0.00      0.01       867\n",
      "\n",
      "    accuracy                           0.89      7804\n",
      "   macro avg       0.69      0.50      0.48      7804\n",
      "weighted avg       0.85      0.89      0.84      7804\n",
      "\n",
      "Confusion_matrix\n",
      "[[6933    4]\n",
      " [ 863    4]]\n",
      "done in 16.604016s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      7008\n",
      "           1       0.75      0.00      0.01       841\n",
      "\n",
      "    accuracy                           0.89      7849\n",
      "   macro avg       0.82      0.50      0.48      7849\n",
      "weighted avg       0.88      0.89      0.84      7849\n",
      "\n",
      "Confusion_matrix\n",
      "[[7007    1]\n",
      " [ 838    3]]\n",
      "done in 16.693274s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12994\n",
      "           1       0.75      0.00      0.01      1100\n",
      "\n",
      "    accuracy                           0.92     14094\n",
      "   macro avg       0.84      0.50      0.48     14094\n",
      "weighted avg       0.91      0.92      0.89     14094\n",
      "\n",
      "Confusion_matrix\n",
      "[[12993     1]\n",
      " [ 1097     3]]\n",
      "done in 16.723400s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12948\n",
      "           1       0.33      0.00      0.00      1101\n",
      "\n",
      "    accuracy                           0.92     14049\n",
      "   macro avg       0.63      0.50      0.48     14049\n",
      "weighted avg       0.88      0.92      0.88     14049\n",
      "\n",
      "Confusion_matrix\n",
      "[[12946     2]\n",
      " [ 1100     1]]\n",
      "done in 16.651348s\n",
      "0.2649943867570085\n",
      "0.2698423370473158\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19931\n",
      "           1       0.33      0.00      0.01      1967\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.62      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19921    10]\n",
      " [ 1962     5]]\n",
      "done in 0.548687s\n",
      "0.2649943867570085\n",
      "0.2675627714271921\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19956\n",
      "           1       0.35      0.00      0.01      1942\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.63      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19943    13]\n",
      " [ 1935     7]]\n",
      "done in 0.545481s\n",
      "0.2649943867570085\n",
      "0.31435489544316514\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6937\n",
      "           1       0.44      0.00      0.01       867\n",
      "\n",
      "    accuracy                           0.89      7804\n",
      "   macro avg       0.67      0.50      0.48      7804\n",
      "weighted avg       0.84      0.89      0.84      7804\n",
      "\n",
      "Confusion_matrix\n",
      "[[6932    5]\n",
      " [ 863    4]]\n",
      "done in 0.532828s\n",
      "0.2649943867570085\n",
      "0.3060250303951873\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      7008\n",
      "           1       0.11      0.00      0.00       841\n",
      "\n",
      "    accuracy                           0.89      7849\n",
      "   macro avg       0.50      0.50      0.47      7849\n",
      "weighted avg       0.81      0.89      0.84      7849\n",
      "\n",
      "Confusion_matrix\n",
      "[[7000    8]\n",
      " [ 840    1]]\n",
      "done in 0.528813s\n",
      "0.2649943867570085\n",
      "0.24519525277590898\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12994\n",
      "           1       0.17      0.00      0.00      1100\n",
      "\n",
      "    accuracy                           0.92     14094\n",
      "   macro avg       0.54      0.50      0.48     14094\n",
      "weighted avg       0.86      0.92      0.88     14094\n",
      "\n",
      "Confusion_matrix\n",
      "[[12989     5]\n",
      " [ 1099     1]]\n",
      "done in 0.540682s\n",
      "0.2649943867570085\n",
      "0.2460743900021942\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12948\n",
      "           1       0.55      0.01      0.01      1101\n",
      "\n",
      "    accuracy                           0.92     14049\n",
      "   macro avg       0.73      0.50      0.49     14049\n",
      "weighted avg       0.89      0.92      0.88     14049\n",
      "\n",
      "Confusion_matrix\n",
      "[[12943     5]\n",
      " [ 1095     6]]\n",
      "done in 0.536336s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19931\n",
      "           1       0.46      0.02      0.04      1967\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19881    50]\n",
      " [ 1925    42]]\n",
      "done in 29.617463s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19956\n",
      "           1       0.42      0.02      0.04      1942\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19900    56]\n",
      " [ 1901    41]]\n",
      "done in 30.036819s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6937\n",
      "           1       0.43      0.02      0.04       867\n",
      "\n",
      "    accuracy                           0.89      7804\n",
      "   macro avg       0.66      0.51      0.49      7804\n",
      "weighted avg       0.84      0.89      0.84      7804\n",
      "\n",
      "Confusion_matrix\n",
      "[[6911   26]\n",
      " [ 847   20]]\n",
      "done in 29.688159s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      7008\n",
      "           1       0.40      0.03      0.05       841\n",
      "\n",
      "    accuracy                           0.89      7849\n",
      "   macro avg       0.65      0.51      0.50      7849\n",
      "weighted avg       0.84      0.89      0.85      7849\n",
      "\n",
      "Confusion_matrix\n",
      "[[6975   33]\n",
      " [ 819   22]]\n",
      "done in 29.709733s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12994\n",
      "           1       0.48      0.02      0.04      1100\n",
      "\n",
      "    accuracy                           0.92     14094\n",
      "   macro avg       0.70      0.51      0.50     14094\n",
      "weighted avg       0.89      0.92      0.89     14094\n",
      "\n",
      "Confusion_matrix\n",
      "[[12970    24]\n",
      " [ 1078    22]]\n",
      "done in 29.767496s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12948\n",
      "           1       0.45      0.02      0.03      1101\n",
      "\n",
      "    accuracy                           0.92     14049\n",
      "   macro avg       0.69      0.51      0.50     14049\n",
      "weighted avg       0.89      0.92      0.89     14049\n",
      "\n",
      "Confusion_matrix\n",
      "[[12925    23]\n",
      " [ 1082    19]]\n",
      "done in 30.516057s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.393\n",
      "threshold:0.2, J-value:0.255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.30000000000000004, J-value:0.149\n",
      "threshold:0.4, J-value:0.07\n",
      "threshold:0.5, J-value:0.037000000000000005\n",
      "threshold:0.6000000000000001, J-value:0.009999999999999998\n",
      "threshold:0.7000000000000001, J-value:0.003\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6964505938982116\n",
      "Balanced accuracy score of test is  0.7007504821627146\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.38099999999999995\n",
      "threshold:0.2, J-value:0.27\n",
      "threshold:0.30000000000000004, J-value:0.17099999999999999\n",
      "threshold:0.4, J-value:0.08399999999999999\n",
      "threshold:0.5, J-value:0.047\n",
      "threshold:0.6000000000000001, J-value:0.011\n",
      "threshold:0.7000000000000001, J-value:0.005\n",
      "threshold:0.8, J-value:0.002\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6901196283107534\n",
      "Balanced accuracy score of test is  0.6923107072467545\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.381\n",
      "threshold:0.2, J-value:0.23299999999999998\n",
      "threshold:0.30000000000000004, J-value:0.127\n",
      "threshold:0.4, J-value:0.057\n",
      "threshold:0.5, J-value:0.028\n",
      "threshold:0.6000000000000001, J-value:0.009000000000000001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6906056641526859\n",
      "Balanced accuracy score of test is  0.6982092065600486\n",
      "True positive rate of class 1 is  0.719\n",
      "True positive rate of class 2 is  0.607\n",
      "Positive prediction rate of class 1 is  0.376\n",
      "Positive prediction rate of class 2 is  0.241\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.383\n",
      "threshold:0.2, J-value:0.28300000000000003\n",
      "threshold:0.30000000000000004, J-value:0.118\n",
      "threshold:0.4, J-value:0.023\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6914708055960324\n",
      "Balanced accuracy score of test is  0.6957434832429491\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.35100000000000003\n",
      "threshold:0.2, J-value:0.29100000000000004\n",
      "threshold:0.30000000000000004, J-value:0.15500000000000003\n",
      "threshold:0.4, J-value:0.039\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6756370857240623\n",
      "Balanced accuracy score of test is  0.6859111923726375\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.38999999999999996\n",
      "threshold:0.2, J-value:0.27\n",
      "threshold:0.30000000000000004, J-value:0.10099999999999999\n",
      "threshold:0.4, J-value:0.015\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6949451495095639\n",
      "Balanced accuracy score of test is  0.7042666579123031\n",
      "True positive rate of class 1 is  0.806\n",
      "True positive rate of class 2 is  0.706\n",
      "Positive prediction rate of class 1 is  0.474\n",
      "Positive prediction rate of class 2 is  0.329\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.36099999999999993\n",
      "threshold:0.2, J-value:0.20099999999999996\n",
      "threshold:0.30000000000000004, J-value:0.093\n",
      "threshold:0.4, J-value:0.012\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6805777976724325\n",
      "Balanced accuracy score of test is  0.683010862827159\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.33599999999999997\n",
      "threshold:0.2, J-value:0.23100000000000004\n",
      "threshold:0.30000000000000004, J-value:0.095\n",
      "threshold:0.4, J-value:0.011\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6677740129113912\n",
      "Balanced accuracy score of test is  0.6712875958985552\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.37300000000000005\n",
      "threshold:0.2, J-value:0.16899999999999998\n",
      "threshold:0.30000000000000004, J-value:0.091\n",
      "threshold:0.4, J-value:0.014000000000000002\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6866167601830215\n",
      "Balanced accuracy score of test is  0.6888525596832941\n",
      "True positive rate of class 1 is  0.699\n",
      "True positive rate of class 2 is  0.691\n",
      "Positive prediction rate of class 1 is  0.393\n",
      "Positive prediction rate of class 2 is  0.343\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.4\n",
      "threshold:0.2, J-value:0.266\n",
      "threshold:0.30000000000000004, J-value:0.14\n",
      "threshold:0.4, J-value:0.060000000000000005\n",
      "threshold:0.5, J-value:0.018000000000000002\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7001140462302111\n",
      "Balanced accuracy score of test is  0.705527598409601\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.373\n",
      "threshold:0.2, J-value:0.28500000000000003\n",
      "threshold:0.30000000000000004, J-value:0.16\n",
      "threshold:0.4, J-value:0.075\n",
      "threshold:0.5, J-value:0.019\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6864442696411384\n",
      "Balanced accuracy score of test is  0.6956871779627427\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.401\n",
      "threshold:0.2, J-value:0.242\n",
      "threshold:0.30000000000000004, J-value:0.12099999999999998\n",
      "threshold:0.4, J-value:0.048\n",
      "threshold:0.5, J-value:0.018000000000000002\n",
      "threshold:0.6000000000000001, J-value:0.004\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7005866343906978\n",
      "Balanced accuracy score of test is  0.704500879224296\n",
      "True positive rate of class 1 is  0.746\n",
      "True positive rate of class 2 is  0.645\n",
      "Positive prediction rate of class 1 is  0.396\n",
      "Positive prediction rate of class 2 is  0.268\n",
      "X train 65694\n",
      "Y train 65694\n",
      "21898 7696 14202\n",
      "21898 7696 14202\n",
      "21898 7840 14058\n",
      "21898 7840 14058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2599848723690683\n",
      "0.25514036585612926\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19973\n",
      "           1       0.52      0.04      0.07      1925\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.72      0.52      0.51     21898\n",
      "weighted avg       0.88      0.91      0.88     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19905    68]\n",
      " [ 1851    74]]\n",
      "done in 0.527524s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2599848723690683\n",
      "0.26502750161480243\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19866\n",
      "           1       0.45      0.03      0.06      2032\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.51      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19782    84]\n",
      " [ 1963    69]]\n",
      "done in 0.521827s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2599848723690683\n",
      "0.28432490741345895\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.95      6911\n",
      "           1       0.51      0.05      0.09       785\n",
      "\n",
      "    accuracy                           0.90      7696\n",
      "   macro avg       0.70      0.52      0.52      7696\n",
      "weighted avg       0.86      0.90      0.86      7696\n",
      "\n",
      "Confusion_matrix\n",
      "[[6874   37]\n",
      " [ 747   38]]\n",
      "done in 0.489822s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2599848723690683\n",
      "0.3044521897662974\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94      6966\n",
      "           1       0.41      0.04      0.07       874\n",
      "\n",
      "    accuracy                           0.89      7840\n",
      "   macro avg       0.65      0.52      0.51      7840\n",
      "weighted avg       0.84      0.89      0.84      7840\n",
      "\n",
      "Confusion_matrix\n",
      "[[6917   49]\n",
      " [ 840   34]]\n",
      "done in 0.503952s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2599848723690683\n",
      "0.23932539389265867\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13062\n",
      "           1       0.54      0.03      0.06      1140\n",
      "\n",
      "    accuracy                           0.92     14202\n",
      "   macro avg       0.73      0.51      0.51     14202\n",
      "weighted avg       0.89      0.92      0.89     14202\n",
      "\n",
      "Confusion_matrix\n",
      "[[13031    31]\n",
      " [ 1104    36]]\n",
      "done in 0.485010s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2599848723690683\n",
      "0.2430407641622686\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12900\n",
      "           1       0.50      0.03      0.06      1158\n",
      "\n",
      "    accuracy                           0.92     14058\n",
      "   macro avg       0.71      0.51      0.51     14058\n",
      "weighted avg       0.89      0.92      0.88     14058\n",
      "\n",
      "Confusion_matrix\n",
      "[[12865    35]\n",
      " [ 1123    35]]\n",
      "done in 0.525046s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19973\n",
      "           1       0.40      0.00      0.00      1925\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.66      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19967     6]\n",
      " [ 1921     4]]\n",
      "done in 17.500645s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19866\n",
      "           1       0.55      0.00      0.01      2032\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.73      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.86     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19861     5]\n",
      " [ 2026     6]]\n",
      "done in 17.859447s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      6911\n",
      "           1       0.38      0.00      0.01       785\n",
      "\n",
      "    accuracy                           0.90      7696\n",
      "   macro avg       0.64      0.50      0.48      7696\n",
      "weighted avg       0.84      0.90      0.85      7696\n",
      "\n",
      "Confusion_matrix\n",
      "[[6906    5]\n",
      " [ 782    3]]\n",
      "done in 17.169151s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6966\n",
      "           1       0.56      0.01      0.01       874\n",
      "\n",
      "    accuracy                           0.89      7840\n",
      "   macro avg       0.72      0.50      0.48      7840\n",
      "weighted avg       0.85      0.89      0.84      7840\n",
      "\n",
      "Confusion_matrix\n",
      "[[6962    4]\n",
      " [ 869    5]]\n",
      "done in 16.524161s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13062\n",
      "           1       1.00      0.00      0.01      1140\n",
      "\n",
      "    accuracy                           0.92     14202\n",
      "   macro avg       0.96      0.50      0.48     14202\n",
      "weighted avg       0.93      0.92      0.88     14202\n",
      "\n",
      "Confusion_matrix\n",
      "[[13062     0]\n",
      " [ 1135     5]]\n",
      "done in 16.540864s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12900\n",
      "           1       0.40      0.00      0.00      1158\n",
      "\n",
      "    accuracy                           0.92     14058\n",
      "   macro avg       0.66      0.50      0.48     14058\n",
      "weighted avg       0.88      0.92      0.88     14058\n",
      "\n",
      "Confusion_matrix\n",
      "[[12897     3]\n",
      " [ 1156     2]]\n",
      "done in 16.531977s\n",
      "0.26553645312445306\n",
      "0.2694114094281803\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19973\n",
      "           1       0.12      0.00      0.00      1925\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.51      0.50      0.48     21898\n",
      "weighted avg       0.84      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19958    15]\n",
      " [ 1923     2]]\n",
      "done in 0.548414s\n",
      "0.26553645312445306\n",
      "0.279841317193865\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19866\n",
      "           1       0.06      0.00      0.00      2032\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.48      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.86     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19849    17]\n",
      " [ 2031     1]]\n",
      "done in 0.547538s\n",
      "0.26553645312445306\n",
      "0.30667662037986243\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      6911\n",
      "           1       0.12      0.00      0.00       785\n",
      "\n",
      "    accuracy                           0.90      7696\n",
      "   macro avg       0.51      0.50      0.47      7696\n",
      "weighted avg       0.82      0.90      0.85      7696\n",
      "\n",
      "Confusion_matrix\n",
      "[[6904    7]\n",
      " [ 784    1]]\n",
      "done in 0.529472s\n",
      "0.26553645312445306\n",
      "0.3199982281891967\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6966\n",
      "           1       0.09      0.00      0.00       874\n",
      "\n",
      "    accuracy                           0.89      7840\n",
      "   macro avg       0.49      0.50      0.47      7840\n",
      "weighted avg       0.80      0.89      0.84      7840\n",
      "\n",
      "Confusion_matrix\n",
      "[[6956   10]\n",
      " [ 873    1]]\n",
      "done in 0.530883s\n",
      "0.26553645312445306\n",
      "0.2492175590209035\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13062\n",
      "           1       0.11      0.00      0.00      1140\n",
      "\n",
      "    accuracy                           0.92     14202\n",
      "   macro avg       0.52      0.50      0.48     14202\n",
      "weighted avg       0.85      0.92      0.88     14202\n",
      "\n",
      "Confusion_matrix\n",
      "[[13054     8]\n",
      " [ 1139     1]]\n",
      "done in 0.580604s\n",
      "0.26553645312445306\n",
      "0.2548203633721037\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12900\n",
      "           1       0.14      0.00      0.00      1158\n",
      "\n",
      "    accuracy                           0.92     14058\n",
      "   macro avg       0.53      0.50      0.48     14058\n",
      "weighted avg       0.85      0.92      0.88     14058\n",
      "\n",
      "Confusion_matrix\n",
      "[[12894     6]\n",
      " [ 1157     1]]\n",
      "done in 0.543402s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19973\n",
      "           1       0.50      0.02      0.04      1925\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.71      0.51      0.49     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19938    35]\n",
      " [ 1890    35]]\n",
      "done in 30.498195s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19866\n",
      "           1       0.49      0.02      0.04      2032\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.70      0.51      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19825    41]\n",
      " [ 1992    40]]\n",
      "done in 29.558038s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      6911\n",
      "           1       0.50      0.02      0.04       785\n",
      "\n",
      "    accuracy                           0.90      7696\n",
      "   macro avg       0.70      0.51      0.49      7696\n",
      "weighted avg       0.86      0.90      0.85      7696\n",
      "\n",
      "Confusion_matrix\n",
      "[[6893   18]\n",
      " [ 767   18]]\n",
      "done in 29.221100s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6966\n",
      "           1       0.48      0.03      0.05       874\n",
      "\n",
      "    accuracy                           0.89      7840\n",
      "   macro avg       0.69      0.51      0.50      7840\n",
      "weighted avg       0.85      0.89      0.84      7840\n",
      "\n",
      "Confusion_matrix\n",
      "[[6940   26]\n",
      " [ 850   24]]\n",
      "done in 29.189054s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     13062\n",
      "           1       0.50      0.01      0.03      1140\n",
      "\n",
      "    accuracy                           0.92     14202\n",
      "   macro avg       0.71      0.51      0.49     14202\n",
      "weighted avg       0.89      0.92      0.88     14202\n",
      "\n",
      "Confusion_matrix\n",
      "[[13045    17]\n",
      " [ 1123    17]]\n",
      "done in 29.186758s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     12900\n",
      "           1       0.52      0.01      0.03      1158\n",
      "\n",
      "    accuracy                           0.92     14058\n",
      "   macro avg       0.72      0.51      0.49     14058\n",
      "weighted avg       0.89      0.92      0.88     14058\n",
      "\n",
      "Confusion_matrix\n",
      "[[12885    15]\n",
      " [ 1142    16]]\n",
      "done in 29.224983s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.40900000000000003\n",
      "threshold:0.2, J-value:0.26399999999999996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.30000000000000004, J-value:0.156\n",
      "threshold:0.4, J-value:0.08\n",
      "threshold:0.5, J-value:0.034999999999999996\n",
      "threshold:0.6000000000000001, J-value:0.012\n",
      "threshold:0.7000000000000001, J-value:0.003\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7044758475890505\n",
      "Balanced accuracy score of test is  0.7055447928284864\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.402\n",
      "threshold:0.2, J-value:0.29\n",
      "threshold:0.30000000000000004, J-value:0.181\n",
      "threshold:0.4, J-value:0.102\n",
      "threshold:0.5, J-value:0.043000000000000003\n",
      "threshold:0.6000000000000001, J-value:0.016999999999999998\n",
      "threshold:0.7000000000000001, J-value:0.004\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.700886060899867\n",
      "Balanced accuracy score of test is  0.70351465207602\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.39799999999999996\n",
      "threshold:0.2, J-value:0.24\n",
      "threshold:0.30000000000000004, J-value:0.138\n",
      "threshold:0.4, J-value:0.063\n",
      "threshold:0.5, J-value:0.03\n",
      "threshold:0.6000000000000001, J-value:0.009000000000000001\n",
      "threshold:0.7000000000000001, J-value:0.003\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6992529555399754\n",
      "Balanced accuracy score of test is  0.6970522552918023\n",
      "True positive rate of class 1 is  0.755\n",
      "True positive rate of class 2 is  0.598\n",
      "Positive prediction rate of class 1 is  0.393\n",
      "Positive prediction rate of class 2 is  0.237\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.404\n",
      "threshold:0.2, J-value:0.276\n",
      "threshold:0.30000000000000004, J-value:0.10600000000000001\n",
      "threshold:0.4, J-value:0.02\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7019280314138372\n",
      "Balanced accuracy score of test is  0.7070074221694804\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.36899999999999994\n",
      "threshold:0.2, J-value:0.28800000000000003\n",
      "threshold:0.30000000000000004, J-value:0.13599999999999998\n",
      "threshold:0.4, J-value:0.020999999999999998\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6845207538614246\n",
      "Balanced accuracy score of test is  0.6831645829925148\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.39599999999999996\n",
      "threshold:0.2, J-value:0.255\n",
      "threshold:0.30000000000000004, J-value:0.094\n",
      "threshold:0.4, J-value:0.014\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6978428789014337\n",
      "Balanced accuracy score of test is  0.7087936297545889\n",
      "True positive rate of class 1 is  0.814\n",
      "True positive rate of class 2 is  0.703\n",
      "Positive prediction rate of class 1 is  0.488\n",
      "Positive prediction rate of class 2 is  0.32\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.33799999999999997\n",
      "threshold:0.2, J-value:0.193\n",
      "threshold:0.30000000000000004, J-value:0.067\n",
      "threshold:0.4, J-value:0.054\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.669213113027262\n",
      "Balanced accuracy score of test is  0.6745815814381553\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.33299999999999996\n",
      "threshold:0.2, J-value:0.19699999999999998\n",
      "threshold:0.30000000000000004, J-value:0.079\n",
      "threshold:0.4, J-value:0.065\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:-0.001\n",
      "threshold:0.7000000000000001, J-value:-0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6666902298283821\n",
      "Balanced accuracy score of test is  0.6666962316475381\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.3360000000000001\n",
      "threshold:0.2, J-value:0.189\n",
      "threshold:0.30000000000000004, J-value:0.057999999999999996\n",
      "threshold:0.4, J-value:0.046\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6680582082215185\n",
      "Balanced accuracy score of test is  0.6770237377997349\n",
      "True positive rate of class 1 is  0.6\n",
      "True positive rate of class 2 is  0.563\n",
      "Positive prediction rate of class 1 is  0.303\n",
      "Positive prediction rate of class 2 is  0.238\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41899999999999993\n",
      "threshold:0.2, J-value:0.26299999999999996\n",
      "threshold:0.30000000000000004, J-value:0.14300000000000002\n",
      "threshold:0.4, J-value:0.053\n",
      "threshold:0.5, J-value:0.016\n",
      "threshold:0.6000000000000001, J-value:0.005\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7093144186209825\n",
      "Balanced accuracy score of test is  0.7089494940907228\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.40700000000000003\n",
      "threshold:0.2, J-value:0.28400000000000003\n",
      "threshold:0.30000000000000004, J-value:0.16699999999999998\n",
      "threshold:0.4, J-value:0.066\n",
      "threshold:0.5, J-value:0.02\n",
      "threshold:0.6000000000000001, J-value:0.005\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7035968690180061\n",
      "Balanced accuracy score of test is  0.6999108451576832\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41200000000000003\n",
      "threshold:0.2, J-value:0.242\n",
      "threshold:0.30000000000000004, J-value:0.12399999999999999\n",
      "threshold:0.4, J-value:0.042\n",
      "threshold:0.5, J-value:0.013999999999999999\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7060643973277244\n",
      "Balanced accuracy score of test is  0.7058792223962727\n",
      "True positive rate of class 1 is  0.763\n",
      "True positive rate of class 2 is  0.634\n",
      "Positive prediction rate of class 1 is  0.408\n",
      "Positive prediction rate of class 2 is  0.256\n"
     ]
    }
   ],
   "source": [
    "records_lr = []\n",
    "records_rf = []\n",
    "records_dt = []\n",
    "records_gbt = []\n",
    "for random_state in range(10):\n",
    "    fairness_metrics (X, y, \"GENDER\", random_state)\n",
    "\n",
    "result_lr = pd.DataFrame(records_lr)\n",
    "result_rf = pd.DataFrame(records_rf)\n",
    "result_dt = pd.DataFrame(records_dt)\n",
    "result_gbt = pd.DataFrame(records_gbt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def add_mean_sd(records, result_table, overall_records, type):\n",
    "    records.append({\n",
    "        'auroc': result_table[\"auroc\"].mean(),\n",
    "        'overall threshold': result_table[\"overall threshold\"].mean(),\n",
    "        'male threshold': result_table[\"male threshold\"].mean(),\n",
    "        'female threshold': result_table[\"female threshold\"].mean(),\n",
    "        'overall ba validation': result_table[\"overall ba validation\"].mean(),\n",
    "        'overall ba test': result_table[\"overall ba test\"].mean(),\n",
    "        'male ba validation': result_table[\"male ba validation\"].mean(),\n",
    "        'male ba test': result_table[\"male ba test\"].mean(),\n",
    "        'female ba validation': result_table[\"female ba validation\"].mean(),\n",
    "        'female ba test': result_table[\"female ba test\"].mean(),\n",
    "        'overall precision':result_table[\"overall precision\"].mean(),\n",
    "        'overall recall':result_table[\"overall recall\"].mean(),\n",
    "        'overall tpr':result_table[\"overall tpr\"].mean(),\n",
    "        'overall tnr':result_table[\"overall tnr\"].mean(),\n",
    "        'overall pd':result_table[\"overall pd\"].mean(),\n",
    "        'male precision':result_table[\"male precision\"].mean(),\n",
    "        'male recall':result_table[\"male recall\"].mean(),\n",
    "        'male tpr':result_table[\"male tpr\"].mean(),\n",
    "        'male tnr':result_table[\"male tnr\"].mean(),\n",
    "        'male pd':result_table[\"male pd\"].mean(),\n",
    "        'female precision':result_table[\"female precision\"].mean(),\n",
    "        'female recall':result_table[\"female recall\"].mean(),\n",
    "        'female tpr':result_table[\"female tpr\"].mean(),\n",
    "        'female tnr':result_table[\"female tnr\"].mean(),\n",
    "        'female pd':result_table[\"female pd\"].mean(),\n",
    "        'eod': result_table[\"eod\"].mean(),\n",
    "        'di': result_table[\"di\"].mean(),\n",
    "        })\n",
    "    records.append({\n",
    "        'auroc': result_table[\"auroc\"].std(),\n",
    "        'overall threshold': result_table[\"overall threshold\"].std(),\n",
    "        'male threshold': result_table[\"male threshold\"].std(),\n",
    "        'female threshold': result_table[\"female threshold\"].std(),\n",
    "        'overall ba validation': result_table[\"overall ba validation\"].std(),\n",
    "        'overall ba test': result_table[\"overall ba test\"].std(),\n",
    "        'male ba validation': result_table[\"male ba validation\"].std(),\n",
    "        'male ba test': result_table[\"male ba test\"].std(),\n",
    "        'female ba validation': result_table[\"female ba validation\"].std(),\n",
    "        'female ba test': result_table[\"female ba test\"].std(),\n",
    "        'overall precision':result_table[\"overall precision\"].std(),\n",
    "        'overall recall':result_table[\"overall recall\"].std(),\n",
    "        'overall tpr':result_table[\"overall tpr\"].std(),\n",
    "        'overall tnr':result_table[\"overall tnr\"].std(),\n",
    "        'overall pd':result_table[\"overall pd\"].std(),\n",
    "        'male precision':result_table[\"male precision\"].std(),\n",
    "        'male recall':result_table[\"male recall\"].std(),\n",
    "        'male tpr':result_table[\"male tpr\"].std(),\n",
    "        'male tnr':result_table[\"male tnr\"].std(),\n",
    "        'male pd':result_table[\"male pd\"].std(),\n",
    "        'female precision':result_table[\"female precision\"].std(),\n",
    "        'female recall':result_table[\"female recall\"].std(),\n",
    "        'female tpr':result_table[\"female tpr\"].std(),\n",
    "        'female tnr':result_table[\"female tnr\"].std(),\n",
    "        'female pd':result_table[\"female pd\"].std(),\n",
    "        'eod': result_table[\"eod\"].std(),\n",
    "        'di': result_table[\"di\"].std(),\n",
    "        })\n",
    "    overall_records.append({\n",
    "        'type': type,\n",
    "        'auroc': result_table[\"auroc\"].mean(),\n",
    "        'overall threshold': result_table[\"overall threshold\"].mean(),\n",
    "        'male threshold': result_table[\"male threshold\"].mean(),\n",
    "        'female threshold': result_table[\"female threshold\"].mean(),\n",
    "        'overall ba test': result_table[\"overall ba test\"].mean(),\n",
    "        'male ba test': result_table[\"male ba test\"].mean(),\n",
    "        'female ba test': result_table[\"female ba test\"].mean(),\n",
    "        'overall tpr':result_table[\"overall tpr\"].mean(),\n",
    "        'overall pd':result_table[\"overall pd\"].mean(),\n",
    "        'male tpr':result_table[\"male tpr\"].mean(),\n",
    "        'male pd':result_table[\"male pd\"].mean(),\n",
    "        'female tpr':result_table[\"female tpr\"].mean(),\n",
    "        'female pd':result_table[\"female pd\"].mean(),\n",
    "        'eod': result_table[\"eod\"].mean(),\n",
    "        'di': result_table[\"di\"].mean(),\n",
    "        })\n",
    "    pd_result = pd.DataFrame(records)\n",
    "    return pd_result, overall_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "overall_table = []\n",
    "result_lr, overall_records = add_mean_sd (records_lr, result_lr, overall_table, 'lr')\n",
    "result_rf, overall_records = add_mean_sd (records_rf, result_rf, overall_records, 'rf')\n",
    "result_dt, overall_records = add_mean_sd (records_dt, result_dt, overall_records, 'dt')\n",
    "result_gbt, overall_records = add_mean_sd (records_gbt, result_gbt, overall_records, 'gbt')\n",
    "\n",
    "result_path='/Users/lifuchen/Desktop/research/resample_data/'\n",
    "result_lr.to_csv(path.join(result_path,'gender-lr-result_no_protected.csv'), index=False)\n",
    "result_rf.to_csv(path.join(result_path,'gender-rf-result_no_protected.csv'), index=False)\n",
    "result_dt.to_csv(path.join(result_path,'gender-dt-result_no_protected.csv'), index=False)\n",
    "result_gbt.to_csv(path.join(result_path,'gender-gbt-result_no_protected.csv'), index=False)\n",
    "\n",
    "overall_result = pd.DataFrame(overall_table)\n",
    "result_path='/Users/lifuchen/Desktop/research/resample_result/'\n",
    "overall_result.to_csv(path.join(result_path,'gender_no_protected.csv'), index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
