{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from os import path\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score\n",
    "import sklearn.preprocessing\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import src.lib.utility_classfier as uclf\n",
    "import src.lib.optimal_threhold_related as thres\n",
    "import src.lib.fairness_tests as fair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_path='/Users/lifuchen/Desktop/research/data.csv'\n",
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109490, 87)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df.Class.values\n",
    "X = df.drop(['GRID','Class'], axis=1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def save_prediction(classifier, characteristic, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_white_scaled, y_val_white, X_test_white_scaled, y_test_white, X_val_black_scaled, y_val_black, X_test_black_scaled, y_test_black):\n",
    "    method_to_call = getattr(uclf, classifier)\n",
    "    y_val_score = method_to_call(X_train_scaled, y_train,X_val_scaled, y_val)\n",
    "    y_test_score = method_to_call(X_train_scaled, y_train,X_test_scaled, y_test)\n",
    "\n",
    "    y_val_score_white = method_to_call(X_train_scaled, y_train, X_val_white_scaled, y_val_white)\n",
    "    y_test_score_white = method_to_call(X_train_scaled, y_train,X_test_white_scaled, y_test_white)\n",
    "\n",
    "    y_val_score_black = method_to_call(X_train_scaled, y_train, X_val_black_scaled, y_val_black)\n",
    "    y_test_score_black = method_to_call(X_train_scaled, y_train,X_test_black_scaled, y_test_black)\n",
    "\n",
    "    my_dict = dict(val_score = y_val_score, test_score = y_test_score, val_1_score = y_val_score_white, test_1_score = y_test_score_white, val_2_score = y_val_score_black, test_2_score = y_test_score_black)\n",
    "    overall_prediction = pd.DataFrame.from_dict(my_dict, orient='index')\n",
    "    overall_prediction = overall_prediction.transpose()\n",
    "\n",
    "    result_path='/Users/lifuchen/Desktop/research/predictions/'\n",
    "    filename = str(classifier) + str(characteristic) + \"prediction.csv\"\n",
    "    overall_prediction.to_csv(path.join(result_path, filename), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_result (classifier, characteristic, records, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_white_scaled, y_val_white, X_test_white_scaled, y_test_white, X_val_black_scaled, y_val_black, X_test_black_scaled, y_test_black):\n",
    "    result_path='/Users/lifuchen/Desktop/research/predictions/'\n",
    "    filename = str(classifier) + characteristic + \"prediction.csv\"\n",
    "    prediction = pd.read_csv(path.join(result_path, filename))\n",
    "\n",
    "    y_val_score = prediction['val_score'][prediction['val_score'].notna()]\n",
    "    y_test_score = prediction['test_score'][prediction['test_score'].notna()]\n",
    "\n",
    "    y_val_score_white = prediction['val_1_score'][prediction['val_1_score'].notna()]\n",
    "    y_test_score_white = prediction['test_1_score'][prediction['test_1_score'].notna()]\n",
    "\n",
    "    y_val_score_black = prediction['val_2_score'][prediction['val_2_score'].notna()]\n",
    "    y_test_score_black = prediction['test_2_score'][prediction['test_2_score'].notna()]\n",
    "\n",
    "    threshold, ba_val, ba_test = balance_accuracy (y_val, y_val_score,y_test, y_test_score)\n",
    "    auroc = roc_auc_score(y_test, y_test_score)\n",
    "    precision, recall, tpr, tnr, pd_overall = thres.calculate_precision_metrics(y_test, y_test_score,threshold)\n",
    "\n",
    "    threshold_white, ba_val_white, ba_test_white = balance_accuracy (y_val_white, y_val_score_white,y_test_white, y_test_score_white)\n",
    "    precision_white, recall_white, tpr_white, tnr_white, pd_white = thres.calculate_precision_metrics(y_test_white, y_test_score_white,threshold_white)\n",
    "\n",
    "    threshold_black, ba_val_black, ba_test_black = balance_accuracy (y_val_black, y_val_score_black, y_test_black, y_test_score_black)\n",
    "    precision_black, recall_black, tpr_black, tnr_black, pd_black = thres.calculate_precision_metrics(y_test_black, y_test_score_black,threshold_black)\n",
    "\n",
    "    eod = fair.get_EOD(y_test_white, y_test_score_white,threshold_white, y_test_black, y_test_score_black, threshold_black)\n",
    "    sp = fair.get_SP(y_test_white, y_test_score_white,threshold_white, y_test_black, y_test_score_black, threshold_black)\n",
    "\n",
    "    records.append({\n",
    "        'auroc': auroc,\n",
    "        'overall threshold': threshold,\n",
    "        'white threshold': threshold_white,\n",
    "        'black threshold': threshold_black,\n",
    "        'overall ba validation': ba_val,\n",
    "        'overall ba test': ba_test,\n",
    "        'white ba validation': ba_val_white,\n",
    "        'white ba test': ba_test_white,\n",
    "        'black ba validation': ba_val_black,\n",
    "        'black ba test': ba_test_black,\n",
    "        'overall precision':precision,\n",
    "        'overall recall':recall,\n",
    "        'overall tpr':tpr,\n",
    "        'overall tnr':tnr,\n",
    "        'overall pd':pd_overall,\n",
    "        'white precision':precision_white,\n",
    "        'white recall':recall_white,\n",
    "        'white tpr':tpr_white,\n",
    "        'white tnr':tnr_white,\n",
    "        'white pd':pd_white,\n",
    "        'black precision':precision_black,\n",
    "        'black recall':recall_black,\n",
    "        'black tpr':tpr_black,\n",
    "        'black tnr':tnr_black,\n",
    "        'black pd':pd_black,\n",
    "        'eod': eod,\n",
    "        'di': sp,\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def balance_accuracy (y_val, y_val_score,y_test, y_test_score):\n",
    "    \n",
    "    threshold, _ = thres.get_optimal_threshold_Jvalue (y_val, y_val_score)\n",
    "    print (\"Optimal threshold by J value is \",threshold)\n",
    "\n",
    "    ba_val = thres.calculate_balanced_accuracy(y_val, y_val_score, threshold)\n",
    "    print (\"Balanced accuracy score of val is \", ba_val)\n",
    "\n",
    "    ba_test = thres.calculate_balanced_accuracy(y_test, y_test_score, threshold)\n",
    "    print (\"Balanced accuracy score of test is \",ba_test)\n",
    "\n",
    "    return threshold, ba_val, ba_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def fairness_metrics (X, y, attribute, random_state):\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, X_val_white, X_val_black, y_val_white, y_val_black, X_test_white, X_test_black, y_test_white, y_test_black \\\n",
    "        = fair.split_by_trait(X, y, attribute, random_state)\n",
    "    print(\"X train\", X_train.shape[0])\n",
    "    print(\"Y train\", y_train.shape[0])\n",
    "    print(X_val.shape[0], X_val_white.shape[0], X_val_black.shape[0])\n",
    "    print(y_val.shape[0], y_val_white.shape[0], y_val_black.shape[0])\n",
    "    print(X_test.shape[0], X_test_white.shape[0], X_test_black.shape[0])\n",
    "    print(y_test.shape[0], y_test_white.shape[0], y_test_black.shape[0])\n",
    "\n",
    "    max_abs_scaler = preprocessing.MaxAbsScaler()\n",
    "    X_train_scaled = max_abs_scaler.fit_transform(X_train)\n",
    "    X_test_scaled = max_abs_scaler.transform(X_test)\n",
    "    X_test_white_scaled = max_abs_scaler.transform(X_test_white)\n",
    "    X_test_black_scaled = max_abs_scaler.transform(X_test_black)\n",
    "    X_val_scaled = max_abs_scaler.transform(X_val)\n",
    "    X_val_white_scaled = max_abs_scaler.transform(X_val_white)\n",
    "    X_val_black_scaled = max_abs_scaler.transform(X_val_black)\n",
    "\n",
    "    characteristic = attribute + str(random_state)\n",
    "    save_prediction (\"logic_regression\", characteristic, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_white_scaled, y_val_white, X_test_white_scaled, y_test_white, X_val_black_scaled, y_val_black, X_test_black_scaled, y_test_black)\n",
    "    save_prediction (\"random_forest\", characteristic, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_white_scaled, y_val_white, X_test_white_scaled, y_test_white, X_val_black_scaled, y_val_black, X_test_black_scaled, y_test_black)\n",
    "    save_prediction (\"decision_tree\", characteristic, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_white_scaled, y_val_white, X_test_white_scaled, y_test_white, X_val_black_scaled, y_val_black, X_test_black_scaled, y_test_black)\n",
    "    save_prediction (\"gradiant_boosting\", characteristic, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_white_scaled, y_val_white, X_test_white_scaled, y_test_white, X_val_black_scaled, y_val_black, X_test_black_scaled, y_test_black)\n",
    "\n",
    "    get_result (\"logic_regression\", characteristic, records_lr, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_white_scaled, y_val_white, X_test_white_scaled, y_test_white, X_val_black_scaled, y_val_black, X_test_black_scaled, y_test_black)\n",
    "    get_result (\"random_forest\", characteristic, records_rf, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_white_scaled, y_val_white, X_test_white_scaled, y_test_white, X_val_black_scaled, y_val_black, X_test_black_scaled, y_test_black)\n",
    "    get_result (\"decision_tree\", characteristic, records_dt, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_white_scaled, y_val_white, X_test_white_scaled, y_test_white, X_val_black_scaled, y_val_black, X_test_black_scaled, y_test_black)\n",
    "    get_result (\"gradiant_boosting\", characteristic, records_gbt, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, X_val_white_scaled, y_val_white, X_test_white_scaled, y_test_white, X_val_black_scaled, y_val_black, X_test_black_scaled, y_test_black)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train 65694\n",
      "Y train 65694\n",
      "21898 18899 2999\n",
      "21898 18899 2999\n",
      "21898 18968 2930\n",
      "21898 18968 2930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25882185696726207\n",
      "0.2619870551548744\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19904\n",
      "           1       0.43      0.03      0.06      1994\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19822    82]\n",
      " [ 1931    63]]\n",
      "done in 0.604577s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25882185696726207\n",
      "0.2623041485961046\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19934\n",
      "           1       0.43      0.03      0.06      1964\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19847    87]\n",
      " [ 1899    65]]\n",
      "done in 0.523775s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25882185696726207\n",
      "0.26282254893490486\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17180\n",
      "           1       0.45      0.03      0.06      1719\n",
      "\n",
      "    accuracy                           0.91     18899\n",
      "   macro avg       0.68      0.51      0.51     18899\n",
      "weighted avg       0.87      0.91      0.87     18899\n",
      "\n",
      "Confusion_matrix\n",
      "[[17114    66]\n",
      " [ 1665    54]]\n",
      "done in 0.517697s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25882185696726207\n",
      "0.26278189359925863\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17260\n",
      "           1       0.42      0.03      0.06      1708\n",
      "\n",
      "    accuracy                           0.91     18968\n",
      "   macro avg       0.67      0.51      0.51     18968\n",
      "weighted avg       0.87      0.91      0.87     18968\n",
      "\n",
      "Confusion_matrix\n",
      "[[17186    74]\n",
      " [ 1654    54]]\n",
      "done in 0.513775s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25882185696726207\n",
      "0.25672196780949413\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95      2724\n",
      "           1       0.36      0.03      0.06       275\n",
      "\n",
      "    accuracy                           0.91      2999\n",
      "   macro avg       0.64      0.51      0.51      2999\n",
      "weighted avg       0.86      0.91      0.87      2999\n",
      "\n",
      "Confusion_matrix\n",
      "[[2708   16]\n",
      " [ 266    9]]\n",
      "done in 0.550020s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25882185696726207\n",
      "0.259211361149066\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.95      2674\n",
      "           1       0.46      0.04      0.08       256\n",
      "\n",
      "    accuracy                           0.91      2930\n",
      "   macro avg       0.69      0.52      0.52      2930\n",
      "weighted avg       0.88      0.91      0.88      2930\n",
      "\n",
      "Confusion_matrix\n",
      "[[2661   13]\n",
      " [ 245   11]]\n",
      "done in 0.497400s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19904\n",
      "           1       0.45      0.00      0.01      1994\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19893    11]\n",
      " [ 1985     9]]\n",
      "done in 21.349485s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19934\n",
      "           1       0.50      0.00      0.01      1964\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.71      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19926     8]\n",
      " [ 1956     8]]\n",
      "done in 24.905319s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17180\n",
      "           1       0.29      0.00      0.01      1719\n",
      "\n",
      "    accuracy                           0.91     18899\n",
      "   macro avg       0.60      0.50      0.48     18899\n",
      "weighted avg       0.85      0.91      0.87     18899\n",
      "\n",
      "Confusion_matrix\n",
      "[[17168    12]\n",
      " [ 1714     5]]\n",
      "done in 24.952868s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17260\n",
      "           1       0.38      0.00      0.00      1708\n",
      "\n",
      "    accuracy                           0.91     18968\n",
      "   macro avg       0.64      0.50      0.48     18968\n",
      "weighted avg       0.86      0.91      0.87     18968\n",
      "\n",
      "Confusion_matrix\n",
      "[[17255     5]\n",
      " [ 1705     3]]\n",
      "done in 24.921246s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2724\n",
      "           1       1.00      0.01      0.01       275\n",
      "\n",
      "    accuracy                           0.91      2999\n",
      "   macro avg       0.95      0.50      0.48      2999\n",
      "weighted avg       0.92      0.91      0.87      2999\n",
      "\n",
      "Confusion_matrix\n",
      "[[2724    0]\n",
      " [ 273    2]]\n",
      "done in 25.109748s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2674\n",
      "           1       0.00      0.00      0.00       256\n",
      "\n",
      "    accuracy                           0.91      2930\n",
      "   macro avg       0.46      0.50      0.48      2930\n",
      "weighted avg       0.83      0.91      0.87      2930\n",
      "\n",
      "Confusion_matrix\n",
      "[[2673    1]\n",
      " [ 256    0]]\n",
      "done in 25.729109s\n",
      "0.26448598669059525\n",
      "0.2722330649120758\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19904\n",
      "           1       0.00      0.00      0.00      1994\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.45      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19903     1]\n",
      " [ 1994     0]]\n",
      "done in 0.764726s\n",
      "0.26448598669059525\n",
      "0.2769244924266795\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19934\n",
      "           1       0.00      0.00      0.00      1964\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.46      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19931     3]\n",
      " [ 1964     0]]\n",
      "done in 0.731615s\n",
      "0.26448598669059525\n",
      "0.2712860393477675\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17180\n",
      "           1       0.00      0.00      0.00      1719\n",
      "\n",
      "    accuracy                           0.91     18899\n",
      "   macro avg       0.45      0.50      0.48     18899\n",
      "weighted avg       0.83      0.91      0.87     18899\n",
      "\n",
      "Confusion_matrix\n",
      "[[17180     0]\n",
      " [ 1719     0]]\n",
      "done in 0.709927s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26448598669059525\n",
      "0.2778694234760347\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17260\n",
      "           1       0.00      0.00      0.00      1708\n",
      "\n",
      "    accuracy                           0.91     18968\n",
      "   macro avg       0.45      0.50      0.48     18968\n",
      "weighted avg       0.83      0.91      0.87     18968\n",
      "\n",
      "Confusion_matrix\n",
      "[[17257     3]\n",
      " [ 1708     0]]\n",
      "done in 0.710314s\n",
      "0.26448598669059525\n",
      "0.27820099960359335\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2724\n",
      "           1       0.00      0.00      0.00       275\n",
      "\n",
      "    accuracy                           0.91      2999\n",
      "   macro avg       0.45      0.50      0.48      2999\n",
      "weighted avg       0.82      0.91      0.86      2999\n",
      "\n",
      "Confusion_matrix\n",
      "[[2723    1]\n",
      " [ 275    0]]\n",
      "done in 0.734793s\n",
      "0.26448598669059525\n",
      "0.270807273264847\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2674\n",
      "           1       0.00      0.00      0.00       256\n",
      "\n",
      "    accuracy                           0.91      2930\n",
      "   macro avg       0.46      0.50      0.48      2930\n",
      "weighted avg       0.83      0.91      0.87      2930\n",
      "\n",
      "Confusion_matrix\n",
      "[[2674    0]\n",
      " [ 256    0]]\n",
      "done in 0.655821s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19904\n",
      "           1       0.46      0.02      0.03      1994\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.51      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19864    40]\n",
      " [ 1960    34]]\n",
      "done in 36.620208s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19934\n",
      "           1       0.46      0.02      0.05      1964\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19878    56]\n",
      " [ 1917    47]]\n",
      "done in 36.264064s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17180\n",
      "           1       0.48      0.02      0.03      1719\n",
      "\n",
      "    accuracy                           0.91     18899\n",
      "   macro avg       0.69      0.51      0.49     18899\n",
      "weighted avg       0.87      0.91      0.87     18899\n",
      "\n",
      "Confusion_matrix\n",
      "[[17146    34]\n",
      " [ 1688    31]]\n",
      "done in 36.373087s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17260\n",
      "           1       0.44      0.02      0.04      1708\n",
      "\n",
      "    accuracy                           0.91     18968\n",
      "   macro avg       0.68      0.51      0.50     18968\n",
      "weighted avg       0.87      0.91      0.87     18968\n",
      "\n",
      "Confusion_matrix\n",
      "[[17209    51]\n",
      " [ 1668    40]]\n",
      "done in 35.868158s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2724\n",
      "           1       0.38      0.01      0.02       275\n",
      "\n",
      "    accuracy                           0.91      2999\n",
      "   macro avg       0.64      0.50      0.49      2999\n",
      "weighted avg       0.86      0.91      0.87      2999\n",
      "\n",
      "Confusion_matrix\n",
      "[[2719    5]\n",
      " [ 272    3]]\n",
      "done in 36.025882s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2674\n",
      "           1       0.54      0.03      0.05       256\n",
      "\n",
      "    accuracy                           0.91      2930\n",
      "   macro avg       0.73      0.51      0.50      2930\n",
      "weighted avg       0.88      0.91      0.88      2930\n",
      "\n",
      "Confusion_matrix\n",
      "[[2668    6]\n",
      " [ 249    7]]\n",
      "done in 36.219138s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41100000000000003\n",
      "threshold:0.2, J-value:0.26399999999999996\n",
      "threshold:0.30000000000000004, J-value:0.154\n",
      "threshold:0.4, J-value:0.07100000000000001\n",
      "threshold:0.5, J-value:0.030000000000000002\n",
      "threshold:0.6000000000000001, J-value:0.011\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7054833108650711\n",
      "Balanced accuracy score of test is  0.6986732387959697\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.404\n",
      "threshold:0.2, J-value:0.258\n",
      "threshold:0.30000000000000004, J-value:0.153\n",
      "threshold:0.4, J-value:0.069\n",
      "threshold:0.5, J-value:0.029\n",
      "threshold:0.6000000000000001, J-value:0.011\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7022796133875924\n",
      "Balanced accuracy score of test is  0.6992264607151677\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.45100000000000007\n",
      "threshold:0.2, J-value:0.299\n",
      "threshold:0.30000000000000004, J-value:0.155\n",
      "threshold:0.4, J-value:0.077\n",
      "threshold:0.5, J-value:0.034\n",
      "threshold:0.6000000000000001, J-value:0.009999999999999998\n",
      "threshold:0.7000000000000001, J-value:-0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7256114003470832\n",
      "Balanced accuracy score of test is  0.6946785013089005\n",
      "True positive rate of class 1 is  0.663\n",
      "True positive rate of class 2 is  0.633\n",
      "Positive prediction rate of class 1 is  0.3\n",
      "Positive prediction rate of class 2 is  0.277\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.4\n",
      "threshold:0.2, J-value:0.28900000000000003\n",
      "threshold:0.30000000000000004, J-value:0.10600000000000001\n",
      "threshold:0.4, J-value:0.026\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7001874796414969\n",
      "Balanced accuracy score of test is  0.6853257296941414\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.39699999999999996\n",
      "threshold:0.2, J-value:0.275\n",
      "threshold:0.30000000000000004, J-value:0.10700000000000001\n",
      "threshold:0.4, J-value:0.028\n",
      "threshold:0.5, J-value:0.005\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6982421521839388\n",
      "Balanced accuracy score of test is  0.6894750624828698\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.44700000000000006\n",
      "threshold:0.2, J-value:0.313\n",
      "threshold:0.30000000000000004, J-value:0.11000000000000001\n",
      "threshold:0.4, J-value:0.018\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.72375383793886\n",
      "Balanced accuracy score of test is  0.6776248130142108\n",
      "True positive rate of class 1 is  0.726\n",
      "True positive rate of class 2 is  0.719\n",
      "Positive prediction rate of class 1 is  0.381\n",
      "Positive prediction rate of class 2 is  0.395\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.37899999999999995\n",
      "threshold:0.2, J-value:0.21299999999999997\n",
      "threshold:0.30000000000000004, J-value:0.08499999999999999\n",
      "threshold:0.4, J-value:0.028999999999999998\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.689387268517772\n",
      "Balanced accuracy score of test is  0.6746810298833401\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.374\n",
      "threshold:0.2, J-value:0.20599999999999996\n",
      "threshold:0.30000000000000004, J-value:0.088\n",
      "threshold:0.4, J-value:0.032\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6866057878087878\n",
      "Balanced accuracy score of test is  0.6737388093926475\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.4149999999999999\n",
      "threshold:0.2, J-value:0.263\n",
      "threshold:0.30000000000000004, J-value:0.063\n",
      "threshold:0.4, J-value:0.015\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7070377786677347\n",
      "Balanced accuracy score of test is  0.6798861724008975\n",
      "True positive rate of class 1 is  0.703\n",
      "True positive rate of class 2 is  0.641\n",
      "Positive prediction rate of class 1 is  0.386\n",
      "Positive prediction rate of class 2 is  0.312\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.42899999999999994\n",
      "threshold:0.2, J-value:0.27799999999999997\n",
      "threshold:0.30000000000000004, J-value:0.143\n",
      "threshold:0.4, J-value:0.060000000000000005\n",
      "threshold:0.5, J-value:0.015000000000000001\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7141743004334546\n",
      "Balanced accuracy score of test is  0.6986843498003696\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.42299999999999993\n",
      "threshold:0.2, J-value:0.26999999999999996\n",
      "threshold:0.30000000000000004, J-value:0.14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.4, J-value:0.056\n",
      "threshold:0.5, J-value:0.016\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7110900495116892\n",
      "Balanced accuracy score of test is  0.6999248305974746\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.46699999999999997\n",
      "threshold:0.2, J-value:0.32699999999999996\n",
      "threshold:0.30000000000000004, J-value:0.165\n",
      "threshold:0.4, J-value:0.085\n",
      "threshold:0.5, J-value:0.009\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7335142170604725\n",
      "Balanced accuracy score of test is  0.6902536579094989\n",
      "True positive rate of class 1 is  0.674\n",
      "True positive rate of class 2 is  0.645\n",
      "Positive prediction rate of class 1 is  0.311\n",
      "Positive prediction rate of class 2 is  0.297\n",
      "X train 65694\n",
      "Y train 65694\n",
      "21898 18825 3073\n",
      "21898 18825 3073\n",
      "21898 18883 3015\n",
      "21898 18883 3015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2620886582289643\n",
      "0.2560448666099038\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.95     19980\n",
      "           1       0.48      0.04      0.07      1918\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.70      0.52      0.51     21898\n",
      "weighted avg       0.88      0.91      0.88     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19898    82]\n",
      " [ 1842    76]]\n",
      "done in 1.062733s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2620886582289643\n",
      "0.25793694183031485\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19972\n",
      "           1       0.43      0.03      0.06      1926\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19885    87]\n",
      " [ 1861    65]]\n",
      "done in 1.134046s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2620886582289643\n",
      "0.2555946141881812\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.95     17178\n",
      "           1       0.46      0.04      0.07      1647\n",
      "\n",
      "    accuracy                           0.91     18825\n",
      "   macro avg       0.69      0.52      0.51     18825\n",
      "weighted avg       0.88      0.91      0.88     18825\n",
      "\n",
      "Confusion_matrix\n",
      "[[17108    70]\n",
      " [ 1587    60]]\n",
      "done in 1.157579s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2620886582289643\n",
      "0.260736585597518\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17196\n",
      "           1       0.44      0.03      0.06      1687\n",
      "\n",
      "    accuracy                           0.91     18883\n",
      "   macro avg       0.68      0.52      0.51     18883\n",
      "weighted avg       0.87      0.91      0.87     18883\n",
      "\n",
      "Confusion_matrix\n",
      "[[17122    74]\n",
      " [ 1629    58]]\n",
      "done in 1.371977s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2620886582289643\n",
      "0.25880308393464396\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.95      2802\n",
      "           1       0.57      0.06      0.11       271\n",
      "\n",
      "    accuracy                           0.91      3073\n",
      "   macro avg       0.74      0.53      0.53      3073\n",
      "weighted avg       0.89      0.91      0.88      3073\n",
      "\n",
      "Confusion_matrix\n",
      "[[2790   12]\n",
      " [ 255   16]]\n",
      "done in 1.208129s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2620886582289643\n",
      "0.24040272184487665\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2776\n",
      "           1       0.35      0.03      0.05       239\n",
      "\n",
      "    accuracy                           0.92      3015\n",
      "   macro avg       0.64      0.51      0.51      3015\n",
      "weighted avg       0.88      0.92      0.89      3015\n",
      "\n",
      "Confusion_matrix\n",
      "[[2763   13]\n",
      " [ 232    7]]\n",
      "done in 1.203346s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19980\n",
      "           1       0.75      0.00      0.00      1918\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.83      0.50      0.48     21898\n",
      "weighted avg       0.90      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19979     1]\n",
      " [ 1915     3]]\n",
      "done in 21.285170s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19972\n",
      "           1       0.43      0.00      0.00      1926\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19968     4]\n",
      " [ 1923     3]]\n",
      "done in 22.416300s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17178\n",
      "           1       0.80      0.00      0.00      1647\n",
      "\n",
      "    accuracy                           0.91     18825\n",
      "   macro avg       0.86      0.50      0.48     18825\n",
      "weighted avg       0.90      0.91      0.87     18825\n",
      "\n",
      "Confusion_matrix\n",
      "[[17177     1]\n",
      " [ 1643     4]]\n",
      "done in 22.033683s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17196\n",
      "           1       0.36      0.00      0.01      1687\n",
      "\n",
      "    accuracy                           0.91     18883\n",
      "   macro avg       0.63      0.50      0.48     18883\n",
      "weighted avg       0.86      0.91      0.87     18883\n",
      "\n",
      "Confusion_matrix\n",
      "[[17187     9]\n",
      " [ 1682     5]]\n",
      "done in 22.223702s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2802\n",
      "           1       1.00      0.01      0.01       271\n",
      "\n",
      "    accuracy                           0.91      3073\n",
      "   macro avg       0.96      0.50      0.48      3073\n",
      "weighted avg       0.92      0.91      0.87      3073\n",
      "\n",
      "Confusion_matrix\n",
      "[[2802    0]\n",
      " [ 269    2]]\n",
      "done in 21.937545s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2776\n",
      "           1       0.00      0.00      0.00       239\n",
      "\n",
      "    accuracy                           0.92      3015\n",
      "   macro avg       0.46      0.50      0.48      3015\n",
      "weighted avg       0.85      0.92      0.88      3015\n",
      "\n",
      "Confusion_matrix\n",
      "[[2775    1]\n",
      " [ 239    0]]\n",
      "done in 21.808978s\n",
      "0.26732574897465733\n",
      "0.2685985620764942\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19980\n",
      "           1       0.40      0.00      0.00      1918\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.66      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19977     3]\n",
      " [ 1916     2]]\n",
      "done in 0.711133s\n",
      "0.26732574897465733\n",
      "0.26985788626648854\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19972\n",
      "           1       0.14      0.00      0.00      1926\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.53      0.50      0.48     21898\n",
      "weighted avg       0.84      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19966     6]\n",
      " [ 1925     1]]\n",
      "done in 0.705574s\n",
      "0.26732574897465733\n",
      "0.2710635696483221\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17178\n",
      "           1       0.33      0.00      0.00      1647\n",
      "\n",
      "    accuracy                           0.91     18825\n",
      "   macro avg       0.62      0.50      0.48     18825\n",
      "weighted avg       0.86      0.91      0.87     18825\n",
      "\n",
      "Confusion_matrix\n",
      "[[17174     4]\n",
      " [ 1645     2]]\n",
      "done in 0.701611s\n",
      "0.26732574897465733\n",
      "0.2708907402588465\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17196\n",
      "           1       0.25      0.00      0.00      1687\n",
      "\n",
      "    accuracy                           0.91     18883\n",
      "   macro avg       0.58      0.50      0.48     18883\n",
      "weighted avg       0.85      0.91      0.87     18883\n",
      "\n",
      "Confusion_matrix\n",
      "[[17193     3]\n",
      " [ 1686     1]]\n",
      "done in 0.698463s\n",
      "0.26732574897465733\n",
      "0.28713293089278685\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2802\n",
      "           1       0.00      0.00      0.00       271\n",
      "\n",
      "    accuracy                           0.91      3073\n",
      "   macro avg       0.46      0.50      0.48      3073\n",
      "weighted avg       0.83      0.91      0.87      3073\n",
      "\n",
      "Confusion_matrix\n",
      "[[2800    2]\n",
      " [ 271    0]]\n",
      "done in 0.677123s\n",
      "0.26732574897465733\n",
      "0.24053451295113856\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2776\n",
      "           1       0.00      0.00      0.00       239\n",
      "\n",
      "    accuracy                           0.92      3015\n",
      "   macro avg       0.46      0.50      0.48      3015\n",
      "weighted avg       0.85      0.92      0.88      3015\n",
      "\n",
      "Confusion_matrix\n",
      "[[2775    1]\n",
      " [ 239    0]]\n",
      "done in 0.659263s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19980\n",
      "           1       0.44      0.02      0.04      1918\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.51      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19935    45]\n",
      " [ 1882    36]]\n",
      "done in 35.992356s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19972\n",
      "           1       0.45      0.02      0.04      1926\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19921    51]\n",
      " [ 1885    41]]\n",
      "done in 35.970581s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17178\n",
      "           1       0.47      0.02      0.04      1647\n",
      "\n",
      "    accuracy                           0.91     18825\n",
      "   macro avg       0.69      0.51      0.50     18825\n",
      "weighted avg       0.87      0.91      0.87     18825\n",
      "\n",
      "Confusion_matrix\n",
      "[[17143    35]\n",
      " [ 1616    31]]\n",
      "done in 35.734483s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17196\n",
      "           1       0.44      0.02      0.04      1687\n",
      "\n",
      "    accuracy                           0.91     18883\n",
      "   macro avg       0.68      0.51      0.50     18883\n",
      "weighted avg       0.87      0.91      0.87     18883\n",
      "\n",
      "Confusion_matrix\n",
      "[[17153    43]\n",
      " [ 1653    34]]\n",
      "done in 35.984385s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2802\n",
      "           1       0.33      0.02      0.03       271\n",
      "\n",
      "    accuracy                           0.91      3073\n",
      "   macro avg       0.62      0.51      0.49      3073\n",
      "weighted avg       0.86      0.91      0.87      3073\n",
      "\n",
      "Confusion_matrix\n",
      "[[2792   10]\n",
      " [ 266    5]]\n",
      "done in 36.081490s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2776\n",
      "           1       0.44      0.03      0.05       239\n",
      "\n",
      "    accuracy                           0.92      3015\n",
      "   macro avg       0.68      0.51      0.51      3015\n",
      "weighted avg       0.88      0.92      0.89      3015\n",
      "\n",
      "Confusion_matrix\n",
      "[[2767    9]\n",
      " [ 232    7]]\n",
      "done in 35.977638s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.2, J-value:0.27599999999999997\n",
      "threshold:0.30000000000000004, J-value:0.155\n",
      "threshold:0.4, J-value:0.07\n",
      "threshold:0.5, J-value:0.036000000000000004\n",
      "threshold:0.6000000000000001, J-value:0.012\n",
      "threshold:0.7000000000000001, J-value:0.004\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7021389481243496\n",
      "Balanced accuracy score of test is  0.6985516223231736\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.406\n",
      "threshold:0.2, J-value:0.27999999999999997\n",
      "threshold:0.30000000000000004, J-value:0.154\n",
      "threshold:0.4, J-value:0.066\n",
      "threshold:0.5, J-value:0.032\n",
      "threshold:0.6000000000000001, J-value:0.011\n",
      "threshold:0.7000000000000001, J-value:0.003\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7031298345980297\n",
      "Balanced accuracy score of test is  0.7005543534269214\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.392\n",
      "threshold:0.2, J-value:0.246\n",
      "threshold:0.30000000000000004, J-value:0.16\n",
      "threshold:0.4, J-value:0.099\n",
      "threshold:0.5, J-value:0.05499999999999999\n",
      "threshold:0.6000000000000001, J-value:0.019999999999999997\n",
      "threshold:0.7000000000000001, J-value:0.006\n",
      "threshold:0.8, J-value:-0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6962370051966045\n",
      "Balanced accuracy score of test is  0.682116135916945\n",
      "True positive rate of class 1 is  0.661\n",
      "True positive rate of class 2 is  0.586\n",
      "Positive prediction rate of class 1 is  0.296\n",
      "Positive prediction rate of class 2 is  0.25\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.389\n",
      "threshold:0.2, J-value:0.308\n",
      "threshold:0.30000000000000004, J-value:0.11500000000000002\n",
      "threshold:0.4, J-value:0.023\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6943534514702399\n",
      "Balanced accuracy score of test is  0.6965857600432922\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.391\n",
      "threshold:0.2, J-value:0.28300000000000003\n",
      "threshold:0.30000000000000004, J-value:0.122\n",
      "threshold:0.4, J-value:0.017\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6953165409816979\n",
      "Balanced accuracy score of test is  0.6930881659662791\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41600000000000004\n",
      "threshold:0.2, J-value:0.318\n",
      "threshold:0.30000000000000004, J-value:0.097\n",
      "threshold:0.4, J-value:0.018\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7076429329603788\n",
      "Balanced accuracy score of test is  0.7037970409848914\n",
      "True positive rate of class 1 is  0.729\n",
      "True positive rate of class 2 is  0.745\n",
      "Positive prediction rate of class 1 is  0.377\n",
      "Positive prediction rate of class 2 is  0.369\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.35300000000000004\n",
      "threshold:0.2, J-value:0.21199999999999997\n",
      "threshold:0.30000000000000004, J-value:0.10800000000000001\n",
      "threshold:0.4, J-value:0.001\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.001\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6761341894553574\n",
      "Balanced accuracy score of test is  0.6841409489380668\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.3430000000000001\n",
      "threshold:0.2, J-value:0.21799999999999997\n",
      "threshold:0.30000000000000004, J-value:0.11599999999999999\n",
      "threshold:0.4, J-value:0.001\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.001\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6716618833637552\n",
      "Balanced accuracy score of test is  0.6788795673936385\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.40700000000000003\n",
      "threshold:0.2, J-value:0.174\n",
      "threshold:0.30000000000000004, J-value:0.06999999999999999\n",
      "threshold:0.4, J-value:-0.001\n",
      "threshold:0.5, J-value:-0.001\n",
      "threshold:0.6000000000000001, J-value:-0.001\n",
      "threshold:0.7000000000000001, J-value:-0.001\n",
      "threshold:0.8, J-value:-0.001\n",
      "threshold:0.9, J-value:-0.001\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7035696695296717\n",
      "Balanced accuracy score of test is  0.716918325636357\n",
      "True positive rate of class 1 is  0.699\n",
      "True positive rate of class 2 is  0.703\n",
      "Positive prediction rate of class 1 is  0.374\n",
      "Positive prediction rate of class 2 is  0.303\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41899999999999993\n",
      "threshold:0.2, J-value:0.27599999999999997\n",
      "threshold:0.30000000000000004, J-value:0.151\n",
      "threshold:0.4, J-value:0.058\n",
      "threshold:0.5, J-value:0.017\n",
      "threshold:0.6000000000000001, J-value:0.006\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7097472081048724\n",
      "Balanced accuracy score of test is  0.7026313994316862\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.417\n",
      "threshold:0.2, J-value:0.28\n",
      "threshold:0.30000000000000004, J-value:0.153\n",
      "threshold:0.4, J-value:0.059000000000000004\n",
      "threshold:0.5, J-value:0.017\n",
      "threshold:0.6000000000000001, J-value:0.007\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7084871126516081\n",
      "Balanced accuracy score of test is  0.7020997701041019\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.43499999999999994\n",
      "threshold:0.2, J-value:0.25\n",
      "threshold:0.30000000000000004, J-value:0.139\n",
      "threshold:0.4, J-value:0.061000000000000006\n",
      "threshold:0.5, J-value:0.015\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.717313147435543\n",
      "Balanced accuracy score of test is  0.7045325744878396\n",
      "True positive rate of class 1 is  0.683\n",
      "True positive rate of class 2 is  0.657\n",
      "Positive prediction rate of class 1 is  0.315\n",
      "Positive prediction rate of class 2 is  0.28\n",
      "X train 65694\n",
      "Y train 65694\n",
      "21898 18936 2962\n",
      "21898 18936 2962\n",
      "21898 18829 3069\n",
      "21898 18829 3069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2594297514603444\n",
      "0.26010346671211954\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19950\n",
      "           1       0.47      0.04      0.07      1948\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.69      0.52      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19873    77]\n",
      " [ 1879    69]]\n",
      "done in 1.355038s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2594297514603444\n",
      "0.26234536939014164\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19883\n",
      "           1       0.51      0.03      0.06      2015\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.71      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19823    60]\n",
      " [ 1953    62]]\n",
      "done in 1.397836s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2594297514603444\n",
      "0.2628301736188533\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17239\n",
      "           1       0.45      0.03      0.06      1697\n",
      "\n",
      "    accuracy                           0.91     18936\n",
      "   macro avg       0.68      0.51      0.51     18936\n",
      "weighted avg       0.87      0.91      0.87     18936\n",
      "\n",
      "Confusion_matrix\n",
      "[[17175    64]\n",
      " [ 1644    53]]\n",
      "done in 1.428232s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2594297514603444\n",
      "0.2631953744968694\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17079\n",
      "           1       0.53      0.03      0.05      1750\n",
      "\n",
      "    accuracy                           0.91     18829\n",
      "   macro avg       0.72      0.51      0.50     18829\n",
      "weighted avg       0.87      0.91      0.87     18829\n",
      "\n",
      "Confusion_matrix\n",
      "[[17035    44]\n",
      " [ 1700    50]]\n",
      "done in 1.572817s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2594297514603444\n",
      "0.24267169021451285\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2711\n",
      "           1       0.55      0.06      0.11       251\n",
      "\n",
      "    accuracy                           0.92      2962\n",
      "   macro avg       0.74      0.53      0.54      2962\n",
      "weighted avg       0.89      0.92      0.88      2962\n",
      "\n",
      "Confusion_matrix\n",
      "[[2698   13]\n",
      " [ 235   16]]\n",
      "done in 1.530497s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2594297514603444\n",
      "0.2571303983394487\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95      2804\n",
      "           1       0.43      0.05      0.08       265\n",
      "\n",
      "    accuracy                           0.91      3069\n",
      "   macro avg       0.67      0.52      0.52      3069\n",
      "weighted avg       0.87      0.91      0.88      3069\n",
      "\n",
      "Confusion_matrix\n",
      "[[2788   16]\n",
      " [ 253   12]]\n",
      "done in 2.061455s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19950\n",
      "           1       0.43      0.00      0.01      1948\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19942     8]\n",
      " [ 1942     6]]\n",
      "done in 19.835581s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19883\n",
      "           1       0.43      0.00      0.00      2015\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.86     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19879     4]\n",
      " [ 2012     3]]\n",
      "done in 20.144478s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17239\n",
      "           1       0.33      0.00      0.01      1697\n",
      "\n",
      "    accuracy                           0.91     18936\n",
      "   macro avg       0.62      0.50      0.48     18936\n",
      "weighted avg       0.86      0.91      0.87     18936\n",
      "\n",
      "Confusion_matrix\n",
      "[[17229    10]\n",
      " [ 1692     5]]\n",
      "done in 19.948721s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17079\n",
      "           1       0.60      0.00      0.00      1750\n",
      "\n",
      "    accuracy                           0.91     18829\n",
      "   macro avg       0.75      0.50      0.48     18829\n",
      "weighted avg       0.88      0.91      0.86     18829\n",
      "\n",
      "Confusion_matrix\n",
      "[[17077     2]\n",
      " [ 1747     3]]\n",
      "done in 20.103698s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2711\n",
      "           1       1.00      0.01      0.02       251\n",
      "\n",
      "    accuracy                           0.92      2962\n",
      "   macro avg       0.96      0.50      0.49      2962\n",
      "weighted avg       0.92      0.92      0.88      2962\n",
      "\n",
      "Confusion_matrix\n",
      "[[2711    0]\n",
      " [ 249    2]]\n",
      "done in 19.520883s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2804\n",
      "           1       0.50      0.00      0.01       265\n",
      "\n",
      "    accuracy                           0.91      3069\n",
      "   macro avg       0.71      0.50      0.48      3069\n",
      "weighted avg       0.88      0.91      0.87      3069\n",
      "\n",
      "Confusion_matrix\n",
      "[[2803    1]\n",
      " [ 264    1]]\n",
      "done in 19.605794s\n",
      "0.264372916262498\n",
      "0.26860351065894233\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19950\n",
      "           1       0.00      0.00      0.00      1948\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.46      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19950     0]\n",
      " [ 1948     0]]\n",
      "done in 0.653644s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.264372916262498\n",
      "0.27783156880023685\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19883\n",
      "           1       0.00      0.00      0.00      2015\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.45      0.50      0.48     21898\n",
      "weighted avg       0.82      0.91      0.86     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19880     3]\n",
      " [ 2015     0]]\n",
      "done in 0.683664s\n",
      "0.264372916262498\n",
      "0.27110982457726274\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17239\n",
      "           1       0.00      0.00      0.00      1697\n",
      "\n",
      "    accuracy                           0.91     18936\n",
      "   macro avg       0.46      0.50      0.48     18936\n",
      "weighted avg       0.83      0.91      0.87     18936\n",
      "\n",
      "Confusion_matrix\n",
      "[[17239     0]\n",
      " [ 1697     0]]\n",
      "done in 0.667593s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.264372916262498\n",
      "0.27474664355551137\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17079\n",
      "           1       0.00      0.00      0.00      1750\n",
      "\n",
      "    accuracy                           0.91     18829\n",
      "   macro avg       0.45      0.50      0.48     18829\n",
      "weighted avg       0.82      0.91      0.86     18829\n",
      "\n",
      "Confusion_matrix\n",
      "[[17079     0]\n",
      " [ 1750     0]]\n",
      "done in 0.603572s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.264372916262498\n",
      "0.2525807016254122\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2711\n",
      "           1       0.00      0.00      0.00       251\n",
      "\n",
      "    accuracy                           0.92      2962\n",
      "   macro avg       0.46      0.50      0.48      2962\n",
      "weighted avg       0.84      0.92      0.87      2962\n",
      "\n",
      "Confusion_matrix\n",
      "[[2711    0]\n",
      " [ 251    0]]\n",
      "done in 0.597418s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.264372916262498\n",
      "0.3080123553195742\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2804\n",
      "           1       0.00      0.00      0.00       265\n",
      "\n",
      "    accuracy                           0.91      3069\n",
      "   macro avg       0.46      0.50      0.48      3069\n",
      "weighted avg       0.83      0.91      0.87      3069\n",
      "\n",
      "Confusion_matrix\n",
      "[[2800    4]\n",
      " [ 265    0]]\n",
      "done in 0.594193s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19950\n",
      "           1       0.43      0.02      0.03      1948\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19904    46]\n",
      " [ 1913    35]]\n",
      "done in 33.001511s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19883\n",
      "           1       0.42      0.02      0.03      2015\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.66      0.51      0.49     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19840    43]\n",
      " [ 1984    31]]\n",
      "done in 33.194539s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17239\n",
      "           1       0.41      0.02      0.03      1697\n",
      "\n",
      "    accuracy                           0.91     18936\n",
      "   macro avg       0.66      0.51      0.49     18936\n",
      "weighted avg       0.87      0.91      0.87     18936\n",
      "\n",
      "Confusion_matrix\n",
      "[[17201    38]\n",
      " [ 1671    26]]\n",
      "done in 33.274519s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17079\n",
      "           1       0.46      0.01      0.03      1750\n",
      "\n",
      "    accuracy                           0.91     18829\n",
      "   macro avg       0.68      0.51      0.49     18829\n",
      "weighted avg       0.87      0.91      0.87     18829\n",
      "\n",
      "Confusion_matrix\n",
      "[[17051    28]\n",
      " [ 1726    24]]\n",
      "done in 33.270108s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2711\n",
      "           1       0.56      0.04      0.07       251\n",
      "\n",
      "    accuracy                           0.92      2962\n",
      "   macro avg       0.74      0.52      0.51      2962\n",
      "weighted avg       0.89      0.92      0.88      2962\n",
      "\n",
      "Confusion_matrix\n",
      "[[2704    7]\n",
      " [ 242    9]]\n",
      "done in 33.038036s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.95      2804\n",
      "           1       0.33      0.03      0.05       265\n",
      "\n",
      "    accuracy                           0.91      3069\n",
      "   macro avg       0.62      0.51      0.50      3069\n",
      "weighted avg       0.87      0.91      0.88      3069\n",
      "\n",
      "Confusion_matrix\n",
      "[[2790   14]\n",
      " [ 258    7]]\n",
      "done in 33.148837s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.397\n",
      "threshold:0.2, J-value:0.254\n",
      "threshold:0.30000000000000004, J-value:0.14100000000000001\n",
      "threshold:0.4, J-value:0.07100000000000001\n",
      "threshold:0.5, J-value:0.028\n",
      "threshold:0.6000000000000001, J-value:0.009000000000000001\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6987633611750115\n",
      "Balanced accuracy score of test is  0.7065258436793205\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.388\n",
      "threshold:0.2, J-value:0.247\n",
      "threshold:0.30000000000000004, J-value:0.138\n",
      "threshold:0.4, J-value:0.066\n",
      "threshold:0.5, J-value:0.024\n",
      "threshold:0.6000000000000001, J-value:0.008\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6938977903051977\n",
      "Balanced accuracy score of test is  0.7105172266693434\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.4610000000000001\n",
      "threshold:0.2, J-value:0.306\n",
      "threshold:0.30000000000000004, J-value:0.16\n",
      "threshold:0.4, J-value:0.1\n",
      "threshold:0.5, J-value:0.06\n",
      "threshold:0.6000000000000001, J-value:0.009000000000000001\n",
      "threshold:0.7000000000000001, J-value:0.004\n",
      "threshold:0.8, J-value:0.004\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7306781725918163\n",
      "Balanced accuracy score of test is  0.6800218017387559\n",
      "True positive rate of class 1 is  0.673\n",
      "True positive rate of class 2 is  0.608\n",
      "Positive prediction rate of class 1 is  0.291\n",
      "Positive prediction rate of class 2 is  0.279\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.391\n",
      "threshold:0.2, J-value:0.279\n",
      "threshold:0.30000000000000004, J-value:0.10700000000000001\n",
      "threshold:0.4, J-value:0.024\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6954572519594675\n",
      "Balanced accuracy score of test is  0.6956838947046176\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.37699999999999995\n",
      "threshold:0.2, J-value:0.276\n",
      "threshold:0.30000000000000004, J-value:0.091\n",
      "threshold:0.4, J-value:0.024\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6885174709207101\n",
      "Balanced accuracy score of test is  0.6974618955609646\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.457\n",
      "threshold:0.2, J-value:0.316\n",
      "threshold:0.30000000000000004, J-value:0.125\n",
      "threshold:0.4, J-value:0.028\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7283584217170418\n",
      "Balanced accuracy score of test is  0.7031551960810702\n",
      "True positive rate of class 1 is  0.737\n",
      "True positive rate of class 2 is  0.781\n",
      "Positive prediction rate of class 1 is  0.378\n",
      "Positive prediction rate of class 2 is  0.41\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.36000000000000004\n",
      "threshold:0.2, J-value:0.226\n",
      "threshold:0.30000000000000004, J-value:0.10600000000000001\n",
      "threshold:0.4, J-value:0.003\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6797208370000978\n",
      "Balanced accuracy score of test is  0.6855804346244389\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.35200000000000004\n",
      "threshold:0.2, J-value:0.222\n",
      "threshold:0.30000000000000004, J-value:0.11100000000000002\n",
      "threshold:0.4, J-value:0.003\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6755665257645271\n",
      "Balanced accuracy score of test is  0.6859463334253427\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41000000000000003\n",
      "threshold:0.2, J-value:0.253\n",
      "threshold:0.30000000000000004, J-value:0.07600000000000001\n",
      "threshold:0.4, J-value:0.0\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7052248402186165\n",
      "Balanced accuracy score of test is  0.680913385190967\n",
      "True positive rate of class 1 is  0.685\n",
      "True positive rate of class 2 is  0.608\n",
      "Positive prediction rate of class 1 is  0.348\n",
      "Positive prediction rate of class 2 is  0.277\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.4149999999999999\n",
      "threshold:0.2, J-value:0.26\n",
      "threshold:0.30000000000000004, J-value:0.138\n",
      "threshold:0.4, J-value:0.053\n",
      "threshold:0.5, J-value:0.016\n",
      "threshold:0.6000000000000001, J-value:0.005\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7072499009330308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy score of test is  0.7106360671466541\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.401\n",
      "threshold:0.2, J-value:0.255\n",
      "threshold:0.30000000000000004, J-value:0.135\n",
      "threshold:0.4, J-value:0.05\n",
      "threshold:0.5, J-value:0.013\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7004537203623789\n",
      "Balanced accuracy score of test is  0.7135740466571312\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.504\n",
      "threshold:0.2, J-value:0.291\n",
      "threshold:0.30000000000000004, J-value:0.159\n",
      "threshold:0.4, J-value:0.07200000000000001\n",
      "threshold:0.5, J-value:0.032999999999999995\n",
      "threshold:0.6000000000000001, J-value:0.02\n",
      "threshold:0.7000000000000001, J-value:0.004\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7522223904088552\n",
      "Balanced accuracy score of test is  0.6913546685328238\n",
      "True positive rate of class 1 is  0.698\n",
      "True positive rate of class 2 is  0.657\n",
      "Positive prediction rate of class 1 is  0.31\n",
      "Positive prediction rate of class 2 is  0.307\n",
      "X train 65694\n",
      "Y train 65694\n",
      "21898 18932 2966\n",
      "21898 18932 2966\n",
      "21898 18882 3016\n",
      "21898 18882 3016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.258858590651608\n",
      "0.2629661801127107\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19908\n",
      "           1       0.46      0.04      0.07      1990\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.69      0.52      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19823    85]\n",
      " [ 1917    73]]\n",
      "done in 1.196525s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.258858590651608\n",
      "0.26086137987781655\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19918\n",
      "           1       0.43      0.03      0.06      1980\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19830    88]\n",
      " [ 1914    66]]\n",
      "done in 0.954461s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.258858590651608\n",
      "0.2631449162676813\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17204\n",
      "           1       0.48      0.04      0.07      1728\n",
      "\n",
      "    accuracy                           0.91     18932\n",
      "   macro avg       0.70      0.52      0.51     18932\n",
      "weighted avg       0.87      0.91      0.87     18932\n",
      "\n",
      "Confusion_matrix\n",
      "[[17139    65]\n",
      " [ 1667    61]]\n",
      "done in 1.179350s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.258858590651608\n",
      "0.2632369222214004\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17156\n",
      "           1       0.40      0.03      0.05      1726\n",
      "\n",
      "    accuracy                           0.91     18882\n",
      "   macro avg       0.66      0.51      0.50     18882\n",
      "weighted avg       0.86      0.91      0.87     18882\n",
      "\n",
      "Confusion_matrix\n",
      "[[17083    73]\n",
      " [ 1677    49]]\n",
      "done in 0.896389s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.258858590651608\n",
      "0.2618253059097764\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95      2704\n",
      "           1       0.38      0.05      0.08       262\n",
      "\n",
      "    accuracy                           0.91      2966\n",
      "   macro avg       0.64      0.52      0.52      2966\n",
      "weighted avg       0.87      0.91      0.88      2966\n",
      "\n",
      "Confusion_matrix\n",
      "[[2684   20]\n",
      " [ 250   12]]\n",
      "done in 0.908404s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.258858590651608\n",
      "0.2459890355371171\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96      2762\n",
      "           1       0.53      0.07      0.12       254\n",
      "\n",
      "    accuracy                           0.92      3016\n",
      "   macro avg       0.73      0.53      0.54      3016\n",
      "weighted avg       0.89      0.92      0.89      3016\n",
      "\n",
      "Confusion_matrix\n",
      "[[2747   15]\n",
      " [ 237   17]]\n",
      "done in 0.898778s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19908\n",
      "           1       0.47      0.00      0.01      1990\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.69      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19900     8]\n",
      " [ 1983     7]]\n",
      "done in 19.833456s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19918\n",
      "           1       0.50      0.00      0.00      1980\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.70      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19915     3]\n",
      " [ 1977     3]]\n",
      "done in 20.032571s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17204\n",
      "           1       0.54      0.00      0.01      1728\n",
      "\n",
      "    accuracy                           0.91     18932\n",
      "   macro avg       0.72      0.50      0.48     18932\n",
      "weighted avg       0.88      0.91      0.87     18932\n",
      "\n",
      "Confusion_matrix\n",
      "[[17198     6]\n",
      " [ 1721     7]]\n",
      "done in 19.788417s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17156\n",
      "           1       0.50      0.00      0.01      1726\n",
      "\n",
      "    accuracy                           0.91     18882\n",
      "   macro avg       0.70      0.50      0.48     18882\n",
      "weighted avg       0.87      0.91      0.87     18882\n",
      "\n",
      "Confusion_matrix\n",
      "[[17151     5]\n",
      " [ 1721     5]]\n",
      "done in 19.853460s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2704\n",
      "           1       0.00      0.00      0.00       262\n",
      "\n",
      "    accuracy                           0.91      2966\n",
      "   macro avg       0.46      0.50      0.48      2966\n",
      "weighted avg       0.83      0.91      0.87      2966\n",
      "\n",
      "Confusion_matrix\n",
      "[[2703    1]\n",
      " [ 262    0]]\n",
      "done in 19.852226s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2762\n",
      "           1       0.00      0.00      0.00       254\n",
      "\n",
      "    accuracy                           0.92      3016\n",
      "   macro avg       0.46      0.50      0.48      3016\n",
      "weighted avg       0.84      0.92      0.88      3016\n",
      "\n",
      "Confusion_matrix\n",
      "[[2761    1]\n",
      " [ 254    0]]\n",
      "done in 19.705799s\n",
      "0.26428564201629917\n",
      "0.2711976984051151\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19908\n",
      "           1       0.00      0.00      0.00      1990\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.45      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19905     3]\n",
      " [ 1990     0]]\n",
      "done in 0.670409s\n",
      "0.26428564201629917\n",
      "0.27048007615636765\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19918\n",
      "           1       0.00      0.00      0.00      1980\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.45      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19915     3]\n",
      " [ 1980     0]]\n",
      "done in 0.644359s\n",
      "0.26428564201629917\n",
      "0.27193464291926434\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17204\n",
      "           1       0.00      0.00      0.00      1728\n",
      "\n",
      "    accuracy                           0.91     18932\n",
      "   macro avg       0.45      0.50      0.48     18932\n",
      "weighted avg       0.83      0.91      0.87     18932\n",
      "\n",
      "Confusion_matrix\n",
      "[[17201     3]\n",
      " [ 1728     0]]\n",
      "done in 0.631198s\n",
      "0.26428564201629917\n",
      "0.27233511337440713\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17156\n",
      "           1       0.00      0.00      0.00      1726\n",
      "\n",
      "    accuracy                           0.91     18882\n",
      "   macro avg       0.45      0.50      0.48     18882\n",
      "weighted avg       0.83      0.91      0.87     18882\n",
      "\n",
      "Confusion_matrix\n",
      "[[17155     1]\n",
      " [ 1726     0]]\n",
      "done in 0.643180s\n",
      "0.26428564201629917\n",
      "0.2667215164112277\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2704\n",
      "           1       0.00      0.00      0.00       262\n",
      "\n",
      "    accuracy                           0.91      2966\n",
      "   macro avg       0.46      0.50      0.48      2966\n",
      "weighted avg       0.83      0.91      0.87      2966\n",
      "\n",
      "Confusion_matrix\n",
      "[[2704    0]\n",
      " [ 262    0]]\n",
      "done in 0.616505s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26428564201629917\n",
      "0.2588664114511214\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2762\n",
      "           1       0.00      0.00      0.00       254\n",
      "\n",
      "    accuracy                           0.92      3016\n",
      "   macro avg       0.46      0.50      0.48      3016\n",
      "weighted avg       0.84      0.92      0.88      3016\n",
      "\n",
      "Confusion_matrix\n",
      "[[2760    2]\n",
      " [ 254    0]]\n",
      "done in 0.613278s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19908\n",
      "           1       0.44      0.02      0.04      1990\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.51      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19859    49]\n",
      " [ 1951    39]]\n",
      "done in 33.386764s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19918\n",
      "           1       0.37      0.02      0.03      1980\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.64      0.51      0.49     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19862    56]\n",
      " [ 1947    33]]\n",
      "done in 33.148178s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17204\n",
      "           1       0.44      0.02      0.03      1728\n",
      "\n",
      "    accuracy                           0.91     18932\n",
      "   macro avg       0.67      0.51      0.49     18932\n",
      "weighted avg       0.87      0.91      0.87     18932\n",
      "\n",
      "Confusion_matrix\n",
      "[[17167    37]\n",
      " [ 1699    29]]\n",
      "done in 33.293990s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17156\n",
      "           1       0.40      0.02      0.03      1726\n",
      "\n",
      "    accuracy                           0.91     18882\n",
      "   macro avg       0.65      0.51      0.49     18882\n",
      "weighted avg       0.86      0.91      0.87     18882\n",
      "\n",
      "Confusion_matrix\n",
      "[[17111    45]\n",
      " [ 1696    30]]\n",
      "done in 33.004972s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2704\n",
      "           1       0.48      0.04      0.07       262\n",
      "\n",
      "    accuracy                           0.91      2966\n",
      "   macro avg       0.70      0.52      0.51      2966\n",
      "weighted avg       0.88      0.91      0.88      2966\n",
      "\n",
      "Confusion_matrix\n",
      "[[2693   11]\n",
      " [ 252   10]]\n",
      "done in 33.018280s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.95      2762\n",
      "           1       0.27      0.02      0.03       254\n",
      "\n",
      "    accuracy                           0.91      3016\n",
      "   macro avg       0.59      0.51      0.49      3016\n",
      "weighted avg       0.86      0.91      0.88      3016\n",
      "\n",
      "Confusion_matrix\n",
      "[[2751   11]\n",
      " [ 250    4]]\n",
      "done in 32.862241s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.397\n",
      "threshold:0.2, J-value:0.26\n",
      "threshold:0.30000000000000004, J-value:0.157\n",
      "threshold:0.4, J-value:0.077\n",
      "threshold:0.5, J-value:0.035\n",
      "threshold:0.6000000000000001, J-value:0.013999999999999999\n",
      "threshold:0.7000000000000001, J-value:0.004\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6984924118280775\n",
      "Balanced accuracy score of test is  0.7102360841064526\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.398\n",
      "threshold:0.2, J-value:0.258\n",
      "threshold:0.30000000000000004, J-value:0.158\n",
      "threshold:0.4, J-value:0.076\n",
      "threshold:0.5, J-value:0.033\n",
      "threshold:0.6000000000000001, J-value:0.012\n",
      "threshold:0.7000000000000001, J-value:0.003\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6986684701878116\n",
      "Balanced accuracy score of test is  0.7099552278363336\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.394\n",
      "threshold:0.2, J-value:0.273\n",
      "threshold:0.30000000000000004, J-value:0.158\n",
      "threshold:0.4, J-value:0.088\n",
      "threshold:0.5, J-value:0.043000000000000003\n",
      "threshold:0.6000000000000001, J-value:0.022\n",
      "threshold:0.7000000000000001, J-value:0.011\n",
      "threshold:0.8, J-value:0.004\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6972748882063327\n",
      "Balanced accuracy score of test is  0.7108009715657375\n",
      "True positive rate of class 1 is  0.673\n",
      "True positive rate of class 2 is  0.642\n",
      "Positive prediction rate of class 1 is  0.292\n",
      "Positive prediction rate of class 2 is  0.256\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.37999999999999995\n",
      "threshold:0.2, J-value:0.272\n",
      "threshold:0.30000000000000004, J-value:0.11400000000000002\n",
      "threshold:0.4, J-value:0.029\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6897668470946252\n",
      "Balanced accuracy score of test is  0.705549292503304\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.38099999999999995\n",
      "threshold:0.2, J-value:0.27\n",
      "threshold:0.30000000000000004, J-value:0.11500000000000002\n",
      "threshold:0.4, J-value:0.026\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6909800934537188\n",
      "Balanced accuracy score of test is  0.6936972210837662\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.381\n",
      "threshold:0.2, J-value:0.313\n",
      "threshold:0.30000000000000004, J-value:0.10600000000000001\n",
      "threshold:0.4, J-value:0.013\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6907394755860699\n",
      "Balanced accuracy score of test is  0.7104560201155159\n",
      "True positive rate of class 1 is  0.729\n",
      "True positive rate of class 2 is  0.764\n",
      "Positive prediction rate of class 1 is  0.377\n",
      "Positive prediction rate of class 2 is  0.378\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.35500000000000004\n",
      "threshold:0.2, J-value:0.227\n",
      "threshold:0.30000000000000004, J-value:0.101\n",
      "threshold:0.4, J-value:0.003\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6776950353535812\n",
      "Balanced accuracy score of test is  0.6807762330605989\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.35300000000000004\n",
      "threshold:0.2, J-value:0.233\n",
      "threshold:0.30000000000000004, J-value:0.10800000000000001\n",
      "threshold:0.4, J-value:0.003\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6762826205361372\n",
      "Balanced accuracy score of test is  0.6804078151902776\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.374\n",
      "threshold:0.2, J-value:0.18799999999999997\n",
      "threshold:0.30000000000000004, J-value:0.06\n",
      "threshold:0.4, J-value:0.005\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6869198586205338\n",
      "Balanced accuracy score of test is  0.681453015331809\n",
      "True positive rate of class 1 is  0.652\n",
      "True positive rate of class 2 is  0.614\n",
      "Positive prediction rate of class 1 is  0.325\n",
      "Positive prediction rate of class 2 is  0.282\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.397\n",
      "threshold:0.2, J-value:0.27299999999999996\n",
      "threshold:0.30000000000000004, J-value:0.14400000000000002\n",
      "threshold:0.4, J-value:0.059000000000000004\n",
      "threshold:0.5, J-value:0.018000000000000002\n",
      "threshold:0.6000000000000001, J-value:0.005\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6984957437377767\n",
      "Balanced accuracy score of test is  0.70961365842378\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.398\n",
      "threshold:0.2, J-value:0.27399999999999997\n",
      "threshold:0.30000000000000004, J-value:0.14600000000000002\n",
      "threshold:0.4, J-value:0.059000000000000004\n",
      "threshold:0.5, J-value:0.015000000000000001\n",
      "threshold:0.6000000000000001, J-value:0.002\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6988955249425198\n",
      "Balanced accuracy score of test is  0.7075214911518781\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.392\n",
      "threshold:0.2, J-value:0.263\n",
      "threshold:0.30000000000000004, J-value:0.132\n",
      "threshold:0.4, J-value:0.05800000000000001\n",
      "threshold:0.5, J-value:0.034\n",
      "threshold:0.6000000000000001, J-value:0.015\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6961513053886805\n",
      "Balanced accuracy score of test is  0.7224751549430688\n",
      "True positive rate of class 1 is  0.688\n",
      "True positive rate of class 2 is  0.689\n",
      "Positive prediction rate of class 1 is  0.311\n",
      "Positive prediction rate of class 2 is  0.281\n",
      "X train 65694\n",
      "Y train 65694\n",
      "21898 18875 3023\n",
      "21898 18875 3023\n",
      "21898 19009 2889\n",
      "21898 19009 2889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26309747172570896\n",
      "0.2547885608939852\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95     20006\n",
      "           1       0.38      0.03      0.06      1892\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.65      0.51      0.51     21898\n",
      "weighted avg       0.87      0.91      0.88     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19905   101]\n",
      " [ 1829    63]]\n",
      "done in 0.960614s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26309747172570896\n",
      "0.25632492941221824\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.95     19975\n",
      "           1       0.47      0.04      0.08      1923\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.69      0.52      0.52     21898\n",
      "weighted avg       0.88      0.91      0.88     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19884    91]\n",
      " [ 1841    82]]\n",
      "done in 1.249491s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26309747172570896\n",
      "0.2557437468569436\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.95     17241\n",
      "           1       0.38      0.03      0.06      1634\n",
      "\n",
      "    accuracy                           0.91     18875\n",
      "   macro avg       0.65      0.51      0.50     18875\n",
      "weighted avg       0.87      0.91      0.88     18875\n",
      "\n",
      "Confusion_matrix\n",
      "[[17162    79]\n",
      " [ 1585    49]]\n",
      "done in 0.986320s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26309747172570896\n",
      "0.2597938656375841\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17310\n",
      "           1       0.48      0.04      0.07      1699\n",
      "\n",
      "    accuracy                           0.91     19009\n",
      "   macro avg       0.70      0.52      0.51     19009\n",
      "weighted avg       0.87      0.91      0.87     19009\n",
      "\n",
      "Confusion_matrix\n",
      "[[17242    68]\n",
      " [ 1637    62]]\n",
      "done in 0.959364s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26309747172570896\n",
      "0.24882457311666448\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95      2765\n",
      "           1       0.39      0.05      0.10       258\n",
      "\n",
      "    accuracy                           0.91      3023\n",
      "   macro avg       0.65      0.52      0.52      3023\n",
      "weighted avg       0.87      0.91      0.88      3023\n",
      "\n",
      "Confusion_matrix\n",
      "[[2743   22]\n",
      " [ 244   14]]\n",
      "done in 0.891903s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26309747172570896\n",
      "0.2335000735077602\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      2665\n",
      "           1       0.47      0.09      0.15       224\n",
      "\n",
      "    accuracy                           0.92      2889\n",
      "   macro avg       0.70      0.54      0.55      2889\n",
      "weighted avg       0.89      0.92      0.90      2889\n",
      "\n",
      "Confusion_matrix\n",
      "[[2642   23]\n",
      " [ 204   20]]\n",
      "done in 0.910578s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     20006\n",
      "           1       0.60      0.00      0.01      1892\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.76      0.50      0.48     21898\n",
      "weighted avg       0.89      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[20000     6]\n",
      " [ 1883     9]]\n",
      "done in 19.500383s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19975\n",
      "           1       0.29      0.00      0.00      1923\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.60      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19970     5]\n",
      " [ 1921     2]]\n",
      "done in 19.691486s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17241\n",
      "           1       0.62      0.00      0.01      1634\n",
      "\n",
      "    accuracy                           0.91     18875\n",
      "   macro avg       0.77      0.50      0.48     18875\n",
      "weighted avg       0.89      0.91      0.87     18875\n",
      "\n",
      "Confusion_matrix\n",
      "[[17238     3]\n",
      " [ 1629     5]]\n",
      "done in 19.850532s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17310\n",
      "           1       0.33      0.00      0.00      1699\n",
      "\n",
      "    accuracy                           0.91     19009\n",
      "   macro avg       0.62      0.50      0.48     19009\n",
      "weighted avg       0.86      0.91      0.87     19009\n",
      "\n",
      "Confusion_matrix\n",
      "[[17302     8]\n",
      " [ 1695     4]]\n",
      "done in 19.723028s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.96      2765\n",
      "           1       0.00      0.00      0.00       258\n",
      "\n",
      "    accuracy                           0.91      3023\n",
      "   macro avg       0.46      0.50      0.48      3023\n",
      "weighted avg       0.84      0.91      0.87      3023\n",
      "\n",
      "Confusion_matrix\n",
      "[[2763    2]\n",
      " [ 258    0]]\n",
      "done in 19.352296s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2665\n",
      "           1       1.00      0.00      0.01       224\n",
      "\n",
      "    accuracy                           0.92      2889\n",
      "   macro avg       0.96      0.50      0.48      2889\n",
      "weighted avg       0.93      0.92      0.89      2889\n",
      "\n",
      "Confusion_matrix\n",
      "[[2665    0]\n",
      " [ 223    1]]\n",
      "done in 19.554874s\n",
      "0.2682128952371694\n",
      "0.2638709963739227\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     20006\n",
      "           1       0.56      0.00      0.01      1892\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.74      0.50      0.48     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19999     7]\n",
      " [ 1883     9]]\n",
      "done in 0.626545s\n",
      "0.2682128952371694\n",
      "0.26619820202997585\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19975\n",
      "           1       0.56      0.00      0.01      1923\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.74      0.50      0.48     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19968     7]\n",
      " [ 1914     9]]\n",
      "done in 0.634474s\n",
      "0.2682128952371694\n",
      "0.26452887711964745\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17241\n",
      "           1       0.50      0.00      0.01      1634\n",
      "\n",
      "    accuracy                           0.91     18875\n",
      "   macro avg       0.71      0.50      0.48     18875\n",
      "weighted avg       0.88      0.91      0.87     18875\n",
      "\n",
      "Confusion_matrix\n",
      "[[17234     7]\n",
      " [ 1627     7]]\n",
      "done in 0.676398s\n",
      "0.2682128952371694\n",
      "0.2686302724769611\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17310\n",
      "           1       0.55      0.00      0.01      1699\n",
      "\n",
      "    accuracy                           0.91     19009\n",
      "   macro avg       0.73      0.50      0.48     19009\n",
      "weighted avg       0.88      0.91      0.87     19009\n",
      "\n",
      "Confusion_matrix\n",
      "[[17305     5]\n",
      " [ 1693     6]]\n",
      "done in 0.617752s\n",
      "0.2682128952371694\n",
      "0.2597633221841926\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2765\n",
      "           1       1.00      0.01      0.02       258\n",
      "\n",
      "    accuracy                           0.92      3023\n",
      "   macro avg       0.96      0.50      0.49      3023\n",
      "weighted avg       0.92      0.92      0.88      3023\n",
      "\n",
      "Confusion_matrix\n",
      "[[2765    0]\n",
      " [ 256    2]]\n",
      "done in 0.592691s\n",
      "0.2682128952371694\n",
      "0.2501957004284727\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2665\n",
      "           1       0.60      0.01      0.03       224\n",
      "\n",
      "    accuracy                           0.92      2889\n",
      "   macro avg       0.76      0.51      0.49      2889\n",
      "weighted avg       0.90      0.92      0.89      2889\n",
      "\n",
      "Confusion_matrix\n",
      "[[2663    2]\n",
      " [ 221    3]]\n",
      "done in 0.604277s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     20006\n",
      "           1       0.37      0.02      0.04      1892\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.64      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19945    61]\n",
      " [ 1856    36]]\n",
      "done in 33.113393s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19975\n",
      "           1       0.46      0.02      0.05      1923\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.69      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19920    55]\n",
      " [ 1876    47]]\n",
      "done in 32.890653s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17241\n",
      "           1       0.37      0.02      0.03      1634\n",
      "\n",
      "    accuracy                           0.91     18875\n",
      "   macro avg       0.64      0.51      0.49     18875\n",
      "weighted avg       0.87      0.91      0.87     18875\n",
      "\n",
      "Confusion_matrix\n",
      "[[17191    50]\n",
      " [ 1605    29]]\n",
      "done in 33.083390s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17310\n",
      "           1       0.49      0.02      0.04      1699\n",
      "\n",
      "    accuracy                           0.91     19009\n",
      "   macro avg       0.70      0.51      0.50     19009\n",
      "weighted avg       0.87      0.91      0.87     19009\n",
      "\n",
      "Confusion_matrix\n",
      "[[17271    39]\n",
      " [ 1661    38]]\n",
      "done in 32.608354s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.95      2765\n",
      "           1       0.37      0.03      0.05       258\n",
      "\n",
      "    accuracy                           0.91      3023\n",
      "   macro avg       0.64      0.51      0.50      3023\n",
      "weighted avg       0.87      0.91      0.88      3023\n",
      "\n",
      "Confusion_matrix\n",
      "[[2753   12]\n",
      " [ 251    7]]\n",
      "done in 33.197533s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96      2665\n",
      "           1       0.39      0.04      0.07       224\n",
      "\n",
      "    accuracy                           0.92      2889\n",
      "   macro avg       0.66      0.52      0.52      2889\n",
      "weighted avg       0.88      0.92      0.89      2889\n",
      "\n",
      "Confusion_matrix\n",
      "[[2651   14]\n",
      " [ 215    9]]\n",
      "done in 33.246648s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.2, J-value:0.262\n",
      "threshold:0.30000000000000004, J-value:0.148\n",
      "threshold:0.4, J-value:0.069\n",
      "threshold:0.5, J-value:0.029\n",
      "threshold:0.6000000000000001, J-value:0.011\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7010668469649379\n",
      "Balanced accuracy score of test is  0.7041008488900258\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.395\n",
      "threshold:0.2, J-value:0.26099999999999995\n",
      "threshold:0.30000000000000004, J-value:0.145\n",
      "threshold:0.4, J-value:0.064\n",
      "threshold:0.5, J-value:0.024\n",
      "threshold:0.6000000000000001, J-value:0.01\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6978414473710832\n",
      "Balanced accuracy score of test is  0.7017047782550581\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.44299999999999995\n",
      "threshold:0.2, J-value:0.274\n",
      "threshold:0.30000000000000004, J-value:0.16799999999999998\n",
      "threshold:0.4, J-value:0.103\n",
      "threshold:0.5, J-value:0.054\n",
      "threshold:0.6000000000000001, J-value:0.016\n",
      "threshold:0.7000000000000001, J-value:0.003\n",
      "threshold:0.8, J-value:-0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7214019372835976\n",
      "Balanced accuracy score of test is  0.7210483114446529\n",
      "True positive rate of class 1 is  0.666\n",
      "True positive rate of class 2 is  0.688\n",
      "Positive prediction rate of class 1 is  0.298\n",
      "Positive prediction rate of class 2 is  0.28\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.399\n",
      "threshold:0.2, J-value:0.29\n",
      "threshold:0.30000000000000004, J-value:0.11699999999999999\n",
      "threshold:0.4, J-value:0.026\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6992129369645765\n",
      "Balanced accuracy score of test is  0.7014149512163215\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.391\n",
      "threshold:0.2, J-value:0.28600000000000003\n",
      "threshold:0.30000000000000004, J-value:0.11000000000000001\n",
      "threshold:0.4, J-value:0.024\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6952772159273918\n",
      "Balanced accuracy score of test is  0.695230534561908\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41900000000000004\n",
      "threshold:0.2, J-value:0.32\n",
      "threshold:0.30000000000000004, J-value:0.12\n",
      "threshold:0.4, J-value:0.034\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7097607132343664\n",
      "Balanced accuracy score of test is  0.7267002814258912\n",
      "True positive rate of class 1 is  0.743\n",
      "True positive rate of class 2 is  0.812\n",
      "Positive prediction rate of class 1 is  0.388\n",
      "Positive prediction rate of class 2 is  0.394\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.35400000000000004\n",
      "threshold:0.2, J-value:0.215\n",
      "threshold:0.30000000000000004, J-value:0.053000000000000005\n",
      "threshold:0.4, J-value:0.049999999999999996\n",
      "threshold:0.5, J-value:0.005\n",
      "threshold:0.6000000000000001, J-value:0.005\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.001\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6772188480876455\n",
      "Balanced accuracy score of test is  0.6904182620371148\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.3549999999999999\n",
      "threshold:0.2, J-value:0.213\n",
      "threshold:0.30000000000000004, J-value:0.051000000000000004\n",
      "threshold:0.4, J-value:0.049999999999999996\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.004\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6775605238345843\n",
      "Balanced accuracy score of test is  0.6888223235267015\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.349\n",
      "threshold:0.2, J-value:0.222\n",
      "threshold:0.30000000000000004, J-value:0.064\n",
      "threshold:0.4, J-value:0.05\n",
      "threshold:0.5, J-value:0.007\n",
      "threshold:0.6000000000000001, J-value:0.008\n",
      "threshold:0.7000000000000001, J-value:0.004\n",
      "threshold:0.8, J-value:0.004\n",
      "threshold:0.9, J-value:0.004\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6745559807673438\n",
      "Balanced accuracy score of test is  0.697860828196194\n",
      "True positive rate of class 1 is  0.716\n",
      "True positive rate of class 2 is  0.67\n",
      "Positive prediction rate of class 1 is  0.372\n",
      "Positive prediction rate of class 2 is  0.305\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.4119999999999999\n",
      "threshold:0.2, J-value:0.265\n",
      "threshold:0.30000000000000004, J-value:0.15\n",
      "threshold:0.4, J-value:0.06199999999999999\n",
      "threshold:0.5, J-value:0.016\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.705811168911483\n",
      "Balanced accuracy score of test is  0.7053091455322793\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.407\n",
      "threshold:0.2, J-value:0.268\n",
      "threshold:0.30000000000000004, J-value:0.148\n",
      "threshold:0.4, J-value:0.060000000000000005\n",
      "threshold:0.5, J-value:0.015\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7036681441018631\n",
      "Balanced accuracy score of test is  0.7041339776107807\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.43800000000000006\n",
      "threshold:0.2, J-value:0.251\n",
      "threshold:0.30000000000000004, J-value:0.154\n",
      "threshold:0.4, J-value:0.075\n",
      "threshold:0.5, J-value:0.023\n",
      "threshold:0.6000000000000001, J-value:0.011\n",
      "threshold:0.7000000000000001, J-value:0.004\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7191534547289625\n",
      "Balanced accuracy score of test is  0.7124371817207182\n",
      "True positive rate of class 1 is  0.691\n",
      "True positive rate of class 2 is  0.683\n",
      "Positive prediction rate of class 1 is  0.319\n",
      "Positive prediction rate of class 2 is  0.291\n",
      "X train 65694\n",
      "Y train 65694\n",
      "21898 18970 2928\n",
      "21898 18970 2928\n",
      "21898 18892 3006\n",
      "21898 18892 3006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25860343089778964\n",
      "0.2639560344941261\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19911\n",
      "           1       0.42      0.03      0.06      1987\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19821    90]\n",
      " [ 1922    65]]\n",
      "done in 0.992911s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25860343089778964\n",
      "0.2609219422405167\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19927\n",
      "           1       0.45      0.03      0.06      1971\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.51      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19853    74]\n",
      " [ 1910    61]]\n",
      "done in 1.055458s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25860343089778964\n",
      "0.26590016935078564\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17229\n",
      "           1       0.41      0.03      0.06      1741\n",
      "\n",
      "    accuracy                           0.91     18970\n",
      "   macro avg       0.66      0.51      0.50     18970\n",
      "weighted avg       0.86      0.91      0.87     18970\n",
      "\n",
      "Confusion_matrix\n",
      "[[17151    78]\n",
      " [ 1686    55]]\n",
      "done in 0.960066s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25860343089778964\n",
      "0.26061002316804543\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17198\n",
      "           1       0.45      0.03      0.05      1694\n",
      "\n",
      "    accuracy                           0.91     18892\n",
      "   macro avg       0.68      0.51      0.50     18892\n",
      "weighted avg       0.87      0.91      0.87     18892\n",
      "\n",
      "Confusion_matrix\n",
      "[[17143    55]\n",
      " [ 1649    45]]\n",
      "done in 0.954593s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25860343089778964\n",
      "0.2513603247158366\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2682\n",
      "           1       0.45      0.04      0.07       246\n",
      "\n",
      "    accuracy                           0.92      2928\n",
      "   macro avg       0.69      0.52      0.52      2928\n",
      "weighted avg       0.88      0.92      0.88      2928\n",
      "\n",
      "Confusion_matrix\n",
      "[[2670   12]\n",
      " [ 236   10]]\n",
      "done in 1.094702s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25860343089778964\n",
      "0.2628822799374982\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95      2729\n",
      "           1       0.46      0.06      0.10       277\n",
      "\n",
      "    accuracy                           0.91      3006\n",
      "   macro avg       0.68      0.53      0.53      3006\n",
      "weighted avg       0.87      0.91      0.87      3006\n",
      "\n",
      "Confusion_matrix\n",
      "[[2710   19]\n",
      " [ 261   16]]\n",
      "done in 0.916068s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19911\n",
      "           1       0.50      0.00      0.01      1987\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.70      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19906     5]\n",
      " [ 1982     5]]\n",
      "done in 19.743428s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19927\n",
      "           1       0.67      0.00      0.00      1971\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.79      0.50      0.48     21898\n",
      "weighted avg       0.89      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19925     2]\n",
      " [ 1967     4]]\n",
      "done in 20.027474s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17229\n",
      "           1       0.71      0.00      0.01      1741\n",
      "\n",
      "    accuracy                           0.91     18970\n",
      "   macro avg       0.81      0.50      0.48     18970\n",
      "weighted avg       0.89      0.91      0.87     18970\n",
      "\n",
      "Confusion_matrix\n",
      "[[17227     2]\n",
      " [ 1736     5]]\n",
      "done in 19.934787s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17198\n",
      "           1       0.67      0.00      0.01      1694\n",
      "\n",
      "    accuracy                           0.91     18892\n",
      "   macro avg       0.79      0.50      0.48     18892\n",
      "weighted avg       0.89      0.91      0.87     18892\n",
      "\n",
      "Confusion_matrix\n",
      "[[17195     3]\n",
      " [ 1688     6]]\n",
      "done in 20.068218s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2682\n",
      "           1       0.50      0.00      0.01       246\n",
      "\n",
      "    accuracy                           0.92      2928\n",
      "   macro avg       0.71      0.50      0.48      2928\n",
      "weighted avg       0.88      0.92      0.88      2928\n",
      "\n",
      "Confusion_matrix\n",
      "[[2681    1]\n",
      " [ 245    1]]\n",
      "done in 19.604852s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2729\n",
      "           1       0.00      0.00      0.00       277\n",
      "\n",
      "    accuracy                           0.91      3006\n",
      "   macro avg       0.45      0.50      0.48      3006\n",
      "weighted avg       0.82      0.91      0.86      3006\n",
      "\n",
      "Confusion_matrix\n",
      "[[2728    1]\n",
      " [ 277    0]]\n",
      "done in 19.565210s\n",
      "0.26445464621705217\n",
      "0.2702963274846509\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19911\n",
      "           1       0.32      0.00      0.01      1987\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.61      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19898    13]\n",
      " [ 1981     6]]\n",
      "done in 0.645417s\n",
      "0.26445464621705217\n",
      "0.26900537003743663\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19927\n",
      "           1       0.30      0.00      0.01      1971\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.61      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19913    14]\n",
      " [ 1965     6]]\n",
      "done in 0.630084s\n",
      "0.26445464621705217\n",
      "0.2725960626011161\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17229\n",
      "           1       0.31      0.00      0.00      1741\n",
      "\n",
      "    accuracy                           0.91     18970\n",
      "   macro avg       0.61      0.50      0.48     18970\n",
      "weighted avg       0.85      0.91      0.86     18970\n",
      "\n",
      "Confusion_matrix\n",
      "[[17220     9]\n",
      " [ 1737     4]]\n",
      "done in 0.595492s\n",
      "0.26445464621705217\n",
      "0.2687477613627732\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17198\n",
      "           1       0.25      0.00      0.00      1694\n",
      "\n",
      "    accuracy                           0.91     18892\n",
      "   macro avg       0.58      0.50      0.48     18892\n",
      "weighted avg       0.85      0.91      0.87     18892\n",
      "\n",
      "Confusion_matrix\n",
      "[[17189     9]\n",
      " [ 1691     3]]\n",
      "done in 0.702664s\n",
      "0.26445464621705217\n",
      "0.2553967458045464\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2682\n",
      "           1       0.33      0.01      0.02       246\n",
      "\n",
      "    accuracy                           0.92      2928\n",
      "   macro avg       0.62      0.50      0.49      2928\n",
      "weighted avg       0.87      0.92      0.88      2928\n",
      "\n",
      "Confusion_matrix\n",
      "[[2678    4]\n",
      " [ 244    2]]\n",
      "done in 0.598150s\n",
      "0.26445464621705217\n",
      "0.2706243797120013\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2729\n",
      "           1       0.38      0.01      0.02       277\n",
      "\n",
      "    accuracy                           0.91      3006\n",
      "   macro avg       0.64      0.50      0.49      3006\n",
      "weighted avg       0.86      0.91      0.87      3006\n",
      "\n",
      "Confusion_matrix\n",
      "[[2724    5]\n",
      " [ 274    3]]\n",
      "done in 0.617410s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19911\n",
      "           1       0.42      0.02      0.04      1987\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19856    55]\n",
      " [ 1947    40]]\n",
      "done in 33.320962s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19927\n",
      "           1       0.43      0.02      0.04      1971\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19879    48]\n",
      " [ 1935    36]]\n",
      "done in 33.113297s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17229\n",
      "           1       0.39      0.02      0.03      1741\n",
      "\n",
      "    accuracy                           0.91     18970\n",
      "   macro avg       0.65      0.51      0.49     18970\n",
      "weighted avg       0.86      0.91      0.87     18970\n",
      "\n",
      "Confusion_matrix\n",
      "[[17182    47]\n",
      " [ 1711    30]]\n",
      "done in 32.921232s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17198\n",
      "           1       0.41      0.02      0.03      1694\n",
      "\n",
      "    accuracy                           0.91     18892\n",
      "   macro avg       0.66      0.51      0.49     18892\n",
      "weighted avg       0.87      0.91      0.87     18892\n",
      "\n",
      "Confusion_matrix\n",
      "[[17161    37]\n",
      " [ 1668    26]]\n",
      "done in 32.910367s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2682\n",
      "           1       0.50      0.04      0.08       246\n",
      "\n",
      "    accuracy                           0.92      2928\n",
      "   macro avg       0.71      0.52      0.52      2928\n",
      "weighted avg       0.88      0.92      0.88      2928\n",
      "\n",
      "Confusion_matrix\n",
      "[[2672   10]\n",
      " [ 236   10]]\n",
      "done in 32.814256s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2729\n",
      "           1       0.48      0.04      0.07       277\n",
      "\n",
      "    accuracy                           0.91      3006\n",
      "   macro avg       0.69      0.52      0.51      3006\n",
      "weighted avg       0.87      0.91      0.87      3006\n",
      "\n",
      "Confusion_matrix\n",
      "[[2718   11]\n",
      " [ 267   10]]\n",
      "done in 32.955357s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.2, J-value:0.248\n",
      "threshold:0.30000000000000004, J-value:0.145\n",
      "threshold:0.4, J-value:0.07\n",
      "threshold:0.5, J-value:0.029\n",
      "threshold:0.6000000000000001, J-value:0.013000000000000001\n",
      "threshold:0.7000000000000001, J-value:0.005\n",
      "threshold:0.8, J-value:0.002\n",
      "threshold:0.9, J-value:0.001\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6950035736531339\n",
      "Balanced accuracy score of test is  0.7058600268453218\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.39\n",
      "threshold:0.2, J-value:0.246\n",
      "threshold:0.30000000000000004, J-value:0.141\n",
      "threshold:0.4, J-value:0.065\n",
      "threshold:0.5, J-value:0.027\n",
      "threshold:0.6000000000000001, J-value:0.009999999999999998\n",
      "threshold:0.7000000000000001, J-value:0.005\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6950732320234417\n",
      "Balanced accuracy score of test is  0.7062750150926367\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.387\n",
      "threshold:0.2, J-value:0.259\n",
      "threshold:0.30000000000000004, J-value:0.164\n",
      "threshold:0.4, J-value:0.101\n",
      "threshold:0.5, J-value:0.049\n",
      "threshold:0.6000000000000001, J-value:0.026000000000000002\n",
      "threshold:0.7000000000000001, J-value:0.015\n",
      "threshold:0.8, J-value:0.007\n",
      "threshold:0.9, J-value:0.004\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6936941852640003\n",
      "Balanced accuracy score of test is  0.7034637990403911\n",
      "True positive rate of class 1 is  0.663\n",
      "True positive rate of class 2 is  0.646\n",
      "Positive prediction rate of class 1 is  0.287\n",
      "Positive prediction rate of class 2 is  0.277\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.397\n",
      "threshold:0.2, J-value:0.281\n",
      "threshold:0.30000000000000004, J-value:0.11300000000000002\n",
      "threshold:0.4, J-value:0.024\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6982697311036123\n",
      "Balanced accuracy score of test is  0.6993127528365393\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.381\n",
      "threshold:0.2, J-value:0.28600000000000003\n",
      "threshold:0.30000000000000004, J-value:0.11500000000000002\n",
      "threshold:0.4, J-value:0.02\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6903436857209715\n",
      "Balanced accuracy score of test is  0.6975162401163311\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.394\n",
      "threshold:0.2, J-value:0.323\n",
      "threshold:0.30000000000000004, J-value:0.12\n",
      "threshold:0.4, J-value:0.022\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6970635310379949\n",
      "Balanced accuracy score of test is  0.7040617356300095\n",
      "True positive rate of class 1 is  0.736\n",
      "True positive rate of class 2 is  0.762\n",
      "Positive prediction rate of class 1 is  0.376\n",
      "Positive prediction rate of class 2 is  0.391\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.348\n",
      "threshold:0.2, J-value:0.21099999999999997\n",
      "threshold:0.30000000000000004, J-value:0.11000000000000001\n",
      "threshold:0.4, J-value:0.007\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.002\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6740769195946623\n",
      "Balanced accuracy score of test is  0.6700628399696437\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.347\n",
      "threshold:0.2, J-value:0.21699999999999997\n",
      "threshold:0.30000000000000004, J-value:0.11100000000000002\n",
      "threshold:0.4, J-value:0.007\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6735025656520175\n",
      "Balanced accuracy score of test is  0.6690458364437368\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.353\n",
      "threshold:0.2, J-value:0.169\n",
      "threshold:0.30000000000000004, J-value:0.096\n",
      "threshold:0.4, J-value:0.005\n",
      "threshold:0.5, J-value:0.007\n",
      "threshold:0.6000000000000001, J-value:0.007\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6765382586711772\n",
      "Balanced accuracy score of test is  0.6765169664507305\n",
      "True positive rate of class 1 is  0.603\n",
      "True positive rate of class 2 is  0.599\n",
      "Positive prediction rate of class 1 is  0.295\n",
      "Positive prediction rate of class 2 is  0.279\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.405\n",
      "threshold:0.2, J-value:0.26399999999999996\n",
      "threshold:0.30000000000000004, J-value:0.137\n",
      "threshold:0.4, J-value:0.052\n",
      "threshold:0.5, J-value:0.017\n",
      "threshold:0.6000000000000001, J-value:0.008\n",
      "threshold:0.7000000000000001, J-value:0.003\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7026204834968048\n",
      "Balanced accuracy score of test is  0.7129174454796536\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.40700000000000003\n",
      "threshold:0.2, J-value:0.26399999999999996\n",
      "threshold:0.30000000000000004, J-value:0.138\n",
      "threshold:0.4, J-value:0.049999999999999996\n",
      "threshold:0.5, J-value:0.014000000000000002\n",
      "threshold:0.6000000000000001, J-value:0.007\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7034533529134803\n",
      "Balanced accuracy score of test is  0.7109446020260174\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.391\n",
      "threshold:0.2, J-value:0.267\n",
      "threshold:0.30000000000000004, J-value:0.139\n",
      "threshold:0.4, J-value:0.065\n",
      "threshold:0.5, J-value:0.037000000000000005\n",
      "threshold:0.6000000000000001, J-value:0.019\n",
      "threshold:0.7000000000000001, J-value:0.008\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6958585693239483\n",
      "Balanced accuracy score of test is  0.725199190933588\n",
      "True positive rate of class 1 is  0.692\n",
      "True positive rate of class 2 is  0.704\n",
      "Positive prediction rate of class 1 is  0.308\n",
      "Positive prediction rate of class 2 is  0.295\n",
      "X train 65694\n",
      "Y train 65694\n",
      "21898 18842 3056\n",
      "21898 18842 3056\n",
      "21898 18914 2984\n",
      "21898 18914 2984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26149046250411156\n",
      "0.25749546772155224\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19944\n",
      "           1       0.44      0.03      0.06      1954\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19861    83]\n",
      " [ 1890    64]]\n",
      "done in 1.044136s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26149046250411156\n",
      "0.25831499130545615\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19955\n",
      "           1       0.47      0.04      0.07      1943\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.69      0.52      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19874    81]\n",
      " [ 1872    71]]\n",
      "done in 0.955716s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26149046250411156\n",
      "0.25820794376035167\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17147\n",
      "           1       0.44      0.03      0.06      1695\n",
      "\n",
      "    accuracy                           0.91     18842\n",
      "   macro avg       0.68      0.51      0.51     18842\n",
      "weighted avg       0.87      0.91      0.87     18842\n",
      "\n",
      "Confusion_matrix\n",
      "[[17077    70]\n",
      " [ 1640    55]]\n",
      "done in 0.941527s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26149046250411156\n",
      "0.2598420371640909\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17231\n",
      "           1       0.43      0.03      0.06      1683\n",
      "\n",
      "    accuracy                           0.91     18914\n",
      "   macro avg       0.67      0.51      0.51     18914\n",
      "weighted avg       0.87      0.91      0.87     18914\n",
      "\n",
      "Confusion_matrix\n",
      "[[17161    70]\n",
      " [ 1630    53]]\n",
      "done in 0.932380s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26149046250411156\n",
      "0.25310264261583926\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.95      2797\n",
      "           1       0.41      0.03      0.06       259\n",
      "\n",
      "    accuracy                           0.91      3056\n",
      "   macro avg       0.66      0.52      0.51      3056\n",
      "weighted avg       0.87      0.91      0.88      3056\n",
      "\n",
      "Confusion_matrix\n",
      "[[2784   13]\n",
      " [ 250    9]]\n",
      "done in 0.855882s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26149046250411156\n",
      "0.24863585411704545\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2724\n",
      "           1       0.62      0.07      0.12       260\n",
      "\n",
      "    accuracy                           0.92      2984\n",
      "   macro avg       0.77      0.53      0.54      2984\n",
      "weighted avg       0.89      0.92      0.88      2984\n",
      "\n",
      "Confusion_matrix\n",
      "[[2713   11]\n",
      " [ 242   18]]\n",
      "done in 0.890443s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19944\n",
      "           1       0.36      0.00      0.01      1954\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.63      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19935     9]\n",
      " [ 1949     5]]\n",
      "done in 19.603858s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19955\n",
      "           1       0.50      0.00      0.00      1943\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.71      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19951     4]\n",
      " [ 1939     4]]\n",
      "done in 19.805990s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17147\n",
      "           1       0.31      0.00      0.00      1695\n",
      "\n",
      "    accuracy                           0.91     18842\n",
      "   macro avg       0.61      0.50      0.48     18842\n",
      "weighted avg       0.86      0.91      0.87     18842\n",
      "\n",
      "Confusion_matrix\n",
      "[[17138     9]\n",
      " [ 1691     4]]\n",
      "done in 19.660675s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17231\n",
      "           1       0.38      0.00      0.00      1683\n",
      "\n",
      "    accuracy                           0.91     18914\n",
      "   macro avg       0.64      0.50      0.48     18914\n",
      "weighted avg       0.86      0.91      0.87     18914\n",
      "\n",
      "Confusion_matrix\n",
      "[[17226     5]\n",
      " [ 1680     3]]\n",
      "done in 19.411033s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2797\n",
      "           1       0.00      0.00      0.00       259\n",
      "\n",
      "    accuracy                           0.91      3056\n",
      "   macro avg       0.46      0.50      0.48      3056\n",
      "weighted avg       0.84      0.91      0.87      3056\n",
      "\n",
      "Confusion_matrix\n",
      "[[2796    1]\n",
      " [ 259    0]]\n",
      "done in 19.534096s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2724\n",
      "           1       0.00      0.00      0.00       260\n",
      "\n",
      "    accuracy                           0.91      2984\n",
      "   macro avg       0.46      0.50      0.48      2984\n",
      "weighted avg       0.83      0.91      0.87      2984\n",
      "\n",
      "Confusion_matrix\n",
      "[[2724    0]\n",
      " [ 260    0]]\n",
      "done in 19.617469s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26691180010608717\n",
      "0.26804236350549815\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19944\n",
      "           1       0.34      0.01      0.03      1954\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.63      0.51      0.49     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19890    54]\n",
      " [ 1926    28]]\n",
      "done in 0.631112s\n",
      "0.26691180010608717\n",
      "0.2720697371491411\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19955\n",
      "           1       0.38      0.01      0.03      1943\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.65      0.51      0.49     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19909    46]\n",
      " [ 1915    28]]\n",
      "done in 0.656124s\n",
      "0.26691180010608717\n",
      "0.26965226840168327\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17147\n",
      "           1       0.35      0.01      0.03      1695\n",
      "\n",
      "    accuracy                           0.91     18842\n",
      "   macro avg       0.63      0.51      0.49     18842\n",
      "weighted avg       0.86      0.91      0.87     18842\n",
      "\n",
      "Confusion_matrix\n",
      "[[17102    45]\n",
      " [ 1671    24]]\n",
      "done in 0.631883s\n",
      "0.26691180010608717\n",
      "0.2733018765049085\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17231\n",
      "           1       0.39      0.01      0.03      1683\n",
      "\n",
      "    accuracy                           0.91     18914\n",
      "   macro avg       0.65      0.51      0.49     18914\n",
      "weighted avg       0.87      0.91      0.87     18914\n",
      "\n",
      "Confusion_matrix\n",
      "[[17193    38]\n",
      " [ 1659    24]]\n",
      "done in 0.622663s\n",
      "0.26691180010608717\n",
      "0.25811637265015813\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.95      2797\n",
      "           1       0.31      0.02      0.03       259\n",
      "\n",
      "    accuracy                           0.91      3056\n",
      "   macro avg       0.61      0.51      0.49      3056\n",
      "weighted avg       0.86      0.91      0.88      3056\n",
      "\n",
      "Confusion_matrix\n",
      "[[2788    9]\n",
      " [ 255    4]]\n",
      "done in 0.591175s\n",
      "0.26691180010608717\n",
      "0.264259856527497\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2724\n",
      "           1       0.33      0.02      0.03       260\n",
      "\n",
      "    accuracy                           0.91      2984\n",
      "   macro avg       0.62      0.51      0.49      2984\n",
      "weighted avg       0.86      0.91      0.87      2984\n",
      "\n",
      "Confusion_matrix\n",
      "[[2716    8]\n",
      " [ 256    4]]\n",
      "done in 0.599317s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19944\n",
      "           1       0.44      0.01      0.03      1954\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.51      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19910    34]\n",
      " [ 1927    27]]\n",
      "done in 33.099868s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19955\n",
      "           1       0.55      0.02      0.03      1943\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.73      0.51      0.49     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19926    29]\n",
      " [ 1908    35]]\n",
      "done in 33.334065s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17147\n",
      "           1       0.45      0.01      0.03      1695\n",
      "\n",
      "    accuracy                           0.91     18842\n",
      "   macro avg       0.68      0.51      0.49     18842\n",
      "weighted avg       0.87      0.91      0.87     18842\n",
      "\n",
      "Confusion_matrix\n",
      "[[17118    29]\n",
      " [ 1671    24]]\n",
      "done in 33.248572s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17231\n",
      "           1       0.50      0.01      0.03      1683\n",
      "\n",
      "    accuracy                           0.91     18914\n",
      "   macro avg       0.71      0.51      0.49     18914\n",
      "weighted avg       0.88      0.91      0.87     18914\n",
      "\n",
      "Confusion_matrix\n",
      "[[17207    24]\n",
      " [ 1659    24]]\n",
      "done in 33.088437s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2797\n",
      "           1       0.38      0.01      0.02       259\n",
      "\n",
      "    accuracy                           0.91      3056\n",
      "   macro avg       0.65      0.50      0.49      3056\n",
      "weighted avg       0.87      0.91      0.88      3056\n",
      "\n",
      "Confusion_matrix\n",
      "[[2792    5]\n",
      " [ 256    3]]\n",
      "done in 33.083322s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2724\n",
      "           1       0.69      0.04      0.08       260\n",
      "\n",
      "    accuracy                           0.91      2984\n",
      "   macro avg       0.80      0.52      0.52      2984\n",
      "weighted avg       0.90      0.91      0.88      2984\n",
      "\n",
      "Confusion_matrix\n",
      "[[2719    5]\n",
      " [ 249   11]]\n",
      "done in 32.946605s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41400000000000003\n",
      "threshold:0.2, J-value:0.26599999999999996\n",
      "threshold:0.30000000000000004, J-value:0.143\n",
      "threshold:0.4, J-value:0.07\n",
      "threshold:0.5, J-value:0.028\n",
      "threshold:0.6000000000000001, J-value:0.011\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.707055317837745\n",
      "Balanced accuracy score of test is  0.7037223485214352\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41700000000000004\n",
      "threshold:0.2, J-value:0.26699999999999996\n",
      "threshold:0.30000000000000004, J-value:0.146\n",
      "threshold:0.4, J-value:0.07300000000000001\n",
      "threshold:0.5, J-value:0.028\n",
      "threshold:0.6000000000000001, J-value:0.012\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7087885029554435\n",
      "Balanced accuracy score of test is  0.7002840504992919\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.39\n",
      "threshold:0.2, J-value:0.261\n",
      "threshold:0.30000000000000004, J-value:0.123\n",
      "threshold:0.4, J-value:0.05600000000000001\n",
      "threshold:0.5, J-value:0.030000000000000002\n",
      "threshold:0.6000000000000001, J-value:0.006\n",
      "threshold:0.7000000000000001, J-value:-0.001\n",
      "threshold:0.8, J-value:-0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6948295401995795\n",
      "Balanced accuracy score of test is  0.7256636168530441\n",
      "True positive rate of class 1 is  0.661\n",
      "True positive rate of class 2 is  0.681\n",
      "Positive prediction rate of class 1 is  0.296\n",
      "Positive prediction rate of class 2 is  0.269\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.393\n",
      "threshold:0.2, J-value:0.28500000000000003\n",
      "threshold:0.30000000000000004, J-value:0.10800000000000001\n",
      "threshold:0.4, J-value:0.021\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6963247605064908\n",
      "Balanced accuracy score of test is  0.6951480641015109\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.4\n",
      "threshold:0.2, J-value:0.276\n",
      "threshold:0.30000000000000004, J-value:0.10900000000000001\n",
      "threshold:0.4, J-value:0.022\n",
      "threshold:0.5, J-value:0.005\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7000065200565714\n",
      "Balanced accuracy score of test is  0.6952784768349738\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.387\n",
      "threshold:0.2, J-value:0.29700000000000004\n",
      "threshold:0.30000000000000004, J-value:0.10500000000000001\n",
      "threshold:0.4, J-value:0.008\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6938956935381676\n",
      "Balanced accuracy score of test is  0.7137100417937423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positive rate of class 1 is  0.737\n",
      "True positive rate of class 2 is  0.785\n",
      "Positive prediction rate of class 1 is  0.382\n",
      "Positive prediction rate of class 2 is  0.394\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.364\n",
      "threshold:0.2, J-value:0.23500000000000001\n",
      "threshold:0.30000000000000004, J-value:0.143\n",
      "threshold:0.4, J-value:0.011\n",
      "threshold:0.5, J-value:0.011\n",
      "threshold:0.6000000000000001, J-value:0.002\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6823207591286309\n",
      "Balanced accuracy score of test is  0.6769141788788026\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.366\n",
      "threshold:0.2, J-value:0.24000000000000002\n",
      "threshold:0.30000000000000004, J-value:0.149\n",
      "threshold:0.4, J-value:0.011\n",
      "threshold:0.5, J-value:0.011\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6831660913017801\n",
      "Balanced accuracy score of test is  0.675193371341217\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.35\n",
      "threshold:0.2, J-value:0.20399999999999996\n",
      "threshold:0.30000000000000004, J-value:0.10500000000000001\n",
      "threshold:0.4, J-value:0.012\n",
      "threshold:0.5, J-value:0.012\n",
      "threshold:0.6000000000000001, J-value:0.011\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6750600132795341\n",
      "Balanced accuracy score of test is  0.687481644640235\n",
      "True positive rate of class 1 is  0.632\n",
      "True positive rate of class 2 is  0.6\n",
      "Positive prediction rate of class 1 is  0.313\n",
      "Positive prediction rate of class 2 is  0.258\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.42799999999999994\n",
      "threshold:0.2, J-value:0.27199999999999996\n",
      "threshold:0.30000000000000004, J-value:0.138\n",
      "threshold:0.4, J-value:0.043\n",
      "threshold:0.5, J-value:0.012\n",
      "threshold:0.6000000000000001, J-value:0.004\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.713955446796578\n",
      "Balanced accuracy score of test is  0.7088256219313838\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.42599999999999993\n",
      "threshold:0.2, J-value:0.27499999999999997\n",
      "threshold:0.30000000000000004, J-value:0.14200000000000002\n",
      "threshold:0.4, J-value:0.048\n",
      "threshold:0.5, J-value:0.013\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7131793223717248\n",
      "Balanced accuracy score of test is  0.7075193485135212\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.43600000000000005\n",
      "threshold:0.2, J-value:0.263\n",
      "threshold:0.30000000000000004, J-value:0.119\n",
      "threshold:0.4, J-value:0.024000000000000004\n",
      "threshold:0.5, J-value:0.01\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7176732378734524\n",
      "Balanced accuracy score of test is  0.717028126058963\n",
      "True positive rate of class 1 is  0.695\n",
      "True positive rate of class 2 is  0.688\n",
      "Positive prediction rate of class 1 is  0.316\n",
      "Positive prediction rate of class 2 is  0.292\n",
      "X train 65694\n",
      "Y train 65694\n",
      "21898 18920 2978\n",
      "21898 18920 2978\n",
      "21898 18865 3033\n",
      "21898 18865 3033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2582296004331764\n",
      "0.2634053423664784\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19893\n",
      "           1       0.41      0.03      0.06      2005\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.66      0.51      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19800    93]\n",
      " [ 1940    65]]\n",
      "done in 0.993990s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2582296004331764\n",
      "0.26237358850595266\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19907\n",
      "           1       0.49      0.03      0.06      1991\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.70      0.51      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19838    69]\n",
      " [ 1926    65]]\n",
      "done in 1.022233s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2582296004331764\n",
      "0.26193518555597833\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17191\n",
      "           1       0.41      0.03      0.06      1729\n",
      "\n",
      "    accuracy                           0.91     18920\n",
      "   macro avg       0.66      0.51      0.51     18920\n",
      "weighted avg       0.87      0.91      0.87     18920\n",
      "\n",
      "Confusion_matrix\n",
      "[[17112    79]\n",
      " [ 1673    56]]\n",
      "done in 1.033473s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2582296004331764\n",
      "0.2644904135081465\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17135\n",
      "           1       0.46      0.03      0.05      1730\n",
      "\n",
      "    accuracy                           0.91     18865\n",
      "   macro avg       0.69      0.51      0.50     18865\n",
      "weighted avg       0.87      0.91      0.87     18865\n",
      "\n",
      "Confusion_matrix\n",
      "[[17081    54]\n",
      " [ 1684    46]]\n",
      "done in 0.942926s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2582296004331764\n",
      "0.27274562673674724\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95      2702\n",
      "           1       0.39      0.03      0.06       276\n",
      "\n",
      "    accuracy                           0.91      2978\n",
      "   macro avg       0.65      0.51      0.51      2978\n",
      "weighted avg       0.86      0.91      0.87      2978\n",
      "\n",
      "Confusion_matrix\n",
      "[[2688   14]\n",
      " [ 267    9]]\n",
      "done in 0.862922s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2582296004331764\n",
      "0.2492071184543907\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96      2772\n",
      "           1       0.56      0.07      0.13       261\n",
      "\n",
      "    accuracy                           0.92      3033\n",
      "   macro avg       0.74      0.53      0.54      3033\n",
      "weighted avg       0.89      0.92      0.88      3033\n",
      "\n",
      "Confusion_matrix\n",
      "[[2757   15]\n",
      " [ 242   19]]\n",
      "done in 0.891453s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19893\n",
      "           1       0.44      0.00      0.01      2005\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19883    10]\n",
      " [ 1997     8]]\n",
      "done in 19.166286s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19907\n",
      "           1       0.67      0.00      0.00      1991\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.79      0.50      0.48     21898\n",
      "weighted avg       0.89      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19906     1]\n",
      " [ 1989     2]]\n",
      "done in 20.201750s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17191\n",
      "           1       0.64      0.01      0.01      1729\n",
      "\n",
      "    accuracy                           0.91     18920\n",
      "   macro avg       0.78      0.50      0.48     18920\n",
      "weighted avg       0.88      0.91      0.87     18920\n",
      "\n",
      "Confusion_matrix\n",
      "[[17186     5]\n",
      " [ 1720     9]]\n",
      "done in 19.989287s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17135\n",
      "           1       0.33      0.00      0.00      1730\n",
      "\n",
      "    accuracy                           0.91     18865\n",
      "   macro avg       0.62      0.50      0.48     18865\n",
      "weighted avg       0.86      0.91      0.86     18865\n",
      "\n",
      "Confusion_matrix\n",
      "[[17131     4]\n",
      " [ 1728     2]]\n",
      "done in 20.210122s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2702\n",
      "           1       0.00      0.00      0.00       276\n",
      "\n",
      "    accuracy                           0.91      2978\n",
      "   macro avg       0.45      0.50      0.48      2978\n",
      "weighted avg       0.82      0.91      0.86      2978\n",
      "\n",
      "Confusion_matrix\n",
      "[[2702    0]\n",
      " [ 276    0]]\n",
      "done in 19.755519s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.96      2772\n",
      "           1       0.00      0.00      0.00       261\n",
      "\n",
      "    accuracy                           0.91      3033\n",
      "   macro avg       0.46      0.50      0.48      3033\n",
      "weighted avg       0.84      0.91      0.87      3033\n",
      "\n",
      "Confusion_matrix\n",
      "[[2772    0]\n",
      " [ 261    0]]\n",
      "done in 19.570604s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2638844630577774\n",
      "0.27072063991639456\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19893\n",
      "           1       0.08      0.00      0.00      2005\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.50      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.86     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19882    11]\n",
      " [ 2004     1]]\n",
      "done in 0.639992s\n",
      "0.2638844630577774\n",
      "0.27224900833516935\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19907\n",
      "           1       0.33      0.00      0.00      1991\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.62      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19903     4]\n",
      " [ 1989     2]]\n",
      "done in 0.636164s\n",
      "0.2638844630577774\n",
      "0.26930585598613827\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17191\n",
      "           1       0.10      0.00      0.00      1729\n",
      "\n",
      "    accuracy                           0.91     18920\n",
      "   macro avg       0.50      0.50      0.48     18920\n",
      "weighted avg       0.83      0.91      0.87     18920\n",
      "\n",
      "Confusion_matrix\n",
      "[[17182     9]\n",
      " [ 1728     1]]\n",
      "done in 0.626252s\n",
      "0.2638844630577774\n",
      "0.27463462524827614\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17135\n",
      "           1       0.25      0.00      0.00      1730\n",
      "\n",
      "    accuracy                           0.91     18865\n",
      "   macro avg       0.58      0.50      0.48     18865\n",
      "weighted avg       0.85      0.91      0.86     18865\n",
      "\n",
      "Confusion_matrix\n",
      "[[17132     3]\n",
      " [ 1729     1]]\n",
      "done in 0.629984s\n",
      "0.2638844630577774\n",
      "0.2797091261354845\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2702\n",
      "           1       0.00      0.00      0.00       276\n",
      "\n",
      "    accuracy                           0.91      2978\n",
      "   macro avg       0.45      0.50      0.48      2978\n",
      "weighted avg       0.82      0.91      0.86      2978\n",
      "\n",
      "Confusion_matrix\n",
      "[[2700    2]\n",
      " [ 276    0]]\n",
      "done in 0.603474s\n",
      "0.2638844630577774\n",
      "0.26873190687609205\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2772\n",
      "           1       0.33      0.00      0.01       261\n",
      "\n",
      "    accuracy                           0.91      3033\n",
      "   macro avg       0.62      0.50      0.48      3033\n",
      "weighted avg       0.86      0.91      0.87      3033\n",
      "\n",
      "Confusion_matrix\n",
      "[[2770    2]\n",
      " [ 260    1]]\n",
      "done in 0.604823s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19893\n",
      "           1       0.46      0.02      0.04      2005\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.51      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19846    47]\n",
      " [ 1965    40]]\n",
      "done in 33.195178s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19907\n",
      "           1       0.51      0.02      0.03      1991\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.71      0.51      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19874    33]\n",
      " [ 1957    34]]\n",
      "done in 33.078483s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17191\n",
      "           1       0.46      0.02      0.04      1729\n",
      "\n",
      "    accuracy                           0.91     18920\n",
      "   macro avg       0.68      0.51      0.49     18920\n",
      "weighted avg       0.87      0.91      0.87     18920\n",
      "\n",
      "Confusion_matrix\n",
      "[[17151    40]\n",
      " [ 1695    34]]\n",
      "done in 32.991866s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17135\n",
      "           1       0.44      0.01      0.03      1730\n",
      "\n",
      "    accuracy                           0.91     18865\n",
      "   macro avg       0.67      0.51      0.49     18865\n",
      "weighted avg       0.87      0.91      0.87     18865\n",
      "\n",
      "Confusion_matrix\n",
      "[[17104    31]\n",
      " [ 1706    24]]\n",
      "done in 33.028022s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2702\n",
      "           1       0.46      0.02      0.04       276\n",
      "\n",
      "    accuracy                           0.91      2978\n",
      "   macro avg       0.69      0.51      0.50      2978\n",
      "weighted avg       0.87      0.91      0.87      2978\n",
      "\n",
      "Confusion_matrix\n",
      "[[2695    7]\n",
      " [ 270    6]]\n",
      "done in 32.813224s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2772\n",
      "           1       0.83      0.04      0.07       261\n",
      "\n",
      "    accuracy                           0.92      3033\n",
      "   macro avg       0.88      0.52      0.51      3033\n",
      "weighted avg       0.91      0.92      0.88      3033\n",
      "\n",
      "Confusion_matrix\n",
      "[[2770    2]\n",
      " [ 251   10]]\n",
      "done in 33.117221s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41000000000000003\n",
      "threshold:0.2, J-value:0.26899999999999996\n",
      "threshold:0.30000000000000004, J-value:0.147\n",
      "threshold:0.4, J-value:0.07100000000000001\n",
      "threshold:0.5, J-value:0.029\n",
      "threshold:0.6000000000000001, J-value:0.008\n",
      "threshold:0.7000000000000001, J-value:0.005\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7048403221574576\n",
      "Balanced accuracy score of test is  0.6978716980720774\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41400000000000003\n",
      "threshold:0.2, J-value:0.27399999999999997\n",
      "threshold:0.30000000000000004, J-value:0.15\n",
      "threshold:0.4, J-value:0.07200000000000001\n",
      "threshold:0.5, J-value:0.029\n",
      "threshold:0.6000000000000001, J-value:0.01\n",
      "threshold:0.7000000000000001, J-value:0.006\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7068077943995269\n",
      "Balanced accuracy score of test is  0.6982196801665117\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.385\n",
      "threshold:0.2, J-value:0.23299999999999998\n",
      "threshold:0.30000000000000004, J-value:0.134\n",
      "threshold:0.4, J-value:0.073\n",
      "threshold:0.5, J-value:0.034\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:-0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6927249273216833\n",
      "Balanced accuracy score of test is  0.6950166691546003\n",
      "True positive rate of class 1 is  0.649\n",
      "True positive rate of class 2 is  0.625\n",
      "Positive prediction rate of class 1 is  0.288\n",
      "Positive prediction rate of class 2 is  0.268\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.39699999999999996\n",
      "threshold:0.2, J-value:0.29700000000000004\n",
      "threshold:0.30000000000000004, J-value:0.11499999999999999\n",
      "threshold:0.4, J-value:0.027\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6985902007159751\n",
      "Balanced accuracy score of test is  0.6970110284545891\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.408\n",
      "threshold:0.2, J-value:0.29600000000000004\n",
      "threshold:0.30000000000000004, J-value:0.11500000000000002\n",
      "threshold:0.4, J-value:0.025\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7042304171493557\n",
      "Balanced accuracy score of test is  0.6991292372202385\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.406\n",
      "threshold:0.2, J-value:0.253\n",
      "threshold:0.30000000000000004, J-value:0.11599999999999999\n",
      "threshold:0.4, J-value:0.029\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7027885945998134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy score of test is  0.6997250833457731\n",
      "True positive rate of class 1 is  0.732\n",
      "True positive rate of class 2 is  0.755\n",
      "Positive prediction rate of class 1 is  0.371\n",
      "Positive prediction rate of class 2 is  0.39\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.37400000000000005\n",
      "threshold:0.2, J-value:0.21000000000000002\n",
      "threshold:0.30000000000000004, J-value:0.093\n",
      "threshold:0.4, J-value:0.008\n",
      "threshold:0.5, J-value:-0.001\n",
      "threshold:0.6000000000000001, J-value:-0.001\n",
      "threshold:0.7000000000000001, J-value:-0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.687285719246347\n",
      "Balanced accuracy score of test is  0.6872702163503284\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.38099999999999995\n",
      "threshold:0.2, J-value:0.21500000000000002\n",
      "threshold:0.30000000000000004, J-value:0.10099999999999999\n",
      "threshold:0.4, J-value:0.008\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6902225729840546\n",
      "Balanced accuracy score of test is  0.6843686906595194\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.33799999999999997\n",
      "threshold:0.2, J-value:0.182\n",
      "threshold:0.30000000000000004, J-value:0.043\n",
      "threshold:0.4, J-value:0.005\n",
      "threshold:0.5, J-value:-0.001\n",
      "threshold:0.6000000000000001, J-value:-0.001\n",
      "threshold:0.7000000000000001, J-value:-0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6693498642980509\n",
      "Balanced accuracy score of test is  0.7046822908891874\n",
      "True positive rate of class 1 is  0.677\n",
      "True positive rate of class 2 is  0.659\n",
      "Positive prediction rate of class 1 is  0.342\n",
      "Positive prediction rate of class 2 is  0.285\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.42399999999999993\n",
      "threshold:0.2, J-value:0.285\n",
      "threshold:0.30000000000000004, J-value:0.14100000000000001\n",
      "threshold:0.4, J-value:0.060000000000000005\n",
      "threshold:0.5, J-value:0.018000000000000002\n",
      "threshold:0.6000000000000001, J-value:0.006\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7122527341727118\n",
      "Balanced accuracy score of test is  0.7062079755746189\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.42999999999999994\n",
      "threshold:0.2, J-value:0.289\n",
      "threshold:0.30000000000000004, J-value:0.14200000000000002\n",
      "threshold:0.4, J-value:0.061000000000000006\n",
      "threshold:0.5, J-value:0.018000000000000002\n",
      "threshold:0.6000000000000001, J-value:0.008\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7147984948746668\n",
      "Balanced accuracy score of test is  0.7041347105862827\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.393\n",
      "threshold:0.2, J-value:0.26199999999999996\n",
      "threshold:0.30000000000000004, J-value:0.127\n",
      "threshold:0.4, J-value:0.05800000000000001\n",
      "threshold:0.5, J-value:0.019\n",
      "threshold:0.6000000000000001, J-value:-0.001\n",
      "threshold:0.7000000000000001, J-value:-0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.696484890419335\n",
      "Balanced accuracy score of test is  0.7199146638801811\n",
      "True positive rate of class 1 is  0.675\n",
      "True positive rate of class 2 is  0.705\n",
      "Positive prediction rate of class 1 is  0.304\n",
      "Positive prediction rate of class 2 is  0.303\n",
      "X train 65694\n",
      "Y train 65694\n",
      "21898 18905 2993\n",
      "21898 18905 2993\n",
      "21898 18918 2980\n",
      "21898 18918 2980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25968103373351586\n",
      "0.26227214953462646\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19931\n",
      "           1       0.51      0.04      0.08      1967\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.71      0.52      0.52     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19850    81]\n",
      " [ 1883    84]]\n",
      "done in 0.980242s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25968103373351586\n",
      "0.2590921607891681\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19956\n",
      "           1       0.47      0.04      0.07      1942\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.69      0.52      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19876    80]\n",
      " [ 1872    70]]\n",
      "done in 0.975455s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25968103373351586\n",
      "0.2606055980332213\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17217\n",
      "           1       0.52      0.04      0.08      1688\n",
      "\n",
      "    accuracy                           0.91     18905\n",
      "   macro avg       0.72      0.52      0.52     18905\n",
      "weighted avg       0.88      0.91      0.88     18905\n",
      "\n",
      "Confusion_matrix\n",
      "[[17151    66]\n",
      " [ 1616    72]]\n",
      "done in 0.941423s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25968103373351586\n",
      "0.2602277946694193\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17231\n",
      "           1       0.45      0.03      0.06      1687\n",
      "\n",
      "    accuracy                           0.91     18918\n",
      "   macro avg       0.68      0.51      0.51     18918\n",
      "weighted avg       0.87      0.91      0.87     18918\n",
      "\n",
      "Confusion_matrix\n",
      "[[17165    66]\n",
      " [ 1633    54]]\n",
      "done in 0.956084s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25968103373351586\n",
      "0.27279876367898453\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95      2714\n",
      "           1       0.44      0.04      0.08       279\n",
      "\n",
      "    accuracy                           0.91      2993\n",
      "   macro avg       0.68      0.52      0.51      2993\n",
      "weighted avg       0.87      0.91      0.87      2993\n",
      "\n",
      "Confusion_matrix\n",
      "[[2699   15]\n",
      " [ 267   12]]\n",
      "done in 0.895694s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25968103373351586\n",
      "0.25188279107554623\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96      2725\n",
      "           1       0.53      0.06      0.11       255\n",
      "\n",
      "    accuracy                           0.92      2980\n",
      "   macro avg       0.73      0.53      0.53      2980\n",
      "weighted avg       0.89      0.92      0.88      2980\n",
      "\n",
      "Confusion_matrix\n",
      "[[2711   14]\n",
      " [ 239   16]]\n",
      "done in 0.978265s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19931\n",
      "           1       0.47      0.00      0.01      1967\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.69      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19923     8]\n",
      " [ 1960     7]]\n",
      "done in 19.471136s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19956\n",
      "           1       0.83      0.01      0.01      1942\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.87      0.50      0.48     21898\n",
      "weighted avg       0.90      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19954     2]\n",
      " [ 1932    10]]\n",
      "done in 20.126703s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17217\n",
      "           1       0.33      0.00      0.01      1688\n",
      "\n",
      "    accuracy                           0.91     18905\n",
      "   macro avg       0.62      0.50      0.48     18905\n",
      "weighted avg       0.86      0.91      0.87     18905\n",
      "\n",
      "Confusion_matrix\n",
      "[[17207    10]\n",
      " [ 1683     5]]\n",
      "done in 20.118950s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17231\n",
      "           1       0.60      0.00      0.00      1687\n",
      "\n",
      "    accuracy                           0.91     18918\n",
      "   macro avg       0.76      0.50      0.48     18918\n",
      "weighted avg       0.88      0.91      0.87     18918\n",
      "\n",
      "Confusion_matrix\n",
      "[[17229     2]\n",
      " [ 1684     3]]\n",
      "done in 20.175215s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2714\n",
      "           1       0.25      0.00      0.01       279\n",
      "\n",
      "    accuracy                           0.91      2993\n",
      "   macro avg       0.58      0.50      0.48      2993\n",
      "weighted avg       0.85      0.91      0.86      2993\n",
      "\n",
      "Confusion_matrix\n",
      "[[2711    3]\n",
      " [ 278    1]]\n",
      "done in 19.853203s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.96      2725\n",
      "           1       0.00      0.00      0.00       255\n",
      "\n",
      "    accuracy                           0.91      2980\n",
      "   macro avg       0.46      0.50      0.48      2980\n",
      "weighted avg       0.84      0.91      0.87      2980\n",
      "\n",
      "Confusion_matrix\n",
      "[[2724    1]\n",
      " [ 255    0]]\n",
      "done in 19.710203s\n",
      "0.2649943867570085\n",
      "0.2698423370473158\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19931\n",
      "           1       0.33      0.00      0.01      1967\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.62      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19921    10]\n",
      " [ 1962     5]]\n",
      "done in 0.627413s\n",
      "0.2649943867570085\n",
      "0.2675627714271921\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19956\n",
      "           1       0.35      0.00      0.01      1942\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.63      0.50      0.48     21898\n",
      "weighted avg       0.86      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19943    13]\n",
      " [ 1935     7]]\n",
      "done in 0.649402s\n",
      "0.2649943867570085\n",
      "0.26939186254002206\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17217\n",
      "           1       0.29      0.00      0.00      1688\n",
      "\n",
      "    accuracy                           0.91     18905\n",
      "   macro avg       0.60      0.50      0.48     18905\n",
      "weighted avg       0.85      0.91      0.87     18905\n",
      "\n",
      "Confusion_matrix\n",
      "[[17212     5]\n",
      " [ 1686     2]]\n",
      "done in 0.666419s\n",
      "0.2649943867570085\n",
      "0.26901786238039543\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17231\n",
      "           1       0.44      0.00      0.00      1687\n",
      "\n",
      "    accuracy                           0.91     18918\n",
      "   macro avg       0.68      0.50      0.48     18918\n",
      "weighted avg       0.87      0.91      0.87     18918\n",
      "\n",
      "Confusion_matrix\n",
      "[[17226     5]\n",
      " [ 1683     4]]\n",
      "done in 0.633066s\n",
      "0.2649943867570085\n",
      "0.2726877164527246\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2714\n",
      "           1       0.38      0.01      0.02       279\n",
      "\n",
      "    accuracy                           0.91      2993\n",
      "   macro avg       0.64      0.50      0.49      2993\n",
      "weighted avg       0.86      0.91      0.86      2993\n",
      "\n",
      "Confusion_matrix\n",
      "[[2709    5]\n",
      " [ 276    3]]\n",
      "done in 0.602310s\n",
      "0.2649943867570085\n",
      "0.2583253853021249\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.95      2725\n",
      "           1       0.27      0.01      0.02       255\n",
      "\n",
      "    accuracy                           0.91      2980\n",
      "   macro avg       0.59      0.50      0.49      2980\n",
      "weighted avg       0.86      0.91      0.87      2980\n",
      "\n",
      "Confusion_matrix\n",
      "[[2717    8]\n",
      " [ 252    3]]\n",
      "done in 0.602148s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19931\n",
      "           1       0.46      0.02      0.04      1967\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19881    50]\n",
      " [ 1925    42]]\n",
      "done in 32.919490s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19956\n",
      "           1       0.42      0.02      0.04      1942\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.50     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19900    56]\n",
      " [ 1901    41]]\n",
      "done in 33.107456s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17217\n",
      "           1       0.44      0.02      0.04      1688\n",
      "\n",
      "    accuracy                           0.91     18905\n",
      "   macro avg       0.68      0.51      0.49     18905\n",
      "weighted avg       0.87      0.91      0.87     18905\n",
      "\n",
      "Confusion_matrix\n",
      "[[17176    41]\n",
      " [ 1656    32]]\n",
      "done in 32.972117s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17231\n",
      "           1       0.41      0.02      0.04      1687\n",
      "\n",
      "    accuracy                           0.91     18918\n",
      "   macro avg       0.66      0.51      0.49     18918\n",
      "weighted avg       0.87      0.91      0.87     18918\n",
      "\n",
      "Confusion_matrix\n",
      "[[17184    47]\n",
      " [ 1655    32]]\n",
      "done in 33.097269s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2714\n",
      "           1       0.53      0.04      0.07       279\n",
      "\n",
      "    accuracy                           0.91      2993\n",
      "   macro avg       0.72      0.52      0.51      2993\n",
      "weighted avg       0.87      0.91      0.87      2993\n",
      "\n",
      "Confusion_matrix\n",
      "[[2705    9]\n",
      " [ 269   10]]\n",
      "done in 32.957981s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2725\n",
      "           1       0.50      0.04      0.07       255\n",
      "\n",
      "    accuracy                           0.91      2980\n",
      "   macro avg       0.71      0.52      0.51      2980\n",
      "weighted avg       0.88      0.91      0.88      2980\n",
      "\n",
      "Confusion_matrix\n",
      "[[2716    9]\n",
      " [ 246    9]]\n",
      "done in 32.916611s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.2, J-value:0.255\n",
      "threshold:0.30000000000000004, J-value:0.149\n",
      "threshold:0.4, J-value:0.07\n",
      "threshold:0.5, J-value:0.037000000000000005\n",
      "threshold:0.6000000000000001, J-value:0.009999999999999998\n",
      "threshold:0.7000000000000001, J-value:0.003\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6964505938982116\n",
      "Balanced accuracy score of test is  0.7007504821627146\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.391\n",
      "threshold:0.2, J-value:0.24900000000000003\n",
      "threshold:0.30000000000000004, J-value:0.152\n",
      "threshold:0.4, J-value:0.07100000000000001\n",
      "threshold:0.5, J-value:0.037000000000000005\n",
      "threshold:0.6000000000000001, J-value:0.009999999999999998\n",
      "threshold:0.7000000000000001, J-value:0.002\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.695777701114874\n",
      "Balanced accuracy score of test is  0.7004161727648129\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.403\n",
      "threshold:0.2, J-value:0.288\n",
      "threshold:0.30000000000000004, J-value:0.131\n",
      "threshold:0.4, J-value:0.06899999999999999\n",
      "threshold:0.5, J-value:0.033\n",
      "threshold:0.6000000000000001, J-value:0.012\n",
      "threshold:0.7000000000000001, J-value:0.006\n",
      "threshold:0.8, J-value:0.003\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7012900056259459\n",
      "Balanced accuracy score of test is  0.7024177010253643\n",
      "True positive rate of class 1 is  0.659\n",
      "True positive rate of class 2 is  0.635\n",
      "Positive prediction rate of class 1 is  0.293\n",
      "Positive prediction rate of class 2 is  0.265\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.387\n",
      "threshold:0.2, J-value:0.28300000000000003\n",
      "threshold:0.30000000000000004, J-value:0.11499999999999999\n",
      "threshold:0.4, J-value:0.024\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6931398326769296\n",
      "Balanced accuracy score of test is  0.7000729101448522\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.375\n",
      "threshold:0.2, J-value:0.276\n",
      "threshold:0.30000000000000004, J-value:0.12\n",
      "threshold:0.4, J-value:0.027\n",
      "threshold:0.5, J-value:0.005\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6872325400580876\n",
      "Balanced accuracy score of test is  0.6953204335233878\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41800000000000004\n",
      "threshold:0.2, J-value:0.352\n",
      "threshold:0.30000000000000004, J-value:0.123\n",
      "threshold:0.4, J-value:0.016999999999999998\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7092812259807767\n",
      "Balanced accuracy score of test is  0.7099442345745638\n",
      "True positive rate of class 1 is  0.734\n",
      "True positive rate of class 2 is  0.773\n",
      "Positive prediction rate of class 1 is  0.379\n",
      "Positive prediction rate of class 2 is  0.389\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.36099999999999993\n",
      "threshold:0.2, J-value:0.20099999999999996\n",
      "threshold:0.30000000000000004, J-value:0.093\n",
      "threshold:0.4, J-value:0.012\n",
      "threshold:0.5, J-value:0.002\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6805777976724325\n",
      "Balanced accuracy score of test is  0.683010862827159\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.3559999999999999\n",
      "threshold:0.2, J-value:0.20299999999999996\n",
      "threshold:0.30000000000000004, J-value:0.095\n",
      "threshold:0.4, J-value:0.012\n",
      "threshold:0.5, J-value:0.001\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6780735252300782\n",
      "Balanced accuracy score of test is  0.68148376241288\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.394\n",
      "threshold:0.2, J-value:0.184\n",
      "threshold:0.30000000000000004, J-value:0.07899999999999999\n",
      "threshold:0.4, J-value:0.018000000000000002\n",
      "threshold:0.5, J-value:0.012\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.696953008824547\n",
      "Balanced accuracy score of test is  0.6920489296636085\n",
      "True positive rate of class 1 is  0.699\n",
      "True positive rate of class 2 is  0.667\n",
      "Positive prediction rate of class 1 is  0.368\n",
      "Positive prediction rate of class 2 is  0.315\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.4\n",
      "threshold:0.2, J-value:0.266\n",
      "threshold:0.30000000000000004, J-value:0.14\n",
      "threshold:0.4, J-value:0.060000000000000005\n",
      "threshold:0.5, J-value:0.018000000000000002\n",
      "threshold:0.6000000000000001, J-value:0.003\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7001140462302111\n",
      "Balanced accuracy score of test is  0.705527598409601\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.395\n",
      "threshold:0.2, J-value:0.266\n",
      "threshold:0.30000000000000004, J-value:0.14200000000000002\n",
      "threshold:0.4, J-value:0.059000000000000004\n",
      "threshold:0.5, J-value:0.017\n",
      "threshold:0.6000000000000001, J-value:0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6974152351899519\n",
      "Balanced accuracy score of test is  0.7052201720634399\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.43400000000000005\n",
      "threshold:0.2, J-value:0.266\n",
      "threshold:0.30000000000000004, J-value:0.127\n",
      "threshold:0.4, J-value:0.068\n",
      "threshold:0.5, J-value:0.032999999999999995\n",
      "threshold:0.6000000000000001, J-value:0.009999999999999998\n",
      "threshold:0.7000000000000001, J-value:-0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7170677464256754\n",
      "Balanced accuracy score of test is  0.7071631588415183\n",
      "True positive rate of class 1 is  0.691\n",
      "True positive rate of class 2 is  0.675\n",
      "Positive prediction rate of class 1 is  0.317\n",
      "Positive prediction rate of class 2 is  0.296\n",
      "X train 65694\n",
      "Y train 65694\n",
      "21898 18847 3051\n",
      "21898 18847 3051\n",
      "21898 18817 3081\n",
      "21898 18817 3081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25995560917913285\n",
      "0.25506086388064353\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19973\n",
      "           1       0.51      0.04      0.07      1925\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.71      0.52      0.51     21898\n",
      "weighted avg       0.88      0.91      0.88     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19904    69]\n",
      " [ 1854    71]]\n",
      "done in 0.983985s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25995560917913285\n",
      "0.26490182741307455\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19866\n",
      "           1       0.44      0.03      0.06      2032\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.67      0.51      0.51     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19780    86]\n",
      " [ 1965    67]]\n",
      "done in 1.223051s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25995560917913285\n",
      "0.2549433177304888\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17189\n",
      "           1       0.49      0.03      0.07      1658\n",
      "\n",
      "    accuracy                           0.91     18847\n",
      "   macro avg       0.70      0.52      0.51     18847\n",
      "weighted avg       0.88      0.91      0.88     18847\n",
      "\n",
      "Confusion_matrix\n",
      "[[17129    60]\n",
      " [ 1600    58]]\n",
      "done in 0.920949s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25995560917913285\n",
      "0.2657918690937799\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17067\n",
      "           1       0.43      0.03      0.05      1750\n",
      "\n",
      "    accuracy                           0.91     18817\n",
      "   macro avg       0.67      0.51      0.50     18817\n",
      "weighted avg       0.86      0.91      0.87     18817\n",
      "\n",
      "Confusion_matrix\n",
      "[[17001    66]\n",
      " [ 1700    50]]\n",
      "done in 0.920628s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25995560917913285\n",
      "0.25578698393700716\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.95      2784\n",
      "           1       0.59      0.05      0.09       267\n",
      "\n",
      "    accuracy                           0.91      3051\n",
      "   macro avg       0.75      0.52      0.52      3051\n",
      "weighted avg       0.89      0.91      0.88      3051\n",
      "\n",
      "Confusion_matrix\n",
      "[[2775    9]\n",
      " [ 254   13]]\n",
      "done in 0.893973s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25995560917913285\n",
      "0.2594659577909285\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95      2799\n",
      "           1       0.46      0.06      0.11       282\n",
      "\n",
      "    accuracy                           0.91      3081\n",
      "   macro avg       0.69      0.53      0.53      3081\n",
      "weighted avg       0.87      0.91      0.87      3081\n",
      "\n",
      "Confusion_matrix\n",
      "[[2779   20]\n",
      " [ 265   17]]\n",
      "done in 0.857947s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19973\n",
      "           1       0.44      0.00      0.00      1925\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.68      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19968     5]\n",
      " [ 1921     4]]\n",
      "done in 19.451231s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19866\n",
      "           1       0.50      0.00      0.01      2032\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.70      0.50      0.48     21898\n",
      "weighted avg       0.87      0.91      0.86     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19859     7]\n",
      " [ 2025     7]]\n",
      "done in 19.565525s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17189\n",
      "           1       0.29      0.00      0.00      1658\n",
      "\n",
      "    accuracy                           0.91     18847\n",
      "   macro avg       0.60      0.50      0.48     18847\n",
      "weighted avg       0.86      0.91      0.87     18847\n",
      "\n",
      "Confusion_matrix\n",
      "[[17184     5]\n",
      " [ 1656     2]]\n",
      "done in 19.792349s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17067\n",
      "           1       0.64      0.01      0.01      1750\n",
      "\n",
      "    accuracy                           0.91     18817\n",
      "   macro avg       0.78      0.50      0.48     18817\n",
      "weighted avg       0.88      0.91      0.86     18817\n",
      "\n",
      "Confusion_matrix\n",
      "[[17062     5]\n",
      " [ 1741     9]]\n",
      "done in 19.723113s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2784\n",
      "           1       0.00      0.00      0.00       267\n",
      "\n",
      "    accuracy                           0.91      3051\n",
      "   macro avg       0.46      0.50      0.48      3051\n",
      "weighted avg       0.83      0.91      0.87      3051\n",
      "\n",
      "Confusion_matrix\n",
      "[[2783    1]\n",
      " [ 267    0]]\n",
      "done in 19.721634s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2799\n",
      "           1       0.00      0.00      0.00       282\n",
      "\n",
      "    accuracy                           0.91      3081\n",
      "   macro avg       0.45      0.50      0.48      3081\n",
      "weighted avg       0.83      0.91      0.86      3081\n",
      "\n",
      "Confusion_matrix\n",
      "[[2799    0]\n",
      " [ 282    0]]\n",
      "done in 19.338056s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26553645312445306\n",
      "0.2694114094281803\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19973\n",
      "           1       0.12      0.00      0.00      1925\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.51      0.50      0.48     21898\n",
      "weighted avg       0.84      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19958    15]\n",
      " [ 1923     2]]\n",
      "done in 0.623379s\n",
      "0.26553645312445306\n",
      "0.2781555748145189\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19866\n",
      "           1       0.11      0.00      0.00      2032\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.51      0.50      0.48     21898\n",
      "weighted avg       0.83      0.91      0.86     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19850    16]\n",
      " [ 2030     2]]\n",
      "done in 0.590243s\n",
      "0.26553645312445306\n",
      "0.2730109877358993\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17189\n",
      "           1       0.12      0.00      0.00      1658\n",
      "\n",
      "    accuracy                           0.91     18847\n",
      "   macro avg       0.51      0.50      0.48     18847\n",
      "weighted avg       0.84      0.91      0.87     18847\n",
      "\n",
      "Confusion_matrix\n",
      "[[17174    15]\n",
      " [ 1656     2]]\n",
      "done in 0.617181s\n",
      "0.26553645312445306\n",
      "0.28017006368715347\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17067\n",
      "           1       0.07      0.00      0.00      1750\n",
      "\n",
      "    accuracy                           0.91     18817\n",
      "   macro avg       0.49      0.50      0.48     18817\n",
      "weighted avg       0.83      0.91      0.86     18817\n",
      "\n",
      "Confusion_matrix\n",
      "[[17054    13]\n",
      " [ 1749     1]]\n",
      "done in 0.617307s\n",
      "0.26553645312445306\n",
      "0.28104969660245416\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2784\n",
      "           1       0.00      0.00      0.00       267\n",
      "\n",
      "    accuracy                           0.91      3051\n",
      "   macro avg       0.46      0.50      0.48      3051\n",
      "weighted avg       0.83      0.91      0.87      3051\n",
      "\n",
      "Confusion_matrix\n",
      "[[2781    3]\n",
      " [ 267    0]]\n",
      "done in 0.580173s\n",
      "0.26553645312445306\n",
      "0.265852219697231\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2799\n",
      "           1       0.25      0.00      0.01       282\n",
      "\n",
      "    accuracy                           0.91      3081\n",
      "   macro avg       0.58      0.50      0.48      3081\n",
      "weighted avg       0.85      0.91      0.87      3081\n",
      "\n",
      "Confusion_matrix\n",
      "[[2796    3]\n",
      " [ 281    1]]\n",
      "done in 0.586277s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19973\n",
      "           1       0.50      0.02      0.04      1925\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.71      0.51      0.49     21898\n",
      "weighted avg       0.88      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19938    35]\n",
      " [ 1890    35]]\n",
      "done in 32.920063s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     19866\n",
      "           1       0.49      0.02      0.04      2032\n",
      "\n",
      "    accuracy                           0.91     21898\n",
      "   macro avg       0.70      0.51      0.49     21898\n",
      "weighted avg       0.87      0.91      0.87     21898\n",
      "\n",
      "Confusion_matrix\n",
      "[[19825    41]\n",
      " [ 1992    40]]\n",
      "done in 33.478234s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17189\n",
      "           1       0.46      0.02      0.03      1658\n",
      "\n",
      "    accuracy                           0.91     18847\n",
      "   macro avg       0.69      0.51      0.49     18847\n",
      "weighted avg       0.87      0.91      0.87     18847\n",
      "\n",
      "Confusion_matrix\n",
      "[[17159    30]\n",
      " [ 1632    26]]\n",
      "done in 33.385855s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17067\n",
      "           1       0.50      0.02      0.04      1750\n",
      "\n",
      "    accuracy                           0.91     18817\n",
      "   macro avg       0.70      0.51      0.49     18817\n",
      "weighted avg       0.87      0.91      0.87     18817\n",
      "\n",
      "Confusion_matrix\n",
      "[[17032    35]\n",
      " [ 1715    35]]\n",
      "done in 33.353930s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.95      2784\n",
      "           1       0.64      0.03      0.06       267\n",
      "\n",
      "    accuracy                           0.91      3051\n",
      "   macro avg       0.78      0.52      0.51      3051\n",
      "weighted avg       0.89      0.91      0.88      3051\n",
      "\n",
      "Confusion_matrix\n",
      "[[2779    5]\n",
      " [ 258    9]]\n",
      "done in 33.271267s\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2799\n",
      "           1       0.45      0.02      0.03       282\n",
      "\n",
      "    accuracy                           0.91      3081\n",
      "   macro avg       0.68      0.51      0.49      3081\n",
      "weighted avg       0.87      0.91      0.87      3081\n",
      "\n",
      "Confusion_matrix\n",
      "[[2793    6]\n",
      " [ 277    5]]\n",
      "done in 33.071679s\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.40900000000000003\n",
      "threshold:0.2, J-value:0.26399999999999996\n",
      "threshold:0.30000000000000004, J-value:0.156\n",
      "threshold:0.4, J-value:0.08\n",
      "threshold:0.5, J-value:0.034999999999999996\n",
      "threshold:0.6000000000000001, J-value:0.012\n",
      "threshold:0.7000000000000001, J-value:0.003\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7044758475890505\n",
      "Balanced accuracy score of test is  0.7055447928284864\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.406\n",
      "threshold:0.2, J-value:0.26499999999999996\n",
      "threshold:0.30000000000000004, J-value:0.154\n",
      "threshold:0.4, J-value:0.078\n",
      "threshold:0.5, J-value:0.032999999999999995\n",
      "threshold:0.6000000000000001, J-value:0.013000000000000001\n",
      "threshold:0.7000000000000001, J-value:0.004\n",
      "threshold:0.8, J-value:0.001\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7028266808218373\n",
      "Balanced accuracy score of test is  0.7057262888280642\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.429\n",
      "threshold:0.2, J-value:0.26\n",
      "threshold:0.30000000000000004, J-value:0.175\n",
      "threshold:0.4, J-value:0.094\n",
      "threshold:0.5, J-value:0.048999999999999995\n",
      "threshold:0.6000000000000001, J-value:0.006\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7145708220328038\n",
      "Balanced accuracy score of test is  0.7042598800483455\n",
      "True positive rate of class 1 is  0.669\n",
      "True positive rate of class 2 is  0.645\n",
      "Positive prediction rate of class 1 is  0.296\n",
      "Positive prediction rate of class 2 is  0.274\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.388\n",
      "threshold:0.2, J-value:0.275\n",
      "threshold:0.30000000000000004, J-value:0.10200000000000001\n",
      "threshold:0.4, J-value:0.02\n",
      "threshold:0.5, J-value:0.003\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6941109068671277\n",
      "Balanced accuracy score of test is  0.7041020556230683\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.401\n",
      "threshold:0.2, J-value:0.277\n",
      "threshold:0.30000000000000004, J-value:0.101\n",
      "threshold:0.4, J-value:0.019\n",
      "threshold:0.5, J-value:0.004\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7005089622708045\n",
      "Balanced accuracy score of test is  0.700696967414141\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.39799999999999996\n",
      "threshold:0.2, J-value:0.276\n",
      "threshold:0.30000000000000004, J-value:0.11599999999999999\n",
      "threshold:0.4, J-value:0.027\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6989639835980885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy score of test is  0.715187034883279\n",
      "True positive rate of class 1 is  0.742\n",
      "True positive rate of class 2 is  0.78\n",
      "Positive prediction rate of class 1 is  0.378\n",
      "Positive prediction rate of class 2 is  0.389\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.33799999999999997\n",
      "threshold:0.2, J-value:0.193\n",
      "threshold:0.30000000000000004, J-value:0.067\n",
      "threshold:0.4, J-value:0.054\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6691380116403898\n",
      "Balanced accuracy score of test is  0.674852813060101\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.33599999999999997\n",
      "threshold:0.2, J-value:0.195\n",
      "threshold:0.30000000000000004, J-value:0.07\n",
      "threshold:0.4, J-value:0.059000000000000004\n",
      "threshold:0.5, J-value:0.0\n",
      "threshold:0.6000000000000001, J-value:0.0\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.668126202263756\n",
      "Balanced accuracy score of test is  0.6728513338188149\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.35200000000000004\n",
      "threshold:0.2, J-value:0.181\n",
      "threshold:0.30000000000000004, J-value:0.05199999999999999\n",
      "threshold:0.4, J-value:0.025\n",
      "threshold:0.5, J-value:-0.001\n",
      "threshold:0.6000000000000001, J-value:-0.001\n",
      "threshold:0.7000000000000001, J-value:0.0\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.6758362391837789\n",
      "Balanced accuracy score of test is  0.6852466306355613\n",
      "True positive rate of class 1 is  0.579\n",
      "True positive rate of class 2 is  0.571\n",
      "Positive prediction rate of class 1 is  0.266\n",
      "Positive prediction rate of class 2 is  0.234\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.41899999999999993\n",
      "threshold:0.2, J-value:0.26299999999999996\n",
      "threshold:0.30000000000000004, J-value:0.14300000000000002\n",
      "threshold:0.4, J-value:0.053\n",
      "threshold:0.5, J-value:0.016\n",
      "threshold:0.6000000000000001, J-value:0.005\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7093144186209825\n",
      "Balanced accuracy score of test is  0.7089494940907228\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.4169999999999999\n",
      "threshold:0.2, J-value:0.26499999999999996\n",
      "threshold:0.30000000000000004, J-value:0.14400000000000002\n",
      "threshold:0.4, J-value:0.049\n",
      "threshold:0.5, J-value:0.014\n",
      "threshold:0.6000000000000001, J-value:0.004\n",
      "threshold:0.7000000000000001, J-value:0.001\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7086122489338533\n",
      "Balanced accuracy score of test is  0.7089518954707916\n",
      "threshold:0.0, J-value:0.0\n",
      "threshold:0.1, J-value:0.42700000000000005\n",
      "threshold:0.2, J-value:0.255\n",
      "threshold:0.30000000000000004, J-value:0.137\n",
      "threshold:0.4, J-value:0.07100000000000001\n",
      "threshold:0.5, J-value:0.032\n",
      "threshold:0.6000000000000001, J-value:0.011\n",
      "threshold:0.7000000000000001, J-value:0.004\n",
      "threshold:0.8, J-value:0.0\n",
      "threshold:0.9, J-value:0.0\n",
      "Optimal threshold by J value is  0.1\n",
      "Balanced accuracy score of val is  0.7135679000387447\n",
      "Balanced accuracy score of test is  0.7091552454143957\n",
      "True positive rate of class 1 is  0.692\n",
      "True positive rate of class 2 is  0.674\n",
      "Positive prediction rate of class 1 is  0.313\n",
      "Positive prediction rate of class 2 is  0.294\n"
     ]
    }
   ],
   "source": [
    "records_lr = []\n",
    "records_rf = []\n",
    "records_dt = []\n",
    "records_gbt = []\n",
    "for random_state in range(10):\n",
    "    fairness_metrics (X, y, \"Race_W\", random_state)\n",
    "\n",
    "result_lr = pd.DataFrame(records_lr)\n",
    "result_rf = pd.DataFrame(records_rf)\n",
    "result_dt = pd.DataFrame(records_dt)\n",
    "result_gbt = pd.DataFrame(records_gbt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def add_mean_sd(records, result_table, overall_records, type):\n",
    "    records.append({\n",
    "        'auroc': result_table[\"auroc\"].mean(),\n",
    "        'overall threshold': result_table[\"overall threshold\"].mean(),\n",
    "        'white threshold': result_table[\"white threshold\"].mean(),\n",
    "        'black threshold': result_table[\"black threshold\"].mean(),\n",
    "        'overall ba validation': result_table[\"overall ba validation\"].mean(),\n",
    "        'overall ba test': result_table[\"overall ba test\"].mean(),\n",
    "        'white ba validation': result_table[\"white ba validation\"].mean(),\n",
    "        'white ba test': result_table[\"white ba test\"].mean(),\n",
    "        'black ba validation': result_table[\"black ba validation\"].mean(),\n",
    "        'black ba test': result_table[\"black ba test\"].mean(),\n",
    "        'overall precision':result_table[\"overall precision\"].mean(),\n",
    "        'overall recall':result_table[\"overall recall\"].mean(),\n",
    "        'overall tpr':result_table[\"overall tpr\"].mean(),\n",
    "        'overall tnr':result_table[\"overall tnr\"].mean(),\n",
    "        'overall pd':result_table[\"overall pd\"].mean(),\n",
    "        'white precision':result_table[\"white precision\"].mean(),\n",
    "        'white recall':result_table[\"white recall\"].mean(),\n",
    "        'white tpr':result_table[\"white tpr\"].mean(),\n",
    "        'white tnr':result_table[\"white tnr\"].mean(),\n",
    "        'white pd':result_table[\"white pd\"].mean(),\n",
    "        'black precision':result_table[\"black precision\"].mean(),\n",
    "        'black recall':result_table[\"black recall\"].mean(),\n",
    "        'black tpr':result_table[\"black tpr\"].mean(),\n",
    "        'black tnr':result_table[\"black tnr\"].mean(),\n",
    "        'black pd':result_table[\"black pd\"].mean(),\n",
    "        'eod': result_table[\"eod\"].mean(),\n",
    "        'di': result_table[\"di\"].mean(),\n",
    "        })\n",
    "    records.append({\n",
    "        'auroc': result_table[\"auroc\"].std(),\n",
    "        'overall threshold': result_table[\"overall threshold\"].std(),\n",
    "        'white threshold': result_table[\"white threshold\"].std(),\n",
    "        'black threshold': result_table[\"black threshold\"].std(),\n",
    "        'overall ba validation': result_table[\"overall ba validation\"].std(),\n",
    "        'overall ba test': result_table[\"overall ba test\"].std(),\n",
    "        'white ba validation': result_table[\"white ba validation\"].std(),\n",
    "        'white ba test': result_table[\"white ba test\"].std(),\n",
    "        'black ba validation': result_table[\"black ba validation\"].std(),\n",
    "        'black ba test': result_table[\"black ba test\"].std(),\n",
    "        'overall precision':result_table[\"overall precision\"].std(),\n",
    "        'overall recall':result_table[\"overall recall\"].std(),\n",
    "        'overall tpr':result_table[\"overall tpr\"].std(),\n",
    "        'overall tnr':result_table[\"overall tnr\"].std(),\n",
    "        'overall pd':result_table[\"overall pd\"].std(),\n",
    "        'white precision':result_table[\"white precision\"].std(),\n",
    "        'white recall':result_table[\"white recall\"].std(),\n",
    "        'white tpr':result_table[\"white tpr\"].std(),\n",
    "        'white tnr':result_table[\"white tnr\"].std(),\n",
    "        'white pd':result_table[\"white pd\"].std(),\n",
    "        'black precision':result_table[\"black precision\"].std(),\n",
    "        'black recall':result_table[\"black recall\"].std(),\n",
    "        'black tpr':result_table[\"black tpr\"].std(),\n",
    "        'black tnr':result_table[\"black tnr\"].std(),\n",
    "        'black pd':result_table[\"black pd\"].std(),\n",
    "        'eod': result_table[\"eod\"].std(),\n",
    "        'di': result_table[\"di\"].std(),\n",
    "        })\n",
    "    overall_records.append({\n",
    "        'type': type,\n",
    "        'auroc': result_table[\"auroc\"].mean(),\n",
    "        'overall threshold': result_table[\"overall threshold\"].mean(),\n",
    "        'white threshold': result_table[\"white threshold\"].mean(),\n",
    "        'black threshold': result_table[\"black threshold\"].mean(),\n",
    "        'overall ba test': result_table[\"overall ba test\"].mean(),\n",
    "        'white ba test': result_table[\"white ba test\"].mean(),\n",
    "        'black ba test': result_table[\"black ba test\"].mean(),\n",
    "        'overall tpr':result_table[\"overall tpr\"].mean(),\n",
    "        'overall pd':result_table[\"overall pd\"].mean(),\n",
    "        'white tpr':result_table[\"white tpr\"].mean(),\n",
    "        'white pd':result_table[\"white pd\"].mean(),\n",
    "        'black tpr':result_table[\"black tpr\"].mean(),\n",
    "        'black pd':result_table[\"black pd\"].mean(),\n",
    "        'eod': result_table[\"eod\"].mean(),\n",
    "        'di': result_table[\"di\"].mean(),\n",
    "        })\n",
    "    pd_result = pd.DataFrame(records)\n",
    "    return pd_result, overall_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "overall_table = []\n",
    "result_lr, overall_records = add_mean_sd (records_lr, result_lr, overall_table, 'lr')\n",
    "result_rf, overall_records = add_mean_sd (records_rf, result_rf, overall_records, 'rf')\n",
    "result_dt, overall_records = add_mean_sd (records_dt, result_dt, overall_records, 'dt')\n",
    "result_gbt, overall_records = add_mean_sd (records_gbt, result_gbt, overall_records, 'gbt')\n",
    "\n",
    "result_path='/Users/lifuchen/Desktop/research/resample_data/'\n",
    "result_lr.to_csv(path.join(result_path,'race-lr-result.csv'), index=False)\n",
    "result_rf.to_csv(path.join(result_path,'race-rf-result.csv'), index=False)\n",
    "result_dt.to_csv(path.join(result_path,'race-dt-result.csv'), index=False)\n",
    "result_gbt.to_csv(path.join(result_path,'race-gbt-result.csv'), index=False)\n",
    "\n",
    "overall_result = pd.DataFrame(overall_table)\n",
    "result_path='/Users/lifuchen/Desktop/research/resample_result/'\n",
    "overall_result.to_csv(path.join(result_path,'race.csv'), index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
